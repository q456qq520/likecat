<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://q456qq520.github.io</id>
    <title>LIKECAT</title>
    <updated>2023-05-12T05:49:50.013Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://q456qq520.github.io"/>
    <link rel="self" href="https://q456qq520.github.io/atom.xml"/>
    <subtitle>一条小咸鱼</subtitle>
    <logo>https://q456qq520.github.io/images/avatar.png</logo>
    <icon>https://q456qq520.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, LIKECAT</rights>
    <entry>
        <title type="html"><![CDATA[《Neo4j权威指南》一]]></title>
        <id>https://q456qq520.github.io/post/lesslessneo4j-quan-wei-zhi-nan-greatergreater-yi/</id>
        <link href="https://q456qq520.github.io/post/lesslessneo4j-quan-wei-zhi-nan-greatergreater-yi/">
        </link>
        <updated>2023-05-11T01:35:33.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="一-图数据库基础">一 图数据库基础</h2>
<h3 id="11-图数据模型">1.1 图数据模型</h3>
]]></summary>
        <content type="html"><![CDATA[<h2 id="一-图数据库基础">一 图数据库基础</h2>
<h3 id="11-图数据模型">1.1 图数据模型</h3>
<!-- more -->
<p>图数据要具体存储到图数据库中，最终落实为具体的数据文件，自然就涉及特定的图数据模型，即如何存，采用什么实现方式来存。常用的有三种：==属性图、超图和三元图。</p>
<p>其中Neo4j就采用属性图模型，因为属性图直观更易于理解，能描述大部分图使用场景。符合下列特征的图数据模型就称为属性图。</p>
<ul>
<li>它包含节点和关系</li>
<li>节点可以有属性（键值对）</li>
<li>节点可以有一个或多个标签</li>
<li>关系有名字和方向，并总是有一个开始节点和一个结束节点。</li>
<li>关系也可以有属性</li>
</ul>
<p>超图是一种更为广义对图模型，在超图中，一个关系（称作超边）可以关联任意数量的节点，无论是开始节点端还是结束节点端，而属性图中一个关系只允许一个开始节点和一个结束节点。因此，超图更适用表示多对多关系。</p>
<h3 id="12-图计算引擎">1.2 图计算引擎</h3>
<p>图数据库的核心也是构建在一个一起闹智商的，那就是图计算引擎，是能够组织存储大型图数据集并且实现了全局图计算算法的一种数据库核心构建。</p>
<p>它包含一个具有联机事务处理过程的数据库记录系统，图计算引擎用于响应用户终端允许时发来的查询请求，周期性从记录系统中进行数据抽取、转换和家在，然后将数据从记录数据系统读入到图计算引擎并进行离线查询和分析，最好将查询、分析的结果返回给用户终端。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1683787705759.png" alt="" loading="lazy"></figure>
<p>目前较为流程的图计算引擎有两种：单机图计算引擎和分布式图计算引擎。</p>
<h3 id="13-neo4j概述">1.3 Neo4j概述</h3>
<p>Neo4j是由Java实现的开源的NoSQL图数据库。</p>
<h3 id="14-neo4j底层存储结构">1.4 Neo4j底层存储结构</h3>
<p>免索引邻接是图数据库实现高效遍历的关键，那么免索引邻接的实现机制就是Neo4j底层存储结构设计的关键。能够支持高效的，本地化的图存储以及任意图算法的快速遍历，是使用图数据库的重要原因。</p>
<p>从宏观角度来说，Neo4j中仅仅只有两种数据类型：</p>
<ol>
<li>节点（Node）：节点类似E-R图中的实体，每一个实体可以有0个或多个属性，这些属性以key-value对的形式存在，属性没有特殊的类别要求，同时每个节点还具有相应的标签（Label），用来区分不同类型的节点。</li>
<li>关系（Relationship）：关系也类似与E-R图中的关系。一个挂你想有起始节点和终止节点。关系也有自己的属性和标签。</li>
</ol>
<p><img src="https://q456qq520.github.io/post-images/1683792894779.png" alt="" loading="lazy"><br>
节点和关系分别采用固定长度存储，节点存储文件用来存储节点的记录，文件名叫<code>neostore.nodestore.db</code>。节点记录的长度为固定大小，每个节点记录的长度为9字节。格式为：<code>Node:inUse+nextRelId+nextPropId</code>。</p>
<ul>
<li>inUse：1表示该节点被正常使用，0表示该节点被删除。</li>
<li>nextRelId：该节点的下一个关系ID</li>
<li>nextPropId：该节点的下一个属性ID</li>
</ul>
<p>如果有一个ID为100的节点，就能直接计算出该记录在存储文件中的第900个字节。成本仅为O(1)。</p>
<p>关系存储文件用来存储关系的记录，文件名为<code>neostore.relationshipstore.db</code>。像节点的存储一样，关系存储区的记录大小也是固定的，格式为<code>Relationshipstore:inUse+firstNode+secondNode+relType+firstPrevRelId+firstNextRelId+secondPrevRelId+secondNextRelId+nextPropId</code>。</p>
<ul>
<li>inUse，nextPropId：作用同上</li>
<li>firstNode：当前关系的起始节点</li>
<li>secondNode：当前关系的终止节点</li>
<li>relType：关系的类型</li>
<li>firstPrevRelId &amp; firstNextRelId：起始节点的前一个和后一个关系的ID</li>
<li>secondPrevRelId &amp; secondNextRelId+nextPropId：终止节点的前一个和后一个关系的ID</li>
</ul>
<p>Neo4j中有一个<code>.id</code>文件用来保持对未使用记录对跟踪，用来回收未使用的空间。节点和关系的存储文件只关系图的基本存储结构而不是属性数据。这两种记录都使用固定大小的记录，以便存储文件内的任何记录都可以根据ID快速的计算出来。</p>
<p>下图是Neo4j中其他常见的基本存储类型，属性记录的物理存储放置在<code>neostore.propertystore.db</code>文件中。与节点和关系的存储记录一样，属性的存储记录也是固定长度。每个属性记录包含4个属性块和属性链中下一个属性的ID。属性链是单向链表，而关系链是双向链表。一个属性记录中可以包含任何JVM支持的基本数据类型、字符串、基于类型的数组以及属性索引文件（<code>neostore.propertystore.db.index</code>）。属性索引文件主要用于存储属性的名称，属性索引的值部分存储的是指向动态内存的记录或者内联值，短字符串和短数组会直接内联在属性存储记录中。当长度超过属性记录中的propBlock长度限制之后，会单独存储在其他的动态存储文件中。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1683795844065.png" alt="" loading="lazy"></figure>
<p>Neo4j中两种动态存储：动态字符串存储（<code>neostore.propertystore.db.strings</code>）和动态数组存储（<code>neostore.propertystore.db.arrays</code>）。动态存储记录是可以扩展的，如果一个属性长到一条动态存储记录仍然无法完全容纳时，可以申请多个动态存储记录逻辑上进行连接。</p>
<h3 id="15-neo4j的遍历方式">1.5 Neo4j的遍历方式</h3>
<p>每个节点记录都包含一个指向该节点的第一个属性的指针和联系链中第一个联系的指针。要读取一个节点的属性，从指向第一个属性的指针开始，遍历整个单向链表的结构。要找到一个节点的关系，从指向的第一个关系开始，遍历整个双向链表，知道找到。一单找到我们就可以与使用和超找节点属性一样的方法查找关系的属性。我们也可以很方便的获取起始节点和结束节点的ID，利用节点ID就可以立即得到每个节点在节点存储文件中的具体位置，时间复杂度为O(1)。</p>
<p>下面通过一个例子来讲解遍历关系和节点的详细过程，假如在Neo4j中纯粹来ABCDE5个节点和R1、R2、R3、R4、R5、R6、R7 7个关系，它们之间的关系如下图所示。<br>
<img src="https://q456qq520.github.io/post-images/1683859055787.png" alt="" loading="lazy"><br>
假如要遍历图中节点B的所有关系，只需要向<code>NODEB-NEXT</code>方向遍历，直到指向NULL为止。如下图所示，可以看出即节点B的所有关系为R1、R3、R4、R5。<br>
<img src="https://q456qq520.github.io/post-images/1683859485562.png" alt="" loading="lazy"></p>
<p>通过固定大小的存储记录和指针ID，只要跟随指针就可以简单的实现遍历并且告诉指向。要遍历一个节点到另一个节点的特定关系，在Neo4j中只需要遍历几个指针。</p>
<ul>
<li>从一个给定节点定位关系链中第一个关系的位置，可以通过计算它在关系存储的偏移量来获得。跟获得节点存储位置的方法一样，使用关系ID乘以关系记录的固定大小即可找到关系在存储文件中的正确位置。</li>
<li>在关系记录中，搜索第二个字段可以找到第二个节点的ID，用节点记录大小乘以节点ID可以得到节点在存储中的正确位置。</li>
</ul>
<h3 id="16-neo4j的存储优化">1.6 Neo4j的存储优化</h3>
<p>Neo4j支持存储优化（压缩和内联存储属性值），对于某些段字符的属性可以直接存储在属性文件中，而不是单独的放到另一个动态存储区，这样可以减少I/O操作并增加吞吐量。</p>
<p>Neo4j还可以对属性名称的空间严格维护。属性名称都通过属性索引文件从属性存储中间接引用。属性索引允许所有具有想用名称的属性共享单个记录，因而可以节省相当大的空间和I/O开销。</p>
<p>Neo4j采用缓存策略，保证那些经常访问的数据可以快速地被多次重复访问。Neo4j高速缓存的页面置换算法是基于最不经常使用的页置换（LFU）缓存策略，即使有些页面近期没有使用过，但是因为以前的使用频率很高，那么在短期之内它页不会被淘汰。</p>
<h2 id="二-neo4j-基础入门">二 Neo4j 基础入门</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[基于代价的慢查询优化建议]]></title>
        <id>https://q456qq520.github.io/post/ji-yu-dai-jie-de-man-cha-xun-you-hua-jian-yi/</id>
        <link href="https://q456qq520.github.io/post/ji-yu-dai-jie-de-man-cha-xun-you-hua-jian-yi/">
        </link>
        <updated>2023-04-21T07:13:41.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="1-背景">1 背景</h2>
<p>慢查询是指数据库中查询时间超过指定阈值的SQL，它是数据库的性能杀手，也是业务优化数据库访问的重要抓手。随着美团业务的高速增长，日均慢查询量已经过亿条，此前因慢查询导致的故障约占数据库故障总数的10%以上，而且高级别的故障呈日益增长趋势。因此，对慢查询的优化已经变得刻不容缓。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="1-背景">1 背景</h2>
<p>慢查询是指数据库中查询时间超过指定阈值的SQL，它是数据库的性能杀手，也是业务优化数据库访问的重要抓手。随着美团业务的高速增长，日均慢查询量已经过亿条，此前因慢查询导致的故障约占数据库故障总数的10%以上，而且高级别的故障呈日益增长趋势。因此，对慢查询的优化已经变得刻不容缓。</p>
<!-- more -->
<p>那么如何优化慢查询呢？最直接有效的方法就是选用一个查询效率高的索引。关于高效率的索引推荐，主要在日常工作中，基于经验规则的推荐随处可见，对于简单的SQL，如<mark>select * from sync_test1 where name like 'Bobby%'</mark>，直接添加索引IX(name) 就可以取得不错的效果；但对于稍微复杂点的SQL，如<mark>select * from sync_test1 where name like 'Bobby%' and dt &gt; '2021-07-06'</mark>，到底选择IX(name)、IX(dt)、IX(dt,name) 还是IX(name,dt)，该方法也无法给出准确的回答。更别说像多表Join、子查询这样复杂的场景了。所以采用基于代价的推荐来解决该问题会更加普适，因为基于代价的方法使用了和数据库优化器相同的方式，去量化评估所有的可能性，选出的是执行SQL耗费代价最小的索引。</p>
<h2 id="2-基于代价的优化器介绍">2 基于代价的优化器介绍</h2>
<h3 id="21-sql执行与优化器">2.1 SQL执行与优化器</h3>
<p>一条SQL在MySQL服务器中执行流程主要包含：SQL解析、基于语法树的准备工作、优化器的逻辑变化、优化器的代价准备工作、基于代价模型的优化、进行额外的优化和运行执行计划等部分。具体如下图所示：</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1682064829235.jpeg" alt="" loading="lazy"></figure>
<h3 id="22-代价模型介绍">2.2 代价模型介绍</h3>
<p>而对于优化器来说，执行一条SQL有各种各样的方案可供选择，如表是否用索引、选择哪个索引、是否使用范围扫描、多表Join的连接顺序和子查询的执行方式等。如何从这些可选方案中选出耗时最短的方案呢？这就需要定义一个量化数值指标，这个指标就是代价(Cost)，我们分别计算出可选方案的操作耗时，从中选出最小值。</p>
<p>代价模型将操作分为Server层和Engine（存储引擎）层两类，<mark>Server层主要是CPU代价，Engine层主要是IO代价</mark>，比如MySQL从磁盘读取一个数据页的代价io_block_read_cost为1，计算符合条件的行代价为row_evaluate_cost为0.2。除此之外还有：</p>
<ol>
<li>memory_temptable_create_cost (default 2.0) 内存临时表的创建代价。</li>
<li>memory_temptable_row_cost (default 0.2) 内存临时表的行代价。</li>
<li>key_compare_cost (default 0.1) 键比较的代价，例如排序。</li>
<li>disk_temptable_create_cost (default 40.0) 内部myisam或innodb临时表的创建代价。</li>
<li>disk_temptable_row_cost (default 1.0) 内部myisam或innodb临时表的行代价。</li>
</ol>
<p>在MySQL 5.7中，这些操作代价的默认值都可以进行配置。为了计算出方案的总代价，还需要参考一些统计数据，如表数据量大小、元数据和索引信息等。MySQL的代价优化器模型整体如下图所示：</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1682065265190.jpeg" alt="" loading="lazy"></figure>
<h3 id="23-基于代价的索引选择">2.3 基于代价的索引选择</h3>
<p>还是继续拿上述的SQL select * from sync_test1 where name like 'Bobby%' and dt &gt; '2021-07-06'为例，我们看看MySQL优化器是如何根据代价模型选择索引的。首先，我们直接在建表时加入四个候选索引。</p>
<pre><code class="language-mysql">Create Table: CREATE TABLE `sync_test1` (
    `id` int(11) NOT NULL AUTO_INCREMENT,
    `cid` int(11) NOT NULL,
    `phone` int(11) NOT NULL,
    `name` varchar(10) NOT NULL,
    `address` varchar(255) DEFAULT NULL,
    `dt` datetime DEFAULT NULL,
    PRIMARY KEY (`id`),
    KEY `IX_name` (`name`),
    KEY `IX_dt` (`dt`),
    KEY `IX_dt_name` (`dt`,`name`),
    KEY `IX_name_dt` (`name`,`dt`)
    ) ENGINE=InnoDB
</code></pre>
<p>通过执行explain看出MySQL最终选择了IX_name索引。</p>
<pre><code class="language-mysql">mysql&gt; explain  select * from sync_test1 where name like 'Bobby%' and dt &gt; '2021-07-06';
+----+-------------+------------+------------+-------+-------------------------------------+---------+---------+------+------+----------+------------------------------------+
| id | select_type | table      | partitions | type  | possible_keys                       | key     | key_len | ref  | rows | filtered | Extra                              |
+----+-------------+------------+------------+-------+-------------------------------------+---------+---------+------+------+----------+------------------------------------+
|  1 | SIMPLE      | sync_test1 | NULL       | range | IX_name,IX_dt,IX_dt_name,IX_name_dt | IX_name | 12      | NULL |  572 |    36.83 | Using index condition; Using where |
+----+-------------+------------+------------+-------+-------------------------------------+---------+---------+------+------+----------+------------------------------------+
</code></pre>
<p>然后再打开MySQL追踪优化器Trace功能。可以看出，没有选择其他三个索引的原因均是因为在其他三个索引上使用range scan的代价均&gt;= IX_name。</p>
<pre><code class="language-mysql">mysql&gt; select * from INFORMATION_SCHEMA.OPTIMIZER_TRACE\G;
*************************** 1. row ***************************

TRACE: {
...
&quot;rows_estimation&quot;: [
{
&quot;table&quot;: &quot;`sync_test1`&quot;,
&quot;range_analysis&quot;: {
&quot;table_scan&quot;: {
  &quot;rows&quot;: 105084,
  &quot;cost&quot;: 21628
},
...
&quot;analyzing_range_alternatives&quot;: {
  &quot;range_scan_alternatives&quot;: [
    {
      &quot;index&quot;: &quot;IX_name&quot;,
      &quot;ranges&quot;: [
        &quot;Bobby\u0000\u0000\u0000\u0000\u0000 &lt;= name &lt;= Bobbyÿÿÿÿÿ&quot;
      ],
      &quot;index_dives_for_eq_ranges&quot;: true,
      &quot;rowid_ordered&quot;: false,
      &quot;using_mrr&quot;: false,
      &quot;index_only&quot;: false,
      &quot;rows&quot;: 572,
      &quot;cost&quot;: 687.41,
      &quot;chosen&quot;: true
    },
    {
      &quot;index&quot;: &quot;IX_dt&quot;,
      &quot;ranges&quot;: [
        &quot;0x99aa0c0000 &lt; dt&quot;
      ],
      &quot;index_dives_for_eq_ranges&quot;: true,
      &quot;rowid_ordered&quot;: false,
      &quot;using_mrr&quot;: false,
      &quot;index_only&quot;: false,
      &quot;rows&quot;: 38698,
      &quot;cost&quot;: 46439,
      &quot;chosen&quot;: false,
      &quot;cause&quot;: &quot;cost&quot;
    },
    {
      &quot;index&quot;: &quot;IX_dt_name&quot;,
      &quot;ranges&quot;: [
        &quot;0x99aa0c0000 &lt; dt&quot;
      ],
      &quot;index_dives_for_eq_ranges&quot;: true,
      &quot;rowid_ordered&quot;: false,
      &quot;using_mrr&quot;: false,
      &quot;index_only&quot;: false,
      &quot;rows&quot;: 38292,
      &quot;cost&quot;: 45951,
      &quot;chosen&quot;: false,
      &quot;cause&quot;: &quot;cost&quot;
    },
    {
      &quot;index&quot;: &quot;IX_name_dt&quot;,
      &quot;ranges&quot;: [
        &quot;Bobby\u0000\u0000\u0000\u0000\u0000 &lt;= name &lt;= Bobbyÿÿÿÿÿ&quot;
      ],
      &quot;index_dives_for_eq_ranges&quot;: true,
      &quot;rowid_ordered&quot;: false,
      &quot;using_mrr&quot;: false,
      &quot;index_only&quot;: false,
      &quot;rows&quot;: 572,
      &quot;cost&quot;: 687.41,
      &quot;chosen&quot;: false,
      &quot;cause&quot;: &quot;cost&quot;
    }
  ],
  &quot;analyzing_roworder_intersect&quot;: {
    &quot;usable&quot;: false,
    &quot;cause&quot;: &quot;too_few_roworder_scans&quot;
  }
},
&quot;chosen_range_access_summary&quot;: {
  &quot;range_access_plan&quot;: {
    &quot;type&quot;: &quot;range_scan&quot;,
    &quot;index&quot;: &quot;IX_name&quot;,
    &quot;rows&quot;: 572,
    &quot;ranges&quot;: [
      &quot;Bobby\u0000\u0000\u0000\u0000\u0000 &lt;= name &lt;= Bobbyÿÿÿÿÿ&quot;
    ]
  },
  &quot;rows_for_plan&quot;: 572,
  &quot;cost_for_plan&quot;: 687.41,
  &quot;chosen&quot;: true
}
...
}
</code></pre>
<p>下面我们根据代价模型来推演一下代价的计算过程：</p>
<ol>
<li>走全表扫描的代价：io_cost + cpu_cost = （数据页个数 * io_block_read_cost）+ (数据行数 * row_evaluate_cost + 1.1) = （data_length / block_size + 1）+ (rows * 0.2 + 1.1) = (9977856 / 16384 + 1) + (105084 * 0.2 + 1.1) = 21627.9。</li>
<li>走二级索引IX_name的代价：io_cost + cpu_cost = (预估范围行数 * io_block_read_cost + 1) + (数据行数 * row_evaluate_cost + 0.01) = (572 * 1 + 1) + (572*0.2 + 0.01) = 687.41。</li>
<li>走二级索引IX_dt的代价：io_cost + cpu_cost = (预估范围行数 * io_block_read_cost + 1) + (数据行数 * row_evaluate_cost + 0.01) = (38698 * 1 + 1) + (38698*0.2 + 0.01) = 46438.61。</li>
<li>走二级索引IX_dt_name的代价: io_cost + cpu_cost = (预估范围行数 * io_block_read_cost + 1) + (数据行数 * row_evaluate_cost + 0.01) = (38292 * 1 + 1) + (38292 * 0.2 + 0.01) = 45951.41。</li>
<li>走二级索引IX_name_dt的代价：io_cost + cpu_cost = (预估范围行数 * io_block_read_cost + 1) + (数据行数 * row_evaluate_cost + 0.01) = (572 * 1 + 1) + (572*0.2 + 0.01) = 687.41。</li>
</ol>
<p>补充说明</p>
<ol>
<li>计算结果在小数上有偏差，因为MySQL使用%g打印浮点数，小数会以最短的方式输出。</li>
<li>除“+1.1 +1”这种调节值外，Cost计算还会出现+0.01, 它是为了避免index scan和range scan出现Cost的竞争。</li>
<li>Cost计算是基于MySQL的默认参数配置，如果Cost Model参数改变，optimizer_switch的选项不同，数据分布不同都会导致最终Cost的计算结果不同。</li>
<li>data_length可查询information_schema.tables，block_size默认16K。</li>
</ol>
<h3 id="24-基于代价的索引推荐思路">2.4 基于代价的索引推荐思路</h3>
<p>如果想借助MySQL优化器给慢查询计算出最佳索引，那么需要真实地在业务表上添加所有候选索引。对于线上业务来说，直接添加索引的时间空间成本太高，是不可接受的。MySQL优化器选最佳索引用到的数据是索引元数据和统计数据，所以我们想是否可以通过给它提供候选索引的这些数据，而非真实添加索引的这种方式来实现。</p>
<p>通过深入调研MySQL的代码结构和优化器流程，我们发现是可行的：一部分存在于Server层的frm文件中，比如索引定义；另一部分存在于Engine层中，或者通过调用Engine层的接口函数来获取，比如索引中某个列的不同值个数、索引占据的页面大小等。索引相关的信息，如下图所示：</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1682067083614.jpeg" alt="" loading="lazy"></figure>
<p>因为MySQL本身就支持自定义存储引擎，所以索引推荐思路是构建一个支持虚假索引的存储引擎，在它上面建立包含候选索引的空表，再采集样本数据，计算出统计数据提供给优化器，让优化器选出最优索引，整个调用关系如下图所示：</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1682067095473.jpeg" alt="" loading="lazy"></figure>
<h2 id="3-索引推荐实现">3 索引推荐实现</h2>
<p>因为存储引擎本身并不具备对外提供服务的能力，直接在MySQL Server层修改也难以维护，所以我们将整个索引推荐系统拆分成支持虚假索引的Fakeindex存储引擎和对外提供服务的Go-Server两部分，整体架构图如下：</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1682067368398.jpeg" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java魔法类：Unsafe应用解析]]></title>
        <id>https://q456qq520.github.io/post/java-mo-fa-lei-unsafe-ying-yong-jie-xi/</id>
        <link href="https://q456qq520.github.io/post/java-mo-fa-lei-unsafe-ying-yong-jie-xi/">
        </link>
        <updated>2023-04-21T06:24:33.000Z</updated>
        <summary type="html"><![CDATA[<p>Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如<code>直接访问系统内存资源</code>、<code>自主管理内存资源</code>等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。</p>
]]></summary>
        <content type="html"><![CDATA[<p>Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如<code>直接访问系统内存资源</code>、<code>自主管理内存资源</code>等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。</p>
<!-- more -->
<p>如下Unsafe源码所示，Unsafe类为一单例实现，提供静态方法getUnsafe获取Unsafe实例，当且仅当调用getUnsafe方法的类为引导类加载器所加载时才合法，否则抛出SecurityException异常。</p>
<pre><code class="language-java">public final class Unsafe {
  // 单例对象
  private static final Unsafe theUnsafe;

  private Unsafe() {
  }
  @CallerSensitive
  public static Unsafe getUnsafe() {
    Class var0 = Reflection.getCallerClass();
    // 仅在引导类加载器`BootstrapClassLoader`加载时才合法
    if(!VM.isSystemDomainLoader(var0.getClassLoader())) {    
      throw new SecurityException(&quot;Unsafe&quot;);
    } else {
      return theUnsafe;
    }
  }
}
</code></pre>
<p>那如若想使用这个类，该如何获取其实例？有如下两个可行方案。</p>
<p>其一，从getUnsafe方法的使用限制条件出发，通过Java命令行命令-Xbootclasspath/a把调用Unsafe相关方法的类A所在jar包路径追加到默认的bootstrap路径中，使得A被引导类加载器加载，从而通过Unsafe.getUnsafe方法安全的获取Unsafe实例。</p>
<blockquote>
<p>java -Xbootclasspath/a: ${path}   // 其中path为调用Unsafe相关方法的类所在jar包路径</p>
</blockquote>
<p>其二，通过反射获取单例对象theUnsafe。</p>
<pre><code class="language-java">private static Unsafe reflectGetUnsafe() {
    try {
      Field field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);
      field.setAccessible(true);
      return (Unsafe) field.get(null);
    } catch (Exception e) {
      log.error(e.getMessage(), e);
      return null;
    }
}
</code></pre>
<h2 id="功能介绍">功能介绍</h2>
<p><img src="https://q456qq520.github.io/post-images/1682058668352.png" alt="" loading="lazy"><br>
如上图所示，Unsafe提供的API大致可分为内存操作、CAS、Class相关、对象操作、线程调度、系统信息获取、内存屏障、数组操作等几类。</p>
<h2 id="内存操作">内存操作</h2>
<p>这部分主要包含堆外内存的分配、拷贝、释放、给定地址值操作等方法。</p>
<pre><code class="language-java">//分配内存, 相当于C++的malloc函数
public native long allocateMemory(long bytes);
//扩充内存
public native long reallocateMemory(long address, long bytes);
//释放内存
public native void freeMemory(long address);
//在给定的内存块中设置值
public native void setMemory(Object o, long offset, long bytes, byte value);
//内存拷贝
public native void copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes);
//获取给定地址值，忽略修饰限定符的访问限制。与此类似操作还有: getInt，getDouble，getLong，getChar等
public native Object getObject(Object o, long offset);
//为给定地址设置值，忽略修饰限定符的访问限制，与此类似操作还有: putInt,putDouble，putLong，putChar等
public native void putObject(Object o, long offset, Object x);
//获取给定地址的byte类型的值（当且仅当该内存地址为allocateMemory分配时，此方法结果为确定的）
public native byte getByte(long address);
//为给定地址设置byte类型的值（当且仅当该内存地址为allocateMemory分配时，此方法结果才是确定的）
public native void putByte(long address, byte x);
</code></pre>
<p>通常，我们在Java中创建的对象都处于堆内内存（heap）中，堆内内存是由JVM所管控的Java进程内存，并且它们遵循JVM的内存管理机制，JVM会采用垃圾回收机制统一管理堆内存。与之相对的是堆外内存，存在于JVM管控之外的内存区域，Java中对堆外内存的操作，依赖于Unsafe提供的操作堆外内存的native方法。</p>
<h3 id="使用堆外内存的原因">使用堆外内存的原因</h3>
<ul>
<li>对垃圾回收停顿的改善。由于堆外内存是直接受操作系统管理而不是JVM，所以当我们使用堆外内存时，即可保持较小的堆内内存规模。从而在GC时减少回收停顿对于应用的影响。</li>
<li>提升程序I/O操作的性能。通常在I/O通信过程中，会存在堆内内存到堆外内存的数据拷贝操作，对于需要频繁进行内存间数据拷贝且生命周期较短的暂存数据，都建议存储到堆外内存。</li>
</ul>
<h3 id="典型应用">典型应用</h3>
<p><code>DirectByteBuffer</code>是Java用于实现堆外内存的一个重要类，通常用在通信过程中做缓冲池，如在Netty、MINA等NIO框架中应用广泛。DirectByteBuffer对于堆外内存的创建、使用、销毁等逻辑均由Unsafe提供的堆外内存API来实现。</p>
<p>下图为DirectByteBuffer构造函数，创建DirectByteBuffer的时候，通过Unsafe.allocateMemory分配内存、Unsafe.setMemory进行内存初始化，而后构建Cleaner对象用于跟踪DirectByteBuffer对象的垃圾回收，以实现当DirectByteBuffer被垃圾回收时，分配的堆外内存一起被释放。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1682059248322.png" alt="" loading="lazy"></figure>
<p>那么如何通过构建垃圾回收追踪对象Cleaner实现堆外内存释放呢？</p>
<p>Cleaner继承自Java四大引用类型之一的虚引用<code>PhantomReference</code>（众所周知，无法通过虚引用获取与之关联的对象实例，且当对象仅被虚引用引用时，在任何发生GC的时候，其均可被回收），通常PhantomReference与引用队列ReferenceQueue结合使用，可以实现虚引用关联对象被垃圾回收时能够进行系统通知、资源清理等功能。如下图所示，当某个被Cleaner引用的对象将被回收时，JVM垃圾收集器会将此对象的引用放入到对象引用中的pending链表中，等待Reference-Handler进行相关处理。其中，Reference-Handler为一个拥有最高优先级的守护线程，会循环不断的处理pending链表中的对象引用，执行Cleaner的clean方法进行相关清理工作。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1682059416664.png" alt="" loading="lazy"></figure>
<p>所以当DirectByteBuffer仅被Cleaner引用（即为虚引用）时，其可以在任意GC时段被回收。当DirectByteBuffer实例对象被回收时，在Reference-Handler线程操作中，会调用Cleaner的clean方法根据创建Cleaner时传入的Deallocator来进行堆外内存的释放。</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1682059508405.png" alt="" loading="lazy"></figure>
<h2 id="cas相关">CAS相关</h2>
<p>如下源代码释义所示，这部分主要为CAS相关操作的方法。</p>
<pre><code class="language-java">/**
	*  CAS
  * @param o         包含要修改field的对象
  * @param offset    对象中某field的偏移量
  * @param expected  期望值
  * @param update    更新值
  * @return          true | false
  */
public final native boolean compareAndSwapObject(Object o, long offset,  Object expected, Object update);

public final native boolean compareAndSwapInt(Object o, long offset, int expected,int update);
  
public final native boolean compareAndSwapLong(Object o, long offset, long expected, long update);
</code></pre>
<p>什么是CAS? 即比较并替换，实现并发算法时常用到的一种技术。CAS操作包含三个操作数——<mark>内存位置、预期原值及新值</mark>。执行CAS操作的时候，将内存位置的值与预期原值比较，如果相匹配，那么处理器会自动将该位置值更新为新值，否则，处理器不做任何操作。我们都知道，CAS是一条CPU的原子指令（<code>cmpxchg指令</code>），不会造成所谓的数据不一致问题，Unsafe提供的CAS方法（如compareAndSwapXXX）底层实现即为CPU指令cmpxchg。</p>
<h3 id="典型应用-2">典型应用</h3>
<p>CAS在java.util.concurrent.atomic相关类、Java AQS、CurrentHashMap等实现上有非常广泛的应用。如下图所示，AtomicInteger的实现中，静态字段valueOffset即为字段value的内存偏移地址，valueOffset的值在AtomicInteger初始化时，在静态代码块中通过Unsafe的objectFieldOffset方法获取。在AtomicInteger中提供的线程安全方法中，通过字段valueOffset的值可以定位到AtomicInteger对象中value的内存地址，从而可以根据CAS实现对value字段的原子操作。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1682059730822.png" alt="" loading="lazy"></figure>
<p>下图为某个AtomicInteger对象自增操作前后的内存示意图，对象的基地址baseAddress=“0x110000”，通过baseAddress+valueOffset得到value的内存地址valueAddress=“0x11000c”；然后通过CAS进行原子性的更新操作，成功则返回，否则继续重试，直到更新成功为止。</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1682059759899.png" alt="" loading="lazy"></figure>
<h2 id="线程调度">线程调度</h2>
<p>这部分，包括线程挂起、恢复、锁机制等方法。</p>
<pre><code class="language-java">//取消阻塞线程
public native void unpark(Object thread);
//阻塞线程
public native void park(boolean isAbsolute, long time);
//获得对象锁（可重入锁）
@Deprecated
public native void monitorEnter(Object o);
//释放对象锁
@Deprecated
public native void monitorExit(Object o);
//尝试获取对象锁
@Deprecated
public native boolean tryMonitorEnter(Object o);
</code></pre>
<p>如上源码说明中，方法park、unpark即可实现线程的挂起与恢复，将一个线程进行挂起是通过park方法实现的，调用park方法后，线程将一直阻塞直到超时或者中断等条件出现；unpark可以终止一个挂起的线程，使其恢复正常。</p>
<h3 id="典型应用-3">典型应用</h3>
<p>Java锁和同步器框架的核心类AbstractQueuedSynchronizer，就是通过调用LockSupport.park()和LockSupport.unpark()实现线程的阻塞和唤醒的，而LockSupport的park、unpark方法实际是调用Unsafe的park、unpark方式来实现。</p>
<h2 id="class相关">Class相关</h2>
<p>此部分主要提供Class和它的静态字段的操作相关方法，包含静态字段内存定位、定义类、定义匿名类、检验&amp;确保初始化等。</p>
<pre><code class="language-java">//获取给定静态字段的内存地址偏移量，这个值对于给定的字段是唯一且固定不变的
public native long staticFieldOffset(Field f);
//获取一个静态类中给定字段的对象指针
public native Object staticFieldBase(Field f);
//判断是否需要初始化一个类，通常在获取一个类的静态属性的时候（因为一个类如果没初始化，它的静态属性也不会初始化）使用。 当且仅当ensureClassInitialized方法不生效时返回false。
public native boolean shouldBeInitialized(Class&lt;?&gt; c);
//检测给定的类是否已经初始化。通常在获取一个类的静态属性的时候（因为一个类如果没初始化，它的静态属性也不会初始化）使用。
public native void ensureClassInitialized(Class&lt;?&gt; c);
//定义一个类，此方法会跳过JVM的所有安全检查，默认情况下，ClassLoader（类加载器）和ProtectionDomain（保护域）实例来源于调用者
public native Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len, ClassLoader loader, ProtectionDomain protectionDomain);
//定义一个匿名类
public native Class&lt;?&gt; defineAnonymousClass(Class&lt;?&gt; hostClass, byte[] data, Object[] cpPatches);
</code></pre>
<h3 id="典型应用-4">典型应用</h3>
<p>从Java 8开始，JDK使用invokedynamic及VM Anonymous Class结合来实现Java语言层面上的Lambda表达式。</p>
<ul>
<li>invokedynamic： invokedynamic是Java 7为了实现在JVM上运行动态语言而引入的一条新的虚拟机指令，它可以实现在运行期动态解析出调用点限定符所引用的方法，然后再执行该方法，invokedynamic指令的分派逻辑是由用户设定的引导方法决定。</li>
<li>VM Anonymous Class：可以看做是一种模板机制，针对于程序动态生成很多结构相同、仅若干常量不同的类时，可以先创建包含常量占位符的模板类，而后通过Unsafe.defineAnonymousClass方法定义具体类时填充模板的占位符生成具体的匿名类。生成的匿名类不显式挂在任何ClassLoader下面，只要当该类没有存在的实例对象、且没有强引用来引用该类的Class对象时，该类就会被GC回收。故而VM Anonymous Class相比于Java语言层面的匿名内部类无需通过ClassClassLoader进行类加载且更易回收。</li>
</ul>
<p>在Lambda表达式实现中，通过invokedynamic指令调用引导方法生成调用点，在此过程中，会通过ASM动态生成字节码，而后利用Unsafe的defineAnonymousClass方法定义实现相应的函数式接口的匿名类，然后再实例化此匿名类，并返回与此匿名类中函数式方法的方法句柄关联的调用点；而后可以通过此调用点实现调用相应Lambda表达式定义逻辑的功能。</p>
<h2 id="对象操作">对象操作</h2>
<p>此部分主要包含对象成员属性相关操作及非常规的对象实例化方式等相关方法。</p>
<pre><code class="language-java">//返回对象成员属性在内存地址相对于此对象的内存地址的偏移量
public native long objectFieldOffset(Field f);
//获得给定对象的指定地址偏移量的值，与此类似操作还有：getInt，getDouble，getLong，getChar等
public native Object getObject(Object o, long offset);
//给定对象的指定地址偏移量设值，与此类似操作还有：putInt，putDouble，putLong，putChar等
public native void putObject(Object o, long offset, Object x);
//从对象的指定偏移量处获取变量的引用，使用volatile的加载语义
public native Object getObjectVolatile(Object o, long offset);
//存储变量的引用到对象的指定的偏移量处，使用volatile的存储语义
public native void putObjectVolatile(Object o, long offset, Object x);
//有序、延迟版本的putObjectVolatile方法，不保证值的改变被其他线程立即看到。只有在field被volatile修饰符修饰时有效
public native void putOrderedObject(Object o, long offset, Object x);
//绕过构造方法、初始化代码来创建对象
public native Object allocateInstance(Class&lt;?&gt; cls) throws InstantiationException;
</code></pre>
<p>###典型应用</p>
<ul>
<li>常规对象实例化方式：我们通常所用到的创建对象的方式，从本质上来讲，都是通过new机制来实现对象的创建。但是，new机制有个特点就是当类只提供有参的构造函数且无显示声明无参构造函数时，则必须使用有参构造函数进行对象构造，而使用有参构造函数时，必须传递相应个数的参数才能完成对象实例化。</li>
<li>非常规的实例化方式：而Unsafe中提供allocateInstance方法，仅通过Class对象就可以创建此类的实例对象，而且不需要调用其构造函数、初始化代码、JVM安全检查等。它抑制修饰符检测，也就是即使构造器是private修饰的也能通过此方法实例化，只需提类对象即可创建相应的对象。由于这种特性，allocateInstance在java.lang.invoke、Objenesis（提供绕过类构造器的对象生成方式）、Gson（反序列化时用到）中都有相应的应用。</li>
</ul>
<h2 id="数组相关">数组相关</h2>
<p>这部分主要介绍与数据操作相关的arrayBaseOffset与arrayIndexScale这两个方法，两者配合起来使用，即可定位数组中每个元素在内存中的位置。</p>
<pre><code class="language-java">//返回数组中第一个元素的偏移地址
public native int arrayBaseOffset(Class&lt;?&gt; arrayClass);
//返回数组中一个元素占用的大小
public native int arrayIndexScale(Class&lt;?&gt; arrayClass);
</code></pre>
<h3 id="典型应用-5">典型应用</h3>
<p>这两个与数据操作相关的方法，在java.util.concurrent.atomic 包下的AtomicIntegerArray（可以实现对Integer数组中每个元素的原子性操作）中有典型的应用，如下图AtomicIntegerArray源码所示，通过Unsafe的arrayBaseOffset、arrayIndexScale分别获取数组首元素的偏移地址base及单个元素大小因子scale。后续相关原子性操作，均依赖于这两个值进行数组中元素的定位，如下图二所示的getAndAdd方法即通过checkedByteOffset方法获取某数组元素的偏移地址，而后通过CAS实现原子性操作。</p>
<figure data-type="image" tabindex="6"><img src="https://q456qq520.github.io/post-images/1682060445869.png" alt="" loading="lazy"></figure>
<h2 id="内存屏障">内存屏障</h2>
<p>在Java 8中引入，用于定义内存屏障（也称内存栅栏，内存栅障，屏障指令等，是一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作），避免代码重排序。</p>
<pre><code class="language-java">//内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏障后，屏障后的load操作不能被重排序到屏障前
public native void loadFence();
//内存屏障，禁止store操作重排序。屏障前的store操作不能被重排序到屏障后，屏障后的store操作不能被重排序到屏障前
public native void storeFence();
//内存屏障，禁止load、store操作重排序
public native void fullFence();
</code></pre>
<p>###典型应用<br>
在Java 8中引入了一种锁的新机制——<code>StampedLock</code>，它可以看成是读写锁的一个改进版本。StampedLock提供了一种乐观读锁的实现，这种乐观读锁类似于无锁的操作，完全不会阻塞写线程获取写锁，从而缓解读多写少时写线程“饥饿”现象。由于StampedLock提供的乐观读锁不阻塞写线程获取读锁，当线程共享变量从主内存load到线程工作内存时，会存在数据不一致问题，所以当使用StampedLock的乐观读锁时，需要遵从如下图用例中使用的模式来确保数据的一致性。<br>
<img src="https://q456qq520.github.io/post-images/1682060534549.png" alt="" loading="lazy"></p>
<p>如上图用例所示计算坐标点Point对象，包含点移动方法move及计算此点到原点的距离的方法distanceFromOrigin。在方法distanceFromOrigin中，首先，通过tryOptimisticRead方法获取乐观读标记；然后从主内存中加载点的坐标值 (x,y)；而后通过StampedLock的validate方法校验锁状态，判断坐标点(x,y)从主内存加载到线程工作内存过程中，主内存的值是否已被其他线程通过move方法修改，如果validate返回值为true，证明(x, y)的值未被修改，可参与后续计算；否则，需加悲观读锁，再次从主内存加载(x,y)的最新值，然后再进行距离计算。其中，校验锁状态这步操作至关重要，需要判断锁状态是否发生改变，从而判断之前copy到线程工作内存中的值是否与主内存的值存在不一致。</p>
<p>下图为StampedLock.validate方法的源码实现，通过锁标记与相关常量进行位运算、比较来校验锁状态，在校验逻辑之前，会通过Unsafe的loadFence方法加入一个load内存屏障，目的是避免上图用例中步骤②和StampedLock.validate中锁状态校验运算发生重排序导致锁状态校验不准确的问题。</p>
<figure data-type="image" tabindex="7"><img src="https://q456qq520.github.io/post-images/1682060654641.png" alt="" loading="lazy"></figure>
<h2 id="系统相关">系统相关</h2>
<p>这部分包含两个获取系统相关信息的方法。</p>
<pre><code class="language-java">//返回系统指针的大小。返回值为4（32位系统）或 8（64位系统）。
public native int addressSize();  
//内存页的大小，此值为2的幂次方。
public native int pageSize();
</code></pre>
<h3 id="典型应用-6">典型应用</h3>
<p>如下图所示的代码片段，为java.nio下的工具类Bits中计算待申请内存所需内存页数量的静态方法，其依赖于Unsafe中pageSize方法获取系统内存页大小实现后续计算逻辑。<br>
<img src="https://q456qq520.github.io/post-images/1682060743739.png" alt="" loading="lazy"></p>
<p>本文对Java中的sun.misc.Unsafe的用法及应用场景进行了基本介绍，我们可以看到Unsafe提供了很多便捷、有趣的API方法。即便如此，由于Unsafe中包含大量自主操作内存的方法，如若使用不当，会对程序带来许多不可控的灾难。因此对它的使用我们需要慎之又慎。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[BTrace]]></title>
        <id>https://q456qq520.github.io/post/btrace/</id>
        <link href="https://q456qq520.github.io/post/btrace/">
        </link>
        <updated>2023-04-21T05:32:18.000Z</updated>
        <summary type="html"><![CDATA[<p>A safe, dynamic tracing tool for the Java platform.<br>
适用于 Java 平台的安全动态跟踪工具。</p>
]]></summary>
        <content type="html"><![CDATA[<p>A safe, dynamic tracing tool for the Java platform.<br>
适用于 Java 平台的安全动态跟踪工具。</p>
<!-- more -->
<p>github地址：https://github.com/btraceio/btrace</p>
<h2 id="btrace是什么">BTrace是什么</h2>
<p>BTrace 可用于动态跟踪正在运行的 Java 程序（类似于 OpenSolaris 应用程序和操作系统的 DTrace）。BTrace 动态检测目标应用程序的类以注入跟踪代码（“字节码跟踪”）。</p>
<p>BTrace是基于Java语言的一个安全的、可提供动态追踪服务的工具。BTrace基于ASM、Java Attach Api、Instruments开发，为用户提供了很多注解。依靠这些注解，我们可以编写BTrace脚本（简单的Java代码）达到我们想要的效果，而不必深陷于ASM对字节码的操作中不可自拔。</p>
<p>看BTrace官方提供的一个简单例子：拦截所有java.io包中所有类中以read开头的方法，打印类名、方法名和参数名。当程序IO负载比较高的时候，就可以从输出的信息中看到是哪些类所引起，是不是很方便？</p>
<pre><code class="language-java">package com.sun.btrace.samples;

import com.sun.btrace.annotations.*;
import com.sun.btrace.AnyType;
import static com.sun.btrace.BTraceUtils.*;

/**
 * This sample demonstrates regular expression
 * probe matching and getting input arguments
 * as an array - so that any overload variant
 * can be traced in &quot;one place&quot;. This example
 * traces any &quot;readXX&quot; method on any class in
 * java.io package. Probed class, method and arg
 * array is printed in the action.
 */
@BTrace public class ArgArray {
    @OnMethod(
        clazz=&quot;/java\\.io\\..*/&quot;,
        method=&quot;/read.*/&quot;
    )
    public static void anyRead(@ProbeClassName String pcn, @ProbeMethodName String pmn, AnyType[] args) {
        println(pcn);
        println(pmn);
        printArray(args);
    }
}
</code></pre>
<p>再来看另一个例子：每隔2秒打印截止到当前创建过的线程数。</p>
<pre><code class="language-java">package com.sun.btrace.samples;

import com.sun.btrace.annotations.*;
import static com.sun.btrace.BTraceUtils.*;
import com.sun.btrace.annotations.Export;

/**
 * This sample creates a jvmstat counter and
 * increments it everytime Thread.start() is
 * called. This thread count may be accessed
 * from outside the process. The @Export annotated
 * fields are mapped to jvmstat counters. The counter
 * name is &quot;btrace.&quot; + &lt;className&gt; + &quot;.&quot; + &lt;fieldName&gt;
 */ 
@BTrace public class ThreadCounter {

    // create a jvmstat counter using @Export
    @Export private static long count;

    @OnMethod(
        clazz=&quot;java.lang.Thread&quot;,
        method=&quot;start&quot;
    ) 
    public static void onnewThread(@Self Thread t) {
        // updating counter is easy. Just assign to
        // the static field!
        count++;
    }

    @OnTimer(2000) 
    public static void ontimer() {
        // we can access counter as &quot;count&quot; as well
        // as from jvmstat counter directly.
        println(count);
        // or equivalently ...
        println(Counters.perfLong(&quot;btrace.com.sun.btrace.samples.ThreadCounter.count&quot;));
    }
}
</code></pre>
<p>除此之外，还可以做那些事情呢？</p>
<p>比如查看HashMap什么时候会触发rehash，以及此时容器中有多少元素等等。</p>
<h2 id="btrace架构">BTrace架构</h2>
<p>BTrace主要有下面几个模块：</p>
<ol>
<li>BTrace脚本：利用BTrace定义的注解，我们可以很方便地根据需要进行脚本的开发。</li>
<li>Compiler：将BTrace脚本编译成BTrace class文件。</li>
<li>Client：将class文件发送到Agent。</li>
<li>Agent：基于Java的Attach Api，Agent可以动态附着到一个运行的JVM上，然后开启一个BTrace Server，接收client发过来的BTrace脚本；解析脚本，然后根据脚本中的规则找到要修改的类；修改字节码后，调用Java Instrument的reTransform接口，完成对对象行为的修改并使之生效。</li>
</ol>
<p>整个BTrace的架构大致如下：<br>
<img src="https://q456qq520.github.io/post-images/1682056181598.jpeg" alt="" loading="lazy"></p>
<blockquote>
<p>名次解释：java.lang.instrument.Instrumentation<br>
redefineClasses和retransformClasses。一个是重新定义class，一个是修改class。都是替换已经存在的class文件，redefineClasses是自己提供字节码文件替换掉已存在的class文件retransformClasses是在已存在的字节码文件上修改后再替换之。当然，运行时直接替换类很不安全。比如新的class文件引用了一个不存在的类，或者把某个类的一个field给删除了等等，这些情况都会引发异常。所以如文档中所言，instrument存在诸多的限制。我们能做的基本上也就是简单修改方法内的一些行为。</p>
</blockquote>
<p>BTrace最终借Instruments实现class的替换。如上文所说，出于安全考虑，Instruments在使用上存在诸多的限制，BTrace也不例外。BTrace对JVM来说是“只读的”，因此BTrace脚本的限制如下：</p>
<ul>
<li>不允许创建对象</li>
<li>不允许创建数组</li>
<li>不允许抛异常</li>
<li>不允许catch异常</li>
<li>不允许随意调用其他对象或者类的方法，只允许调用com.sun.btrace.BTraceUtils中提供的静态方法（一些数据处理和信息输出工具）</li>
<li>不允许改变类的属性</li>
<li>不允许有成员变量和方法，只允许存在static public void方法</li>
<li>不允许有内部类、嵌套类</li>
<li>不允许有同步方法和同步块</li>
<li>不允许有循环</li>
<li>不允许随意继承其他类（当然，java.lang.Object除外）</li>
<li>不允许实现接口</li>
<li>不允许使用assert</li>
<li>不允许使用Class对象</li>
</ul>
<p>如此多的限制，其实可以理解。BTrace要做的是，虽然修改了字节码，但是除了输出需要的信息外，对整个程序的正常运行并没有影响。</p>
<h2 id="其他-arthas">其他-Arthas</h2>
<p>BTrace脚本在使用上有一定的学习成本，如果能把一些常用的功能封装起来，对外直接提供简单的命令即可操作的话，那就再好不过了。阿里的工程师们早已想到这一点，就在去年（2018年9月份），阿里巴巴开源了自己的Java诊断工具——<a href="https://github.com/alibaba/arthas">Arthas</a>。Arthas提供简单的命令行操作，功能强大。究其背后的技术原理，和本文中提到的大致无二。</p>
<p>Java的Instruments给运行时的动态追踪留下了希望，Attach API则给运行时动态追踪提供了“出入口”，ASM则大大方便了“人类”操作Java字节码的操作。</p>
<p>基于Instruments和Attach API前辈们创造出了诸如JProfiler、Jvisualvm、BTrace、Arthas这样的工具。以ASM为基础发展出了cglib、动态代理，继而是应用广泛的Spring AOP。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mac 安装Golang（一）]]></title>
        <id>https://q456qq520.github.io/post/mac-an-zhuang-golangyi/</id>
        <link href="https://q456qq520.github.io/post/mac-an-zhuang-golangyi/">
        </link>
        <updated>2023-04-04T07:34:55.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="一-下载">一 下载</h2>
<p>前往官网下载最新安装包，地址如下：<br>
https://golang.google.cn/dl/</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="一-下载">一 下载</h2>
<p>前往官网下载最新安装包，地址如下：<br>
https://golang.google.cn/dl/</p>
<!-- more -->
<p>下载完成，运行安装包。</p>
<h3 id="11-检查环境">1.1 检查环境</h3>
<ol>
<li>检查环境</li>
</ol>
<pre><code class="language-go"> go env
</code></pre>
<ol start="2">
<li>查看版本</li>
</ol>
<pre><code class="language-go">go version
</code></pre>
<ol start="3">
<li>查看目录<br>
<img src="https://q456qq520.github.io/post-images/1680594021632.png" alt="" loading="lazy"></li>
</ol>
<ul>
<li>bin: 存储可执行bin文件</li>
<li>pkg: 编译完成的文件</li>
<li>src: 源代码文件</li>
</ul>
<ol start="4">
<li>编辑环境变量<br>
如果需要修改环境变量，参考如下：</li>
</ol>
<pre><code class="language-go">vim ~/.bash_profile

# GOPATH配置为你的工作区目录
export GOROOT=/usr/local/go
export PATH=$PATH:$GOROOT/bin
export GOPATH=$HOME/go

source ~/.bash_profile
</code></pre>
<ol start="5">
<li>设置go国内模块代理</li>
</ol>
<pre><code class="language-go">vim ~/.bash_profile

export GO111MODULE=on
export GOPROXY=https://goproxy.cn
</code></pre>
<h2 id="二-运行">二 运行</h2>
<h3 id="21-创建一个go文件">2.1 创建一个go文件</h3>
<blockquote>
<p>提示: Go 语言源文件的拓展名以 .go 结尾。</p>
</blockquote>
<pre><code class="language-go">package main

import &quot;fmt&quot;

func main() {
    fmt.Println(&quot;Hello World !&quot;)
}
</code></pre>
<h3 id="22-执行-go-程序">2.2 执行 Go 程序</h3>
<h4 id="221-go-run">2.2.1 go run</h4>
<p>通过 go run 命令来执行刚刚的代码， 执行命令如下：</p>
<pre><code class="language-go">go run helloworld.go 
</code></pre>
<h5 id="222-go-bulid">2.2.2 go bulid</h5>
<p>还可以通过执行 go build 命令，将刚刚这段代码编译成可执行文件:</p>
<pre><code class="language-go">go build helloworld.go
</code></pre>
<p>编译完成后，可以在目录下看到一个 helloworld可执行文件，通过 ./helloworld 命令来执行它，即可输出 Hello World !</p>
<h2 id="三-jetbrains-golang-安装开发环境搭建">三 Jetbrains GoLang 安装&amp;开发环境搭建</h2>
<p>https://www.macyy.cn/archives/1157</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题（三）]]></title>
        <id>https://q456qq520.github.io/post/mian-shi-ti-san/</id>
        <link href="https://q456qq520.github.io/post/mian-shi-ti-san/">
        </link>
        <updated>2023-03-12T04:28:47.000Z</updated>
        <content type="html"><![CDATA[<h2 id="mysql">mysql</h2>
<h3 id="1-什么是mysql中的降序索引">1. 什么是mysql中的降序索引</h3>
<p>降序索引是mysql8.0中才有的一种索引排序类型，默认为升序。</p>
<p>在MySQL中，降序索引是一种索引类型，可以帮助优化查询性能。与普通的升序索引不同，降序索引将索引键值按照降序排列，这意味着在查询时可以更快地找到符合条件的数据。</p>
<p>例如，假设有一个包含数百万条记录的表，其中有一个日期列，你经常需要按照日期倒序查找最新的数据。如果你在该列上创建了一个降序索引，则查询将非常快，因为MySQL将从索引的末尾开始查找最新的数据。</p>
<p>创建降序索引的语法与创建普通升序索引的语法类似，只需在索引定义中使用DESC关键字即可。例如，创建一个名为date_index的降序索引，可以使用以下语句：</p>
<pre><code class="language-mysql">CREATE INDEX date_index ON mytable (date_column DESC);
</code></pre>
<h2 id="线程池">线程池</h2>
<h3 id="1-线程池中线程是如何保活和回收的">1. 线程池中线程是如何保活和回收的</h3>
<p>线程保活：线程池中的线程通过调用线程管理器中的addWorker()方法来创建新的线程，这些线程被创建后会一直保活在线程池中。当任务到来时，线程池会通过线程管理器的getWorker()方法获取一个空闲线程来执行任务。线程池还会定期调用线程管理器的keepAlive()方法来检查空闲线程的数量，如果发现空闲线程过多，线程池会将多余的线程置为等待状态，以便在需要时能够立即响应任务。</p>
<p>线程回收：线程池中的线程在执行完任务后，并不会立即退出，而是会等待新的任务到来。线程池会通过线程管理器的getTask()方法获取任务，并将任务分配给空闲线程执行。如果线程空闲时间超过设定的时间，线程管理器会将该线程置为等待状态，并等待新的任务到来。如果等待的时间超过了设定的线程空闲时间，线程管理器会将该线程回收，并从线程池中移除该线程。</p>
<p>线程池的线程保活和回收机制是由线程管理器来管理的，线程管理器是线程池的核心组件之一。线程管理器通过对线程的创建、调度、回收等过程进行管理，保证线程池的运行效率和稳定性。同时，线程管理器还会通过使用锁、条件变量等机制来保证线程的安全性和可靠性。</p>
<h3 id="2-线程池有哪几种状态分别是如何变化的">2. 线程池有哪几种状态，分别是如何变化的</h3>
<p>Running（运行状态）：线程池处于正常运行状态，可以接受新的任务。<br>
Shutdown（关闭状态）：线程池不再接受新的任务，但会执行完已经提交的任务。<br>
Stop（停止状态）：线程池不再接受新的任务，并且会中断正在执行的任务。<br>
Tidying（整理状态）：所有的任务都已经执行完毕，工作线程数量为0，线程池将会转换到Terminated状态。<br>
Terminated（终止状态）：线程池彻底终止，不再处理任何任务。</p>
<p>线程池的状态转换通常是通过线程池的状态控制变量来实现的。例如，当线程池接收到shutdown()方法的调用时，线程池的状态会从Running状态转换为Shutdown状态。当线程池中的所有任务都执行完毕时，线程池的状态会从Tidying状态转换为Terminated状态。</p>
<h2 id="tomcat">tomcat</h2>
<h3 id="1-tomcat的最大线程数为什么默认是200">1. tomcat的最大线程数为什么默认是200</h3>
<p>Tomcat默认的最大线程数是200，这是一个经验值。具体来说，这个值取决于以下几个因素：</p>
<p>硬件资源：Tomcat所运行的服务器的硬件资源（如CPU和内存）越高，最大线程数就可以设置得更高。<br>
应用程序的负载：应用程序的负载越高，需要更多的线程来处理请求，最大线程数也就需要设置得更高。<br>
并发请求的处理时间：如果应用程序中的每个请求都需要大量的时间来处理，那么处理每个请求的线程就需要更长的时间。在这种情况下，最大线程数需要设置得更高，以便同时处理更多的请求。<br>
服务器的负载：如果Tomcat所运行的服务器还运行着其他的应用程序，那么这些应用程序也需要共享服务器的资源。因此，在这种情况下，最大线程数需要设置得更低，以免影响其他应用程序的运行。</p>
<p>总之，200作为Tomcat默认的最大线程数，是一个经验值，并不适用于所有情况。在实际应用中，最大线程数的设置应该根据应用程序的负载、硬件资源和服务器的负载等因素进行调整。</p>
<h2 id="分布式">分布式</h2>
<h3 id="1-什么是集群脑裂如何解决脑裂问题">1. 什么是集群脑裂，如何解决脑裂问题</h3>
<p>集群脑裂是指分布式系统中的节点之间失去联系或者通信故障，导致系统出现不一致的状态或无法提供服务的问题。举个例子，假设有一个由3个节点组成的集群，当节点1和节点2之间的通信故障时，这个集群就出现了脑裂问题，因为节点1和节点2之间的状态不一致会导致集群无法正常工作。</p>
<p>解决集群脑裂问题的方法有很多种，以下是一些常见的解决方法：</p>
<ol>
<li>心跳检测：在分布式系统中，通常使用心跳检测来检测节点之间的通信状态。当某个节点长时间无响应时，系统会将该节点视为已经失效，避免了因失效节点导致的脑裂问题。心跳检测可以使用UDP协议来实现，因为UDP协议的开销比TCP协议低，更适合在分布式系统中使用。</li>
<li>选举机制：在集群中选举一个“领导者”节点来负责处理请求，避免出现不一致的状态。当发生脑裂问题时，每个节点都会进行选举，选择一个新的领导者来处理请求。</li>
<li>数据复制：在分布式系统中，数据复制可以避免因为某个节点失效导致的脑裂问题。当某个节点失效时，可以使用其他节点上的备份数据来保证系统的一致性。</li>
<li>分布式锁：在分布式系统中，使用分布式锁可以避免因为不同节点之间的操作冲突导致的脑裂问题。例如，当多个节点同时对一个资源进行读写操作时，可以使用分布式锁来保证只有一个节点可以进行写操作，从而避免脑裂问题的发生。</li>
</ol>
<p>总之，解决集群脑裂问题的方法很多，具体选择哪种方法需要根据具体的应用场景和系统架构来进行评估和选择。</p>
<h3 id="2-微服物中什么是应用级注册什么是接口级注册优缺点是什么">2. 微服物中什么是应用级注册？什么是接口级注册？优缺点是什么</h3>
<p>在微服务架构中，应用级注册和接口级注册都是服务发现的方式，用于将服务注册到服务注册中心，以便其他服务或客户端可以发现和调用这些服务。</p>
<p>应用级注册是指将整个应用程序注册到服务注册中心，由服务注册中心负责维护该应用程序中所有的服务实例。在这种模式下，应用程序中的所有服务都共享同一个注册信息，服务注册中心可以自动维护服务实例的健康状态，并根据需要自动进行负载均衡和故障转移。应用级注册的优点是简单易用，适用于中小型的微服务应用场景，但缺点是不够灵活，如果一个应用程序中的某个服务实例出现故障，整个应用程序将会被标记为不可用，从而影响到其他服务的可用性。</p>
<p>接口级注册是指将每个服务实例注册到服务注册中心，并指定服务所提供的接口信息。在这种模式下，服务的注册信息更加细粒度，服务消费者可以根据具体的接口信息来发现和调用服务，而不必依赖于整个应用程序的注册信息。接口级注册的优点是更加灵活，服务实例之间相互独立，不会因为某个服务实例的故障而影响到整个应用程序的可用性，但缺点是注册信息的维护相对复杂，需要进行额外的配置和管理。</p>
<p>综上所述，应用级注册和接口级注册都有各自的优缺点，具体使用哪种注册方式需要根据实际的应用场景来进行选择和评估。对于大型的微服务应用场景，一般会采用接口级注册的方式来管理服务实例，以保证服务之间的独立性和灵活性。对于中小型的微服务应用场景，应用级注册的方式可以更加简单易用，快速搭建起微服务应用程序。</p>
<h2 id="框架">框架</h2>
<h3 id="1-springboot的自动配置是如何实现的">1. springboot的自动配置是如何实现的</h3>
<p>Spring Boot的自动配置机制的实现是基于Spring Framework的条件化配置机制，主要是通过使用@Conditional注解来实现的。</p>
<p>具体来说，自动配置是通过以下步骤实现的：</p>
<ol>
<li>Spring Boot在classpath中查找所有的spring.factories文件，并从这些文件中加载所有可用的自动配置类。</li>
<li>每个自动配置类都有一个或多个条件，这些条件使用@Conditional注解进行标注，以指示在何种情况下自动配置应该生效。</li>
<li>当Spring Boot应用程序启动时，Spring容器会根据条件化配置机制加载和实例化自动配置类中的bean。</li>
<li>自动配置类中的@Bean方法定义了应用程序所需的各种组件，这些组件可以是Spring容器管理的bean，例如数据源，事务管理器等。</li>
<li>根据应用程序的配置和条件，Spring Boot会选择性地启用或禁用自动配置类中的bean，这些条件可以是环境变量、系统属性、JVM参数等。</li>
<li>如果自动配置中的某些bean与应用程序中手动配置的bean冲突，那么手动配置的bean会覆盖自动配置的bean。</li>
</ol>
<p>Spring Boot的自动配置机制是基于Java Config的，它使用了许多Java Config的特性，例如使用@Bean注解定义bean，使用@Configuration注解标识配置类等。自动配置还利用了Spring的条件化配置机制来实现灵活的配置，这使得应用程序可以根据环境和需求自动选择需要的组件。</p>
<h3 id="2-如何设计一个rpc框架">2. 如何设计一个rpc框架</h3>
<p>设计一个RPC框架需要考虑以下几个方面：</p>
<ul>
<li>通信协议的设计。需要设计一个协议来定义消息的格式和内容，包括请求消息和响应消息。</li>
<li>服务注册与发现。需要设计一个机制来注册和发现可用的服务，以便客户端可以找到需要调用的服务。</li>
<li>序列化和反序列化。需要选择一种序列化方式来将对象序列化为字节流，并在接收方将字节流反序列化为对象。</li>
<li>网络通信。需要实现网络通信，包括客户端和服务端的通信。</li>
<li>负载均衡。需要设计一种负载均衡策略，以便在多个服务实例中选择一个最合适的实例进行调用。</li>
<li>异常处理。需要处理异常情况，例如网络连接失败、超时、服务不可用等情况。</li>
<li>安全认证。需要设计一种安全认证机制来保护数据的安全性。</li>
</ul>
<p>在实现RPC框架时，可以考虑使用以下技术：</p>
<ul>
<li>Java NIO或Netty等高性能的网络通信框架。</li>
<li>JSON或Protobuf等高效的序列化方式。</li>
<li>ZooKeeper或Consul等服务注册中心，以便实现服务注册和发现。</li>
<li>Ribbon或Nginx等负载均衡器。</li>
<li>Spring框架或Dubbo等RPC框架的实现方式，以便快速开发和管理。</li>
</ul>
<p>一个简单的RPC框架实现步骤如下：</p>
<ul>
<li>定义通信协议和消息格式。</li>
<li>定义服务接口和服务实现类，并使用注解将服务注册到注册中心。</li>
<li>实现客户端调用逻辑，包括负载均衡、序列化、网络通信等。</li>
<li>实现服务端接收请求逻辑，包括反序列化、调用服务实现类、序列化响应消息等。</li>
<li>添加异常处理、安全认证等扩展功能。</li>
<li>进行性能测试和调优，确保RPC框架的性能和稳定性。</li>
</ul>
<p>需要注意的是，RPC框架的设计和实现需要考虑很多细节，包括线程池管理、心跳机制、消息重试、请求超时等，因此需要进行充分的测试和验证，确保RPC框架的稳定性和可靠性。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringCloud微服务实战(二)]]></title>
        <id>https://q456qq520.github.io/post/springcloud-wei-fu-wu-shi-zhan-er/</id>
        <link href="https://q456qq520.github.io/post/springcloud-wei-fu-wu-shi-zhan-er/">
        </link>
        <updated>2023-03-07T08:22:24.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="四-服务容错保护-spring-cloud-hystrix">四 服务容错保护: Spring Cloud Hystrix</h2>
]]></summary>
        <content type="html"><![CDATA[<h2 id="四-服务容错保护-spring-cloud-hystrix">四 服务容错保护: Spring Cloud Hystrix</h2>
<!-- more -->
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringCloud微服务实战(一)]]></title>
        <id>https://q456qq520.github.io/post/springcloud-wei-fu-wu-shi-zhan-yi/</id>
        <link href="https://q456qq520.github.io/post/springcloud-wei-fu-wu-shi-zhan-yi/">
        </link>
        <updated>2023-03-02T08:30:07.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="一-spring-cloud简介">一 Spring Cloud简介</h2>
]]></summary>
        <content type="html"><![CDATA[<h2 id="一-spring-cloud简介">一 Spring Cloud简介</h2>
<!-- more -->
<p>Spring Cloud是一个基千SpringBoot实现的微服务架构开发 工具。它为微服务架构中<br>
涉及的 配置管理、服务治理、 断路器、 智能路由、微代理、 控制总线、 全局锁、 决策竞选、<br>
分布式会话和集群状态管理等操作提供了一种简单的开发方式。</p>
<p>Spring Cloud包含了多个子项目，如下所示：</p>
<ol>
<li>Spring Cloud Config: 配置管理工具， 支持使用Git存储配置内容， 可以使用它实现<br>
应用配置的外部化存储，并支持客户端配置信息刷新、 加密／解密配置内容等。</li>
<li>Spring Cloud Netflix: 核心 组件，对多个Netflix OSS开源套件进行整合。
<ul>
<li>Eureka: 服务治理组件， 包含服务注册中心、 服务注册与发现机制的实现。</li>
<li>Hystrix: 容错管理组件，实现断路器模式，帮助服务依赖中出现的延迟和为故障<br>
提供强大的容错能力。</li>
<li>Ribbon: 客户端负载均衡的服务调用组件。</li>
<li>Feign: 基于Ribbon 和 Hystrix 的声明式服务调用组件。</li>
<li>Zuul: 网关组件，提供智能路由、 访问过滤等功能。</li>
<li>Archaius: 外部化配置组件。</li>
</ul>
</li>
<li>Spring Cloud Bus: 事件、 消息总线， 用于传播集群中的状态变化或事件， 以触发后<br>
续的处理， 比如用来动态刷新配置等。</li>
<li>Spring Cloud Cluster: 针对 ZooKeeper、 Redis、 Hazelcast、 Consul 的选举算法和通用<br>
状态模式的实现。</li>
<li>Spring Cloud Cloudfoundry: 与 Pivotal Cloudfoundry 的整合支持。</li>
<li>Spring Cloud Consul: 服务发现与配置管理工具。</li>
<li>Spring Cloud Stream: 通过 Redis、 Rabbit 或者 Kafka 实现的消费微服务， 可以通过<br>
简单的声明式模型来发送和接收消息。</li>
<li>Spring Cloud A WS: 用千简化整合 Amazon Web Service 的组件。</li>
<li>Spring Cloud Security: 安全工具包， 提供在 Zuul 代理中对 0Auth2 客户端请求的中<br>
继器。</li>
<li>Spring Cloud Sleuth: Spring Cloud 应用的分布式跟踪实现， 可以完美整合 Zipkin。</li>
<li>Spring Cloud ZooKeeper: 基于 ZooKeeper 的服务发现与配置管理组件。</li>
<li>Spring Cloud Starters: Spring Cloud 的基础组件， 它是基于Spring Boot 风格项目的<br>
基础依赖模块。</li>
<li>Spring Cloud CLI: 用于在 Groovy 中快速创建 Spring Cloud 应用的 Spring Boot CLI<br>
插件。</li>
</ol>
<h2 id="二-服务治理-spring-cloud-eureka">二 服务治理： Spring Cloud Eureka</h2>
<p>Spring Cloud Eureka 是 Spring Cloud Netflix 微服务套件中的一部分， 它基于 Netflix<br>
Eureka 做了二次封装， 主要负责完成微服务架构中的服务治理功能。 Spring Cloud 通过为<br>
Eureka 增加了 Spring Boot 风格的自动化配置，我们只需通过简单引入依赖和注解配置就能<br>
让 Spring Boot 构建的微服务应用轻松地与 Eureka 服务治理体系进行整合。</p>
<h3 id="21-服务治理">2.1 服务治理</h3>
<p>为了解决微服务架构中的服务实例维护问题， 产生了大量的服务治理框架和产品。 这<br>
些框架和产品的实现都围绕着服务注册与服务发现机制来完成对微服务应用实例的自动化<br>
管理。</p>
<ol>
<li>
<p>服务注册<br>
在服务治理框架中， 通常都会构建一个注册中心， 每个服务单元向注册中心登记自己提供的服务， 将主机与端口号、 版本号、 通信协议等一些附加信息告知注册中心， 注册中心按服务名分类组织服务清单。</p>
</li>
<li>
<p>服务发现<br>
由于在服务治理框架下运作， 服务间的调用不再通过指定具体的实例地址来实现， 而是通过向服务名发起请求调用实现。 所以，服务调用方在调用服务提供方接口的时候， 并不知道具体的服务实例位置。 因此， 调用方需要向服务注册中心咨询服务， 并获取所有服务的实例清单， 以实现对具体服务实例的访问。</p>
</li>
</ol>
<h3 id="22-netflix-eureka">2.2 Netflix Eureka</h3>
<p>Spring Cloud Eureka, 使用Netflix Eureka来实现服务注册与发现， 它既包含了服务端组件，也包含了客户端组件，并且服务端与客户端均采用Java编写，所以Eureka主要适用于通过Java实现的分布式系统，或是与JVM兼容语言构建的系统。</p>
<p>Eureka服务端，我们也称为服务注册中心。 它同其他服务注册中心一样，支持高可用配置。它依托于强一致性提供良好的服务实例可用性，可以应对多种不同的故障场景。 如果Eureka以集群模式部署，当集群中有分片出现故障时，那么Eureka就转入自我保护模式。它允许在分片故障期间继续提供服务的发现和注册，当故障分片恢复运行时， 集群中的其他分片会把它们的状态再次同步回来。</p>
<p>Eureka客户端，主要处理服务的注册与发现。客户端服务通过注解和参数配置的方式，嵌入在客户端应用程序的代码中，在应用程序运行时，Eureka客户端向注册中心注册自身提供的服务并周期性地发送心跳来更新它的服务租约。同时，它也能从服务端查询当前注册的服务信息并把它们缓存到本地并周期性地刷新服务状态。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1677827704328.png" alt="" loading="lazy"></figure>
<h4 id="221-服务提供者">2.2.1 服务提供者</h4>
<h5 id="服务注册">服务注册</h5>
<p>“服务提供者” 在启动的时候会通过发送REST请求的方式将自己注册到EurekaServer上， 同时带上了自身服务的一些元数据信息。<mark>Eureka Server接收到这个REST请求之后，将元数据信息存储在一个<code>双层结构Map</code>中， 其中第一层的key是服务名， 第二层的key是具体服务的实例名</mark>。</p>
<blockquote>
<p>在服务注册时， 需要确认一下 eureka.client.register-with-eureka=true参数是否正确， 该值默认为true。 若设置为false将不会启动注册操作。</p>
</blockquote>
<h5 id="服务同步">服务同步</h5>
<p>如架构图中所示， 这里的两个服务提供者分别注册到了两个不同的服务注册中心上，也就是说， 它们的信息分别被两个服务注册中心所维护。 此时， 由于服务注册中心之间因互相注册为服务， 当服务提供者发送注册请求到一个服务注册中心时， 它会将该请求转发给集群中相连的其他注册中心， 从而实现注册中心之间的服务同步 。 通过服务同步，两个服务提供者的服务信息就可以通过这两台服务注册中心中的任意一台获取到。</p>
<h5 id="服务续约">服务续约</h5>
<p>在注册完服务之后，服务提供者会维护一个心跳用来持续告诉EurekaServer: &quot;我还活着 ”， 以防止Eureka Server 的 “ 剔除任务 ” 将该服务实例 从服务列表中排除出去， 我们称该操作为服务续约(Renew)。</p>
<h4 id="222-服务消费者">2.2.2 服务消费者</h4>
<h5 id="获取服务">获取服务</h5>
<p>到这里，在服务注册中心已经注册了一个服务，并且该服务有两个实例。当我们启动服务消费者的时候， 它会发送一个REST请求给服务注册中心，来获取上面注册的服务清单。为了性能考虑，Eureka Server会维护一份只读的服务清单来返回给客户端，同时该缓存清单会每隔30秒更新一次。</p>
<p>获取服务是服务消费者的基础，所以必须确保eureka.client.fetch-registry= true参数没有被修改成false, 该值默认为true。若希望修改缓存清单的更新时间，可以通过 eureka.client.registry-fetch-interval-seconds=30参数进行修改，该参数默认值为30, 单位为秒。</p>
<h5 id="服务调用">服务调用</h5>
<p>服务消费者在获取服务清单后，通过服务名可以获得具体提供服务的实例名和该实例的元数据信息。 因为有这些服务实例的详细信息， 所以客户端可以根据自己的需要决定具 体调用哪个实例，在ribbon中会默认采用轮询的方式进行调用，从而实现客户端的负载均衡。</p>
<p>对于访问实例的选择，Eureka中有Region和Zone的概念，一个Region中可以包含多个 Zone, 每个服务客户端需要被注册到一个Zone中，所以每个客户端对应一个Region和一个Zone。 在进行服务调用的时候，优先访问同处一个Zone中的服务提供方，若访问不到，就访问其他的Zone。</p>
<h5 id="服务下线">服务下线</h5>
<p>在系统运行过程中必然会面临关闭或重启服务的某个实例的情况， 在服务关闭期间， 我们自然不希望客户端会继续调用关闭了的实例。 所以在客户端程序中，当服务实例进行正常的关闭操作时， 它会触发一个服务下线的REST请求给Eueka Server, 告诉服务注册中心:“我要下线了”。 服务端在接收到请求之后， 将该服务状态置为下线(DOWN), 并把 该下线事件传播出去。</p>
<h4 id="223-服务注册中心">2.2.3 服务注册中心</h4>
<h5 id="失效剔除">失效剔除</h5>
<p>有些时候， 我们的服务实例并不一定会正常下线， 可能由于内存溢出、 网络故障等原因使得服务不能正常工作， 而服务注册中心并未收到 “ 服务下线 ” 的请求。 为了从服务列表中将这些无法提供服务的实例剔除， Eureka Srevre 在启动的时候会创建一个定时任务， 默认每隔一段时间(默认为60秒) 将当前清单中超时(默认为90秒)没有续约的服务剔除出去。</p>
<h5 id="自我保护">自我保护</h5>
<p>服务注 册到EurekaSrever 之后，会维护一个心跳连接，告诉EurekaServer自己还活着。EurekaServer 在运行期间，会统计心跳失败的比例在15分钟之内是否低于85%, 如果出现低于的情况，Eureka Server会将当前的实例注册信息保护起来，让这些实例不会过期，尽可能保护这些注册信息。但是 在这段保护期间内实例若出现问题，那么客户端很容易拿到实际已经不存在的服务实例，会出现调用失败的清况，所以客户端必须要有容错机制，比如可以使用请求重试、 断路器等机制。</p>
<p>由于本地调试很容易触发注册中心的保护机制， 这会使得注册中心维护的服务实例不那么准确。 所以， 我们在本地进行开发的时候， 可以使用eureka.server.enable­-self-preservervation=false参数来关闭保护机制， 以确保注册中心可以将不可用的实例正确剔除。</p>
<h3 id="23-源码分析">2.3 源码分析</h3>
<p>首先，对于服务注册中心、服务提供者、服务消费者这三个主要元素来说，后两者(也就是 Eureka 客户端)在整个运行机制中是大部分通信行为的主动发起者，而注册中 心主要是处理请求的接收者。所以，我们可以从Eureka的客户端作为入口看看它是如何完 成这些主动通信行为的。</p>
<p>我们在将一个普通的 Spring Boot 应用注册到 Eureka Server 或是从 Eureka Server 中获取服务列表时， 主要就做了两件事:</p>
<ul>
<li>在应用主类中配置了@EnableDiscoveryClient注解。</li>
<li>在application.properties中用eureka.client.serviceUrl.defaultZone参数指定了服务注册中心的位置。</li>
</ul>
<p>我们来看看@EnableDiscoveryClient 的源码， 具体如下:</p>
<pre><code class="language-java">@Target({ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@Import({EnableDiscoveryClientImportSelector.class})
public @interface EnableDiscoveryClient {
    boolean autoRegister() default true;
}
</code></pre>
<p>它主要用来开启DiscoveryClient 的实例。通过搜索DiscoveryClient, 我们可以发现有 个类和一个接口。 通过梳理可以得到如下图所示的关系:<br>
<img src="https://q456qq520.github.io/post-images/1677830336714.png" alt="" loading="lazy"></p>
<p>其中， 左边的org.springframework.cloud.client.discovery.DiscoveryClient 是Spring Cloud的接口，它定义了用来发现服务的常用抽象方法， 通过该接口可以有效地 屏蔽服务治理的实现细节， 所以使用 Spring Cloud 构建的微服务应用可以方便地切换不同服务治理框架， 而不改动程序代码， 只需要另外添加一些针对服务治理框架的配置即可。</p>
<p>org.springframework.cloud.netflix.eureka.EurekaDiscoveryClient是对该接口的实现，从命名来判断， 它实现的是对 Eureka 发现服务的封装。 所以 EurekaDiscoveryClient 依赖了 Netflix Eureka 的 com.netflix.discovery. EurekaClient 接口， EurekaClient 继承了 LookupService 接口， 它们都是Netflix 开源包中的内容， 主要定义了针对Eureka的发现服务的抽象方法， 而真正实现发现服务的 则是Netflix 包中的 com.netflix.discovery.DiscoveryClient类。</p>
<p>EurekaClient负责下面的任务:</p>
<ul>
<li>向Eureka Server注册服务实例</li>
<li>向Eureka Server服务租约</li>
<li>当服务关闭期间， 向Eureka Server取消租约</li>
<li>查询Eureka Server中的服务实例列表</li>
</ul>
<p>在具体研究 Eureka Client负责完成的任务之前，我们先看看在哪里对 Eureka Server的URL列表进行配置。根据我们配置的属性名eureka.client.serviceUrl.defaultZone, 通过serviceUrl可以找到该属性相关的加载属性，但是在 SR5 版本中它们都被 @Deprecated 标注为不再建议使用，并@link到了替代类com.netflix.discovery.endpoint.EndpointUtils, 所以我们可以在该类中找到下面这个函数:</p>
<pre><code class="language-java">public static List&lt;String&gt; getServiceUrlsFromConfig(EurekaClientConfig clientConfig, String instanceZone, boolean preferSameZone) {
    List&lt;String&gt; orderedUrls = new ArrayList();
    String region = getRegion(clientConfig);
    String[] availZones = clientConfig.getAvailabilityZones(clientConfig.getRegion());
    if (availZones == null || availZones.length == 0) {
        availZones = new String[]{&quot;default&quot;};
    }
    int myZoneOffset = getZoneOffset(instanceZone, preferSameZone, availZones);
    List&lt;String&gt; serviceUrls = clientConfig.getEurekaServerServiceUrls(availZones[myZoneOffset]);
    if (serviceUrls != null) {
        orderedUrls.addAll(serviceUrls);
    }
    int currentOffset = myZoneOffset == availZones.length - 1 ? 0 : myZoneOffset + 1;
    while(currentOffset != myZoneOffset) {
        serviceUrls = clientConfig.getEurekaServerServiceUrls(availZones[currentOffset]);
        if (serviceUrls != null) {
            orderedUrls.addAll(serviceUrls);
        }
        if (currentOffset == availZones.length - 1) {
            currentOffset = 0;
        } else {
            ++currentOffset;
        }
    }
    if (orderedUrls.size() &lt; 1) {
        throw new IllegalArgumentException(&quot;DiscoveryClient: invalid serviceUrl specified!&quot;);
    } else {
        return orderedUrls;
    }
}
</code></pre>
<h4 id="231-region-zone">2.3.1 Region、Zone</h4>
<p>在上面的函数中， 可以发现， 客户端依次加载了两个内容， 第一个是Region, 第二个 是Zone, 从其加载逻辑上我们可以判断它们之间的关系:<br>
通过getRegion函数，我们可以看到它从配置中读取了一个Region返回， 所以一个微服务应用只可以属于 一个Region, 如果不特别配置， 默认为default。若我们要自己设置， 可以通过eureka.client.region属性来定义。</p>
<pre><code class="language-java">public static String getRegion(EurekaClientConfig clientConfig) {
    String region = clientConfig.getRegion();
    if (region == null) {
        region = &quot;default&quot;;
    }
    region = region.trim().toLowerCase();
    return region;
}
</code></pre>
<p>通过 getAvailabi让tyZones函数，可以知道当我们没有特别为Region配置Zone的时候，将默认采用defaultZone , 这也是我们之前配置参数 eureka.client.serviceUrl.defaultZone的由来。 若要为应用指定Zone, 可以通过 eureka.client.availability-zones属性来进行设置。从该函数的return内容， 我们可以知道Zone能够设置多个，并且通过逗号分隔来配置。 由此， 我们可以判断<mark>Region与Zone是一对多的关系</mark>。</p>
<pre><code class="language-java">public String[] getAvailabilityZones(String region) {
    String value = (String)this.availabilityZones.get(region);
    if (value == null) {
        value = &quot;defaultZone&quot;;
    }
    return value.split(&quot;,&quot;);
}
</code></pre>
<p>在获取了Region和Zone的信息之后，才开始真正加载 Eureka Server 的具体地址。它根据传入的参数按 一定算法确定加载位于哪一个Zone配置的serviceUris。</p>
<pre><code class="language-java">int myZoneOffset = getZoneOffset(instanceZone, preferSameZone, availZones);
List&lt;String&gt; serviceUrls = clientConfig.getEurekaServerServiceUrls(availZones[myZoneOffset]);
</code></pre>
<p>具体获取 serviceUrls 的实现， 我们可以详细查看 getEurekaServerServiceUrls 函数的具体实现类 EurekaClientConfigBean, 该类是 EurekaClientConfig 和 EurekaConstants 接口的实现，用来加载配置文件中的内容。</p>
<pre><code class="language-java">public List&lt;String&gt; getEurekaServerServiceUrls(String myZone) {
    String serviceUrls = (String)this.serviceUrl.get(myZone);
    if (serviceUrls == null || serviceUrls.isEmpty()) {
        serviceUrls = (String)this.serviceUrl.get(&quot;defaultZone&quot;);
    }
    if (!StringUtils.isEmpty(serviceUrls)) {
        String[] serviceUrlsSplit = StringUtils.commaDelimitedListToStringArray(serviceUrls);
        List&lt;String&gt; eurekaServiceUrls = new ArrayList(serviceUrlsSplit.length);
        String[] var5 = serviceUrlsSplit;
        int var6 = serviceUrlsSplit.length;
        for(int var7 = 0; var7 &lt; var6; ++var7) {
            String eurekaServiceUrl = var5[var7];
            if (!this.endsWithSlash(eurekaServiceUrl)) {
                eurekaServiceUrl = eurekaServiceUrl + &quot;/&quot;;
            }
            eurekaServiceUrls.add(eurekaServiceUrl);
        }
        return eurekaServiceUrls;
    } else {
        return new ArrayList();
    }
}
</code></pre>
<p>当我们在微服务应用中使用 Ribbon 来实现服务调用时，Zone 的设置可以在负载均衡时实现区域亲和特性,，Ribbon 的默认策略会优先访问同客户端处于一个Zone中的服务端实例，只有当同一个Zone 中没有可用服务端实例的时候才会访问其他Zone中的实例。所以通过Zone属性的定义，配合实际部署的物理结构，我们就可以有效地设计出对区域性故障的容错集群。</p>
<h4 id="232-服务注册">2.3.2 服务注册</h4>
<p>在理解了多个服务注册中心信息的加载后，我们再回头看看 DiscoveryClient类是 如何实现<mark>服务注册</mark>行为的， 通过查看它的构造类，可以找到它调用了下面这个函数:</p>
<pre><code class="language-java">private void initScheduledTasks() {
    int renewalIntervalInSecs;
    int expBackOffBound;
    if (this.clientConfig.shouldFetchRegistry()) {
        renewalIntervalInSecs = this.clientConfig.getRegistryFetchIntervalSeconds();
        expBackOffBound = this.clientConfig.getCacheRefreshExecutorExponentialBackOffBound();
        //服务获取
        this.scheduler.schedule(new TimedSupervisorTask(&quot;cacheRefresh&quot;, this.scheduler, this.cacheRefreshExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new DiscoveryClient.CacheRefreshThread()), (long)renewalIntervalInSecs, TimeUnit.SECONDS);
    }
    if (this.clientConfig.shouldRegisterWithEureka()) {
        renewalIntervalInSecs = this.instanceInfo.getLeaseInfo().getRenewalIntervalInSecs();
        expBackOffBound = this.clientConfig.getHeartbeatExecutorExponentialBackOffBound();
        logger.info(&quot;Starting heartbeat executor: renew interval is: &quot; + renewalIntervalInSecs);
        //维持心跳，服务续约
        this.scheduler.schedule(new TimedSupervisorTask(&quot;heartbeat&quot;, this.scheduler, this.heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new DiscoveryClient.HeartbeatThread()), (long)renewalIntervalInSecs, TimeUnit.SECONDS);
        // 创建了一个InstanceinfoReplicator类的实例，它会执行一个定时任务进行服务注册
        this.instanceInfoReplicator = new InstanceInfoReplicator(this, this.instanceInfo, this.clientConfig.getInstanceInfoReplicationIntervalSeconds(), 2);
        this.statusChangeListener = new StatusChangeListener() {
            public String getId() {
                return &quot;statusChangeListener&quot;;
            }
            public void notify(StatusChangeEvent statusChangeEvent) {
                if (InstanceStatus.DOWN != statusChangeEvent.getStatus() &amp;&amp; InstanceStatus.DOWN != statusChangeEvent.getPreviousStatus()) {
                    DiscoveryClient.logger.info(&quot;Saw local status change event {}&quot;, statusChangeEvent);
                } else {
                    DiscoveryClient.logger.warn(&quot;Saw local status change event {}&quot;, statusChangeEvent);
                }
                DiscoveryClient.this.instanceInfoReplicator.onDemandUpdate();
            }
        };
        if (this.clientConfig.shouldOnDemandUpdateStatusChange()) {
            this.applicationInfoManager.registerStatusChangeListener(this.statusChangeListener);
        }
        this.instanceInfoReplicator.start(this.clientConfig.getInitialInstanceInfoReplicationIntervalSeconds());
    } else {
        logger.info(&quot;Not registering with Eureka server per configuration&quot;);
    }
}
</code></pre>
<p>其中创建了一个 InstanceinfoReplicator 类的实例， 它会执行一个定时任务， 而这个定时任务的具体工作可以查看该类的 run() 函数，具体如下所示:</p>
<pre><code class="language-java">public void run() {
    boolean var6 = false;

    ScheduledFuture next;
    label53: {
        try {
            var6 = true;
            this.discoveryClient.refreshInstanceInfo();
            Long dirtyTimestamp = this.instanceInfo.isDirtyWithTime();
            if (dirtyTimestamp != null) {
                this.discoveryClient.register();
                this.instanceInfo.unsetIsDirty(dirtyTimestamp);
                var6 = false;
            } else {
                var6 = false;
            }
            break label53;
        } catch (Throwable var7) {
            logger.warn(&quot;There was a problem with the instance info replicator&quot;, var7);
            var6 = false;
        } finally {
            if (var6) {
                ScheduledFuture next = this.scheduler.schedule(this, (long)this.replicationIntervalSeconds, TimeUnit.SECONDS);
                this.scheduledPeriodicRef.set(next);
            }
        }
        next = this.scheduler.schedule(this, (long)this.replicationIntervalSeconds, TimeUnit.SECONDS);
        this.scheduledPeriodicRef.set(next);
        return;
    }
    next = this.scheduler.schedule(this, (long)this.replicationIntervalSeconds, TimeUnit.SECONDS);
    this.scheduledPeriodicRef.set(next);
}
</code></pre>
<p>相信大家都发现了中scoveryClient.register () ; 这一行，真正触发调用注册的地方就在这里。 继续查看 register ()的实现内容，如下所示:</p>
<pre><code class="language-java">boolean register() throws Throwable {
    logger.info(&quot;DiscoveryClient_&quot; + this.appPathIdentifier + &quot;: registering service...&quot;);

    EurekaHttpResponse httpResponse;
    try {
        httpResponse = this.eurekaTransport.registrationClient.register(this.instanceInfo);
    } catch (Exception var3) {
        logger.warn(&quot;{} - registration failed {}&quot;, new Object[]{&quot;DiscoveryClient_&quot; + this.appPathIdentifier, var3.getMessage(), var3});
        throw var3;
    }

    if (logger.isInfoEnabled()) {
        logger.info(&quot;{} - registration status: {}&quot;, &quot;DiscoveryClient_&quot; + this.appPathIdentifier, httpResponse.getStatusCode());
    }

    return httpResponse.getStatusCode() == 204;
}
</code></pre>
<p>注册操作也是通过REST请求的方式进行的。同时， 我们能看到发起注册请求的时候， 传入了一个com.neflix.appinfo.Instanceinfo 对象，该对象就是注册时客户端给服务端的服务的元数据。</p>
<h4 id="233-服务获取和服务续约">2.3.3 服务获取和服务续约</h4>
<p>我们继续来看 DiscoveryClient 的initScheduledTasks 函 数，不难发现在其中还有两个定时任务， 分别是<mark>服务获取</mark>和<mark>服务续约</mark>。</p>
<p>服务获取任务相对于服务续约和服务注册任务更 为独立。服务续约与服务注册在同一个if逻辑中，这个不难理解，服务注册到 Eureka Server 后，自然需要一个心跳去续约， 防止被剔除， 所以它们肯定是成对出现的。 从源码中， 对于服务续约相关的时间控制参数有两个重要属性， 我们可以关注并根据需要来进行调整:</p>
<pre><code class="language-yml">#用于定义服务续约任务的调用间隔时间，默认为30秒
eureka.instance.lease-renewal-interval-in-seconds=30 
#用于定义服务失效的时间，默认为90秒
eureka.instance.lease-expiration-duration-in-seconds=90
</code></pre>
<p>其中 “ 服务续约 ” 的实现较为简单， 直接以REST请求的方式进行续约:</p>
<pre><code class="language-java">boolean renew() {
   try {
       EurekaHttpResponse&lt;InstanceInfo&gt; httpResponse = this.eurekaTransport.registrationClient.sendHeartBeat(this.instanceInfo.getAppName(), this.instanceInfo.getId(), this.instanceInfo, (InstanceStatus)null);
       logger.debug(&quot;{} - Heartbeat status: {}&quot;, &quot;DiscoveryClient_&quot; + this.appPathIdentifier, httpResponse.getStatusCode());
       if (httpResponse.getStatusCode() == 404) {
           this.REREGISTER_COUNTER.increment();
           logger.info(&quot;{} - Re-registering apps/{}&quot;, &quot;DiscoveryClient_&quot; + this.appPathIdentifier, this.instanceInfo.getAppName());
           return this.register();
       } else {
           return httpResponse.getStatusCode() == 200;
       }
   } catch (Throwable var3) {
       logger.error(&quot;{} - was unable to send heartbeat!&quot;, &quot;DiscoveryClient_&quot; + this.appPathIdentifier, var3);
       return false;
   }
}
</code></pre>
<p>而 “ 服务获取 ” 则复杂一些， 会根据是否是第一次获取发起不同的 REST 请求和相应 的处理。 具体的实现逻辑跟之前类似。</p>
<h4 id="234-服务注册中心处理">2.3.4 服务注册中心处理</h4>
<p>Eureka Server 对于各类 REST 请求的定义都位于 com.netflix.eureka.resources 包下。<br>
以 “服务注册“ 请求为例:</p>
<pre><code class="language-java"> @POST
@Consumes({&quot;application/json&quot;, &quot;application/xml&quot;})
public Response addInstance(InstanceInfo info,
                            @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) {
    logger.debug(&quot;Registering instance {} (replication={})&quot;, info.getId(), isReplication);
    // validate that the instanceinfo contains all the necessary required fields
    if (isBlank(info.getId())) {
        return Response.status(400).entity(&quot;Missing instanceId&quot;).build();
    } else if (isBlank(info.getHostName())) {
        return Response.status(400).entity(&quot;Missing hostname&quot;).build();
    } else if (isBlank(info.getIPAddr())) {
        return Response.status(400).entity(&quot;Missing ip address&quot;).build();
    } else if (isBlank(info.getAppName())) {
        return Response.status(400).entity(&quot;Missing appName&quot;).build();
    } else if (!appName.equals(info.getAppName())) {
        return Response.status(400).entity(&quot;Mismatched appName, expecting &quot; + appName + &quot; but was &quot; + info.getAppName()).build();
    } else if (info.getDataCenterInfo() == null) {
        return Response.status(400).entity(&quot;Missing dataCenterInfo&quot;).build();
    } else if (info.getDataCenterInfo().getName() == null) {
        return Response.status(400).entity(&quot;Missing dataCenterInfo Name&quot;).build();
    }

    // handle cases where clients may be registering with bad DataCenterInfo with missing data
    DataCenterInfo dataCenterInfo = info.getDataCenterInfo();
    if (dataCenterInfo instanceof UniqueIdentifier) {
        String dataCenterInfoId = ((UniqueIdentifier) dataCenterInfo).getId();
        if (isBlank(dataCenterInfoId)) {
            boolean experimental = &quot;true&quot;.equalsIgnoreCase(serverConfig.getExperimental(&quot;registration.validation.dataCenterInfoId&quot;));
            if (experimental) {
                String entity = &quot;DataCenterInfo of type &quot; + dataCenterInfo.getClass() + &quot; must contain a valid id&quot;;
                return Response.status(400).entity(entity).build();
            } else if (dataCenterInfo instanceof AmazonInfo) {
                AmazonInfo amazonInfo = (AmazonInfo) dataCenterInfo;
                String effectiveId = amazonInfo.get(AmazonInfo.MetaDataKey.instanceId);
                if (effectiveId == null) {
                    amazonInfo.getMetadata().put(AmazonInfo.MetaDataKey.instanceId.getName(), info.getId());
                }
            } else {
                logger.warn(&quot;Registering DataCenterInfo of type {} without an appropriate id&quot;, dataCenterInfo.getClass());
            }
        }
    }

    registry.register(info, &quot;true&quot;.equals(isReplication));
    return Response.status(204).build();  // 204 to be backwards compatible
}
</code></pre>
<p>在对注册信息进行了一堆校验之后，会调用org.springframework.cloud. netflix.eureka.server.InstanceRegistry对象中的register(Instanceinfo info, int leaseDuration, boolean isReplication)函数来进行服务注册:</p>
<pre><code class="language-java">public void register(InstanceInfo info, boolean isReplication) {
    this.handleRegistration(info, this.resolveInstanceLeaseDuration(info), isReplication);
    super.register(info, isReplication);
}
</code></pre>
<p>在注册函数中， 先调用handleRegistration中的publishEvent函数，将该新服务注册的事件传播出去， 然 后调用com.netflix.eureka.registry.AbstractlnstanceRegistry父类中的注册实现，将InstanceInfo中的元数据信息存储在 一个ConcurrentHashMap对象中。 正如我们之前所说的， 注册中心存储了两层Map结构， 第一层的key存储服务名:Instancelnfo中的appName属性， 第二层的key存储实例名: Instancelnfo中的 instanceid属性。</p>
<pre><code class="language-java">private final ConcurrentHashMap&lt;String, Map&lt;String, Lease&lt;InstanceInfo&gt;&gt;&gt; registry = new ConcurrentHashMap();

public void register(InstanceInfo registrant, int leaseDuration, boolean isReplication) {
    try {
        this.read.lock();
        Map&lt;String, Lease&lt;InstanceInfo&gt;&gt; gMap = (Map)this.registry.get(registrant.getAppName());
        EurekaMonitors.REGISTER.increment(isReplication);
        if (gMap == null) {
            ConcurrentHashMap&lt;String, Lease&lt;InstanceInfo&gt;&gt; gNewMap = new ConcurrentHashMap();
            gMap = (Map)this.registry.putIfAbsent(registrant.getAppName(), gNewMap);
            if (gMap == null) {
                gMap = gNewMap;
            }
       }
    Lease&lt;InstanceInfo&gt; existingLease = (Lease)((Map)gMap).get(registrant.getId());
    //...
    Lease&lt;InstanceInfo&gt; lease = new Lease(registrant, leaseDuration);
    if (existingLease != null) {
        lease.setServiceUpTimestamp(existingLease.getServiceUpTimestamp());
    }

    ((Map)gMap).put(registrant.getId(), lease);
</code></pre>
<h4 id="235-配置详解">2.3.5 配置详解</h4>
<p>Eureka客户端的配置主要分为以下两个方面。<br>
• 服务注册相关的配置信息， 包括服务注册中心的地址、 服务获取的间隔时间、 可用 区域等。<br>
• 服务实例相关的配置信息， 包括服务实例的名称、IP地址、 端口号、 健康检查路径<br>
等。</p>
<h5 id="服务注册类配置">服务注册类配置</h5>
<table>
<thead>
<tr>
<th>参数名</th>
<th>说明</th>
<th>默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td>enabled</td>
<td>启用Eureka客户端</td>
<td>true</td>
</tr>
<tr>
<td>registryFetchIntervalSeconds</td>
<td>从Eureka服务端获取注册信息的间隔时间，单位为秒</td>
<td>30</td>
</tr>
<tr>
<td>instancelnfoReplicationlntervalSeconds</td>
<td>更新实例信息的变化到E田eka服务端的间隔时间， 单位为秒</td>
<td>30</td>
</tr>
<tr>
<td>inItiallnstancelnfoRepIicationintervalSeconds</td>
<td>初始化实例信息到Eureka服务端的间隔时间，单位为秒</td>
<td>40</td>
</tr>
<tr>
<td>eurekaServiceUrlPolllntervalSeconds</td>
<td>轮询Eureka服务端地址更改的间隔时间，单位为秒</td>
<td>300</td>
</tr>
<tr>
<td>eurekaServerReadTimeoutSeconds</td>
<td>读取Eureka Server信息的超时时间， 单位为秒</td>
<td>8</td>
</tr>
<tr>
<td>eurekaServerConnectTimeoutSeconds</td>
<td>连接 Eureka Server的超时时间， 单位为秒</td>
<td>5</td>
</tr>
<tr>
<td>eurekaServerTotalConnections</td>
<td>从Eureka客户端到所有Eureka服务端的连接总数</td>
<td>200</td>
</tr>
<tr>
<td>eurekaServerTotalConnectionsPerHost</td>
<td>从Eureka客户端到每个Eureka服务端主机的连接总数</td>
<td>50</td>
</tr>
<tr>
<td>eurekaConnectionldleTimeoutSeconds</td>
<td>Eureka服务端连接的空闲关闭时间，单位为秒</td>
<td>30</td>
</tr>
<tr>
<td>heartbeatExecutorThreadPoolSize</td>
<td>心跳连接池的初始化线程数</td>
<td>2</td>
</tr>
<tr>
<td>heartbeatExecutorExponenttalBackOffBound</td>
<td>心跳超时重试延迟时间的最大乘数值</td>
<td>10</td>
</tr>
<tr>
<td>cacheRefreshExecutorThreadPoolSize</td>
<td>缓存刷新线程池的初始化线程数</td>
<td>2</td>
</tr>
<tr>
<td>cacheRefreshExecutorExponentialBackOffBound</td>
<td>缓存刷新重试延迟时间的最大乘数值</td>
<td>10</td>
</tr>
<tr>
<td>useDnsForFetchmgServerUrls</td>
<td>使用DNS来获取Eureka服务端的serviceUrl</td>
<td>false</td>
</tr>
<tr>
<td>registerWithEureka</td>
<td>是否要将自身的实例信息注册到Eureka服务端</td>
<td>true</td>
</tr>
<tr>
<td>preferSameZoneEureka</td>
<td>是否偏好使用处于相同Zone的Eureka服务端</td>
<td>true</td>
</tr>
<tr>
<td>filterOnlyUplnstances</td>
<td>获取实例时是否过滤，仅保留UP状态的实例</td>
<td>true</td>
</tr>
<tr>
<td>fetchRegistry</td>
<td>是否从 Eureka服务端获取注册信息</td>
<td>true</td>
</tr>
</tbody>
</table>
<h5 id="服务实例类配置">服务实例类配置</h5>
<h2 id="三-客户端负载均衡-ribbon">三 客户端负载均衡: Ribbon</h2>
<p>Spring Cloud Ribbon 是一个基于HTTP和TCP的客户端负载均衡工具，它基于 Netflix ribbon实现。 通过SpringCloud的封装，可以让我们轻松地将面向服务的REST模板请求 自动转换成客户端负载均衡的服务调用。</p>
<h3 id="31-客户端负载均衡">3.1 客户端负载均衡</h3>
<p>我们通常所说的负 载均衡都指的是服务端负载均衡，其中分为硬件负载均衡和软件负载均衡。 硬件负载均衡 主要通过在服务器节点之间安装专门用于负载均衡的设备，比如 F5 等;而软件负载均衡则 是通过在服务器上安装一 些具有均衡负载功能或模块的软件来完成请求分发工作， 比如 Nginx 等。 不论采用硬件负载均衡还是软件负载均衡，只要是服务端负载均衡都能以类似 下图的架构方式构建起来:<br>
<img src="https://q456qq520.github.io/post-images/1677991001866.png" alt="" loading="lazy"></p>
<p>硬件负载均衡的设备或是软件负载均衡的软件模块都会维护一个下挂可用的服务端清单，通过心跳检测来剔除故障的服务端节点以保证清单中都是可以正常访问的服务端节点。 当客户端发送请求到负载均衡设备的时候 ，该设备按某种算法(比如线性轮询、按权重负载、按流量负载等)从维护的可用服务端清单中取出一台服务端的地址， 然后进行转发。</p>
<p>而客户端负载均衡和服务端负载均衡最大的不同点在千上面所提到的服务清单所存储的位置。 在客户端负载均衡中，所有客户端节点都维护着自己要访问的服务端清单， 而这些 服务端的清单来自于服务注册中心，比如的Eureka服务端。同服务端负载均衡的架构类似，在客户端负载均衡中也需要心跳去维护服务端清单的健康性， 只是这个步骤 需要与服务注册中心配合完成。在SpringCloud实现的服务治理框架中，默认会创建针对各 个服务治理框架的ribbon自动化整合配置，比如Eureka中的org.springframework. cloud.netflix.ribbon.eureka. RibbonEurekaAutoConfiguration,Consul 中的org.springframework.cloud.consul.discovery. RibbonConsulAuto- Configuration。</p>
<p>通过Spring CloudRibbon的封装， 我们在微服务架构中使用客户端负载均衡调用非常简单， 只需要如下两步:</p>
<ol>
<li>服务提供者只需要启动多个服务实例并注册到一个注册中心或是多个相关联的服务 注册中心。</li>
<li>服务消费者直接通过调用被@LoadBalanced注解修饰过的 RestTemplate 来实现面向服务的接口调用。</li>
</ol>
<h3 id="32-resttemplate-详解">3.2 RestTemplate 详解</h3>
<p>RestTemplate会使用 Ribbon 的自动化配置， 同时通过配置@LoadBalanced 还能够开启客户端负载均衡。RestTemplate针对几种不同请求类型和参数类型的服务调用实现如下。</p>
<h4 id="321-get请求">3.2.1 GET请求</h4>
<p>在RestTemplate中，对GET 请求可以通过如下两个方法进行调用实现。</p>
<p>第一种: <mark>getForEntity函数</mark>。该方法返回的是ResponseEntity, 该对象是 Spring 对 HTTP 请求响应的封装， 其中主要存储了 HTTP 的几个重要元素， 比如 HTTP 请求状态 码的枚举对象 HttpStatus (也就是我们常说的 404、 500 这些错误码)、 在它的父类 HttpEntity 中还存储着 HTTP 请求的头信息对象 HttpHeaders 以及泛型类型的请求体对象。</p>
<p>比如下面的例子，就是访问USER-SERVER服务的/user请求，同时最后一个参数 didi 会替换 url 中的{1} 占位符，而返回的 ResponseEntity 对象中的 body 内容类型 会根据第二个参数转换为String类型。getForEntity 函数实际上提供了以下三种不同的重载实现。</p>
<ol>
<li>getForEntity(String url, Class responseType, Object... urlVariables):该方法提供 了三个参数，其中 url 为请求的地址，responseType为请求响应体body的包装类型，urlVariables为url中的参数绑定。</li>
<li>getForEntity(String url, Class responseType, Map urlVariables):该方法提供的参数中， 只有 urlVariables 的参数类型与上面的方法不同。这里使用了Map类型，所以使用该方法进行参数绑定时需要在占位符中指定Map中参数的 key 值。</li>
<li>getForEntity(UR工 url, Class responseType): 该方法使用URI 对象来 替代之前的 url 和 urlVariables 参数来指定访问地址和参数绑定。 URI 是 JDK java.net 包下的一个类，它表示一个统一 资源标识符 (Uniform Resource Identifier)引用。</li>
</ol>
<p>第二种: getForObject 函数。该方法可以理解为对 getForEntity的进一步封装， 它通过 HttpMessageConverterExtractor 对 HTTP 的请求响应体 body内容进行对象转换，实现请求直接返回包装好的对象内容。</p>
<h4 id="322-post请求">3.2.2 POST请求</h4>
<p>在 RestTemplate 中， 对 POST请求时可以通过如下三个方法进行调用实现。</p>
<p>第一种: postForEntity 函数。该方法同 GET 请求中的 getForEntity 类似， 会在调用后返回 ResponseEntity<T>对象， 其中T为请求响应的 body类型。<br>
第二种: postForObject 函数。</p>
<h4 id="323-put请求">3.2.3 PUT请求</h4>
<p>在RestTemplate中，对PUT请求可以通过put方法 进行调用实现，比如:</p>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate ();
Long id = 100011;
User user = new User(&quot;didi&quot;, 40); restTemplate.put(&quot;http://USER-SERVICE/user/{l}&quot;, user, id);
</code></pre>
<p>• put(String url, Object request, Object... urlVariables)<br>
• put(String url, Object request, Map urlVariables)<br>
• put(URI url, Object request)</p>
<h4 id="324-delete请求">3.2.4 DELETE请求</h4>
<p>在RestTemplate中，对DELETE请求可以通过delete方法进行调用实现，比如:</p>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate();
Long id= 10001L; 
restTemplate.delete(&quot;http://USER-SERVICE/user/{1)&quot;, id);
</code></pre>
<p>• delete(String url, Object ... urlVariables)<br>
• delete(String url, Map urlVariables)<br>
• delete(URI url)</p>
<h3 id="33-源码分析">3.3 源码分析</h3>
<p>RestTemplate 不是 Spring自己就提供的吗?跟Ribbon的客户端负载均衡又有什么关系呢?接下来看看Ribbon是如何通过 RestTemplate 实现客户端负载均衡的。</p>
<p>从<code>@LoadBalanced</code>注解源码的注释中可以知道， 该注解用来给RestTemplate做标记， 以使用负载均衡的客户端(LoadBalancerClient)来配置它。</p>
<p>通过搜索LoadBalancerClient可以发现 ， 这 是SpringCloud中定义的一个接口 :</p>
<pre><code class="language-java">public interface LoadBalancerClient extends ServiceInstanceChooser {
    &lt;T&gt; T execute(String var1, LoadBalancerRequest&lt;T&gt; var2) throws IOException;

    &lt;T&gt; T execute(String var1, ServiceInstance var2, LoadBalancerRequest&lt;T&gt; var3) throws IOException;

    URI reconstructURI(ServiceInstance var1, URI var2);
}

public interface ServiceInstanceChooser {
    ServiceInstance choose(String var1);
}
</code></pre>
<p>从该接口中，我们可以通过定义的抽象方法来了解客户端负载均衡器中应具备的几种能力。</p>
<ul>
<li>ServiceInstance choose(String var1)：根据传入的服务名 serviceld,从负载均衡器中挑选一个对应服务的实例。</li>
<li>T execute(String var1, LoadBalancerRequest<T> var2)：使用从负载均衡器中挑选出的服务实例来执行请求内容。</li>
<li><T> T execute(String var1, ServiceInstance var2, LoadBalancerRequest<T> var3) ：使用从负载均衡器中挑选出指定的服务实例来执行请求内容。</li>
<li>URI reconstructURI(ServiceInstance var1, URI var2)：为系统构建一个合适的host:post形式的URI。</li>
</ul>
<blockquote>
<p>ServiceInstance对象是带有host和port的具体服务实例 ， 而URI入参对象则是使用逻辑服务名定义为host的URI , 而返回的URI内容则是通过ServiceInstance的服务实例详情拼接出的具体host:post形式的请求地址。</p>
</blockquote>
<p>顺着LoadBalancerClient接口的所属包org .springframework.cloud.client.loadbalancer, 我们对其内容进行整理， 可以得出如下图所示的关系。<br>
<img src="https://q456qq520.github.io/post-images/1677995464270.png" alt="" loading="lazy"></p>
<p>其中，LoadBalancerAutoConfiguration 为实现客户端负载均衡器的自动化配置类。</p>
<pre><code class="language-java">@Configuration
@ConditionalOnClass({RestTemplate.class})
@ConditionalOnBean({LoadBalancerClient.class})
@EnableConfigurationProperties({LoadBalancerRetryProperties.class})
public class LoadBalancerAutoConfiguration {
    @LoadBalanced
    @Autowired( required = false)
    private List&lt;RestTemplate&gt; restTemplates = Collections.emptyList();
    @Autowired(required = false)
    private List&lt;LoadBalancerRequestTransformer&gt; transformers = Collections.emptyList();
    @Bean
    public SmartInitializingSingleton loadBalancedRestTemplateInitializer(final List&lt;RestTemplateCustomizer&gt; customizers) {
        return new SmartInitializingSingleton() {
            public void afterSingletonsInstantiated() {
                Iterator var1 = LoadBalancerAutoConfiguration.this.restTemplates.iterator();

                while(var1.hasNext()) {
                    RestTemplate restTemplate = (RestTemplate)var1.next();
                    Iterator var3 = customizers.iterator();

                    while(var3.hasNext()) {
                        RestTemplateCustomizer customizer = (RestTemplateCustomizer)var3.next();
                        customizer.customize(restTemplate);
                    }
                }
            }
        };
    }

    @Bean
    @ConditionalOnMissingBean
    public LoadBalancerRequestFactory loadBalancerRequestFactory(LoadBalancerClient loadBalancerClient) {
        return new LoadBalancerRequestFactory(loadBalancerClient, this.transformers);
    }
    
    @Configuration
    @ConditionalOnClass({RetryTemplate.class})
    public static class RetryInterceptorAutoConfiguration {
        public RetryInterceptorAutoConfiguration() {
        }

        @Bean
        @ConditionalOnMissingBean
        public RetryLoadBalancerInterceptor ribbonInterceptor(LoadBalancerClient loadBalancerClient, LoadBalancerRetryProperties properties, LoadBalancedRetryPolicyFactory lbRetryPolicyFactory, LoadBalancerRequestFactory requestFactory, LoadBalancedBackOffPolicyFactory backOffPolicyFactory) {
            return new RetryLoadBalancerInterceptor(loadBalancerClient, properties, lbRetryPolicyFactory, requestFactory, backOffPolicyFactory);
        }

        @Bean
        @ConditionalOnMissingBean
        public RestTemplateCustomizer restTemplateCustomizer(final RetryLoadBalancerInterceptor loadBalancerInterceptor) {
            return new RestTemplateCustomizer() {
                public void customize(RestTemplate restTemplate) {
                    List&lt;ClientHttpRequestInterceptor&gt; list = new ArrayList(restTemplate.getInterceptors());
                    list.add(loadBalancerInterceptor);
                    restTemplate.setInterceptors(list);
                }
            };
        }
    }

    @Configuration
    @ConditionalOnMissingClass({&quot;org.springframework.retry.support.RetryTemplate&quot;})
    static class LoadBalancerInterceptorConfig {
        LoadBalancerInterceptorConfig() {
        }

        @Bean
        public LoadBalancerInterceptor ribbonInterceptor(LoadBalancerClient loadBalancerClient, LoadBalancerRequestFactory requestFactory) {
            return new LoadBalancerInterceptor(loadBalancerClient, requestFactory);
        }

        @Bean
        @ConditionalOnMissingBean
        public RestTemplateCustomizer restTemplateCustomizer(final LoadBalancerInterceptor loadBalancerInterceptor) {
            return new RestTemplateCustomizer() {
                public void customize(RestTemplate restTemplate) {
                    List&lt;ClientHttpRequestInterceptor&gt; list = new ArrayList(restTemplate.getInterceptors());
                    list.add(loadBalancerInterceptor);
                    restTemplate.setInterceptors(list);
                }
            };
        }
    }
}
</code></pre>
<p>从LoadBalancerAutoConfiguration类头上的注解可以知道， Ribbon实现的负载均衡自动化配置需要满足下面条件。</p>
<ul>
<li>@ConditionalOnClass( RestTemplate.class): RestTemplate类必须存在当前工程的环境中。</li>
<li>@ConditionalOnBean(LoadBalancerClient.class): 在Spring的Bean工厂中必须有LoadBalancerClient的实现Bean。</li>
</ul>
<p>在该自动化配置类中， 主要做了下面三件事:</p>
<ul>
<li>创建了一个LoadBalancerInterceptor的Bean, 用于实现对客户端发起请时进行拦截， 以实现客户端负载均衡。</li>
<li>创建了一个RestTemplateCustomizer的Bean, 用于给RestTemplate增加 LoadBalancerInterceptor拦截器。</li>
<li>维护了一个被@LoadBalanced 注解修饰的RestTemplate对象列表，并在这里进行初始化，通过调用RestTemplateCustomizer的实例来给需要客户端负载均衡的RestTemplate增加LoadBalancerinterceptor拦截器。</li>
</ul>
<p>接下来， 我们看看LoadBalancerInterceptor 拦截器是如何将一个普通的RestTemplate变成客户端负载均衡的:</p>
<pre><code class="language-java">public class LoadBalancerInterceptor implements ClientHttpRequestInterceptor {
    private LoadBalancerClient loadBalancer;
    private LoadBalancerRequestFactory requestFactory;

    public LoadBalancerInterceptor(LoadBalancerClient loadBalancer, LoadBalancerRequestFactory requestFactory) {
        this.loadBalancer = loadBalancer;
        this.requestFactory = requestFactory;
    }

    public LoadBalancerInterceptor(LoadBalancerClient loadBalancer) {
        this(loadBalancer, new LoadBalancerRequestFactory(loadBalancer));
    }

    public ClientHttpResponse intercept(HttpRequest request, byte[] body, ClientHttpRequestExecution execution) throws IOException {
        URI originalUri = request.getURI();
        String serviceName = originalUri.getHost();
        Assert.state(serviceName != null, &quot;Request URI does not contain a valid hostname: &quot; + originalUri);
        return (ClientHttpResponse)this.loadBalancer.execute(serviceName, this.requestFactory.createRequest(request, body, execution));
    }
}
</code></pre>
<p>我们可以看到在拦截器中注入了LoadBalancerClient的实现。 当一个被@LoadBalanced注解修饰的 RestTemplate 对象向外发起HTTP请求时， 会被LoadBalancerInterceptor 类的 <code>intercept</code> 函数所拦截。 由于我们在使用RestTemplate时采用了服务名作为host, 所以直接从 <code>HttpRequest</code>的URI对象中 通过 <code>getHost ()</code>就可以拿到服务名，然后调用 <code>execute</code> 函数去根据服务名来选择实例并发起实际的请求。</p>
<p>分析到这里，LoadBalancerClient还只是一个抽象的负载均衡器接口 所以我们还需要找到它的具体实现类来进一步进行分析。通过查看Ribbon的源码，可以很容易地在 org.springframework.cloud.netflix.ribbon 包下找到对应的实现类Ribbon­LoadBalancerClient。</p>
<blockquote>
<p>org.springframework.cloud.netflix.ribbon.RibbonLoadBalancerClient</p>
</blockquote>
<pre><code class="language-java">public &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request) throws IOException {
    ILoadBalancer loadBalancer = this.getLoadBalancer(serviceId);
    Server server = this.getServer(loadBalancer);
    if (server == null) {
        throw new IllegalStateException(&quot;No instances available for &quot; + serviceId);
    } else {
        RibbonLoadBalancerClient.RibbonServer ribbonServer = new RibbonLoadBalancerClient.RibbonServer(serviceId, server, this.isSecure(server, serviceId), this.serverIntrospector(serviceId).getMetadata(server));
        return this.execute(serviceId, ribbonServer, request);
    }
}

public &lt;T&gt; T execute(String serviceId, ServiceInstance serviceInstance, LoadBalancerRequest&lt;T&gt; request) throws IOException {
    Server server = null;
    if (serviceInstance instanceof RibbonLoadBalancerClient.RibbonServer) {
        server = ((RibbonLoadBalancerClient.RibbonServer)serviceInstance).getServer();
    }

    if (server == null) {
        throw new IllegalStateException(&quot;No instances available for &quot; + serviceId);
    } else {
        RibbonLoadBalancerContext context = this.clientFactory.getLoadBalancerContext(serviceId);
        RibbonStatsRecorder statsRecorder = new RibbonStatsRecorder(context, server);

        try {
            T returnVal = request.apply(serviceInstance);
            statsRecorder.recordStats(returnVal);
            return returnVal;
        } catch (IOException var8) {
            statsRecorder.recordStats(var8);
            throw var8;
        } catch (Exception var9) {
            statsRecorder.recordStats(var9);
            ReflectionUtils.rethrowRuntimeException(var9);
            return null;
        }
    }
}
</code></pre>
<p>可以看到，在execute函数的实现中，第一步做的就是通过<code>getServer</code>根据传入的服务名<code>serviceId</code>去获得具体的服务实例:</p>
<pre><code class="language-java">protected Server getServer(ILoadBalancer loadBalancer) {
    return loadBalancer == null ? null : loadBalancer.chooseServer(&quot;default&quot;);
}
</code></pre>
<p>通过getServer函数的实现源码， 我们可以看到这里获取具体服务实例的时候并没 有使用LoadBalancerClient接口中的choose函数，而是使用了Netflix Ribbon自身的<code>ILoadBalancer接口</code>中定义的<code>chooseServer</code>函数。</p>
<p>我们先来认识一下这个 ILoadBalancer 接口:</p>
<pre><code class="language-java">public interface ILoadBalancer {
    //向负载均衡器中维护的实例列表增加服务实例。
    void addServers(List&lt;Server&gt; var1);
    //通过某种策略， 从负载均衡器中挑选出一个具体的服务实例。
    Server chooseServer(Object var1);
    //用来通知和标识负载均衡器中某个具体实例已经停止服务，不然负载均衡器在下一次获取服务实例清单前都会认为服务实例均是正常服务的。
    void markServerDown(Server var1);

    /** @deprecated */
    @Deprecated
    List&lt;Server&gt; getServerList(boolean var1);
    //获取当前正常服务的实例列表。
    List&lt;Server&gt; getReachableServers();
    //获取所有已知的服务实例列表， 包括正常服务和停止服务的实例。
    List&lt;Server&gt; getAllServers();
}
</code></pre>
<p>在该接口定义中涉及的Server对象定义是一个传统的服务端节点， 在该类中存储了服务端节点的一些元数据信息， 包括 host、 port 以及一 些部署信息等。</p>
<pre><code class="language-java">public class Server {
    public static final String UNKNOWN_ZONE = &quot;UNKNOWN&quot;;
    private String host;
    private int port;
    private String scheme;
    private volatile String id;
    private volatile boolean isAliveFlag;
    private String zone;
    private volatile boolean readyToServe;
    private Server.MetaInfo simpleMetaInfo;
</code></pre>
<p>而对于该接口的实现，有出如下图所示的结构。可以看到，BaseLoadBalancer类实现了基础的负载均衡，而 DynamicServerListLoaclBalancer和ZoneAwareLoaclBalancer在负载均衡的策略上做了一些功能的扩展。<br>
<img src="https://q456qq520.github.io/post-images/1677996949186.png" alt="" loading="lazy"></p>
<p>那么在整合ribbon的时候Spring Cloud默认采用了哪个具体实现呢?我们通ribbonClientConfiguration配置类，可以知道在整合时默认采用了ZoneAware­LoadBalancer来实现负载均衡器。</p>
<blockquote>
<p>`org.springframework.cloud.netflix.ribbon.ribbonClientConfiguration</p>
</blockquote>
<pre><code class="language-java">@Bean
@ConditionalOnMissingBean
public ILoadBalancer ribbonLoadBalancer(IClientConfig config, ServerList&lt;Server&gt; serverList, ServerListFilter&lt;Server&gt; serverListFilter, IRule rule, IPing ping, ServerListUpdater serverListUpdater) {
    return (ILoadBalancer)(this.propertiesFactory.isSet(ILoadBalancer.class, this.name) ? (ILoadBalancer)this.propertiesFactory.get(ILoadBalancer.class, config, this.name) : new ZoneAwareLoadBalancer(config, rule, ping, serverList, serverListFilter, serverListUpdater));
}
</code></pre>
<p>下面，我们再回到RibbonLoadBalancerClient的execute函数逻辑，在通过ZoneAwareLoadBalancer 的chooseServer函数获取了负载均衡策略分配到的服务实例对象Server之后，将其内容包装成<code>ribbonServer</code>对象(该对象除了存储了服务 实例的信息之外， 还增加了服务名serviceId、 是否需要使用 HTTPS 等其他信息)，然后使用该对象再回调LoadBalancerinterceptor请求拦截器中 LoadBalancerRequest的 <code>apply(final ServiceinsIance instance)</code>函数， 向一个实际的具体服务实例发起请求，从而实现一开始以服务名为host的URI请求到host:post 形式的实际访问地址的转换。</p>
<p>在apply(final Serviceinstance instance) 函数中传入的Serviceinstance接口对象是对服务实例的抽象定义。在该接口中暴露了服务治理系统中每个服务实例需要提供的一些基本信息，比如serviceld、 host、port等，具体定义如下:</p>
<pre><code class="language-java">public interface ServiceInstance {
    String getServiceId();

    String getHost();

    int getPort();

    boolean isSecure();

    URI getUri();

    Map&lt;String, String&gt; getMetadata();
}
</code></pre>
<p>而上面提到的具体包装Server服务实例的RibbonServer对象就是ServiceInstance接口的实现， 可以看到它除了包含Server对象之外， 还存储了服务名、是否使用HTTPS标识以及一个Map类型的元数据集合。</p>
<pre><code class="language-java">public static class RibbonServer implements ServiceInstance {
    private final String serviceId;
    private final Server server;
    private final boolean secure;
    private Map&lt;String, String&gt; metadata;

    public RibbonServer(String serviceId, Server server) {
        this(serviceId, server, false, Collections.emptyMap());
    }

    public RibbonServer(String serviceId, Server server, boolean secure, Map&lt;String, String&gt; metadata) {
        this.serviceId = serviceId;
        this.server = server;
        this.secure = secure;
        this.metadata = metadata;
    }
</code></pre>
<p>那么apply (final Serviceinstance instance)函数在接收到了具体ServiceInstance实例后，是如何通过 LoadBalancerClient 接口中的<code>reconstructURI</code>操作来组织具体请求地址的呢?</p>
<pre><code class="language-java">public LoadBalancerRequest&lt;ClientHttpResponse&gt; createRequest(final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) {
    return new LoadBalancerRequest&lt;ClientHttpResponse&gt;() {
        public ClientHttpResponse apply(ServiceInstance instance) throws Exception {
            HttpRequest serviceRequest = new ServiceRequestWrapper(request, instance, LoadBalancerRequestFactory.this.loadBalancer);
            LoadBalancerRequestTransformer transformer;
            if (LoadBalancerRequestFactory.this.transformers != null) {
                for(Iterator var3 = LoadBalancerRequestFactory.this.transformers.iterator(); var3.hasNext(); serviceRequest = transformer.transformRequest((HttpRequest)serviceRequest, instance)) {
                    transformer = (LoadBalancerRequestTransformer)var3.next();
                }
            }

            return execution.execute((HttpRequest)serviceRequest, body);
        }
    };
}
</code></pre>
<p>可以看到它具体执行的时候，还传入了<code>ServiceRequest­Wrapper</code>对象，该对象继承了HttpRequestWrapper并重写了<code>getURI</code>函数，重写后的getURI通过调用LoadBalancerClient接口的 reconstructURI 函数来重新构建一个URI来进行访问。</p>
<p>在 LoadBalancerinterceptor 拦截器中， ClientHttpRequestExecution 的实例 具体执行 execution.execute(serviceRequest, body) 时， 会调用 Intercepting­ ClientHttpRequest 下 InterceptingRequestExecution 类的 execute 函数</p>
<pre><code class="language-java">public class ServiceRequestWrapper extends HttpRequestWrapper {
    private final ServiceInstance instance;
    private final LoadBalancerClient loadBalancer;

    public ServiceRequestWrapper(HttpRequest request, ServiceInstance instance, LoadBalancerClient loadBalancer) {
        super(request);
        this.instance = instance;
        this.loadBalancer = loadBalancer;
    }

    public URI getURI() {
        URI uri = this.loadBalancer.reconstructURI(this.instance, this.getRequest().getURI());
        return uri;
    }
}
</code></pre>
<p>此时，它就会使用 <code>RibbonLoadBalancerClient</code> 中实现的 reconstructURI 来组织具体请求的服务实例地址。</p>
<pre><code class="language-java">public URI reconstructURI(ServiceInstance instance, URI original) {
    Assert.notNull(instance, &quot;instance can not be null&quot;);
    String serviceId = instance.getServiceId();
    RibbonLoadBalancerContext context = this.clientFactory.getLoadBalancerContext(serviceId);
    Server server = new Server(instance.getHost(), instance.getPort());
    IClientConfig clientConfig = this.clientFactory.getClientConfig(serviceId);
    ServerIntrospector serverIntrospector = this.serverIntrospector(serviceId);
    URI uri = RibbonUtils.updateToHttpsIfNeeded(original, clientConfig, serverIntrospector, server);
    return context.reconstructURIWithServer(server, uri);
}
</code></pre>
<p>从 reconstructURI 函数中我们可以看到，它通过 ServiceInstance实例对象的 serviceid, 从 SpringeClientFactory 类的clientFactory对象 中获取对应 serviceId 的负载均衡器的上下文ribbonLoadBalancerContext对象。然后根据 ServiceInstance 中的信息来构建具体服务实例信息的 Server 对象，并使用 RibbonLoadBalancerContext对象的reconstructURIWithServer函数来构建服 务实例的URI。</p>
<p>简单介绍一 下上面提到的 SpringClientFactory 和 RibbonLoad­BalancerContext:<br>
• SpringClientFactory 类是一个用来创建客户端负载均衡器的工厂类， 该工厂类会为每一个不同名的 Ribbon客户端生成不同的 Spring 上下文。<br>
• RibbonLoadBalancerContext 类是 LoadBalancerContext的子类， 该类用与存储一些被负载均衡器 使用的上下文内容和API操作(reconstructURIWithServer就是其中之一)。</p>
<p>从reconstructURIWithServer的实现中我们可以看到，它同reconstructURI的定义类似。 只是reconstructURI的第一个保存具体服务实例的参数使用了Spring Cloud定义的ServiceInstance, 而reconstructURIWithServer中使用了Netflix中定义的 Server, 所以在 RibbonLoadBalancerClient 实现 reconstructURI 的 时候， 做了一次转换，使用Serviceinstance的host和port信息构建了 一 个 Server 对象来给reconstructURIWithServer使用。</p>
<p>从reconstructURIWithServer的 实现逻辑中， 我们可以看到， 它从 Server 对象中获取 host 和 port 信息， 然后根据以服务名为 host 的 URI 对象original中获取其他请求信息， 将两者内容进行拼接整合，形成最终要访间的服务实例的具体地址。</p>
<pre><code class="language-java">public URI reconstructURIWithServer(Server server, URI original) {
    String host = server.getHost();
    int port = server.getPort();
    String scheme = server.getScheme();
    if (host.equals(original.getHost()) &amp;&amp; port == original.getPort() &amp;&amp; scheme == original.getScheme()) {
        return original;
    } else {
        if (scheme == null) {
            scheme = original.getScheme();
        }

        if (scheme == null) {
            scheme = (String)this.deriveSchemeAndPortFromPartialUri(original).first();
        }

        try {
            StringBuilder sb = new StringBuilder();
            sb.append(scheme).append(&quot;://&quot;);
            if (!Strings.isNullOrEmpty(original.getRawUserInfo())) {
                sb.append(original.getRawUserInfo()).append(&quot;@&quot;);
            }

            sb.append(host);
            if (port &gt;= 0) {
                sb.append(&quot;:&quot;).append(port);
            }

            sb.append(original.getRawPath());
            if (!Strings.isNullOrEmpty(original.getRawQuery())) {
                sb.append(&quot;?&quot;).append(original.getRawQuery());
            }

            if (!Strings.isNullOrEmpty(original.getRawFragment())) {
                sb.append(&quot;#&quot;).append(original.getRawFragment());
            }

            URI newURI = new URI(sb.toString());
            return newURI;
        } catch (URISyntaxException var8) {
            throw new RuntimeException(var8);
        }
    }
}
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1678069909739.png" alt="" loading="lazy"></figure>
<p>另外，从ribbonLoadBalancerClient的execute函数逻辑中，我们还能看到在回调拦截器中， 执行具体的请求之后，Ribbon还通过ribbonStatsRecorder对象对服务的请求进行了跟踪记录。</p>
<h3 id="34-负载均衡器">3.4 负载均衡器</h3>
<p>虽然SpringCloud中定义了LoadBalancerClient作为负载均衡器的通用接口， 并且针对Ribbon实现了ribbonLoadBalancerClient，但是它在具体实现客户端负载均衡时，是通过ribbon的ILoadBalancer接口实现的。</p>
<p>下面我们根据ILoadBalancer接口的实现类逐个看看它是如何实现客户端负载均衡的。</p>
<h4 id="341-abstractloadbalancer">3.4.1 AbstractloadBalancer</h4>
<p>AbstractLoadBalancer是ILoadBalancer接口的抽象实现。在该抽象类中定义了一个关于服务实例的分组枚举类 ServerGroup, 它包含三种不同类型。还实现了一个chooseServer()函数， 该函数通过调用接口中的chooseServer (Objectkey)实现， 其中参数key为null, 表示在选择具体服务实例时忽略key的条件判断。</p>
<pre><code class="language-java">public abstract class AbstractLoadBalancer implements ILoadBalancer {
    public AbstractLoadBalancer() {
    }

    public Server chooseServer() {
        return this.chooseServer((Object)null);
    }

    public abstract List&lt;Server&gt; getServerList(AbstractLoadBalancer.ServerGroup var1);

    public abstract LoadBalancerStats getLoadBalancerStats();

    public static enum ServerGroup {
        //所有服务实例
        ALL,
        //正常服务的实例
        STATUS_UP,
        //停止服务的实例
        STATUS_NOT_UP;

        private ServerGroup() {
        }
    }
}
</code></pre>
<p>最后， 还定义了两个抽象函数。<br>
• getServerList(ServerGroup serverGroup): 定义了根据分组类型来获取不同的服务实例的列表。<br>
• getLoadBalancerStats(): 定义了获取LoadBalancerStats 对象的方法，LoadBalancerStats对象被用来存储负载均衡器中各个服务实例当前的属性和统计信息。这些信息非常有用，我们可以利用这些信息来观察负载均衡器的运行情况，同时这些信息也是用来制定负载均衡策略的重要依据。</p>
<h4 id="342-baseloadbalancer">3.4.2 BaseloadBalancer</h4>
<p>BaseLoadBalancer类是ribbon负载均衡器的基础实现类，在该类中定义了很多关 于负载均衡器相关的基础内容。</p>
<ul>
<li>定义并维护了两个存储服务实例Server对象的列表。 一个用与存储所有服务实例的清单， 一个用于存储正常服务的实例清单。</li>
</ul>
<pre><code class="language-java">@Monitor(
    name = &quot;LoadBalancer_AllServerList&quot;,
    type = DataSourceType.INFORMATIONAL
)
protected volatile List&lt;Server&gt; allServerList;
@Monitor(
    name = &quot;LoadBalancer_UpServerList&quot;,
    type = DataSourceType.INFORMATIONAL
)
protected volatile List&lt;Server&gt; upServerList;
</code></pre>
<ul>
<li>
<p>定义了用来存储负载均衡器各服务实例属性和统计信息的LoadBalancerStats对象。</p>
</li>
<li>
<p>定义了检查服务实例是否正常服务的IPing对象，在BaseLoadBalancer中默认为null, 需要在构造时注入它的具体实现。</p>
</li>
<li>
<p>定义了检查服务实例操作的执行策略对象IPingStrategy,在BaseLoadBalancer中默认使用了该类中定义的静态内部类SerialPingStrategy实现。</p>
</li>
<li>
<p>定义了负载均衡的处理规则IRule对象，从BaseLoadBalancer中chooseServer(Object key) 的实现源码，我们可以知道，负载均衡器实际将服务实例选择任务委托给了IRule实例中的choose函数来实现。 而在这里， 默认初始化了RoundRobinRule为IRule 的实现对象。RoundRobinRule实现了最基本且常用的线性负载均衡规则。</p>
</li>
<li>
<p>启动ping任务:在BaseLoadBalancer的默认构造函数中，会直接启动一个用于定时检查 Server是否健康的任务。 该任务默认的执行间隔为10秒。</p>
</li>
<li>
<p>实现了ILoadBalancer接口定义的负载均衡器应具备以下一系列基本操作。<br>
1、addServers(List newServers): 向负载均衡器中增加新的服务实例列表。<br>
2、chooseServer(Object key): 挑选一个具体的服务实例。<br>
3、markServerDown(Server server): 标记某个服务实例暂停服务。<br>
4、getReachableServers(): 获取可用的服务实例列表。<br>
5、getA11Servers (): 获取所有的服务实例列表。</p>
</li>
</ul>
<pre><code class="language-java">public void addServers(List&lt;Server&gt; newServers) {
    if (newServers != null &amp;&amp; newServers.size() &gt; 0) {
        try {
            ArrayList&lt;Server&gt; newList = new ArrayList();
            newList.addAll(this.allServerList);
            newList.addAll(newServers);
            this.setServersList(newList);
        } catch (Exception var3) {
            logger.error(&quot;LoadBalancer [{}]: Exception while adding Servers&quot;, this.name, var3);
        }
    }
}

public Server chooseServer(Object key) {
    if (this.counter == null) {
        this.counter = this.createCounter();
    }

    this.counter.increment();
    if (this.rule == null) {
        return null;
    } else {
        try {
            return this.rule.choose(key);
        } catch (Exception var3) {
            logger.warn(&quot;LoadBalancer [{}]:  Error choosing server for key {}&quot;, new Object[]{this.name, key, var3});
            return null;
        }
    }
}

public void markServerDown(Server server) {
    if (server != null &amp;&amp; server.isAlive()) {
        logger.error(&quot;LoadBalancer [{}]:  markServerDown called on [{}]&quot;, this.name, server.getId());
        server.setAlive(false);
        this.notifyServerStatusChangeListener(Collections.singleton(server));
    }
}

public List&lt;Server&gt; getReachableServers() {
    return Collections.unmodifiableList(this.upServerList);
}

public List&lt;Server&gt; getAllServers() {
    return Collections.unmodifiableList(this.allServerList);
}
</code></pre>
<h4 id="343-dynamicserverlistloadbalancer">3.4.3 DynamicServerListloadBalancer</h4>
<p>DynamicServerListloadBalancer类继承于 BaseLoadBalancer 类，它是对基础负载均衡器的扩展。 在该负载均衡器中，实现了服务实例清单在运行期的动态更新能力;同时，它还具备了对服务实例清单的过滤功能，也就是说，我们可以通过过滤器来选择性地获取一批服务实例清单。</p>
<p><code>ServerList</code><br>
其中含有一个关于服务列表的操作对象ServerList<T> serverListimpl，其中泛型T从类名中对于T的限定DynamicServerListLoadBalancer<T extends Server>可以获知它是一个 Server 的子类，即代表了一个具体的服务实例的扩展类。而ServerList 接口定义如下所示:</p>
<pre><code class="language-java">public interface ServerList&lt;T extends Server&gt; {
    //用于获取初始化的服务实例清单
    List&lt;T&gt; getInitialListOfServers();
    //用于获取更新的服务实例清单 
    List&lt;T&gt; getUpdatedListOfServers();
}
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1678073946735.png" alt="" loading="lazy"></figure>
<p>从上图中我可们以看到有多个ServerList 的实现类，那么在DynamicServer­ListLoadBalancer中的ServerList默认配置到底使用了哪个具体实现呢?然在该负载均衡器中需要实现 服务实例的动态更新， 那么势必需要Ribbon具备访问Eureka来获取服务实例的能力，所以我们从Spring Cloud整合和ribbon与Eureka的包org.springframework.cloud.netflix.ribbon.eureka下进行探索，可以找到配置类 <code>EurekaRibbonClientConfiguration</code>, 在该类中可以找到如下创建ServerList实例的内容:</p>
<pre><code class="language-java">@Bean
@ConditionalOnMissingBean
public ServerList&lt;?&gt; ribbonServerList(IClientConfig config) {
    DiscoveryEnabledNIWSServerList discoveryServerList = new DiscoveryEnabledNIWSServerList( config);
    DomainExtractingServerList serverList = new DomainExtractingServerList( discoveryServerList, config, this.approximateZoneFromHostname);
    return serverList;
}
</code></pre>
<p>这里创建的是 一个DomainExtractingServerList 实例，从下面它的源码中我们可以看到， 在它内部还定义了一个ServerList list。同时，Domain­ExtractingServerList类中getinitialListOfServers和getUpdated­ListOfServers的具体实现， 其实委托给了内部定义的ServerList list对象，而该对象是通过创建 DomainExtractingServerList 时，由构造函数传入的 DiscoveryEnabledNIWSServerList实现的。</p>
<pre><code class="language-java">public class DomainExtractingServerList implements ServerList&lt;DiscoveryEnabledServer&gt; {
    private ServerList&lt;DiscoveryEnabledServer&gt; list;
    private IClientConfig clientConfig;
    private boolean approximateZoneFromHostname;

    public DomainExtractingServerList(ServerList&lt;DiscoveryEnabledServer&gt; list, IClientConfig clientConfig, boolean approximateZoneFromHostname) {
        this.list = list;
        this.clientConfig = clientConfig;
        this.approximateZoneFromHostname = approximateZoneFromHostname;
    }

    public List&lt;DiscoveryEnabledServer&gt; getInitialListOfServers() {
        List&lt;DiscoveryEnabledServer&gt; servers = this.setZones(this.list.getInitialListOfServers());
        return servers;
    }

    public List&lt;DiscoveryEnabledServer&gt; getUpdatedListOfServers() {
        List&lt;DiscoveryEnabledServer&gt; servers = this.setZones(this.list.getUpdatedListOfServers());
        return servers;
    }

    private List&lt;DiscoveryEnabledServer&gt; setZones(List&lt;DiscoveryEnabledServer&gt; servers) {
        List&lt;DiscoveryEnabledServer&gt; result = new ArrayList();
        boolean isSecure = this.clientConfig.getPropertyAsBoolean(CommonClientConfigKey.IsSecure, Boolean.TRUE);
        boolean shouldUseIpAddr = this.clientConfig.getPropertyAsBoolean(CommonClientConfigKey.UseIPAddrForServer, Boolean.FALSE);
        Iterator var5 = servers.iterator();

        while(var5.hasNext()) {
            DiscoveryEnabledServer server = (DiscoveryEnabledServer)var5.next();
            result.add(new DomainExtractingServer(server, isSecure, shouldUseIpAddr, this.approximateZoneFromHostname));
        }

        return result;
    }
}
</code></pre>
<p>那么DiscoveryEnabledNIWSServerList是如何实现这两个服务实例获取的呢?我们从源码中可以看到这 两 个方法都是通过该类中的一个私有函数 obtainServersViaDiscovery 通过服务发现机制来实现服务实例的获取的。</p>
<blockquote>
<p>com.netflix.niws.loadbalancer.DiscoveryEnabledNIWSServerList</p>
</blockquote>
<pre><code class="language-java">public List&lt;DiscoveryEnabledServer&gt; getInitialListOfServers() {
    return this.obtainServersViaDiscovery();
}

public List&lt;DiscoveryEnabledServer&gt; getUpdatedListOfServers() {
    return this.obtainServersViaDiscovery();
}
</code></pre>
<p>而obtainServersViaDiscovery的实现逻辑如下所示，主要依靠EurekaClient从服务注册中心中获取到具体的服务实例InstanceInfo列表(这里传入的 vipAddress可以理解为逻辑上的服务名， 比如USER-SERVICE)。接着，对这些服务实例进行遍历，将状态为UP (正常服务)的实例转换成 DiscoveryEnabledServer对象， 最后将这些实例组织成列表返回。</p>
<pre><code class="language-java">private List&lt;DiscoveryEnabledServer&gt; obtainServersViaDiscovery() {
    List&lt;DiscoveryEnabledServer&gt; serverList = new ArrayList();
    if (this.eurekaClientProvider != null &amp;&amp; this.eurekaClientProvider.get() != null) {
        EurekaClient eurekaClient = (EurekaClient)this.eurekaClientProvider.get();
        if (this.vipAddresses != null) {
            String[] var3 = this.vipAddresses.split(&quot;,&quot;);
            int var4 = var3.length;

            for(int var5 = 0; var5 &lt; var4; ++var5) {
                String vipAddress = var3[var5];
                List&lt;InstanceInfo&gt; listOfInstanceInfo = eurekaClient.getInstancesByVipAddress(vipAddress, this.isSecure, this.targetRegion);
                Iterator var8 = listOfInstanceInfo.iterator();

                while(var8.hasNext()) {
                    InstanceInfo ii = (InstanceInfo)var8.next();
                    if (ii.getStatus().equals(InstanceStatus.UP)) {
                        if (this.shouldUseOverridePort) {
                            if (logger.isDebugEnabled()) {
                                logger.debug(&quot;Overriding port on client name: &quot; + this.clientName + &quot; to &quot; + this.overridePort);
                            }

                            InstanceInfo copy = new InstanceInfo(ii);
                            if (this.isSecure) {
                                ii = (new Builder(copy)).setSecurePort(this.overridePort).build();
                            } else {
                                ii = (new Builder(copy)).setPort(this.overridePort).build();
                            }
                        }

                        DiscoveryEnabledServer des = new DiscoveryEnabledServer(ii, this.isSecure, this.shouldUseIpAddr);
                        des.setZone(DiscoveryClient.getZone(ii));
                        serverList.add(des);
                    }
                }

                if (serverList.size() &gt; 0 &amp;&amp; this.prioritizeVipAddressBasedServers) {
                    break;
                }
            }
        }

        return serverList;
    } else {
        logger.warn(&quot;EurekaClient has not been initialized yet, returning an empty list&quot;);
        return new ArrayList();
    }
}
</code></pre>
<p>在DiscoveryEnabledNIWSServerLi江中通过EurekaClien七从服务注册中心 获取到最新的服务实例清单后， 返回的List到了DomainExtractingServerList类中，将继续通过setZones函数进行处理。而这里的处理具体内容如下所示， 主要完成将DiscoveryEnabledNIWSServerList返回的List列表中的元素， 转换成内部定义的DiscoveryEnabledServer 的子类对象 DomainExtractingServer, 在该对象的构造函数中将为服务实例对象设置一些必要的属性， 比如id、zone、isAliveFlag、readyToServe等信息。</p>
<pre><code class="language-java">private List&lt;DiscoveryEnabledServer&gt; setZones(List&lt;DiscoveryEnabledServer&gt; servers) {
    List&lt;DiscoveryEnabledServer&gt; result = new ArrayList();
    boolean isSecure = this.clientConfig.getPropertyAsBoolean(CommonClientConfigKey.IsSecure, Boolean.TRUE);
    boolean shouldUseIpAddr = this.clientConfig.getPropertyAsBoolean(CommonClientConfigKey.UseIPAddrForServer, Boolean.FALSE);
    Iterator var5 = servers.iterator();

    while(var5.hasNext()) {
        DiscoveryEnabledServer server = (DiscoveryEnabledServer)var5.next();
        result.add(new DomainExtractingServer(server, isSecure, shouldUseIpAddr, this.approximateZoneFromHostname));
    }

    return result;
}
</code></pre>
<p><code>ServerListUpdater</code><br>
通过上面的分析我们已经知道了ribbon与Eureka整合后，如何实现从Eureka Server中获取服务实例清单。那么它又是如何触发向 Eureka Server 去获取服务实例清单以及如何在获取到服务实例清单后更新本地的服务实例清单的呢?继续来看DynamicServer­ListLoadBalancer中的实现内容：</p>
<pre><code class="language-java">protected volatile ServerListUpdater serverListUpdater;
class NamelessClass_1 implements UpdateAction {
    NamelessClass_1() {
    }

    public void doUpdate() {
        DynamicServerListLoadBalancer.this.updateListOfServers();
    }
}

this.updateAction = new NamelessClass_1();
</code></pre>
<p>在ServerListUpdater内部还定义了一个UpdateAction接口，上面定义的updateAction对象就是以匿名内部 类的方式创建了一个它的具体实现，其中doUpdate实现的内容就是对Serverlist的具体更新操作。除此之外，ServerListUpdater中还定义了一系列控制它和获取它的信息的操作。</p>
<pre><code class="language-java">public interface ServerListUpdater {
    //启动服务更新器，传入的UpdateAction对象为更新操作的具体实现。
    void start(ServerListUpdater.UpdateAction var1);
    //停止服务更新器
    void stop();
    //荻取最近的更新时间戳
    String getLastUpdate();
    //获取上一次更新到现在的时间间隔，单位为毫秒
    long getDurationSinceLastUpdateMs();
    //荻取错过的更新周期数
    int getNumberMissedCycles();
    //荻取核心线程数
    int getCoreThreads();

    public interface UpdateAction {
        void doUpdate();
    }
}
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1678086494267.png" alt="" loading="lazy"></figure>
<p>而ServerListUpdater的实现类不多，根据两个类的注释，我们可以很容易地知道它们的作用。</p>
<ul>
<li>PollingServerListUpdater: 动态服务列表更新的默认策略，DynamicServerListLoadBalancer负载均衡器中的默认实现就是它，它通过定时任务的方式进行服务列表的更新。</li>
<li>EurekaNotificationServerListUpdater: 该更新器也可服务于 Dynamic­ServerListLoadBalancer负载均衡器，但是它的触发机制与PollingServer­ListUpdater不同，它需要利用Eureka的事件监听器来驱动服务列表的更新操作。</li>
</ul>
<p>下面我们来详细看看它默认实现的PollingServerListUpdater。 先从用于启动 “服务更新器 ” 的 start函数源码看起，具体如下。它先创建了一个Runnable的线程实现，在该实现中调用了上面提到的具体更新服务实例列表的方法updateAcyion.doUpdate(), 最后再为这个Runnable线程实现启动了一个定时任务来执行。</p>
<pre><code class="language-java">public synchronized void start(final UpdateAction updateAction) {
    if (this.isActive.compareAndSet(false, true)) {
        Runnable wrapperRunnable = new Runnable() {
            public void run() {
                if (!PollingServerListUpdater.this.isActive.get()) {
                    if (PollingServerListUpdater.this.scheduledFuture != null) {
                        PollingServerListUpdater.this.scheduledFuture.cancel(true);
                    }

                } else {
                    try {
                        updateAction.doUpdate();
                        PollingServerListUpdater.this.lastUpdated = System.currentTimeMillis();
                    } catch (Exception var2) {
                        PollingServerListUpdater.logger.warn(&quot;Failed one update cycle&quot;, var2);
                    }

                }
            }
        };
        this.scheduledFuture = getRefreshExecutor().scheduleWithFixedDelay(wrapperRunnable, this.initialDelayMs, this.refreshIntervalMs, TimeUnit.MILLISECONDS);
    } else {
        logger.info(&quot;Already active, no-op&quot;);
    }
}
</code></pre>
<p>我们可以找到用于启动定时任务的两个重要参数<code>initialDelayMs</code>和<code>refreshIntervalMs</code>的默认定义分别为 1000和30*1000, 单位为毫秒。 也就是说， 更新服务实例在初始化之后延迟1秒后开始执行，并以 30秒为周期重复执行。除了这些内容之外，还能看到它还会记录最后更新时间、是否存活等信息，同时也实现了ServerListUpdater中定义的一 些其他操作内容。</p>
<p><code>ServerListFilter</code><br>
我们回到updateAction. doUpdate()调用的具体实现位置，在DynamicServerListLoadBalancer中， 它的实际实现委托给了updateListOfServers函数，具体实现如下:</p>
<pre><code class="language-java">@VisibleForTesting
public void updateListOfServers() {
    List&lt;T&gt; servers = new ArrayList();
    if (this.serverListImpl != null) {
        servers = this.serverListImpl.getUpdatedListOfServers();
        LOGGER.debug(&quot;List of Servers for {} obtained from Discovery client: {}&quot;, this.getIdentifier(), servers);
        if (this.filter != null) {
            servers = this.filter.getFilteredListOfServers((List)servers);
            LOGGER.debug(&quot;Filtered List of Servers for {} obtained from Discovery client: {}&quot;, this.getIdentifier(), servers);
        }
    }

    this.updateAllServerList((List)servers);
}
</code></pre>
<p>可以看到这里终于用到了之前提到的ServerList的getUpdatedListOfServers() 通过之前的介绍已经知道这一步实现从Eureka Server中获取服务可用实例的列表。 在获得了服务实例列表之后，这里又将引入一个新的对象filter, 追溯该对象的定义，我们可以找到它是ServerListFilter定义的。</p>
<p>ServerListFilter接口非常简单，该接口中定义了一个方法List getFiltered ListOfServers(List servers), 主要用于实现对服务实例列表的过滤，通过传入的服务实例清单，根据一些规则返回过滤后的服务实例清单。 该接口的实现如下图所示。<br>
<img src="https://q456qq520.github.io/post-images/1678088123586.png" alt="" loading="lazy"></p>
<p>其中， 除了ZonePreferenceServerListFilter的实现是Spring Cloud Ribbon中对Netflix Ribbon的扩展实现外，其他均是Netflix Ribbon中的原生实现类。下面，我们 可以分别看看这些过滤器实现都有什么特点。</p>
<ul>
<li>AbstractServerListFilter: 这是一个抽象过滤器，在这里定义了过滤时需要的一个重要依据对象 LoadBalancerStats,，该对象存储了关于负载均衡器的一些属性和统计信息等。</li>
</ul>
<pre><code class="language-java">public abstract class AbstractServerListFilter&lt;T extends Server&gt; implements ServerListFilter&lt;T&gt; {
    private volatile LoadBalancerStats stats;

    public AbstractServerListFilter() {
    }

    public void setLoadBalancerStats(LoadBalancerStats stats) {
        this.stats = stats;
    }

    public LoadBalancerStats getLoadBalancerStats() {
        return this.stats;
    }
}
</code></pre>
<ul>
<li>ZoneAffinityServerListFilter: 该过滤器基于==区域感知 (Zone Affinity)==的方式实现服务实例的过滤，也就是说，它会根据提供服务的实例所处的区域 (Zone) 与消费者自身的所处区域 (Zone) 进行比较，过滤掉那些不是同处一个区域的实例。</li>
</ul>
<pre><code class="language-java">public List&lt;T&gt; getFilteredListOfServers(List&lt;T&gt; servers) {
    if (this.zone != null &amp;&amp; (this.zoneAffinity || this.zoneExclusive) &amp;&amp; servers != null &amp;&amp; servers.size() &gt; 0) {
        List&lt;T&gt; filteredServers = Lists.newArrayList(Iterables.filter(servers, this.zoneAffinityPredicate.getServerOnlyPredicate()));
        if (this.shouldEnableZoneAffinity(filteredServers)) {
            return filteredServers;
        }

        if (this.zoneAffinity) {
            this.overrideCounter.increment();
        }
    }
    return servers;
}
</code></pre>
<p>对千服务实例列表的过滤是通过Iterables. filter(servers,this.zoneAffinityPredicate.getServerOnlyPredicate()) 来实现的，其中判断依据由 ZoneAffinityPredicate实现服务实例与消费者的Zone比较。而在过滤之后，这里并不会马上返回过滤的结果，而是通过 shouldEnableZone­Affinity函数来判断是否要启用区域感知的功能。</p>
<p>从下面shouldEnableZoneAffinity的实现中，它使用了LoadBalancerStats的getZoneSnapshot方法 来获取这些过滤后的同区域实例的基础指标(包含实例数量、断路器断开数、 活动请求数、 实例平均负载等)，根据一系列的算法求出下 面的几个评价值并与设置的阙值进行对比(下面的为默认值)，若有一个条件符合， 就不启用区域感知过滤的服务实例清单。这一算法实现为集群出现区域故障时，依然可以依靠其他区域的实例进行正常服务提供了完善的高可用保障。<br>
1、blackOutServerPercentage: 故障实例百分比(断路器断开数/实例数量) &gt;=0.8。<br>
2、activeReqeustsPerServer: 实例平均负载 &gt;=0.6 。<br>
3、availableServers: 可用实例数(实例数量 - 断路器断开数)&lt; 2。</p>
<pre><code class="language-java">private boolean shouldEnableZoneAffinity(List&lt;T&gt; filtered) {
    if (!this.zoneAffinity &amp;&amp; !this.zoneExclusive) {
        return false;
    } else if (this.zoneExclusive) {
        return true;
    } else {
        LoadBalancerStats stats = this.getLoadBalancerStats();
        if (stats == null) {
            return this.zoneAffinity;
        } else {
            logger.debug(&quot;Determining if zone affinity should be enabled with given server list: {}&quot;, filtered);
            ZoneSnapshot snapshot = stats.getZoneSnapshot(filtered);
            double loadPerServer = snapshot.getLoadPerServer();
            int instanceCount = snapshot.getInstanceCount();
            int circuitBreakerTrippedCount = snapshot.getCircuitTrippedCount();
            if (!((double)circuitBreakerTrippedCount / (double)instanceCount &gt;= this.blackOutServerPercentageThreshold.get()) &amp;&amp; !(loadPerServer &gt;= this.activeReqeustsPerServerThreshold.get()) &amp;&amp; instanceCount - circuitBreakerTrippedCount &gt;= this.availableServersThreshold.get()) {
                return true;
            } else {
                logger.debug(&quot;zoneAffinity is overriden. blackOutServerPercentage: {}, activeReqeustsPerServer: {}, availableServers: {}&quot;, new Object[]{(double)circuitBreakerTrippedCount / (double)instanceCount, loadPerServer, instanceCount - circuitBreakerTrippedCount});
                return false;
            }
        }
    }
}
</code></pre>
<ul>
<li>DefaultNIWSServerListFilter: 该过滤器完全继承自ZoneAffinity­ServerListFilter, 是默认的NIWS (Netflix Internal Web Service)过滤器。</li>
<li>ServerListSubsetFilter: 该过滤器也继承自 ZoneAffinityServer­ListFilter, 它非常适用于拥有大规模服务器集群(上百或更多)的系统。 因为它可以产生一个区域感知结果的子集列表，同时它还能够通过比较服务实例的通信失败数量和并发连接数来判定该服务是否健康来选择性地从服务实例列表中剔除那些相对不够健康的实例。</li>
<li>ZonePreferenceServerListFilter: Spring Cloud整合时新增的过滤器。若使用Spring Cloud整合Eureka和Ribbon时会默认使用该过滤器。它实现了通过配置或者Eureka实例元数据的所属区域 (Zone) 来过滤出同区域的服务实例。</li>
</ul>
<pre><code class="language-java">public List&lt;Server&gt; getFilteredListOfServers(List&lt;Server&gt; servers) {
    List&lt;Server&gt; output = super.getFilteredListOfServers(servers);
    if (this.zone != null &amp;&amp; output.size() == servers.size()) {
        List&lt;Server&gt; local = new ArrayList();
        Iterator var4 = output.iterator();

        while(var4.hasNext()) {
            Server server = (Server)var4.next();
            if (this.zone.equalsIgnoreCase(server.getZone())) {
                local.add(server);
            }
        }

        if (!local.isEmpty()) {
            return local;
        }
    }
    return output;
}
</code></pre>
<p>首先通过父类ZoneAffinityServerListFilter的过滤器来获得区域感的服务实例列表，然后遍历这个结果，取出根据消费 者配置预设的区域Zone来进行过滤，如果过滤的结果是空就直接返回父类获取的<br>
结果 如果不为空就返回通过消费者配置的Zone过滤后的结果。</p>
<h4 id="344-zoneawareloadbalancer">3.4.4 ZoneAwareloadBalancer</h4>
<p>ZoneAwareLoadBalancer负载均衡器是对DynamicServerListLoadBalancer的扩展。在 DynamicServerListLoadBalancer中，我们可以看到它并没有重写选择具体服务实例的chooseServer 函数，所以它依然会采用在BaseLoadBalancer中实现的算法。使用 RoundRobinRule 规则，以线性轮询的方式来选择调用的服务实例，该算法实现简单并没有区域 (Zone) 的概念，所以它会把所有实例视为一个 Zone下的节点来看待，这样就会周期性地产生跨区域 (Zone) 访问的情况，由于跨区域会产生更高的延迟， 这些实例主要以防止区域性故障实现高可用为目的而不能作为常规访问的实例，所以在多区域部署的清况下会有一定的性能问题，而该负载均衡器则可以避免这样的问题。 那么它是如何实现的呢?</p>
<p>首先在ZoneAwareLoadBalancer中，我们可以发现，它并没有重写setServersList, 说明实现服务实例清单的更新主逻辑没有修改。但是我们可以发现它重写了这个函数setServerListForZones(Map&lt;String, List<Server>&gt;zoneServersMap)。</p>
<p>看到这里可能会有一 些陌生，因为它并不是接口中定义的必备函数， 所以我们不妨去父类 DynamicServerListLoadBalancer中寻找一下该函数，我们可以找到下面的定义:</p>
<blockquote>
<p>DynamicServerListLoadBalancer</p>
</blockquote>
<pre><code class="language-java">public void setServersList(List lsrv) {
    super.setServersList(lsrv);
    Map&lt;String, List&lt;Server&gt;&gt; serversInZones = new HashMap();
    Iterator var4 = lsrv.iterator();

    while(var4.hasNext()) {
        Server server = (Server)var4.next();
        this.getLoadBalancerStats().getSingleServerStat(server);
        String zone = server.getZone();
        if (zone != null) {
            zone = zone.toLowerCase();
            List&lt;Server&gt; servers = (List)serversInZones.get(zone);
            if (servers == null) {
                servers = new ArrayList();
                serversInZones.put(zone, servers);
            }

            ((List)servers).add(server);
        }
    }

    this.setServerListForZones(serversInZones);
}

protected void setServerListForZones(Map&lt;String, List&lt;Server&gt;&gt; zoneServersMap) {
    LOGGER.debug(&quot;Setting server list for zones: {}&quot;, zoneServersMap);
    this.getLoadBalancerStats().updateZoneServerMapping(zoneServersMap);
}
</code></pre>
<p>setServerListForZones函数的调用位于更新服务实例清单函数setServers­List的最后，同时从其实现的内容来看，它在父类 DynamicServerListLoadBalancer中的作用是根据按区域Zone分组的实例列表， 为负载均衡器中的LoadBalancerStats对象创建Zonestats并放入Map zonestatsMap 集合中，每一个区域Zone对应一个ZoneStats, 它用于存储每个Zone 的一些状态和统计信息。</p>
<p>在 ZoneAwareLoadBalancer 中对 setServerListForZones 的重写如下:</p>
<pre><code class="language-java">protected void setServerListForZones(Map&lt;String, List&lt;Server&gt;&gt; zoneServersMap) {
    super.setServerListForZones(zoneServersMap);
    if (this.balancers == null) {
        this.balancers = new ConcurrentHashMap();
    }

    Iterator var2 = zoneServersMap.entrySet().iterator();

    Entry existingLBEntry;
    while(var2.hasNext()) {
        existingLBEntry = (Entry)var2.next();
        String zone = ((String)existingLBEntry.getKey()).toLowerCase();
        this.getLoadBalancer(zone).setServersList((List)existingLBEntry.getValue());
    }

    var2 = this.balancers.entrySet().iterator();
    while(var2.hasNext()) {
        existingLBEntry = (Entry)var2.next();
        if (!zoneServersMap.keySet().contains(existingLBEntry.getKey())) {
            ((BaseLoadBalancer)existingLBEntry.getValue()).setServersList(Collections.emptyList());
        }
    }
}
</code></pre>
<p>可以看到，在该实现中创建了一个ConcurrentHashMap() 类型的balancers对象，它将用来存储每个 Zone区域对应的负载均衡器。而具体的负载均衡器的创建则是通过在下面的第一个循环中调用getLoadBalancer函数来完成，同时在创建负载均衡器的时候会创建它的规则(如果当前实现中没有IRule的实例，就创建一个 AvailabilityFilteringRule规则;如果已经有具体实例，就克隆一个)。在创建完负载均衡器后又马上调用setServersList函数为其设置对应Zone区域的实例清单。而第二个循环则是对 Zone 区域中实例清单的检查，看看是否有Zone区域下已经没有实例了，是的话就将balancers中对应Zone区域的实例列表清空，该操作的作用是为了后续选择节点时，防止过时的Zone区域统计信息干扰具体实例的选择算法。</p>
<p>在了解了该负载均衡器是如何扩展服务实例清单的实现后， 我们来具体看看它是如何挑选服务实例，来实现对区域的识别的:</p>
<pre><code class="language-java">public Server chooseServer(Object key) {
    if (ENABLED.get() &amp;&amp; this.getLoadBalancerStats().getAvailableZones().size() &gt; 1) {
        Server server = null;

        try {
            LoadBalancerStats lbStats = this.getLoadBalancerStats();
            Map&lt;String, ZoneSnapshot&gt; zoneSnapshot = ZoneAvoidanceRule.createSnapshot(lbStats);
            logger.debug(&quot;Zone snapshots: {}&quot;, zoneSnapshot);
            if (this.triggeringLoad == null) {
                this.triggeringLoad = DynamicPropertyFactory.getInstance().getDoubleProperty(&quot;ZoneAwareNIWSDiscoveryLoadBalancer.&quot; + this.getName() + &quot;.triggeringLoadPerServerThreshold&quot;, 0.2D);
            }

            if (this.triggeringBlackoutPercentage == null) {
                this.triggeringBlackoutPercentage = DynamicPropertyFactory.getInstance().getDoubleProperty(&quot;ZoneAwareNIWSDiscoveryLoadBalancer.&quot; + this.getName() + &quot;.avoidZoneWithBlackoutPercetage&quot;, 0.99999D);
            }

            Set&lt;String&gt; availableZones = ZoneAvoidanceRule.getAvailableZones(zoneSnapshot, this.triggeringLoad.get(), this.triggeringBlackoutPercentage.get());
            if (availableZones != null &amp;&amp; availableZones.size() &lt; zoneSnapshot.keySet().size()) {
                String zone = ZoneAvoidanceRule.randomChooseZone(zoneSnapshot, availableZones);
                if (zone != null) {
                    BaseLoadBalancer zoneLoadBalancer = this.getLoadBalancer(zone);
                    server = zoneLoadBalancer.chooseServer(key);
                }
            }
        } catch (Exception var8) {
        }

        if (server != null) {
            return server;
        } else {
            return super.chooseServer(key);
        }
    } else {
        return super.chooseServer(key);
    }
}
</code></pre>
<p>只有当负载均衡器中维护的实例所属的Zone区域的个数大于 1 的时候才会执行这里的选择策略，否则还是将使用父类的实现。当Zone区域的个数大于1的时候，它的实现步骤如下所示。<br>
• 调用ZoneAvoidanceRule中的静态方法createSnapshot(lbStats)为当前负载均衡器中所有的Zone区域分别创建快照，保存在Map zoneSnapshot中 这些快照中的数据将用于后续的算法。<br>
• 调用ZoneAvoidanceRule中的静态方法getAvailableZones(zoneSnapshot, this.triggeringLoad.get(), this.triggeringBlackoutPercentage.get())，来获取可用的Zone区域集合，在该函数中会通过Zone区域快照中的统计数据来实现可用区的挑选。<br>
首先它会剔除符合这些规则的Zone区域: 所属实例数为零的Zone区域; Zone区域内实例的平均负载小于零，或者实例故障率( 断路器断开次数/实例数)大于等于阙值(默认为0.99999)。<br>
然后根据Zone区域的实例平均负载计算出最差的Zone区域，这里的最差指的是实例平均负载最高的Zone区域。<br>
如果在上面的过程中没有符合剔除要求的区域，同时实例最大平均负载小于阈值 (默认为20%), 就直接返回所有Zone区域为可用区域。 否则，从最坏Zone区域集合中随机选择一个，将它从可用Zone区域集合中 剔除。<br>
• 当获得的可用Zone区域集合不为空，并且个数小于Zone区域总数，就随机选择一个Zone区域。<br>
• 在确定了某个Zone区域后，则获取了对应Zone区域的服务均衡器，并调用chooseServer来选择具体的服务实例，而在chooseServer中将使用IRule接口的choose函数来选择具体的服务实例。在这里IRule接口的实现会使用ZoneAvoidanceRule来挑选出具体的服务实例。</p>
<h3 id="35-负载均衡策略">3.5 负载均衡策略</h3>
<p>Ribbon中实现了非常多的选择策略，其中也包含了我们在前面内容中提到过的RoundRobinRule和ZoneAvoidanceRule。下面我们来详细解读一下IRule接口的各个实现。</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1678098942806.png" alt="" loading="lazy"></figure>
<h4 id="351-abstractloadbalancerrule">3.5.1 AbstractloadBalancerRule</h4>
<p>负载均衡策略的抽象类，在该抽象类中定义了负载均衡器ILoadBalancer对象，该对象能够在具体实现选择服务策略时，获取到一些负载均衡器中维护的信息来作为分配依据，并以此设计一些符法来实现针对特定场景的高效策略。</p>
<pre><code class="language-java">public abstract class AbstractLoadBalancerRule implements IRule, IClientConfigAware {
    private ILoadBalancer lb;

    public AbstractLoadBalancerRule() {
    }

    public void setLoadBalancer(ILoadBalancer lb) {
        this.lb = lb;
    }

    public ILoadBalancer getLoadBalancer() {
        return this.lb;
    }
}
</code></pre>
<h4 id="352-randomrule">3.5.2 RandomRule</h4>
<p>该策略实现了从服务实例清单中随机选择一个服务实例的功能。可以看到IRule接口的choose (Object key)函数实现，委托给了该类中的choose (ILoadBalancer lb, Object key), 该方法增加了一个负载均衡器对象的参数。从具体的实现上看，它会使用传入的负载均衡器来获得可用实例列表upList和所有实例列表 allList, 并通过rand.nextInt(serverCount)函数来获取一个随机数，并将该随机数作为upList的索引值来返回具体实例。同时，具体的选择逻辑在一个while(server == null)循环之内，而根据选择逻辑的实现，正常情况下每次选择都应该选出一个服务实例，如果出现死循环获取不到服务实例时，则很有可能存在并发的Bug。</p>
<pre><code class="language-java">@SuppressWarnings({&quot;RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE&quot;})
public Server choose(ILoadBalancer lb, Object key) {
    if (lb == null) {
        return null;
    } else {
        Server server = null;
        while(server == null) {
            if (Thread.interrupted()) {
                return null;
            }

            List&lt;Server&gt; upList = lb.getReachableServers();
            List&lt;Server&gt; allList = lb.getAllServers();
            int serverCount = allList.size();
            if (serverCount == 0) {
                return null;
            }
            int index = this.rand.nextInt(serverCount);
            server = (Server)upList.get(index);
            if (server == null) {
                Thread.yield();
            } else {
                if (server.isAlive()) {
                    return server;
                }
                server = null;
                Thread.yield();
            }
        }
        return server;
    }
}

public Server choose(Object key) {
    return this.choose(this.getLoadBalancer(), key);
}
</code></pre>
<h4 id="353-roundrobinrule">3.5.3 RoundRobinRule</h4>
<p>该策略实现了按照线性轮询的方式依次选择每个服务实例的功能。它的具体实现如下，其详细结构与 RandomRule 非常类似。除了循环条件不同外，就是从可用列表中获取所谓的逻辑不同。 从循环条件中，我们可以看到增加了一个 count计数变量，该变量会在每次循环之后累加，也就是说，如果一直选择不到server超过10次，那么就会结束尝试，并打印一个警告信息。</p>
<p>而线性轮询的实现则是通过Atomicinteger nextServerCyclicCounter对象实现，每次进行实例选择时通过调用incrementAndGetModulo函数实现递增。</p>
<pre><code class="language-java">public Server choose(ILoadBalancer lb, Object key) {
    if (lb == null) {
        return null;
    } else {
        Server server = null;
        int count = 0;

        while(true) {
            if (server == null &amp;&amp; count++ &lt; 10) {
                List&lt;Server&gt; reachableServers = lb.getReachableServers();
                List&lt;Server&gt; allServers = lb.getAllServers();
                int upCount = reachableServers.size();
                int serverCount = allServers.size();
                if (upCount != 0 &amp;&amp; serverCount != 0) {
                    int nextServerIndex = this.incrementAndGetModulo(serverCount);
                    server = (Server)allServers.get(nextServerIndex);
                    if (server == null) {
                        Thread.yield();
                    } else {
                        if (server.isAlive() &amp;&amp; server.isReadyToServe()) {
                            return server;
                        }

                        server = null;
                    }
                    continue;
                }

                return null;
            }

            if (count &gt;= 10) {
            }

            return server;
        }
    }
}
</code></pre>
<h4 id="354-retryrule">3.5.4 RetryRule</h4>
<p>该策略实现了一个具备重试机制的实例选择功能。在其内部还定义了一个IRule对象，默认使用了 RoundRobinRule实例。而在choose方法中则实现了对内部定义的策略进行反复尝试的策略， 若期间能够选择到具体的服务实例就返回，若选择不到就根据设置的尝试结束时间为阙值(maxRetryMillis 参数定义的值 + choose 方法开始执行的时间戳)， 当超过该阑值后就返回 null。</p>
<pre><code class="language-java">public class RetryRule extends AbstractLoadBalancerRule {
    IRule subRule = new RoundRobinRule();
    long maxRetryMillis = 500L;
     public Server choose(ILoadBalancer lb, Object key) {
        long requestTime = System.currentTimeMillis();
        long deadline = requestTime + this.maxRetryMillis;
        Server answer = null;
        answer = this.subRule.choose(key);
        if ((answer == null || !answer.isAlive()) &amp;&amp; System.currentTimeMillis() &lt; deadline) {
            InterruptTask task = new InterruptTask(deadline - System.currentTimeMillis());

            while(!Thread.interrupted()) {
                answer = this.subRule.choose(key);
                if (answer != null &amp;&amp; answer.isAlive() || System.currentTimeMillis() &gt;= deadline) {
                    break;
                }

                Thread.yield();
            }

            task.cancel();
        }

        return answer != null &amp;&amp; answer.isAlive() ? answer : null;
    }
}
</code></pre>
<h4 id="355-weightedresponsetimerule">3.5.5 WeightedResponseTimeRule</h4>
<p>该策略是对RoundRobinRule的扩展，增加了根据实例的运行情况来计算权重， 并根据权重来挑选实例， 以达到更优的分配效果，它的实现主要有三个核心内容。</p>
<p><code>定时任务</code><br>
WeightedResponseTimeRule策略在初始化的时候会通过==serverWeightTimer. schedule (new DynamicServerWeightTask(), 0, serverWeightTaskTimerinterval)==启动一个定时任务， 用来为每个服务实例计算权重，该任务默认30秒执行一次。</p>
<pre><code class="language-java">class DynamicServerWeightTask extends TimerTask {
    DynamicServerWeightTask() {
    }

    public void run() {
        WeightedResponseTimeRule.ServerWeight serverWeight = WeightedResponseTimeRule.this.new ServerWeight();

        try {
            serverWeight.maintainWeights();
        } catch (Exception var3) {
            WeightedResponseTimeRule.logger.error(&quot;Error running DynamicServerWeightTask for {}&quot;, WeightedResponseTimeRule.this.name, var3);
        }

    }
}
</code></pre>
<p><code>权重计算</code><br>
用千存储权重的对象为List<Double> accumulatedWeights = new ArrayList() , 该List 中每个权重值所处的位置对应了负载均衡器维护的服务实例清单中所有实例在清单中的位置。维护实例权重的计算过程通过maintainWeights函数实现，具体如下面的代码所示:</p>
<pre><code class="language-java">class ServerWeight {
    ServerWeight() {
    }

    public void maintainWeights() {
        ILoadBalancer lb = WeightedResponseTimeRule.this.getLoadBalancer();
        if (lb != null) {
            if (WeightedResponseTimeRule.this.serverWeightAssignmentInProgress.compareAndSet(false, true)) {
                try {
                    WeightedResponseTimeRule.logger.info(&quot;Weight adjusting job started&quot;);
                    AbstractLoadBalancer nlb = (AbstractLoadBalancer)lb;
                    LoadBalancerStats stats = nlb.getLoadBalancerStats();
                    if (stats != null) {
                        //计算所有实例的平均响应时间的总和
                        double totalResponseTime = 0.0D;

                        ServerStats ss;
                        for(Iterator var6 = nlb.getAllServers().iterator(); var6.hasNext(); totalResponseTime += ss.getResponseTimeAvg()) {
                            Server server = (Server)var6.next();
                            //如果服务实例的状态快照不在缓存中， 那么这里会进行自动加载
                            ss = stats.getSingleServerStat(server);
                        }
                        //逐个计算每个实例的权重: weightSoFar + totalResponseTime -实例的平均响应时间
                        Double weightSoFar = 0.0D;
                        List&lt;Double&gt; finalWeights = new ArrayList();
                        Iterator var20 = nlb.getAllServers().iterator();

                        while(var20.hasNext()) {
                            Server serverx = (Server)var20.next();
                            ServerStats ssx = stats.getSingleServerStat(serverx);
                            double weight = totalResponseTime - ssx.getResponseTimeAvg();
                            weightSoFar = weightSoFar + weight;
                            finalWeights.add(weightSoFar);
                        }

                        WeightedResponseTimeRule.this.setWeights(finalWeights);
                        return;
                    }
                } catch (Exception var16) {
                    return;
                } finally {
                    WeightedResponseTimeRule.this.serverWeightAssignmentInProgress.set(false);
                }

            }
        }
    }
}
</code></pre>
<p>该函数的实现主要分为两个步骤:</p>
<ul>
<li>根据LoadBalancerStats中记录的每个实例的统计信息，累加所有实例的平均响应时间，得到总平均响应时间totalResponseTime, 该值会用于后续的计算。</li>
<li>为负载均衡器中维护的实例清单逐个计算权重(从第 一个开始)，计算规则为<mark>weigh七SoFar+totalResponseTime — 实例的平均响应时间</mark>，其中weightSoFar初始化为零，并且每计算好一个权重需要累加到weightSoFar上供下一次计算使用。</li>
</ul>
<p>举个简单的例子来理解这个计算过程， 假设有4个实例A、 B、 C、 D, 它们的平均响 应时间为10、40、 80、 100, 所以总响应时间是230, 每个实例的权重为总响应时间与实例自身的平均响应时间的差的累积所得， 所以实例A、 B、 C、 D 的权重分别如下所示。<br>
• 实例A: 230-10 =220<br>
• 实例B: 220 + (230-40) =410<br>
• 实例C:410 + (230- 80) = 560<br>
• 实例D: 560 + (230-100) = 690</p>
<p>需要注意的是， 这里的权重值只是<mark>表示了各实例权重区间的上限，并非某个实例的优先级</mark>， 所以不是数值越大被选中的概率就越大。那么什么是权重区间呢?以上面例子的计算结果为例， 它实际上是为这4个实例构建了4个不同的区间，每个实例的区间下限是上一个实例的区间上限，而每个实例的区间上限则是 我们上面计算并存储于List accumulatedWeights的权重值，其中第一个实例的下限默认为零。 所以， 根据上面示例的权重计算结果， 我们可以得到每个实例的权重区间。</p>
<p>• 实例A: [0, 220]<br>
• 实例B: (20,410]<br>
• 实例C: (410, 560]<br>
• 实例D: (560, 690)</p>
<p>实际上每个区间的宽度就是: 总的平均响应时间 - 实例的平均响应时间，所以实例的平均响应时间越短、 权重区间的宽度越大，而权重区间的宽度越大被选中的概率就越高。</p>
<p><code>实例选择</code><br>
WeightedResponseTimeRule选择实例的实现与之前介绍的算法结构类似，下面是它主体的算法:</p>
<pre><code class="language-java">public Server choose(ILoadBalancer lb, Object key) {
    if (lb == null) {
        return null;
    } else {
        Server server = null;

        while(server == null) {
            List&lt;Double&gt; currentWeights = this.accumulatedWeights;
            if (Thread.interrupted()) {
                return null;
            }

            List&lt;Server&gt; allList = lb.getAllServers();
            int serverCount = allList.size();
            if (serverCount == 0) {
                return null;
            }

            int serverIndex = 0;
            //获取最后一个实例的权重
            double maxTotalWeight = currentWeights.size() == 0 ? 0.0D : (Double)currentWeights.get(currentWeights.size() - 1);
            if (maxTotalWeight &lt; 0.001D) {
                //如果最后一个实例的权重值小于0.001, 则采用父类实现的线性轮询的策略
                server = super.choose(this.getLoadBalancer(), key);
                if (server == null) {
                    return server;
                }
            } else {
                //如果最后一个实例的权重值大于等于0.001, 就产生一个(0, maxTotalWeight)的随机数
                double randomWeight = this.random.nextDouble() * maxTotalWeight;
                int n = 0;

                for(Iterator var13 = currentWeights.iterator(); var13.hasNext(); ++n) {
                    Double d = (Double)var13.next();
                    //遍历维护的权重清单， 若权重大于等于随机得到的数值， 就选择这个实例
                    if (d &gt;= randomWeight) {
                        serverIndex = n;
                        break;
                    }
                }

                server = (Server)allList.get(serverIndex);
            }

            if (server == null) {
                Thread.yield();
            } else {
                if (server.isAlive()) {
                    return server;
                }

                server = null;
            }
        }

        return server;
    }
}
</code></pre>
<ul>
<li>生成一个[ 0, 最大权重值)区间内的随机数。</li>
<li>遍历权重列表， 比较权重值与随机数的大小，如果权重值大于等千随机数， 就拿当前权重列表的索引值去服务实例列表中获取具体的实例。</li>
</ul>
<h4 id="356-clientconfigenabledroundrobinrule">3.5.6 ClientConfigEnabledRoundRobinRule</h4>
<p>该策略较为特殊，我们一般不直接使用它。因为它本身并没有实现什么特殊的处理逻辑， 正如下面的源码所示， 在它的内部定义了一个RoundRobinRule策略，而choose函数的实现也正是使用了RoundRobinRule 的线性轮询机制，所以它实现的功能实际上与RoundRobinRule相同，那么定义它有什么特殊的用处呢?</p>
<p>虽然我们不会直接使用该策略，但是通过继承该策略，默认的choose就实现了线性轮询机制，在子类中做一 些高级策略时通常有可能会存在一些无法实施的情况，那么就可以用父类的实现作为备选。 在后文中我们将继续介绍的高级策略均是基 ClientConfigEnabledRoundRobinRule的扩展。</p>
<pre><code class="language-java">public class ClientConfigEnabledRoundRobinRule extends AbstractLoadBalancerRule {
    RoundRobinRule roundRobinRule = new RoundRobinRule();

    public ClientConfigEnabledRoundRobinRule() {
    }

    public void initWithNiwsConfig(IClientConfig clientConfig) {
        this.roundRobinRule = new RoundRobinRule();
    }

    public void setLoadBalancer(ILoadBalancer lb) {
        super.setLoadBalancer(lb);
        this.roundRobinRule.setLoadBalancer(lb);
    }

    public Server choose(Object key) {
        if (this.roundRobinRule != null) {
            return this.roundRobinRule.choose(key);
        } else {
            throw new IllegalArgumentException(&quot;This class has not been initialized with the RoundRobinRule class&quot;);
        }
    }
}
</code></pre>
<h4 id="357-bestavailablerule">3.5.7 BestAvailableRule</h4>
<p>该策略继承自ClientConfigEnabledRoundRobinRule, 在实现中它注入了负载均衡器的统计对象 LoadBalancerStats, 同时在具体的choose算法中利用LoadBalancerStats保存的实例统计信息来选择满足要求的实例。它通过遍历负载均衡器中维护的所有服务实例，会过滤掉故障的实例，并找出并发请求数最小的一个，所以该策略的特性是=可选出最空闲的实例==。</p>
<pre><code class="language-java">public Server choose(Object key) {
    if (this.loadBalancerStats == null) {
        return super.choose(key);
    } else {
        List&lt;Server&gt; serverList = this.getLoadBalancer().getAllServers();
        int minimalConcurrentConnections = 2147483647;
        long currentTime = System.currentTimeMillis();
        Server chosen = null;
        Iterator var7 = serverList.iterator();

        while(var7.hasNext()) {
            Server server = (Server)var7.next();
            ServerStats serverStats = this.loadBalancerStats.getSingleServerStat(server);
            if (!serverStats.isCircuitBreakerTripped(currentTime)) {
                int concurrentConnections = serverStats.getActiveRequestsCount(currentTime);
                if (concurrentConnections &lt; minimalConcurrentConnections) {
                    minimalConcurrentConnections = concurrentConnections;
                    chosen = server;
                }
            }
        }

        if (chosen == null) {
            return super.choose(key);
        } else {
            return chosen;
        }
    }
}
</code></pre>
<p>同时，由于该算法的核心依据是统计对象 loadBalancerStats, 当其为空的时候， 该策略是无法执行的。所以从源码中我们可以看到，当loadBalancerStats为空的时候，它会采用父类的线性轮询策略。</p>
<h4 id="358-predicatebasedrule">3.5.8 PredicateBasedRule</h4>
<p>这是一个抽象策略，它也继承了ClientConfigEnabledRoundRobinRule, 从其命名中可以猜出这是一个基于Predicate实现的策略，Predicate是Google Guava Collection工具对集合进行过滤的条件接口。</p>
<p>它定义了一个抽象函数getPredicate来获取AbstractServer­ redicate对象的实现， 而在choose函数中，通过AbstractServerPredicate的chooseRoundRobinAfterFiltering函数来选出具体的服务实例。从该函数的命名我们也大致能猜出它的基础逻辑: 先通过子类中实现的 Predicate 逻辑来过滤一部分服务实例， 然后再以线性轮询的方式从过滤后的实例清单中选出一个。</p>
<pre><code class="language-java">public abstract class PredicateBasedRule extends ClientConfigEnabledRoundRobinRule {
    public PredicateBasedRule() {
    }

    public abstract AbstractServerPredicate getPredicate();

    public Server choose(Object key) {
        ILoadBalancer lb = this.getLoadBalancer();
        Optional&lt;Server&gt; server = this.getPredicate().chooseRoundRobinAfterFiltering(lb.getAllServers(), key);
        return server.isPresent() ? (Server)server.get() : null;
    }
}
</code></pre>
<h4 id="359-availabilityfilteringrule">3.5.9 AvailabilityFilteringRule</h4>
<p>该策略继承自上面介绍的抽象策略PredicateBasedRule 所以它也继承了先过滤清单，再轮询选择的基本处理逻辑，其中过滤条件使用了AbstractServerPredicate:</p>
<h4 id="3510-zoneavoidancerule">3.5.10 ZoneAvoidanceRule</h4>
<p>从ZoneAvoidanceRule的源码片段中可以看到，它使用了CompositePredicate来进行服务实例清单的过滤。 这是一个组合过滤条件，在其构造函数中，它以ZoneAvoidancePredicate为主过滤条件，AvailabilityPredicate为次过滤条件初始化了组合过滤条件的实例。</p>
<pre><code class="language-java">public class ZoneAvoidanceRule extends PredicateBasedRule {
    private static final Random random = new Random();
    private CompositePredicate compositePredicate;

    public ZoneAvoidanceRule() {
        ZoneAvoidancePredicate zonePredicate = new ZoneAvoidancePredicate(this);
        AvailabilityPredicate availabilityPredicate = new AvailabilityPredicate(this);
        this.compositePredicate = this.createCompositePredicate(zonePredicate, availabilityPredicate);
    }
</code></pre>
<p>在实现的时候并没有像AvailabilityFilteringRule那样重写choose函数来优化，所以它完全遵循了父类的过滤主逻辑先过滤清单，再轮询选择。其中过滤清单的条件就是我们上面提到的以ZoneAvoidancePredicate为主过滤条件、AvailabilityPredicate为次过滤条件的组合过滤条件CompositePredicate。从 CompositePredicate 的源码片段中，我们可以看到它定义了一个主过滤条件 AbstractServerPredicate delegate 以及一组次过滤条件列表List fallbacks, 所以它的次过滤列表是可以拥有多个的，并且由于它采用了List存储所以次过滤条件是按顺序执行的。</p>
<pre><code class="language-java">public class CompositePredicate extends AbstractServerPredicate {
    private AbstractServerPredicate delegate;
    private List&lt;AbstractServerPredicate&gt; fallbacks = Lists.newArrayList();
    private int minimalFilteredServers = 1;
    private float minimalFilteredPercentage = 0.0F;

    public boolean apply(@Nullable PredicateKey input) {
        return this.delegate.apply(input);
    }

    public List&lt;Server&gt; getEligibleServers(List&lt;Server&gt; servers, Object loadBalancerKey) {
        List&lt;Server&gt; result = super.getEligibleServers(servers, loadBalancerKey);

        AbstractServerPredicate predicate;
        for(Iterator i = this.fallbacks.iterator(); (result.size() &lt; this.minimalFilteredServers || result.size() &lt;= (int)((float)servers.size() * this.minimalFilteredPercentage)) &amp;&amp; i.hasNext(); result = predicate.getEligibleServers(servers, loadBalancerKey)) {
            predicate = (AbstractServerPredicate)i.next();
        }

        return result;
    }
}
</code></pre>
<p>在获取过滤结果的实现函数getEligibleServers中， 它的处理逻辑如下所示。</p>
<ul>
<li>使用主过滤条件对所有实例过滤并返回过滤后的实例清单。</li>
<li>依次使用次过滤条件列表中的过滤条件对主过滤条件的结果进行过滤。</li>
<li>每次过滤之后(包括主过滤条件和次过滤条件)，都需要判断下面两个条件， 只要有 一个符合就不再进行过滤， 将当前结果返回供线性轮询算法选择:<br>
过滤后的实例总数&gt;=最小过滤实例数(minimalFilteredServers, 默认为1) 。<br>
过滤后的实例比例&gt;最小过滤百分比(minimalFilteredPercentage, 默认为0) 。</li>
</ul>
<h3 id="36-配置详解自动化配置">3.6 配置详解&amp;自动化配置</h3>
<h4 id="361-自动化配置">3.6.1 自动化配置</h4>
<p>由于Ribbon中定义的每一个接口都有多种不同的策略实现，同时这些接口之间又有一定的依赖关系，在引入Spring CloudRibbon的依赖之后， 就能够自动化构建下面这些接口的实现。</p>
<ol>
<li>IClientConfig: Ribbon的客户端配置，默认采用com.netflix.client.config.DefaultClientConfigimpl实现。</li>
<li>IRule: Ribbon的负载均衡策略， 默认采用 com.netflix.loadbalancer.ZoneAvoidanceRule实现，该策略能够在多区域环境下选出最佳区域的实例进行访问。</li>
<li>IPing:ribbon的实例检查策略，默认采用com.netflix.loadbalancer.NoOpPing实现，该检查策略是一个特殊的实现，实际上它并不会检查实例是否可用，而是始终返回true, 默认认为所有服务实例都是可用的。</li>
<li>ServerList<Server>: 服务实例清单的维护机制， 默认采用 com.netflix.loadbalancer.ConfigurationBasedServerList实现。</li>
<li>ServerListFilter<Server>: 服务实例清单过滤机制，默认采用org.springframework.cloud.netflix.ribbon.ZonePreferenceServerListFilter实现，该策略能够优先过滤出与请求调用方处于同区域的服务实例。</li>
<li>ILoadBalancer: 负载均衡器， 默认采用 com.netflix.loadbalancer.ZoneAwareLoadBalancer实现，它具备了区域感知的能力。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《从根儿上理解MySQL》读书笔记(五)]]></title>
        <id>https://q456qq520.github.io/post/lesslesscong-gen-er-shang-li-jie-mysqlgreatergreater-du-shu-bi-ji-wu/</id>
        <link href="https://q456qq520.github.io/post/lesslesscong-gen-er-shang-li-jie-mysqlgreatergreater-du-shu-bi-ji-wu/">
        </link>
        <updated>2023-02-27T10:18:30.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="第22章-undo日志上">第22章 undo日志（上）</h2>
]]></summary>
        <content type="html"><![CDATA[<h2 id="第22章-undo日志上">第22章 undo日志（上）</h2>
<!-- more -->
<h3 id="221-事务回滚的需求">22.1 事务回滚的需求</h3>
<p>我们说过事务需要保证原子性，也就是事务中的操作要么全部完成，要么什么也不做。但是偏偏有时候事务执行到一半会出现一些情况，比如：</p>
<p>情况一：事务执行过程中可能遇到各种错误，比如服务器本身的错误，操作系统错误，甚至是突然断电导致的错误。<br>
情况二：程序员可以在事务执行过程中手动输入ROLLBACK语句结束当前的事务的执行。</p>
<p>这两种情况都会导致事务执行到一半就结束，但是事务执行过程中可能已经修改了很多东西，为了保证事务的原子性，我们需要把东西改回原先的样子，这个过程就称之为回滚（英文名：rollback），这样就可以造成一个假象：这个事务看起来什么都没做，所以符合原子性要求。</p>
<p>你插入了一条记录，回滚操作对应的就是把这条记录删除掉；你更新了一条记录，回滚操作对应的就是把该记录更新为旧值；你删除了一条记录，回滚操作对应的自然就是把该记录再插进去。每当我们要对一条记录做改动时（这里的改动可以指INSERT、DELETE、UPDATE），都需要把回滚时所需的东西都给记下来。比方说：</p>
<ul>
<li>你插入一条记录时，至少要把这条记录的主键值记下来，之后回滚的时候只需要把这个主键值对应的记录删掉就好了。</li>
<li>你删除了一条记录，至少要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录插入到表中就好了。</li>
<li>你修改了一条记录，至少要把修改这条记录前的旧值都记录下来，这样之后回滚时再把这条记录更新为旧值就好了。</li>
</ul>
<p>数据库把这些为了回滚而记录的这些东东称之为<mark>撤销日志</mark>，英文名为<mark>undo log</mark>，称之为undo日志。这里需要注意的一点是，由于查询操作（SELECT）并不会修改任何用户记录，所以在查询操作执行时，并不需要记录相应的undo日志。</p>
<h3 id="222-事务id">22.2 事务id</h3>
<h4 id="2221-给事务分配id的时机">22.2.1 给事务分配id的时机</h4>
<p>一个事务可以是一个只读事务，或者是一个读写事务：</p>
<ul>
<li>可以通过<mark>START TRANSACTION READ ONLY</mark>语句开启一个只读事务。<br>
  在只读事务中不可以对普通的表（其他事务也能访问到的表）进行增、删、改操作，但可以对临时表做增、删、改操作。</li>
<li>可以通过<mark>START TRANSACTION READ WRITE</mark>语句开启一个读写事务，或者使用BEGIN、START TRANSACTION语句开启的事务默认也算是读写事务。<br>
  在读写事务中可以对表执行增删改查操作。</li>
</ul>
<p>如果某个事务执行过程中对某个表执行了增、删、改操作，那么InnoDB存储引擎就会给它分配一个独一无二的事务id，分配方式如下：</p>
<ul>
<li>对于只读事务来说，只有在它第一次对某个用户创建的临时表执行增、删、改操作时才会为这个事务分配一个事务id，否则的话是不分配事务id的。</li>
<li>对于读写事务来说，只有在它第一次对某个表（包括用户创建的临时表）执行增、删、改操作时才会为这个事务分配一个事务id，否则的话也是不分配事务id的。</li>
</ul>
<h4 id="2221-事务id是怎么生成的">22.2.1 事务id是怎么生成的</h4>
<p>这个事务id本质上就是一个数字，它的分配策略和我们前面提到的对隐藏列row_id（当用户没有为表创建主键和UNIQUE键时InnoDB自动创建的列）的分配策略大抵相同，具体策略如下：</p>
<ul>
<li>服务器会在内存中维护一个全局变量，每当需要为某个事务分配一个事务id时，就会把该变量的值当作事务id分配给该事务，并且把该变量自增1。</li>
<li>每当这个变量的值为256的倍数时，就会将该变量的值刷新到系统表空间的页号为<mark>5</mark>的页面中一个称之为<mark>Max Trx ID</mark>的属性处，这个属性占用8个字节的存储空间。</li>
<li>当系统下一次重新启动时，会将上面提到的Max Trx ID属性加载到内存中，将该值加上256之后赋值给我们前面提到的全局变量（因为在上次关机时该全局变量的值可能大于Max Trx ID属性值）。</li>
</ul>
<p>这样就可以保证整个系统中分配的事务id值是一个递增的数字。先被分配id的事务得到的是较小的事务id，后被分配id的事务得到的是较大的事务id。</p>
<h4 id="2222-trx_id隐藏列">22.2.2 trx_id隐藏列</h4>
<p>聚簇索引的记录除了会保存完整的用户数据以外，而且还会自动添加名为trx_id、roll_pointer的隐藏列，如果用户没有在表中定义主键以及UNIQUE键，还会自动添加一个名为row_id的隐藏列。所以一条记录在页面中的真实结构看起来就是这样的：<br>
<img src="https://q456qq520.github.io/post-images/1677551326518.png" alt="" loading="lazy"></p>
<h3 id="223-undo日志的格式">22.3 undo日志的格式</h3>
<p>为了实现事务的原子性，InnoDB存储引擎在实际进行增、删、改一条记录时，都需要先把对应的undo日志记下来。一般每对一条记录做一次改动，就对应着一条undo日志，，但在某些更新记录的操作中，也可能会对应着2条undo日志。一个事务在执行过程中可能新增、删除、更新若干条记录，也就是说需要记录很多条对应的undo日志，这些undo日志会被从0开始编号，也就是说根据生成的顺序分别被称为第0号undo日志、第1号undo日志、...、第n号undo日志等，这个编号也被称之为undo no。</p>
<p>这些undo日志是被记录到类型为<mark>FIL_PAGE_UNDO_LOG</mark>（对应的十六进制是0x0002）的页面中。这些页面可以从系统表空间中分配，也可以从一种专门存放undo日志的表空间，也就是所谓的undo tablespace中分配。</p>
<p>我们先来创建一个名为undo_demo的表：</p>
<pre><code class="language-mysql">CREATE TABLE undo_demo (
    id INT NOT NULL,
    key1 VARCHAR(100),
    col VARCHAR(100),
    PRIMARY KEY (id),
    KEY idx_key1 (key1)
)Engine=InnoDB CHARSET=utf8;
</code></pre>
<p>现在我们查看一下undo_demo对应的table id是多少：</p>
<pre><code class="language-mysql">mysql&gt; SELECT * FROM information_schema.innodb_sys_tables WHERE name = 'xiaohaizi/undo_demo';
+----------+---------------------+------+--------+-------+-------------+------------+---------------+------------+
| TABLE_ID | NAME                | FLAG | N_COLS | SPACE | FILE_FORMAT | ROW_FORMAT | ZIP_PAGE_SIZE | SPACE_TYPE |
+----------+---------------------+------+--------+-------+-------------+------------+---------------+------------+
|      138 | xiaohaizi/undo_demo |   33 |      6 |   482 | Barracuda   | Dynamic    |             0 | Single     |
+----------+---------------------+------+--------+-------+-------------+------------+---------------+------------+
1 row in set (0.01 sec)
</code></pre>
<h3 id="224-insert操作对应的undo日志">22.4 INSERT操作对应的undo日志</h3>
<p>当我们向表中插入一条记录时会有乐观插入和悲观插入的区分，但是不管怎么插入，最终导致的结果就是这条记录被放到了一个数据页中。如果希望回滚这个插入操作，那么把这条记录删除就好了，也就是说在写对应的undo日志时，主要是把这条记录的主键信息记上。所以InnoDB设计了一个类型为<mark>TRX_UNDO_INSERT_REC</mark>的undo日志，它的完整结构如下图所示：<br>
<img src="https://q456qq520.github.io/post-images/1677551633425.png" alt="" loading="lazy"></p>
<ul>
<li>undo no在一个事务中是从0开始递增的，也就是说只要事务没提交，每生成一条undo日志，那么该条日志的undo no就增1。</li>
<li>如果记录中的主键只包含一个列，那么在类型为TRX_UNDO_INSERT_REC的undo日志中只需要把该列占用的存储空间大小和真实值记录下来，如果记录中的主键包含多个列，那么每个列占用的存储空间大小和对应的真实值都需要记录下来（图中的len就代表列占用的存储空间大小，value就代表列的真实值）。</li>
</ul>
<blockquote>
<p>当我们向某个表中插入一条记录时，实际上需要向聚簇索引和所有的二级索引都插入一条记录。不过记录undo日志时，我们只需要考虑向聚簇索引插入记录时的情况就好了，因为其实聚簇索引记录和二级索引记录是一一对应的，我们在回滚插入操作时，只需要知道这条记录的主键信息，然后根据主键信息做对应的删除操作，做删除操作时就会顺带着把所有二级索引中相应的记录也删除掉。DELETE操作和UPDATE操作对应的undo日志也都是针对聚簇索引记录而言的</p>
</blockquote>
<h4 id="2241-roll_pointer隐藏列的含义">22.4.1 roll_pointer隐藏列的含义</h4>
<p>这个占用7个字节的字段本质上就是一个指向记录对应的undo日志的一个指针，undo日志被存放到了类型为FIL_PAGE_UNDO_LOG的页面中。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1677551914332.png" alt="" loading="lazy"></figure>
<p><mark>roll_pointer本质就是一个指针，指向记录对应的undo日志。</mark></p>
<h3 id="225-delete操作对应的undo日志">22.5 DELETE操作对应的undo日志</h3>
<p>插入到页面中的记录会根据记录头信息中的next_record属性组成一个单向链表，我们把这个链表称之为正常记录链表；被删除的记录其实也会根据记录头信息中的next_record属性组成一个链表，只不过这个链表中的记录占用的存储空间可以被重新利用，所以也称这个链表为垃圾链表。Page Header部分有一个称之为PAGE_FREE的属性，它指向由被删除记录组成的垃圾链表中的头节点。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1677552050687.png" alt="" loading="lazy"></figure>
<p>假设现在我们准备使用DELETE语句把正常记录链表中的最后一条记录给删除掉，其实这个删除的过程需要经历两个阶段：</p>
<p>阶段一：仅仅将记录的delete_mask标识位设置为1，其他的不做修改（其实会修改记录的trx_id、roll_pointer这些隐藏列的值）。InnoDB把这个阶段称之为delete mark。也就是正常记录链表中的最后一条记录的delete_mask值被设置为1，但是并没有被加入到垃圾链表。也就是此时记录处于一个中间状态</p>
<p>阶段二：当该删除语句所在的事务提交之后，会有专门的线程后来真正的把记录删除掉。所谓真正的删除就是把该记录从正常记录链表中移除，并且加入到垃圾链表中，然后还要调整一些页面的其他信息，比如页面中的用户记录数量PAGE_N_RECS、上次插入记录的位置PAGE_LAST_INSERT、垃圾链表头节点的指针PAGE_FREE、页面中可重用的字节数量PAGE_GARBAGE、还有页目录的一些信息等等。InnoDB把这个阶段称之为<mark>purge</mark>。</p>
<p>我们还要注意一点，将被删除记录加入到垃圾链表时，实际上加入到链表的头节点处，会跟着修改PAGE_FREE属性的值。</p>
<blockquote>
<p>小贴士：页面的Page Header部分有一个PAGE_GARBAGE属性，该属性记录着当前页面中可重用存储空间占用的总字节数。每当有已删除记录被加入到垃圾链表后，都会把这个PAGE_GARBAGE属性的值加上该已删除记录占用的存储空间大小。PAGE_FREE指向垃圾链表的头节点，之后每当新插入记录时，首先判断PAGE_FREE指向的头节点代表的已删除记录占用的存储空间是否足够容纳这条新插入的记录，如果不可以容纳，就直接向页面中申请新的空间来存储这条记录。如果可以容纳，那么直接重用这条已删除记录的存储空间，并且把PAGE_FREE指向垃圾链表中的下一条已删除记录。但是这里有一个问题，如果新插入的那条记录占用的存储空间大小小于垃圾链表的头节点占用的存储空间大小，那就意味头节点对应的记录占用的存储空间里有一部分空间用不到，这部分空间就被称之为碎片空间。那这些碎片空间岂不是永远都用不到了么？其实也不是，这些碎片空间占用的存储空间大小会被统计到PAGE_GARBAGE属性中，这些碎片空间在整个页面快使用完前并不会被重新利用，不过当页面快满时，如果再插入一条记录，此时页面中并不能分配一条完整记录的空间，这时候会首先看一看PAGE_GARBAGE的空间和剩余可利用的空间加起来是不是可以容纳下这条记录，如果可以的话，InnoDB会尝试重新组织页内的记录，重新组织的过程就是先开辟一个临时页面，把页面内的记录依次插入一遍，因为依次插入时并不会产生碎片，之后再把临时页面的内容复制到本页面，这样就可以把那些碎片空间都解放出来（很显然重新组织页面内的记录比较耗费性能）。</p>
</blockquote>
<p>在删除语句所在的事务提交之前，只会经历阶段一，也就是delete mark阶段（提交之后我们就不用回滚了，所以只需考虑对删除操作的阶段一做的影响进行回滚）。InnoDB设计了一种称之为<mark>TRX_UNDO_DEL_MARK_REC</mark>类型的undo日志，它的完整结构如下图所示：<br>
<img src="https://q456qq520.github.io/post-images/1677552432693.png" alt="" loading="lazy"></p>
<ul>
<li>在对一条记录进行delete mark操作前，需要把该记录的旧的trx_id和roll_pointer隐藏列的值都给记到对应的undo日志中来，就是我们图中显示的old trx_id和old roll_pointer属性。这样有一个好处，那就是可以通过undo日志的old roll_pointer找到记录在修改之前对应的undo日志。执行完delete mark操作后，它对应的undo日志和INSERT操作对应的undo日志就串成了一个链表，这个链表就称之为版本链</li>
<li>与类型为TRX_UNDO_INSERT_REC的undo日志不同，类型为TRX_UNDO_DEL_MARK_REC的undo日志还多了一个索引列各列信息的内容，也就是说如果某个列被包含在某个索引中，那么它的相关信息就应该被记录到这个索引列各列信息部分，所谓的相关信息包括该列在记录中的位置（用pos表示），该列占用的存储空间大小（用len表示），该列实际值（用value表示）。所以索引列各列信息存储的内容实质上就是&lt;pos, len, value&gt;的一个列表。这部分信息主要是用在事务提交后，对该中间状态记录做真正删除的阶段二，也就是purge阶段中使用的。</li>
</ul>
<h3 id="226-update操作对应的undo日志">22.6 UPDATE操作对应的undo日志</h3>
<p>在执行UPDATE语句时，InnoDB对更新主键和不更新主键这两种情况有截然不同的处理方案。</p>
<h5 id="2261-不更新主键的情况">22.6.1 不更新主键的情况</h5>
<p>在不更新主键的情况下，又可以细分为被更新的列占用的存储空间不发生变化和发生变化的情况。</p>
<ol>
<li>
<p>就地更新（in-place update）<br>
更新记录时，对于被更新的每个列来说，如果更新后的列和更新前的列占用的存储空间都一样大，那么就可以进行就地更新，也就是直接在原记录的基础上修改对应列的值。</p>
</li>
<li>
<p>先删除掉旧记录，再插入新记录<br>
在不更新主键的情况下，如果有任何一个被更新的列更新前和更新后占用的存储空间大小不一致，那么就需要先把这条旧的记录从聚簇索引页面中删除掉，然后再根据更新后列的值创建一条新的记录插入到页面中。<br>
我们这里所说的删除并不是delete mark操作，而是真正的删除掉，也就是把这条记录从正常记录链表中移除并加入到垃圾链表中，并且修改页面中相应的统计信息（比如PAGE_FREE、PAGE_GARBAGE等这些信息）。不过这里做真正删除操作的线程并不是在介绍DELETE语句中做purge操作时使用的另外专门的线程，而是由用户线程同步执行真正的删除操作，真正删除之后紧接着就要根据各个列更新后的值创建的新记录插入。</p>
<p>这里如果新创建的记录占用的存储空间大小不超过旧记录占用的空间，那么可以直接重用被加入到垃圾链表中的旧记录所占用的存储空间，否则的话需要在页面中新申请一段空间以供新记录使用，如果本页面内已经没有可用的空间的话，那就需要进行页面分裂操作，然后再插入新记录。</p>
</li>
</ol>
<p>针对UPDATE不更新主键的情况（包括上面所说的就地更新和先删除旧记录再插入新记录），InnoDB设计了一种类型为<mark>TRX_UNDO_UPD_EXIST_REC</mark>的undo日志，它的完整结构如下：<br>
<img src="https://q456qq520.github.io/post-images/1677552943688.png" alt="" loading="lazy"></p>
<ul>
<li>n_updated属性表示本条UPDATE语句执行后将有几个列被更新，后边跟着的&lt;pos, old_len, old_value&gt;分别表示被更新列在记录中的位置、更新前该列占用的存储空间大小、更新前该列的真实值。</li>
<li>如果在UPDATE语句中更新的列包含索引列，那么也会添加索引列各列信息这个部分，否则的话是不会添加这个部分的。</li>
</ul>
<h5 id="2262-更新主键的情况">22.6.2 更新主键的情况</h5>
<p>在聚簇索引中，记录是按照主键值的大小连成了一个单向链表的，如果我们更新了某条记录的主键值，意味着这条记录在聚簇索引中的位置将会发生改变，比如你将记录的主键值从1更新为10000，如果还有非常多的记录的主键值分布在1 ~ 10000之间的话，那么这两条记录在聚簇索引中就有可能离得非常远，甚至中间隔了好多个页面。针对UPDATE语句中更新了记录主键值的这种情况，InnoDB在聚簇索引中分了两步处理：</p>
<ul>
<li>
<p>将旧记录进行delete mark操作<br>
这里是delete mark操作！也就是说在UPDATE语句所在的事务提交前，对旧记录只做一个delete mark操作，在事务提交后才由专门的线程做purge操作，把它加入到垃圾链表中。</p>
<blockquote>
<p>之所以只对旧记录做delete mark操作，是因为别的事务同时也可能访问这条记录，如果把它真正的删除加入到垃圾链表后，别的事务就访问不到了。这个功能就是所谓的MVCC</p>
</blockquote>
</li>
<li>
<p>根据更新后各列的值创建一条新记录，并将其插入到聚簇索引中（需重新定位插入的位置）。<br>
由于更新后的记录主键值发生了改变，所以需要重新从聚簇索引中定位这条记录所在的位置，然后把它插进去。</p>
</li>
</ul>
<p>针对UPDATE语句更新记录主键值的这种情况，在对该记录进行delete mark操作前，会记录一条类型为<mark>TRX_UNDO_DEL_MARK_REC</mark>的undo日志；之后插入新记录时，会记录一条类型为<mark>TRX_UNDO_INSERT_REC</mark>的undo日志，也就是说每对一条记录的主键值做改动时，会记录2条undo日志。</p>
<h2 id="第23章-undo日志下">第23章 undo日志（下）</h2>
<h3 id="231-通用链表结构">23.1 通用链表结构</h3>
<p>在写入undo日志的过程中会使用到多个链表，很多链表都有同样的节点结构，如图所示：<br>
<img src="https://q456qq520.github.io/post-images/1677554741854.png" alt="" loading="lazy"><br>
在某个表空间内，我们可以通过一个页的页号和在页内的偏移量来唯一定位一个节点的位置，这两个信息也就相当于指向这个节点的一个指针。所以：</p>
<ul>
<li>Pre Node Page Number和Pre Node Offset的组合就是指向前一个节点的指针</li>
<li>Next Node Page Number和Next Node Offset的组合就是指向后一个节点的指针。</li>
</ul>
<p>为了更好的管理链表，InnoDB还提出了一个基节点的结构，里边存储了这个链表的头节点、尾节点以及链表长度信息，基节点的结构示意图如下：<br>
<img src="https://q456qq520.github.io/post-images/1677554824666.png" alt="" loading="lazy"></p>
<ul>
<li>List Length表明该链表一共有多少节点。</li>
<li>First Node Page Number和First Node Offset的组合就是指向链表头节点的指针。</li>
<li>Last Node Page Number和Last Node Offset的组合就是指向链表尾节点的指针。</li>
</ul>
<h3 id="232-fil_page_undo_log页面">23.2 FIL_PAGE_UNDO_LOG页面</h3>
<p>一种称之为FIL_PAGE_UNDO_LOG类型的页面是专门用来存储undo日志的，简称为Undo页面，这种类型的页面的通用结构如下图所示（以默认的16KB大小为例）：</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1677555270281.png" alt="" loading="lazy"></figure>
<p>Undo Page Header是Undo页面所特有的，我们来看一下它的结构：<br>
<img src="https://q456qq520.github.io/post-images/1677555427248.png" alt="" loading="lazy"></p>
<ul>
<li>
<p>TRX_UNDO_PAGE_TYPE：本页面准备存储什么种类的undo日志。<br>
TRX_UNDO_INSERT（使用十进制1表示）：类型为TRX_UNDO_INSERT_REC的undo日志属于此大类，一般由INSERT语句产生，或者在UPDATE语句中有更新主键的情况也会产生此类型的undo日志。<br>
TRX_UNDO_UPDATE（使用十进制2表示），除了类型为TRX_UNDO_INSERT_REC的undo日志，其他类型的undo日志都属于这个大类，比如我们前面说的TRX_UNDO_DEL_MARK_REC、TRX_UNDO_UPD_EXIST_REC什么的，一般由DELETE、UPDATE语句产生的undo日志属于这个大类。</p>
<blockquote>
<p>之所以把undo日志分成两个大类，是因为类型为TRX_UNDO_INSERT_REC的undo日志在事务提交后可以直接删除掉，而其他类型的undo日志还需要为所谓的MVCC服务，不能直接删除掉</p>
</blockquote>
</li>
<li>
<p>TRX_UNDO_PAGE_START：表示在当前页面中是从什么位置开始存储undo日志的，或者说表示第一条undo日志在本页面中的起始偏移量。</p>
</li>
<li>
<p>TRX_UNDO_PAGE_FREE：与上面的TRX_UNDO_PAGE_START对应，表示当前页面中存储的最后一条undo日志结束时的偏移量，或者说从这个位置开始，可以继续写入新的undo日志。</p>
</li>
<li>
<p>TRX_UNDO_PAGE_NODE：代表一个List Node结构</p>
</li>
</ul>
<h3 id="233-undo页面链表">23.3 Undo页面链表</h3>
<h4 id="2331-单个事务中的undo页面链表">23.3.1 单个事务中的Undo页面链表</h4>
<p>因为一个事务可能包含多个语句，而且一个语句可能对若干条记录进行改动，而对每条记录进行改动前，都需要记录1条或2条的undo日志，所以在一个事务执行过程中可能产生很多undo日志，这些日志可能一个页面放不下，需要放到多个页面中，这些页面就通过我们上面介绍的TRX_UNDO_PAGE_NODE属性连成了链表：<br>
<img src="https://q456qq520.github.io/post-images/1677555758250.png" alt="" loading="lazy"></p>
<p>在一个事务执行过程中，可能混着执行INSERT、DELETE、UPDATE语句，也就意味着会产生不同类型的undo日志。但是同一个Undo页面要么只存储TRX_UNDO_INSERT大类的undo日志，要么只存储TRX_UNDO_UPDATE大类的undo日志，反正不能混着存，所以在一个事务执行过程中就可能需要2个Undo页面的链表，一个称之为insert undo链表，另一个称之为update undo链表。</p>
<p>另外，InnoDB规定对普通表和临时表的记录改动时产生的undo日志要分别记录，所以在一个事务中最多有4个以Undo页面为节点组成的链表</p>
<p>当然，并不是在事务一开始就会为这个事务分配这4个链表，具体分配策略如下：</p>
<ul>
<li>刚刚开启事务时，一个Undo页面链表也不分配。</li>
<li>当事务执行过程中向普通表中插入记录或者执行更新记录主键的操作之后，就会为其分配一个普通表的insert undo链表。</li>
<li>当事务执行过程中删除或者更新了普通表中的记录之后，就会为其分配一个普通表的update undo链表。</li>
<li>当事务执行过程中向临时表中插入记录或者执行更新记录主键的操作之后，就会为其分配一个临时表的insert undo链表。</li>
<li>当事务执行过程中删除或者更新了临时表中的记录之后，就会为其分配一个临时表的update undo链表。</li>
</ul>
<h4 id="2332-多个事务中的undo页面链表">23.3.2 多个事务中的Undo页面链表</h4>
<p>为了尽可能提高undo日志的写入效率，不同事务执行过程中产生的undo日志需要被写入到不同的Undo页面链表中。</p>
<h3 id="234-undo日志具体写入过程">23.4 undo日志具体写入过程</h3>
<h4 id="2341-段segment的概念">23.4.1 段（Segment）的概念</h4>
<p>段是一个逻辑上的概念，本质上是由若干个零散页面和若干个完整的区组成的。比如一个B+树索引被划分成两个段，一个叶子节点段，一个非叶子节点段，这样叶子节点就可以被尽可能的存到一起，非叶子节点被尽可能的存到一起。每一个段对应一个INODE Entry结构，这个INODE Entry结构描述了这个段的各种信息，比如段的ID，段内的各种链表基节点，零散页面的页号有哪些等信息。为了定位一个INODE Entry，InnoDB设计了一个Segment Header的结构：<br>
<img src="https://q456qq520.github.io/post-images/1677556137591.png" alt="" loading="lazy"></p>
<ul>
<li>Space ID of the INODE Entry：INODE Entry结构所在的表空间ID。</li>
<li>Page Number of the INODE Entry：INODE Entry结构所在的页面页号。</li>
<li>Byte Offset of the INODE Ent：INODE Entry结构在该页面中的偏移量</li>
</ul>
<h4 id="2342-undo-log-segment-header">23.4.2 Undo Log Segment Header</h4>
<p>每一个Undo页面链表都对应着一个段，称之为<mark>Undo Log Segment</mark>。也就是说链表中的页面都是从这个段里边申请的，所以他们在Undo页面链表的第一个页面，也就是上面提到的first undo page中设计了一个称之为<mark>Undo Log Segment Header</mark>的部分，这个部分中包含了该链表对应的段的segment header信息以及其他的一些关于这个段的信息。<br>
<img src="https://q456qq520.github.io/post-images/1677556260660.png" alt="" loading="lazy"></p>
<ol>
<li>TRX_UNDO_STATE：本Undo页面链表处在什么状态。
<ul>
<li>TRX_UNDO_ACTIVE：活跃状态，也就是一个活跃的事务正在往这个段里边写入undo日志。</li>
<li>TRX_UNDO_CACHED：被缓存的状态。处在该状态的Undo页面链表等待着之后被其他事务重用。</li>
<li>TRX_UNDO_TO_FREE：对于insert undo链表来说，如果在它对应的事务提交之后，该链表不能被重用，那么就会处于这种状态。</li>
<li>TRX_UNDO_TO_PURGE：对于update undo链表来说，如果在它对应的事务提交之后，该链表不能被重用，那么就会处于这种状态。</li>
<li>TRX_UNDO_PREPARED：包含处于PREPARE阶段的事务产生的undo日志。</li>
</ul>
</li>
<li>TRX_UNDO_LAST_LOG：本Undo页面链表中最后一个Undo Log Header的位置。</li>
<li>TRX_UNDO_FSEG_HEADER：本Undo页面链表对应的段的Segment Header信息。</li>
<li>TRX_UNDO_PAGE_LIST：Undo页面链表的基节点。</li>
</ol>
<h4 id="2343-undo-log-header">23.4.3 Undo Log Header</h4>
<p>一个事务在向Undo页面中写入undo日志时的方式是十分简单暴力的，就是直接往写，写完一条紧接着写另一条，各条undo日志之间是亲密无间的。写完一个Undo页面后，再从段里申请一个新页面，然后把这个页面插入到Undo页面链表中，继续往这个新申请的页面中写。</p>
<p>InnoDB认为同一个事务向一个Undo页面链表中写入的undo日志算是一个组。在每写入一组undo日志时，都会在这组undo日志前先记录一下关于这个组的一些属性，InnoDB把存储这些属性的地方称之为Undo Log Header。所以Undo页面链表的第一个页面在真正写入undo日志前，其实都会被填充Undo Page Header、Undo Log Segment Header、Undo Log Header这3个部分，如图所示：<br>
<img src="https://q456qq520.github.io/post-images/1677556642689.png" alt="" loading="lazy"></p>
<p>这个Undo Log Header具体的结构如下：<br>
<img src="https://q456qq520.github.io/post-images/1677572594825.png" alt="" loading="lazy"></p>
<ul>
<li>TRX_UNDO_TRX_ID：生成本组undo日志的事务id。</li>
<li>TRX_UNDO_TRX_NO：事务提交后生成的一个需要序号，使用此序号来标记事务的提交顺序（先提交的此序号小，后提交的此序号大）。</li>
<li>TRX_UNDO_DEL_MARKS：标记本组undo日志中是否包含由于Delete mark操作产生的undo日志。</li>
<li>TRX_UNDO_LOG_START：表示本组undo日志中第一条undo日志的在页面中的偏移量。</li>
<li>TRX_UNDO_XID_EXISTS：本组undo日志是否包含XID信息。</li>
<li>TRX_UNDO_DICT_TRANS：标记本组undo日志是不是由DDL语句产生的。</li>
<li>TRX_UNDO_TABLE_ID：如果TRX_UNDO_DICT_TRANS为真，那么本属性表示DDL语句操作的表的table id。</li>
<li>TRX_UNDO_NEXT_LOG：下一组的undo日志在页面中开始的偏移量。</li>
<li>TRX_UNDO_PREV_LOG：上一组的undo日志在页面中开始的偏移量。</li>
<li>TRX_UNDO_HISTORY_NODE：一个12字节的List Node结构，代表一个称之为History链表的节点。</li>
</ul>
<h3 id="235-重用undo页面">23.5 重用Undo页面</h3>
<p>为了能提高并发执行的多个事务写入undo日志的性能，InnoDB决定为每个事务单独分配相应的Undo页面链表（最多可能单独分配4个链表）。但是这样也造成了一些问题，比如其实大部分事务执行过程中可能只修改了一条或几条记录，针对某个Undo页面链表只产生了非常少的undo日志，这些undo日志可能只占用一丢丢存储空间，每开启一个事务就新创建一个Undo页面链表（虽然这个链表中只有一个页面）来存储这么一丢丢undo日志岂不是太浪费了。InnoDB在事务提交后在某些情况下重用该事务的Undo页面链表。一个Undo页面链表是否可以被重用的条件很简单：</p>
<ul>
<li>该链表中只包含一个Undo页面。<br>
如果一个事务执行过程中产生了非常多的undo日志，那么它可能申请非常多的页面加入到Undo页面链表中。在该事物提交后，如果将整个链表中的页面都重用，那就意味着即使新的事务并没有向该Undo页面链表中写入很多undo日志，那该链表中也得维护非常多的页面，那些用不到的页面也不能被别的事务所使用，这样就造成了另一种浪费。InnoDB规定只有在Undo页面链表中只包含一个Undo页面时，该链表才可以被下一个事务所重用。</li>
<li>该Undo页面已经使用的空间小于整个页面空间的3/4。<br>
Undo页面链表按照存储的undo日志所属的大类可以被分为insert undo链表和update undo链表两种，这两种链表在被重用时的策略也是不同的，我们分别看一下：<br>
insert undo链表中只存储类型为TRX_UNDO_INSERT_REC的undo日志，这种类型的undo日志在事务提交之后就没用了，就可以被清除掉。所以在某个事务提交后，重用这个事务的insert undo链表（这个链表中只有一个页面）时，可以直接把之前事务写入的一组undo日志覆盖掉，从头开始写入新事务的一组undo日志。<br>
在一个事务提交后，它的update undo链表中的undo日志也不能立即删除掉（这些日志用于MVCC）。所以如果之后的事务想重用update undo链表时，就不能覆盖之前事务写入的undo日志。这样就相当于在同一个Undo页面中写入了多组的undo日志</li>
</ul>
<h3 id="236-回滚段">23.6 回滚段</h3>
<h4 id="2361-回滚段的概念">23.6.1 回滚段的概念</h4>
<p>我们现在知道一个事务在执行过程中最多可以分配4个Undo页面链表，在同一时刻不同事务拥有的Undo页面链表是不一样的，所以在同一时刻系统里其实可以有许许多多个Undo页面链表存在。为了更好的管理这些链表，InnoDB又设计了一个称之为<mark>Rollback Segment Header</mark>的页面，在这个页面中存放了各个Undo页面链表的frist undo page的页号，他们把这些页号称之为<mark>undo slot</mark>。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1677575600323.png" alt="" loading="lazy"></figure>
<p>每一个Rollback Segment Header页面都对应着一个段，这个段就称为<mark>Rollback Segment</mark>，翻译过来就是<mark>回滚段</mark>。与我们之前介绍的各种段不同的是，这个Rollback Segment里其实只有一个页面。</p>
<ul>
<li>TRX_RSEG_MAX_SIZE：本Rollback Segment中管理的所有Undo页面链表中的Undo页面数量之和的最大值。换句话说，本Rollback Segment中所有Undo页面链表中的Undo页面数量之和不能超过TRX_RSEG_MAX_SIZE代表的值。</li>
<li>TRX_RSEG_HISTORY_SIZE：History链表占用的页面数量。</li>
<li>TRX_RSEG_HISTORY：History链表的基节点。</li>
<li>TRX_RSEG_FSEG_HEADER：本Rollback Segment对应的10字节大小的Segment Header结构，通过它可以找到本段对应的INODE Entry。</li>
<li>TRX_RSEG_UNDO_SLOTS：各个Undo页面链表的first undo page的页号集合，也就是undo slot集合。<br>
一个页号占用4个字节，对于16KB大小的页面来说，这个TRX_RSEG_UNDO_SLOTS部分共存储了1024个undo slot，所以共需1024 × 4 = 4096个字节。</li>
</ul>
<h4 id="2362-从回滚段中申请undo页面链表">23.6.2 从回滚段中申请Undo页面链表</h4>
<p>初始情况下，由于未向任何事务分配任何Undo页面链表，所以对于一个Rollback Segment Header页面来说，它的各个undo slot都被设置成了一个特殊的值：FIL_NULL（对应的十六进制就是0xFFFFFFFF），表示该undo slot不指向任何页面。</p>
<p>开始有事务需要分配Undo页面链表了，就从回滚段的第一个undo slot开始，看看该undo slot的值是不是FIL_NULL：</p>
<ul>
<li>如果是FIL_NULL，那么在表空间中新创建一个段（也就是Undo Log Segment），然后从段里申请一个页面作为Undo页面链表的first undo page，然后把该undo slot的值设置为刚刚申请的这个页面的地址，这样也就意味着这个undo slot被分配给了这个事务。</li>
<li>如果不是FIL_NULL，说明该undo slot已经指向了一个undo链表，也就是说这个undo slot已经被别的事务占用了，那就跳到下一个undo slot，判断该undo slot的值是不是FIL_NULL，重复上面的步骤。</li>
</ul>
<p>一个Rollback Segment Header页面中包含1024个undo slot，如果这1024个undo slot的值都不为FIL_NULL，这就意味着这1024个undo slot都已经名花有主（被分配给了某个事务），此时由于新事务无法再获得新的Undo页面链表，就会回滚这个事务并且给用户报错：</p>
<pre><code class="language-java">Too many active concurrent transactions
</code></pre>
<p>当一个事务提交时，它所占用的undo slot有两种命运：</p>
<ul>
<li>
<p>如果该undo slot指向的Undo页面链表符合被重用的条件（就是我们上面说的Undo页面链表只占用一个页面并且已使用空间小于整个页面的3/4）。<br>
该undo slot就处于被缓存的状态，InnoDB规定这时该Undo页面链表的TRX_UNDO_STATE属性（该属性在first undo page的Undo Log Segment Header部分）会被设置为TRX_UNDO_CACHED。<br>
被缓存的undo slot都会被加入到一个链表，根据对应的Undo页面链表的类型不同，也会被加入到不同的链表：<br>
1、如果对应的Undo页面链表是insert undo链表，则该undo slot会被加入insert undo cached链表。<br>
2、如果对应的Undo页面链表是update undo链表，则该undo slot会被加入update undo cached链表。<br>
一个回滚段就对应着上述两个cached链表，如果有新事务要分配undo slot时，先从对应的cached链表中找。如果没有被缓存的undo slot，才会到回滚段的Rollback Segment Header页面中再去找。</p>
</li>
<li>
<p>如果该undo slot指向的Undo页面链表不符合被重用的条件，那么针对该undo slot对应的Undo页面链表类型不同，也会有不同的处理：<br>
如果对应的Undo页面链表是insert undo链表，则该Undo页面链表的TRX_UNDO_STATE属性会被设置为TRX_UNDO_TO_FREE，之后该Undo页面链表对应的段会被释放掉（也就意味着段中的页面可以被挪作他用），然后把该undo slot的值设置为FIL_NULL。<br>
如果对应的Undo页面链表是update undo链表，则该Undo页面链表的TRX_UNDO_STATE属性会被设置为TRX_UNDO_TO_PRUGE，则会将该undo slot的值设置为FIL_NULL，然后将本次事务写入的一组undo日志放到所谓的History链表中（需要注意的是，这里并不会将Undo页面链表对应的段给释放掉，因为这些undo日志还有用呢～）。</p>
</li>
</ul>
<h4 id="2363-多个回滚段">23.6.3 多个回滚段</h4>
<p>我们说一个事务执行过程中最多分配4个Undo页面链表，而一个回滚段里只有1024个undo slot，很显然undo slot的数量有点少啊。我们即使假设一个读写事务执行过程中只分配1个Undo页面链表，那1024个undo slot也只能支持1024个读写事务同时执行。</p>
<p>InnoDB一口气定义了128个回滚段，也就相当于有了<mark>128 × 1024 = 131072个undo slot</mark>。假设一个读写事务执行过程中只分配1个Undo页面链表，那么就可以同时支持131072个读写事务并发执行。</p>
<p>每个回滚段都对应着一个Rollback Segment Header页面，有128个回滚段，自然就要有128个Rollback Segment Header页面，于是InnoDB在系统表空间的第<mark>5</mark>号页面的某个区域包含了128个8字节大小的格子，每个8字节的格子的构造就像这样：<br>
<img src="https://q456qq520.github.io/post-images/1677577317818.png" alt="" loading="lazy"></p>
<ul>
<li>4字节大小的Space ID，代表一个表空间的ID。</li>
<li>4字节大小的Page number，代表一个页号。</li>
</ul>
<p>也就是说每个8字节大小的格子相当于一个指针，指向某个表空间中的某个页面，这些页面就是Rollback Segment Header。这里需要注意的一点事，要定位一个Rollback Segment Header还需要知道对应的表空间ID，<mark>这也就意味着不同的回滚段可能分布在不同的表空间中</mark>。</p>
<p>所以通过上面的叙述我们可以大致清楚，在系统表空间的第5号页面中存储了128个Rollback Segment Header页面地址，每个Rollback Segment Header就相当于一个回滚段。在Rollback Segment Header页面中，又包含1024个undo slot，每个undo slot都对应一个Undo页面链表。我们画个示意图：<br>
<img src="https://q456qq520.github.io/post-images/1677577529720.png" alt="" loading="lazy"></p>
<h4 id="2364-回滚段的分类">23.6.4 回滚段的分类</h4>
<p>我们把这128个回滚段给编一下号，最开始的回滚段称之为第0号回滚段，之后依次递增，最后一个回滚段就称之为第127号回滚段。这128个回滚段可以被分成两大类：</p>
<ul>
<li>
<p>第0号、第33～127号回滚段属于一类。其中第0号回滚段必须在系统表空间中（就是说第0号回滚段对应的Rollback Segment Header页面必须在系统表空间中），第33～127号回滚段既可以在系统表空间中，也可以在自己配置的undo表空间中。</p>
</li>
<li>
<p>第1～32号回滚段属于一类。这些回滚段必须在临时表空间（对应着数据目录中的ibtmp1文件）中。</p>
</li>
</ul>
<p>也就是说如果一个事务在执行过程中既对普通表的记录做了改动，又对临时表的记录做了改动，那么需要为这个记录分配2个回滚段，再分别到这两个回滚段中分配对应的undo slot。</p>
<p>为什么要把针对普通表和临时表来划分不同种类的回滚段呢？这个还得从Undo页面本身说起，我们说Undo页面其实是类型为FIL_PAGE_UNDO_LOG的页面的简称，说到底它也是一个普通的页面。我们前面说过，在修改页面之前一定要先把对应的redo日志写上，这样在系统奔溃重启时才能恢复到奔溃前的状态。</p>
<p>我们向Undo页面写入undo日志本身也是一个写页面的过程，InnoDB为此还设计了许多种redo日志的类型，比方说MLOG_UNDO_HDR_CREATE、MLOG_UNDO_INSERT、MLOG_UNDO_INIT等等，也就是说我们对Undo页面做的任何改动都会记录相应类型的redo日志。但是对于临时表来说，因为修改临时表而产生的undo日志只需要在系统运行过程中有效，如果系统奔溃了，那么在重启时也不需要恢复这些undo日志所在的页面，所以在写针对临时表的Undo页面时，并不需要记录相应的redo日志。</p>
<p><code>总结一下针对普通表和临时表划分不同种类的回滚段的原因：在修改针对普通表的回滚段中的Undo页面时，需要记录对应的redo日志，而修改针对临时表的回滚段中的Undo页面时，不需要记录对应的redo日志。</code></p>
<blockquote>
<p>小贴士：实际上在MySQL 5.7.21这个版本中，如果我们仅仅对普通表的记录做了改动，那么只会为该事务分配针对普通表的回滚段，不分配针对临时表的回滚段。但是如果我们仅仅对临时表的记录做了改动，那么既会为该事务分配针对普通表的回滚段，又会为其分配针对临时表的回滚段（不过分配了回滚段并不会立即分配undo slot，只有在真正需要Undo页面链表时才会去分配回滚段中的undo slot）。</p>
</blockquote>
<h3 id="237-为事务分配undo页面链表详细过程">23.7 为事务分配Undo页面链表详细过程</h3>
<ol>
<li>事务在执行过程中对普通表的记录首次做改动之前，首先会到系统表空间的第5号页面中分配一个回滚段（其实就是获取一个Rollback Segment Header页面的地址）。一旦某个回滚段被分配给了这个事务，那么之后该事务中再对普通表的记录做改动时，就不会重复分配了。</li>
<li>在分配到回滚段后，首先看一下这个回滚段的两个cached链表有没有已经缓存了的undo slot，比如如果事务做的是INSERT操作，就去回滚段对应的insert undo cached链表中看看有没有缓存的undo slot；如果事务做的是DELETE操作，就去回滚段对应的update undo cached链表中看看有没有缓存的undo slot。如果有缓存的undo slot，那么就把这个缓存的undo slot分配给该事务。</li>
<li>如果没有缓存的undo slot可供分配，那么就要到Rollback Segment Header页面中找一个可用的undo slot分配给当前事务。</li>
<li>找到可用的undo slot后，如果该undo slot是从cached链表中获取的，那么它对应的Undo Log Segment已经分配了，否则的话需要重新分配一个Undo Log Segment，然后从该Undo Log Segment中申请一个页面作为Undo页面链表的first undo page。</li>
<li>然后事务就可以把undo日志写入到上面申请的Undo页面链表了。</li>
</ol>
<p>对临时表的记录做改动的步骤和上述的一样，就不赘述了。不错需要再次强调一次，<mark>如果一个事务在执行过程中既对普通表的记录做了改动，又对临时表的记录做了改动，那么需要为这个记录分配2个回滚段。并发执行的不同事务其实也可以被分配相同的回滚段，只要分配不同的undo slot就可以了</mark>。</p>
<h3 id="238-回滚段相关配置">23.8 回滚段相关配置</h3>
<h4 id="2381-配置回滚段数量">23.8.1 配置回滚段数量</h4>
<p>系统中一共有128个回滚段，其实这只是默认值，我们可以通过启动参数<code>innodb_rollback_segments</code>来配置回滚段的数量，可配置的范围是1~128。但是这个参数并不会影响针对临时表的回滚段数量，针对临时表的回滚段数量一直是32，也就是说：</p>
<ul>
<li>如果我们把innodb_rollback_segments的值设置为1，那么只会有1个针对普通表的可用回滚段，但是仍然有32个针对临时表的可用回滚段。</li>
<li>如果我们把innodb_rollback_segments的值设置为2～33之间的数，效果和将其设置为1是一样的。</li>
<li>如果我们把innodb_rollback_segments设置为大于33的数，那么针对普通表的可用回滚段数量就是该值减去32。</li>
</ul>
<h4 id="2382-配置undo表空间">23.8.2 配置undo表空间</h4>
<p>默认情况下，针对普通表设立的回滚段（第0号以及第33<sub>127号回滚段）都是被分配到系统表空间的。其中的第0号回滚段是一直在系统表空间的，但是第33</sub>127号回滚段可以通过配置放到自定义的undo表空间中。但是这种配置只能在系统初始化（创建数据目录时）的时候使用，一旦初始化完成，之后就不能再次更改了。我们看一下相关启动参数：</p>
<ul>
<li>通过innodb_undo_directory指定undo表空间所在的目录，如果没有指定该参数，则默认undo表空间所在的目录就是数据目录。</li>
<li>通过innodb_undo_tablespaces定义undo表空间的数量。该参数的默认值为0，表明不创建任何undo表空间。</li>
</ul>
<h2 id="第24章-事务的隔离级别与mvcc">第24章 事务的隔离级别与MVCC</h2>
<h3 id="241-事前准备">24.1 事前准备</h3>
<pre><code class="language-mysql">CREATE TABLE hero (
    number INT,
    name VARCHAR(100),
    country varchar(100),
    PRIMARY KEY (number)
) Engine=InnoDB CHARSET=utf8;

INSERT INTO hero VALUES(1, '刘备', '蜀');
</code></pre>
<h3 id="242-事务隔离级别">24.2 事务隔离级别</h3>
<p>MySQL是一个客户端／服务器架构的软件，对于同一个服务器来说，可以有若干个客户端与之连接，每个客户端与服务器连接上之后，就可以称之为一个会话（Session）。每个客户端都可以在自己的会话中向服务器发出请求语句，一个请求语句可能是某个事务的一部分，也就是对于服务器来说可能同时处理多个事务。</p>
<p>事务有一个称之为隔离性的特性，理论上在某个事务对某个数据进行访问时，其他事务应该进行排队，当该事务提交之后，其他事务才可以继续访问这个数据。但是这样子的话对性能影响太大，我们既想保持事务的隔离性，又想让服务器在处理访问同一数据的多个事务时性能尽量高些，鱼和熊掌不可得兼，舍一部分隔离性而取性能者也。</p>
<h4 id="2421-事务并发执行遇到的问题">24.2.1 事务并发执行遇到的问题</h4>
<p>访问相同数据的事务在不保证串行执行（也就是执行完一个再执行另一个）的情况下可能会出现哪些问题：</p>
<ul>
<li><code>脏写（Dirty Write）</code><br>
如果一个事务修改了另一个未提交事务修改过的数据，那就意味着发生了脏写。</li>
<li><code>脏读（Dirty Read）</code><br>
如果一个事务读到了另一个未提交事务修改过的数据，那就意味着发生了脏读。</li>
<li><code>不可重复读（Non-Repeatable Read）</code><br>
如果一个事务能读到另一个已经提交的事务修改过的数据，并且其他事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值，那就意味着发生了不可重复读。</li>
<li><code>幻读（Phantom）</code><br>
如果一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来，那就意味着发生了幻读。</li>
</ul>
<h4 id="2422-sql标准中的四种隔离级别">24.2.2 SQL标准中的四种隔离级别</h4>
<blockquote>
<p>脏写 &gt; 脏读 &gt; 不可重复读 &gt; 幻读</p>
</blockquote>
<p>我们上面所说的舍弃一部分隔离性来换取一部分性能在这里就体现在：<mark>设立一些隔离级别，隔离级别越低，越严重的问题就越可能发生</mark>。制定了一个所谓的SQL标准，在标准中设立了4个隔离级别：</p>
<ul>
<li>READ UNCOMMITTED：未提交读。</li>
<li>READ COMMITTED：已提交读。</li>
<li>REPEATABLE READ：可重复读。</li>
<li>SERIALIZABLE：可串行化。</li>
</ul>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody>
<tr>
<td>READ UNCOMMITTED</td>
<td>Possible</td>
<td>Possible</td>
<td>Possible</td>
</tr>
<tr>
<td>READ COMMITTED</td>
<td>Not Possible</td>
<td>Possible</td>
<td>Possible</td>
</tr>
<tr>
<td>REPEATABLE READ</td>
<td>Not Possible</td>
<td>Not Possible</td>
<td>Possible</td>
</tr>
<tr>
<td>SERIALIZABLE</td>
<td>Not Possible</td>
<td>Not Possible</td>
<td>Not Possible</td>
</tr>
</tbody>
</table>
<p>也就是说：</p>
<ul>
<li>READ UNCOMMITTED隔离级别下，可能发生脏读、不可重复读和幻读问题。</li>
<li>READ COMMITTED隔离级别下，可能发生不可重复读和幻读问题，但是不可以发生脏读问题。</li>
<li>REPEATABLE READ隔离级别下，可能发生幻读问题，但是不可以发生脏读和不可重复读的问题。</li>
<li>SERIALIZABLE隔离级别下，各种问题都不可以发生。</li>
</ul>
<h4 id="2423-mysql中支持的四种隔离级别">24.2.3 MySQL中支持的四种隔离级别</h4>
<p>MySQL的默认隔离级别为REPEATABLE READ，我们可以手动修改一下事务的隔离级别。</p>
<pre><code class="language-mysql">SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL level;

level: {
     REPEATABLE READ
   | READ COMMITTED
   | READ UNCOMMITTED
   | SERIALIZABLE
}
</code></pre>
<p>如果我们在服务器启动时想改变事务的默认隔离级别，可以修改启动参数transaction-isolation的值，比方说我们在启动服务器时指定了--transaction-isolation=SERIALIZABLE，那么事务的默认隔离级别就从原来的REPEATABLE READ变成了SERIALIZABLE。</p>
<pre><code class="language-mysql">SHOW VARIABLES LIKE 'transaction_isolation';
SELECT @@transaction_isolation;
</code></pre>
<h3 id="243-mvcc原理">24.3 MVCC原理</h3>
<h4 id="2431-版本链">24.3.1 版本链</h4>
<p>对于使用InnoDB存储引擎的表来说，它的聚簇索引记录中都包含两个必要的隐藏列（row_id并不是必要的，我们创建的表中有主键或者非NULL的UNIQUE键时都不会包含row_id列）：</p>
<ul>
<li>trx_id：每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的事务id赋值给trx_id隐藏列。</li>
<li>roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到undo日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。</li>
</ul>
<p>比方说我们的表hero现在只包含一条记录，假设插入该记录的事务id为80，那么此刻该条记录的示意图如下所示：<br>
<img src="https://q456qq520.github.io/post-images/1677641519242.png" alt="" loading="lazy"></p>
<blockquote>
<p>小贴士：实际上insert undo只在事务回滚时起作用，当事务提交后，该类型的undo日志就没用了，它占用的Undo Log Segment也会被系统回收（也就是该undo日志占用的Undo页面链表要么被重用，要么被释放）。虽然真正的insert undo日志占用的存储空间被释放了，但是roll_pointer的值并不会被清除，roll_pointer属性占用7个字节，第一个比特位就标记着它指向的undo日志的类型，如果该比特位的值为1时，就代表着它指向的undo日志类型为insert undo。</p>
</blockquote>
<p>假设之后两个事务id分别为100、200的事务对这条记录进行UPDATE操作，操作流程如下：<br>
<img src="https://q456qq520.github.io/post-images/1677641595137.png" alt="" loading="lazy"></p>
<blockquote>
<p>小贴士：能不能在两个事务中交叉更新同一条记录呢？这不就是一个事务修改了另一个未提交事务修改过的数据，沦为了脏写了么？InnoDB使用锁来保证不会有脏写情况的发生，也就是在第一个事务更新了某条记录后，就会给这条记录加锁，另一个事务再次更新时就需要等待第一个事务提交了，把锁释放之后才可以继续更新。</p>
</blockquote>
<p>每次对记录进行改动，都会记录一条undo日志，每条undo日志也都有一个roll_pointer属性（INSERT操作对应的undo日志没有该属性，因为该记录并没有更早的版本），可以将这些undo日志都连起来，串成一个链表，所以现在的情况就像下图一样：<br>
<img src="https://q456qq520.github.io/post-images/1677641689718.png" alt="" loading="lazy"></p>
<p>对该记录每次更新后，都会将旧值放到一条undo日志中，就算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被roll_pointer属性连接成一个链表，我们把这个链表称之为<code>版本链</code>，<mark>版本链的头节点就是当前记录最新的值</mark>。另外，每个版本中还包含生成该版本时对应的事务id。</p>
<h4 id="2432-readview">24.3.2 ReadView</h4>
<p>对于使用READ UNCOMMITTED隔离级别的事务来说，由于可以读到未提交事务修改过的记录，所以直接读取记录的最新版本就好了；对于使用SERIALIZABLE隔离级别的事务来说，设计InnoDB的大佬规定使用加锁的方式来访问记录；对于使用READ COMMITTED和REPEATABLE READ隔离级别的事务来说，都必须保证读到已经提交了的事务修改过的记录，也就是说假如另一个事务已经修改了记录但是尚未提交，是不能直接读取最新版本的记录的，核心问题就是：<mark>需要判断一下版本链中的哪个版本是当前事务可见的</mark>。为此InnoDB提出了一个<code>ReadView</code>的概念，这个ReadView中主要包含4个比较重要的内容：</p>
<ul>
<li>m_ids：表示在生成ReadView时当前系统中活跃的读写事务的事务id列表。</li>
<li>min_trx_id：表示在生成ReadView时当前系统中活跃的读写事务中最小的事务id，也就是m_ids中的最小值。</li>
<li>max_trx_id：表示生成ReadView时系统中应该分配给下一个事务的id值。</li>
<li>creator_trx_id：表示生成该ReadView的事务的事务id，只读事务中的事务id值都默认为0。</li>
</ul>
<p>有了这个ReadView，这样在访问某条记录时，只需要按照下面的步骤判断记录的某个版本是否可见：</p>
<ul>
<li>如果被访问版本的trx_id属性值与ReadView中的creator_trx_id值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。</li>
<li>如果被访问版本的trx_id属性值小于ReadView中的min_trx_id值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。</li>
<li>如果被访问版本的trx_id属性值大于ReadView中的max_trx_id值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。</li>
<li>如果被访问版本的trx_id属性值在ReadView的min_trx_id和max_trx_id之间，那就需要判断一下trx_id属性值是不是在m_ids列表中，如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。</li>
</ul>
<p><mark>如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上面的步骤判断可见性，依此类推，直到版本链中的最后一个版本。如果最后一个版本也不可见的话，那么就意味着该条记录对该事务完全不可见，查询结果就不包含该记录。</mark></p>
<p>在MySQL中，READ COMMITTED和REPEATABLE READ隔离级别的的一个非常大的区别就是它们生成ReadView的时机不同。我们还是以表hero为例来，假设现在表hero中只有一条由事务id为80的事务插入的一条记录：</p>
<p><strong>READ COMMITTED —— 每次读取数据前都生成一个ReadView</strong><br>
比方说现在系统里有两个事务id分别为100、200的事务在执行：</p>
<pre><code class="language-mysql"># Transaction 100
BEGIN;
UPDATE hero SET name = '关羽' WHERE number = 1;
UPDATE hero SET name = '张飞' WHERE number = 1;

# Transaction 200
BEGIN;

# 更新了一些别的表的记录
...
</code></pre>
<p>此刻，表hero中number为1的记录得到的版本链表如下所示：<br>
<img src="https://q456qq520.github.io/post-images/1677642299129.png" alt="" loading="lazy"></p>
<p>假设现在有一个使用READ COMMITTED隔离级别的事务开始执行：</p>
<pre><code class="language-mysql"># 使用READ COMMITTED隔离级别的事务
BEGIN;

# SELECT1：Transaction 100、200未提交
SELECT * FROM hero WHERE number = 1; # 得到的列name的值为'刘备'
</code></pre>
<p>这个SELECT1的执行过程如下：</p>
<ul>
<li>在执行SELECT语句时会先生成一个ReadView，ReadView的m_ids列表的内容就是[100, 200]，min_trx_id为100，max_trx_id为201，creator_trx_id为0。</li>
<li>然后从版本链中挑选可见的记录，从图中可以看出，最新版本的列name的内容是'张飞'，该版本的trx_id值为100，在m_ids列表内，所以不符合可见性要求，根据roll_pointer跳到下一个版本。</li>
<li>下一个版本的列name的内容是'关羽'，该版本的trx_id值也为100，也在m_ids列表内，所以也不符合要求，继续跳到下一个版本。</li>
<li>下一个版本的列name的内容是'刘备'，该版本的trx_id值为80，小于ReadView中的min_trx_id值100，所以这个版本是符合要求的，最后返回给用户的版本就是这条列name为'刘备'的记录。</li>
</ul>
<p>总结一下就是：<mark>使用READ COMMITTED隔离级别的事务在每次查询开始时都会生成一个独立的ReadView</mark>。</p>
<p><strong>REPEATABLE READ —— 在第一次读取数据时生成一个ReadView</strong><br>
 对于使用REPEATABLE READ隔离级别的事务来说，只会在第一次执行查询语句时生成一个ReadView，之后的查询就不会重复生成了。我们还是用例子看一下是什么效果。</p>
<p>比方说现在系统里有两个事务id分别为100、200的事务在执行：</p>
<pre><code class="language-mysql"># Transaction 100
BEGIN;
UPDATE hero SET name = '关羽' WHERE number = 1;
UPDATE hero SET name = '张飞' WHERE number = 1;
# Transaction 200
BEGIN;
# 更新了一些别的表的记录
...
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1677642299129.png" alt="" loading="lazy"></figure>
<p>假设现在有一个使用REPEATABLE READ隔离级别的事务开始执行：</p>
<pre><code class="language-mysql"># 使用REPEATABLE READ隔离级别的事务
BEGIN;

# SELECT1：Transaction 100、200未提交
SELECT * FROM hero WHERE number = 1; # 得到的列name的值为'刘备'
</code></pre>
<p>这个SELECT1的执行过程如下：</p>
<ul>
<li>在执行SELECT语句时会先生成一个ReadView，ReadView的m_ids列表的内容就是[100, 200]，min_trx_id为100，max_trx_id为201，creator_trx_id为0。</li>
<li>然后从版本链中挑选可见的记录，从图中可以看出，最新版本的列name的内容是'张飞'，该版本的trx_id值为100，在m_ids列表内，所以不符合可见性要求，根据roll_pointer跳到下一个版本。</li>
<li>下一个版本的列name的内容是'关羽'，该版本的trx_id值也为100，也在m_ids列表内，所以也不符合要求，继续跳到下一个版本。</li>
<li>下一个版本的列name的内容是'刘备'，该版本的trx_id值为80，小于ReadView中的min_trx_id值100，所以这个版本是符合要求的，最后返回给用户的版本就是这条列name为'刘备'的记录。</li>
</ul>
<p>我们把事务id为100的事务提交一下，然后再到事务id为200的事务中更新一下表hero中number为1的记录：</p>
<pre><code class="language-mysql"># Transaction 200
BEGIN;

# 更新了一些别的表的记录
...
UPDATE hero SET name = '赵云' WHERE number = 1;

UPDATE hero SET name = '诸葛亮' WHERE number = 1;
</code></pre>
<p>然后再到刚才使用REPEATABLE READ隔离级别的事务中继续查找这个number为1的记录，如下：</p>
<pre><code class="language-mysql"># 使用REPEATABLE READ隔离级别的事务
BEGIN;

# SELECT1：Transaction 100、200均未提交
SELECT * FROM hero WHERE number = 1; # 得到的列name的值为'刘备'

# SELECT2：Transaction 100提交，Transaction 200未提交
SELECT * FROM hero WHERE number = 1; # 得到的列name的值仍为'刘备'
</code></pre>
<p>因为当前事务的隔离级别为REPEATABLE READ，而之前在执行SELECT1时已经生成过ReadView了，所以此时直接复用之前的ReadView。也就是说两次SELECT查询得到的结果是重复的，记录的列c值都是'刘备'，这就是可重复读的含义。如果我们之后再把事务id为200的记录提交了，然后再到刚才使用REPEATABLE READ隔离级别的事务中继续查找这个number为1的记录，得到的结果还是'刘备'。</p>
<h3 id="244-mvcc小结">24.4 MVCC小结</h3>
<p>从上面的描述中我们可以看出来，所谓的MVCC（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用READ COMMITTD、REPEATABLE READ这两种隔离级别的事务在执行普通的SEELCT操作时访问记录的版本链的过程，这样子可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。READ COMMITTD、REPEATABLE READ这两个隔离级别的一个很大不同就是：<mark>生成ReadView的时机不同，READ COMMITTD在每一次进行普通SELECT操作前都会生成一个ReadView，而REPEATABLE READ只在第一次进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView就好了</mark>。</p>
<blockquote>
<p>我们之前说执行DELETE语句或者更新主键的UPDATE语句并不会立即把对应的记录完全从页面中删除，而是执行一个所谓的delete mark操作，相当于只是对记录打上了一个删除标志位，这主要就是为MVCC服务的。</p>
</blockquote>
<p>随着系统的运行，在确定系统中包含最早产生的那个ReadView的事务不会再访问某些update undo日志以及被打了删除标记的记录后，有一个后台运行的purge线程会把它们真正的删除掉。</p>
<h2 id="第25章-锁">第25章 锁</h2>
<h3 id="251-解决并发事务带来问题的两种基本方式">25.1 解决并发事务带来问题的两种基本方式</h3>
<p>并发事务访问相同记录的情况大致可以划分为3种：</p>
<p><strong>读-读情况</strong>：即并发事务相继读取相同的记录。<br>
  读取操作本身不会对记录有一毛钱影响，并不会引起什么问题，所以允许这种情况的发生。</p>
<p><strong>写-写情况</strong>：即并发事务相继对相同的记录做出改动。<br>
  在这种情况下会发生脏写的问题，任何一种隔离级别都不允许这种问题的发生。所以在多个未提交事务相继对一条记录做改动时，需要让它们排队执行，这个排队的过程其实是通过锁来实现的。这个所谓的锁其实是一个内存中的结构，在事务执行前本来是没有锁的，当一个事务想对这条记录做改动时，首先会看看内存中有没有与这条记录关联的锁结构，当没有的时候就会在内存中生成一个锁结构与之关联。<br>
<img src="https://q456qq520.github.io/post-images/1677721702728.png" alt="" loading="lazy"></p>
<p>我们现在只把两个比较重要的属性拿了出来：<br>
1、trx信息：代表这个锁结构是哪个事务生成的。<br>
2、is_waiting：代表当前事务是否在等待。</p>
<p>如图所示，当事务T1改动了这条记录后，就生成了一个锁结构与该记录关联，因为之前没有别的事务为这条记录加锁，所以is_waiting属性就是false，我们把这个场景就称之为获取锁成功，或者加锁成功，然后就可以继续执行操作了。<br>
在事务T1提交之前，另一个事务T2也想对该记录做改动，那么先去看看有没有锁结构与这条记录关联，发现有一个锁结构与之关联后，然后也生成了一个锁结构与这条记录关联，不过锁结构的is_waiting属性值为true，表示当前事务需要等待，我们把这个场景就称之为获取锁失败，或者加锁失败，或者没有成功的获取到锁。<br>
在事务T1提交之后，就会把该事务生成的锁结构释放掉，然后看看还有没有别的事务在等待获取锁，发现了事务T2还在等待获取锁，所以把事务T2对应的锁结构的is_waiting属性设置为false，然后把该事务对应的线程唤醒，让它继续执行，此时事务T2就算获取到锁了。</p>
<p><strong>读-写或写-读情况</strong>：也就是一个事务进行读取操作，另一个进行改动操作。这种情况下可能发生脏读、不可重复读、幻读的问题。</p>
<p>怎么解决脏读、不可重复读、幻读这些问题呢？其实有两种可选的解决方案：</p>
<p>方案一：读操作利用多版本并发控制（MVCC），写操作进行加锁。<br>
就是通过生成一个ReadView，然后通过ReadView找到符合条件的记录版本（历史版本是由undo日志构建的），其实就像是在生成ReadView的那个时刻做了一次时间静止（就像用相机拍了一个快照），查询语句只能读到在生成ReadView之前已提交事务所做的更改，在生成ReadView之前未提交的事务或者之后才开启的事务所做的更改是看不到的。而写操作肯定针对的是最新版本的记录，读记录的历史版本和改动记录的最新版本本身并不冲突，也就是采用MVCC时，读-写操作并不冲突。</p>
<p>方案二：读、写操作都采用加锁的方式。<br>
如果我们的一些业务场景不允许读取记录的旧版本，而是每次都必须去读取记录的最新版本，这样在读取记录的时候也就需要对其进行加锁操作，这样也就意味着读操作和写操作也像写-写操作那样排队执行。</p>
<h3 id="252-一致性读consistent-reads">25.2 一致性读（Consistent Reads）</h3>
<p>事务利用MVCC进行的读取操作称之为一致性读，或者一致性无锁读，有的地方也称之为快照读。所有普通的SELECT语句（plain SELECT）在READ COMMITTED、REPEATABLE READ隔离级别下都算是一致性读。</p>
<p>一致性读并不会对表中的任何记录做加锁操作，其他事务可以自由的对表中的记录做改动。</p>
<h3 id="253-锁定读locking-reads">25.3 锁定读（Locking Reads）</h3>
<h4 id="2531-共享锁和独占锁">25.3.1 共享锁和独占锁</h4>
<p>在使用加锁的方式解决问题时，由于既要允许读-读情况不受影响，又要使写-写、读-写或写-读情况中的操作相互阻塞，所以MySQL给锁分了个类：</p>
<p><code>共享锁</code>，英文名：Shared  Locks，简称S锁。在事务要读取一条记录时，需要先获取该记录的S锁。<br>
<code>独占锁</code>，也常称排他锁，英文名：Exclusive Locks，简称X锁。在事务要改动一条记录时，需要先获取该记录的X锁。</p>
<p>假如事务T1首先获取了一条记录的S锁之后，事务T2接着也要访问这条记录：<br>
如果事务T2想要再获取一个记录的S锁，那么事务T2也会获得该锁，也就意味着事务T1和T2在该记录上同时持有S锁。<br>
如果事务T2想要再获取一个记录的X锁，那么此操作会被阻塞，直到事务T1提交之后将S锁释放掉。<br>
如果事务T1首先获取了一条记录的X锁之后，那么不管事务T2接着想获取该记录的S锁还是X锁都会被阻塞，直到事务T1提交。</p>
<h4 id="2532-锁定读的语句">25.3.2 锁定读的语句</h4>
<p>我们前面说在采用加锁方式解决脏读、不可重复读、幻读这些问题时，读取一条记录时需要获取一下该记录的S锁，其实这是不严谨的，有时候想在读取记录时就获取记录的X锁，来禁止别的事务读写该记录，为此MySQL提出了两种比较特殊的SELECT语句格式：</p>
<ol>
<li>对读取的记录加S锁：</li>
</ol>
<pre><code class="language-mysql">SELECT ... LOCK IN SHARE MODE;
</code></pre>
<p>也就是在普通的SELECT语句后边加LOCK IN SHARE MODE，如果当前事务执行了该语句，那么它会为读取到的记录加S锁，这样允许别的事务继续获取这些记录的S锁（比方说别的事务也使用SELECT ... LOCK IN SHARE MODE语句来读取这些记录），但是不能获取这些记录的X锁（比方说使用SELECT ... FOR UPDATE语句来读取这些记录，或者直接修改这些记录）。如果别的事务想要获取这些记录的X锁，那么它们会阻塞，直到当前事务提交之后将这些记录上的S锁释放掉。</p>
<ol start="2">
<li>对读取的记录加X锁：</li>
</ol>
<pre><code class="language-mysql">SELECT ... FOR UPDATE;
</code></pre>
<p>也就是在普通的SELECT语句后边加FOR UPDATE，如果当前事务执行了该语句，那么它会为读取到的记录加X锁，这样既不允许别的事务获取这些记录的S锁，也不允许获取这些记录的X锁。如果别的事务想要获取这些记录的S锁或者X锁，那么它们会阻塞，直到当前事务提交之后将这些记录上的X锁释放掉。</p>
<h4 id="2533-写操作">25.3.3 写操作</h4>
<ol>
<li>
<p>DELETE：<br>
  对一条记录做DELETE操作的过程其实是先在B+树中定位到这条记录的位置，然后获取一下这条记录的X锁，然后再执行delete mark操作。我们也可以把这个定位待删除记录在B+树中位置的过程看成是一个获取X锁的锁定读。</p>
</li>
<li>
<p>UPDATE：对一条记录做UPDATE操作时分为三种情况：<br>
  - 如果未修改该记录的键值并且被更新的列占用的存储空间在修改前后未发生变化，则先在B+树中定位到这条记录的位置，然后再获取一下记录的X锁，最后在原记录的位置进行修改操作。其实我们也可以把这个定位待修改记录在B+树中位置的过程看成是一个获取X锁的锁定读。<br>
  - 如果未修改该记录的键值并且至少有一个被更新的列占用的存储空间在修改前后发生变化，则先在B+树中定位到这条记录的位置，然后获取一下记录的X锁，将该记录彻底删除掉（就是把记录彻底移入垃圾链表），最后再插入一条新记录。这个定位待修改记录在B+树中位置的过程看成是一个获取X锁的锁定读，新插入的记录由INSERT操作提供的隐式锁进行保护<br>
  - 如果修改了该记录的键值，则相当于在原记录上做DELETE操作之后再来一次INSERT操作，加锁操作就需要按照DELETE和INSERT的规则进行了。</p>
</li>
<li>
<p>INSERT：<br>
  一般情况下，新插入一条记录的操作并不加锁，设计InnoDB的大佬通过一种称之为隐式锁的东东来保护这条新插入的记录在本事务提交前不被别的事务访问</p>
</li>
</ol>
<h3 id="254-多粒度锁">25.4 多粒度锁</h3>
<p>前面提到的锁都是针对记录的，也可以被称之为行级锁或者行锁，对一条记录加锁影响的也只是这条记录而已，我们就说这个锁的粒度比较细；其实一个事务也可以在表级别进行加锁，自然就被称之为<mark>表级锁</mark>或者<mark>表锁</mark>，对一个表加锁影响整个表中的记录，我们就说这个锁的粒度比较粗。给表加的锁也可以分为共享锁（S锁）和独占锁（X锁）：</p>
<p>给表加S锁：<br>
  如果一个事务给表加了S锁，那么：<br>
  别的事务可以继续获得该表的S锁<br>
  别的事务可以继续获得该表中的某些记录的S锁<br>
  别的事务不可以继续获得该表的X锁<br>
  别的事务不可以继续获得该表中的某些记录的X锁<br>
给表加X锁：<br>
  如果一个事务给表加了X锁（意味着该事务要独占这个表），那么：<br>
  别的事务不可以继续获得该表的S锁<br>
  别的事务不可以继续获得该表中的某些记录的S锁<br>
  别的事务不可以继续获得该表的X锁<br>
  别的事务不可以继续获得该表中的某些记录的X锁</p>
<p>我们在对表上表锁时，怎么知道该表有没有上行锁呢？依次检查有没有上锁？那这效率也太慢了吧！于是乎InnoDB提出了一种称之为<mark>意向锁（英文名：Intention Locks）</mark>：</p>
<ul>
<li>意向共享锁，英文名：Intention Shared Lock，简称IS锁。当事务准备在某条记录上加S锁时，需要先在表级别加一个IS锁。</li>
<li>意向独占锁，英文名：Intention Exclusive Lock，简称IX锁。当事务准备在某条记录上加X锁时，需要先在表级别加一个IX锁。</li>
</ul>
<p><mark>IS、IX锁是表级锁，它们的提出仅仅为了在之后加表级别的S锁和X锁时可以快速判断表中的记录是否被上锁，以避免用遍历的方式来查看表中有没有上锁的记录，也就是说其实IS锁和IX锁是兼容的，IX锁和IX锁是兼容的</mark>。</p>
<h3 id="255-mysql中的行锁和表锁">25.5 MySQL中的行锁和表锁</h3>
<h4 id="2551-其他存储引擎中的锁">25.5.1 其他存储引擎中的锁</h4>
<p>对于MyISAM、MEMORY、MERGE这些存储引擎来说，它们只支持表级锁，而且这些引擎并不支持事务，所以使用这些存储引擎的锁一般都是针对当前会话来说的。</p>
<p>比方说在Session 1中对一个表执行SELECT操作，就相当于为这个表加了一个表级别的S锁，如果在SELECT操作未完成时，Session 2中对这个表执行UPDATE操作，相当于要获取表的X锁，此操作会被阻塞，直到Session 1中的SELECT操作完成，释放掉表级别的S锁后，Session 2中对这个表执行UPDATE操作才能继续获取X锁，然后执行具体的更新语句。</p>
<blockquote>
<p>小贴士：因为使用MyISAM、MEMORY、MERGE这些存储引擎的表在同一时刻只允许一个会话对表进行写操作，所以这些存储引擎实际上最好用在只读，或者大部分都是读操作，或者单用户的情景下。另外，在MyISAM存储引擎中有一个称之为Concurrent Inserts的特性，支持在对MyISAM表读取时同时插入记录，这样可以提升一些插入速度。</p>
</blockquote>
<h4 id="2552-innodb存储引擎中的锁">25.5.2 InnoDB存储引擎中的锁</h4>
<p>InnoDB存储引擎既支持表锁，也支持行锁。表锁实现简单，占用资源较少，不过粒度很粗，有时候你仅仅需要锁住几条记录，但使用表锁的话相当于为表中的所有记录都加锁，所以性能比较差。行锁粒度更细，可以实现更精准的并发控制。</p>
<h5 id="innodb中的表级锁">InnoDB中的表级锁</h5>
<ol>
<li>
<p>表级别的S锁、X锁<br>
在对某个表执行SELECT、INSERT、DELETE、UPDATE语句时，InnoDB存储引擎是不会为这个表添加表级别的S锁或者X锁的。<br>
在对某个表执行一些诸如ALTER TABLE、DROP TABLE这类的DDL语句时，其他事务对这个表并发执行诸如SELECT、INSERT、DELETE、UPDATE的语句会发生阻塞，同理，某个事务中对某个表执行SELECT、INSERT、DELETE、UPDATE语句时，在其他会话中对这个表执行DDL语句也会发生阻塞。这个过程其实是通过在server层使用一种称之为==元数据锁（英文名：Metadata Locks，简称MDL）==来实现的，一般情况下也不会使用InnoDB存储引擎自己提供的表级别的S锁和X锁。</p>
<p>其实这个InnoDB存储引擎提供的表级S锁或者X锁是相当鸡肋，只会在一些特殊情况下，比方说崩溃恢复过程中用到。不过我们还是可以手动获取一下的，比方说在系统变量<mark>autocommit=0，innodb_table_locks = 1</mark>时，手动获取InnoDB存储引擎提供的表t的S锁或者X锁可以这么写：</p>
</li>
</ol>
<pre><code class="language-mysql">LOCK TABLES t READ：InnoDB存储引擎会对表t加表级别的S锁。
LOCK TABLES t WRITE：InnoDB存储引擎会对表t加表级别的X锁。
</code></pre>
<ol start="2">
<li>表级别的IS锁、IX锁<br>
当我们在对使用InnoDB存储引擎的表的某些记录加S锁之前，那就需要先在表级别加一个IS锁，当我们在对使用InnoDB存储引擎的表的某些记录加X锁之前，那就需要先在表级别加一个IX锁。IS锁和IX锁的使命只是为了后续在加表级别的S锁和X锁时判断表中是否有已经被加锁的记录，以避免用遍历的方式来查看表中有没有上锁的记录。</li>
<li>表级别的AUTO-INC锁<br>
在使用MySQL过程中，我们可以为表的某个列添加AUTO_INCREMENT属性，之后在插入记录时，可以不指定该列的值，系统会自动为它赋上递增的值。系统实现这种自动给AUTO_INCREMENT修饰的列递增赋值的原理主要是两个：<br>
采用AUTO-INC锁，也就是在执行插入语句时就在表级别加一个AUTO-INC锁，然后为每条待插入记录的AUTO_INCREMENT修饰的列分配递增的值，在该语句执行结束后，再把AUTO-INC锁释放掉。这样一个事务在持有AUTO-INC锁的过程中，其他事务的插入语句都要被阻塞，可以保证一个语句中分配的递增值是连续的。<br>
采用一个轻量级的锁，在为插入语句生成AUTO_INCREMENT修饰的列的值时获取一下这个轻量级锁，然后生成本次插入语句需要用到的AUTO_INCREMENT列的值之后，就把该轻量级锁释放掉，并不需要等到整个插入语句执行完才释放锁。</li>
</ol>
<h5 id="innodb中的行级锁">InnoDB中的行级锁</h5>
<p>行锁，也称为<mark>记录锁</mark>，顾名思义就是在记录上加的锁。InnoDB把行锁分成了各种类型。换句话说即使对同一条记录加行锁，如果类型不同，起到的功效也是不同的。我们先将之前介绍MVCC时用到的表抄一遍：</p>
<pre><code class="language-mysql">CREATE TABLE hero (
    number INT,
    name VARCHAR(100),
    country varchar(100),
    PRIMARY KEY (number),
    KEY idx_name (name)
) Engine=InnoDB CHARSET=utf8;

mysql&gt; SELECT * FROM hero;
+--------+------------+---------+
| number | name       | country |
+--------+------------+---------+
|      1 | l刘备      | 蜀      |
|      3 | z诸葛亮    | 蜀      |
|      8 | c曹操      | 魏      |
|     15 | x荀彧      | 魏      |
|     20 | s孙权      | 吴      |
+--------+------------+---------+
5 rows in set (0.01 sec)
</code></pre>
<p>下面我们来看看都有哪些常用的行锁类型:<br>
<code>Record Locks</code><br>
我们前面提到的记录锁就是这种类型，是有S锁和X锁之分的，让我们分别称之为S型记录锁和X型记录锁吧，当一个事务获取了一条记录的S型记录锁后，其他事务也可以继续获取该记录的S型记录锁，但不可以继续获取X型记录锁；当一个事务获取了一条记录的X型记录锁后，其他事务既不可以继续获取该记录的S型记录锁，也不可以继续获取X型记录锁；</p>
<p><code>Gap Locks</code><br>
我们说MySQL在REPEATABLE READ隔离级别下是可以解决幻读问题的，解决方案有两种，可以使用MVCC方案解决，也可以采用加锁方案解决。但是在使用加锁方案解决时有个大问题，就是事务在第一次执行读取操作时，那些幻影记录尚不存在，我们无法给这些幻影记录加上记录锁。InnoDB提出了一种称之为Gap Locks的锁，官方的类型名称为：<mark>LOCK_GAP</mark>，我们也可以简称为gap锁。比方说我们把number值为8的那条记录加一个gap锁的示意图如下：<br>
<img src="https://q456qq520.github.io/post-images/1677727164236.png" alt="" loading="lazy"></p>
<p>如图中为number值为8的记录加了gap锁，意味着不允许别的事务在number值为8的记录前面的间隙插入新记录，其实就是number列的值(3, 8)这个区间的新记录是不允许立即插入的。比方说有另外一个事务再想插入一条number值为4的新记录，它定位到该条新记录的下一条记录的number值为8，而这条记录上又有一个gap锁，所以就会阻塞插入操作，直到拥有这个gap锁的事务提交了之后，number列的值在区间(3, 8)中的新记录才可以被插入。</p>
<p>这个gap锁的提出仅仅是<mark>为了防止插入幻影记录而提出的</mark>，虽然有共享gap锁和独占gap锁这样的说法，但是它们起到的作用都是相同的。而且如果你对一条记录加了gap锁（不论是共享gap锁还是独占gap锁），并不会限制其他事务对这条记录加记录锁或者继续加gap锁，再强调一遍，gap锁的作用仅仅是为了防止插入幻影记录的而已。</p>
<p>给一条记录加了gap锁只是不允许其他事务往这条记录前面的间隙插入新记录，那对于最后一条记录之后的间隙，也就是hero表中number值为20的记录之后的间隙该咋办呢？也就是说给哪条记录加gap锁才能阻止其他事务插入number值在(20, +∞)这个区间的新记录呢？这时候应该想起数据页的两条伪记录了：</p>
<ul>
<li>Infimum记录，表示该页面中最小的记录。</li>
<li>Supremum记录，表示该页面中最大的记录。<br>
为了实现阻止其他事务插入number值在(20, +∞)这个区间的新记录，我们可以给索引中的最后一条记录，也就是number值为20的那条记录所在页面的Supremum记录加上一个gap锁。</li>
</ul>
<p><code>Next-Key Locks</code><br>
有时候我们既想锁住某条记录，又想阻止其他事务在该记录前面的间隙插入新记录，InnoDB就提出了一种称之为Next-Key Locks的锁，官方的类型名称为：LOCK_ORDINARY，我们也可以简称为next-key锁。比方说我们把number值为8的那条记录加一个next-key锁的示意图如下：<br>
<img src="https://q456qq520.github.io/post-images/1677728107529.png" alt="" loading="lazy"></p>
<p><code>Insert Intention Locks</code><br>
一个事务在插入一条记录时需要判断一下插入位置是不是被别的事务加了所谓的gap锁（next-key锁也包含gap锁），如果有的话，插入操作需要等待，直到拥有gap锁的那个事务提交。但是InnoDB规定事务在等待的时候也需要在内存中生成一个锁结构，表明有事务想在某个间隙中插入新记录，但是现在在等待。设计InnoDB的大佬就把这种类型的锁命名为Insert Intention Locks，官方的类型名称为：LOCK_INSERT_INTENTION，我们也可以称为插入意向锁。<br>
<img src="https://q456qq520.github.io/post-images/1677728301191.png" alt="" loading="lazy"><br>
比方说现在T1为number值为8的记录加了一个gap锁，然后T2和T3分别想向hero表中插入number值分别为4、5的两条记录，所以现在为number值为8的记录加的锁的示意图就如下所示：<br>
<img src="https://q456qq520.github.io/post-images/1677728355806.png" alt="" loading="lazy"></p>
<p>从图中可以看到，由于T1持有gap锁，所以T2和T3需要生成一个插入意向锁的锁结构并且处于等待状态。当T1提交后会把它获取到的锁都释放掉，这样T2和T3就能获取到对应的插入意向锁了（本质上就是把插入意向锁对应锁结构的is_waiting属性改为false），T2和T3之间也并不会相互阻塞，它们可以同时获取到number值为8的插入意向锁，然后执行插入操作。事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁（插入意向锁就是这么鸡肋）。</p>
<p><code>隐式锁</code><br>
一个事务在执行INSERT操作时，如果即将插入的间隙已经被其他事务加了gap锁，那么本次INSERT操作会阻塞，并且当前事务会在该间隙上加一个插入意向锁，否则一般情况下INSERT操作是不加锁的。那如果一个事务首先插入了一条记录（此时并没有与该记录关联的锁结构），然后另一个事务：</p>
<ul>
<li>立即使用SELECT ... LOCK IN SHARE MODE语句读取这条事务，也就是在要获取这条记录的S锁，或者使用SELECT ... FOR UPDATE语句读取这条事务或者直接修改这条记录，也就是要获取这条记录的X锁。该咋办？如果允许这种情况的发生，那么可能产生脏读问题。</li>
<li>立即修改这条记录，也就是要获取这条记录的X锁，该咋办？如果允许这种情况的发生，那么可能产生脏写问题。</li>
</ul>
<p>这时候我们前面介绍了很多遍的事务id又要起作用了。<br>
情景一：对于聚簇索引记录来说，有一个trx_id隐藏列，该隐藏列记录着最后改动该记录的事务id。那么如果在当前事务中新插入一条聚簇索引记录后，该记录的trx_id隐藏列代表的的就是当前事务的事务id，如果其他事务此时想对该记录添加S锁或者X锁时，首先会看一下该记录的trx_id隐藏列代表的事务是否是当前的活跃事务，如果是的话，那么就帮助当前事务创建一个X锁（也就是为当前事务创建一个锁结构，is_waiting属性是false），然后自己进入等待状态（也就是为自己也创建一个锁结构，is_waiting属性是true）。</p>
<p>情景二：对于二级索引记录来说，本身并没有trx_id隐藏列，但是在二级索引页面的Page Header部分有一个PAGE_MAX_TRX_ID属性，该属性代表对该页面做改动的最大的事务id，如果PAGE_MAX_TRX_ID属性值小于当前最小的活跃事务id，那么说明对该页面做修改的事务都已经提交了，否则就需要在页面中定位到对应的二级索引记录，然后回表找到它对应的聚簇索引记录，然后再重复情景一的做法。</p>
<p>通过上面的叙述我们知道，一个事务对新插入的记录可以不显式的加锁（生成一个锁结构），但是由于事务id的存在，相当于加了一个隐式锁。别的事务在对这条记录加S锁或者X锁时，由于隐式锁的存在，会先帮助当前事务生成一个锁结构，然后自己再生成一个锁结构后进入等待状态。</p>
<h3 id="256-innodb锁的内存结构">25.6 InnoDB锁的内存结构</h3>
<p>一条记录加锁的本质就是在内存中创建一个锁结构与之关联，那么是不是一个事务对多条记录加锁，就要创建多个锁结构呢？比方说事务T1要执行下面这个语句：</p>
<pre><code class="language-mysql"># 事务T1
SELECT * FROM hero LOCK IN SHARE MODE;
</code></pre>
<p>很显然这条语句需要为hero表中的所有记录进行加锁，那是不是需要为每条记录都生成一个锁结构呢？其实理论上创建多个锁结构没问题，反而更容易理解，但是谁知道你在一个事务里想对多少记录加锁呢，如果一个事务要获取10000条记录的锁，要生成10000个这样的结构也太亏了吧！所以InnoDB，决定在对不同记录加锁时，如果符合下面这些条件：</p>
<ul>
<li>在同一个事务中进行加锁操作</li>
<li>被加锁的记录在同一个页面中</li>
<li>加锁的类型是一样的</li>
<li>等待状态是一样的</li>
</ul>
<p>那么这些记录的锁就可以被放到一个锁结构中。我们还是画个图来看看InnoDB存储引擎中的锁结构具体长什么样吧：<br>
<img src="https://q456qq520.github.io/post-images/1677739806152.png" alt="" loading="lazy"></p>
<ol>
<li>锁所在的事务信息<br>
不论是表锁还是行锁，都是在事务执行过程中生成的，哪个事务生成了这个锁结构，这里就记载着这个事务的信息。</li>
<li>索引信息<br>
对于行锁来说，需要记录一下加锁的记录是属于哪个索引的。</li>
<li>表锁／行锁信息<br>
表锁结构和行锁结构在这个位置的内容是不同的：</li>
</ol>
<ul>
<li>表锁：记载着这是对哪个表加的锁，还有其他的一些信息。</li>
<li>行锁：记载了三个重要的信息：Space ID记录所在表空间。Page Number记录所在页号。n_bits对于行锁来说，一条记录就对应着一个比特位，一个页面中包含很多记录，用不同的比特位来区分到底是哪一条记录加了锁。为此在行锁结构的末尾放置了一堆比特位，这个n_bits属性代表使用了多少比特位。</li>
</ul>
<ol start="4">
<li>type_mode：<br>
这是一个32位的数，被分成了lock_mode、lock_type和rec_lock_type三个部分，如图所示：<br>
<img src="https://q456qq520.github.io/post-images/1677740543847.png" alt="" loading="lazy"></li>
</ol>
<p>锁的模式（lock_mode），占用低4位，可选的值如下：</p>
<ul>
<li>LOCK_IS（十进制的0）：表示共享意向锁，也就是IS锁。</li>
<li>LOCK_IX（十进制的1）：表示独占意向锁，也就是IX锁。</li>
<li>LOCK_S（十进制的2）：表示共享锁，也就是S锁。</li>
<li>LOCK_X（十进制的3）：表示独占锁，也就是X锁。</li>
<li>LOCK_AUTO_INC（十进制的4）：表示AUTO-INC锁。</li>
</ul>
<p>锁的类型（lock_type），占用第5～8位，不过现阶段只有第5位和第6位被使用：</p>
<ul>
<li>LOCK_TABLE（十进制的16），也就是当第5个比特位置为1时，表示表级锁。</li>
<li>LOCK_REC（十进制的32），也就是当第6个比特位置为1时，表示行级锁。</li>
</ul>
<p>行锁的具体类型（rec_lock_type），使用其余的位来表示。只有在lock_type的值为LOCK_REC时，也就是只有在该锁为行级锁时，才会被细分为更多的类型：</p>
<ul>
<li>LOCK_ORDINARY（十进制的0）：表示next-key锁。</li>
<li>LOCK_GAP（十进制的512）：也就是当第10个比特位置为1时，表示gap锁。</li>
<li>LOCK_REC_NOT_GAP（十进制的1024）：也就是当第11个比特位置为1时，表示正经记录锁。</li>
<li>LOCK_INSERT_INTENTION（十进制的2048）：也就是当第12个比特位置为1时，表示插入意向锁。</li>
<li>LOCK_WAIT（十进制的256） ：也就是当第9个比特位置为1时，表示is_waiting为true，也就是当前事务尚未获取到锁，处在等待状态；当这个比特位为0时，表示is_waiting为false，也就是当前事务获取锁成功。</li>
</ul>
<ol start="4">
<li>其他信息：为了更好的管理系统运行过程中生成的各种锁结构而设计了各种哈希表和链表。</li>
<li>一堆比特位<br>
如果是行锁结构的话，在该结构末尾还放置了一堆比特位，比特位的数量是由上面提到的n_bits属性表示的。<br>
InnoDB页面中的每条记录在记录头信息中都包含一个heap_no属性，伪记录Infimum的heap_no值为0，Supremum的heap_no值为1，之后每插入一条记录，heap_no值就增1。锁结构最后的一堆比特位就对应着一个页面中的记录，一个比特位映射一个heap_no。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMq技术内幕笔记（四）]]></title>
        <id>https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-si/</id>
        <link href="https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-si/">
        </link>
        <updated>2023-02-26T09:58:46.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="5-rocketmq-消息消费">5 RocketMQ 消息消费</h2>
<h3 id="51-rocketmq-消息消费概述">5.1 RocketMQ 消息消费概述</h3>
<p>消息消费以组的模式开展， 一个消费组内可以包含多个消费者，每一个消费组可订阅 多个主题，消费组之间有集群模式与广播模式两种消费模式 。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="5-rocketmq-消息消费">5 RocketMQ 消息消费</h2>
<h3 id="51-rocketmq-消息消费概述">5.1 RocketMQ 消息消费概述</h3>
<p>消息消费以组的模式开展， 一个消费组内可以包含多个消费者，每一个消费组可订阅 多个主题，消费组之间有集群模式与广播模式两种消费模式 。</p>
<!-- more -->
<p>集群模式，主题下的同一条 消息只允许被其中一个消费者消费 。<br>
广播模式，主题下的同一条消息将被集群内的所有消 费者消费一次。</p>
<p>消息服务器与消费者之间的消息传送也有两种方式:推模式、拉模式。 所谓的拉模式，是消费端主动发起拉消息请求，而推模式是消息到达消息服务器后，推送给消息消费者。 RocketMQ 消息推模式的实现基于拉模式，在拉模式上包装一层，一个拉取任务完成后开始下一个拉取任务。</p>
<p>集群模式下，多个消费者如何对消息队列进行负载呢?消息队列负载机制遵循一个通用的思想 : <mark>一个消息队列同一时间只允许被一个消费者消费，一个消费者可以消费多个消息队列</mark> 。</p>
<p>RocketMQ 支持局部顺序消息消费，也就是保证同一个消息队列上的消息顺序消费。 不 支持消息全局顺序消费， 如果要实现某一主题的全局顺序消息消费， 可以将该主题的队列数设置为1，牺牲高可用性。</p>
<p>RocketMQ 支持两种消息过滤模式:表达式(TAG、 SQL92)与类过滤模式。</p>
<p>消息拉模式，主要是由客户端手动调用消息拉取API，而消息推模式是消息服务器主 动将消息推送到消息消费端</p>
<h3 id="52-消息消费者初探">5.2 消息消费者初探</h3>
<p>下面分析推模式的消费者 MQPushConsume的主要API， 如下图所示。<br>
<img src="https://q456qq520.github.io/post-images/1677406267122.png" alt="" loading="lazy"></p>
<blockquote>
<p>MQConsume</p>
</blockquote>
<pre><code class="language-java">/**
* 发送消息 ACK确认
* @param msg 消息
* @param delayLevel 消息延迟级别
* @param brokerName 消息服务器名称
*/
void sendMessageBack(final MessageExt msg, final int delayLevel, final String brokerName)
throws RemotingException, MQBrokerException, InterruptedException, MQClientException;

/**
* 获取消费者对主题 topic分配了哪些消息队列
* @param topic 主题名称
*/
Set&lt;MessageQueue&gt; fetchSubscribeMessageQueues(final String topic) throws MQClientException;
</code></pre>
<blockquote>
<p>MQPushConsumer</p>
</blockquote>
<pre><code class="language-java">/**
* 注册并发消息事件监昕器
* @param messageListener
*/
void registerMessageListener(final MessageListenerConcurrently messageListener);

/**
* 注册顺序消费事件监听器
* @param messageListener
*/
void registerMessageListener(final MessageListenerOrderly messageListener);

/**
* 基于主题订阅消息
* @param topic 消息主题
* @param subExpression 消息过滤表达式，TAG或SQL92表达式
*/
void subscribe(final String topic, final String subExpression) ;
/**

* 基于主题订阅消息，消息过滤方式使用类模式
* @param topic 消息主题
* @param fullClassName 过滤类全路径名
* @param filterClassSource 过滤类代码
*/
void subscribe(final String topic, final String fullClassName,final String filterClassSource);

/**
* 取消消息订阅 
* @param topic
*/
void unsubscribe(final String topic);
</code></pre>
<p>DefaultMQPushConsumer (推模式消息消费者)主要属性:</p>
<blockquote>
<p>DefaultMQPushConsumer</p>
</blockquote>
<pre><code class="language-java">//消费者所属组
private String consumerGroup;

//消息消费模式，分为集群模式、广播模式，默认为集群模式
private MessageModel messageModel = MessageModel.CLUSTERING;

//根据消息进度从消息服务器拉取不到消息时重新计算消费策略
//CONSUME_FROM_MIN_OFFSET,从队列当前最小偏移量开始消费
//CONSUME_FROM_MAX_OFFSET,从队列当前最大偏移量开始消费
//CONSUME_FROM_TIMESTAMP,从消费者启动时间戳开始消费
private ConsumeFromWhere consumeFromWhere = ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET;
//集群模式下消息队列负载策略 
private AllocateMessageQueueStrategy allocateMessageQueueStrategy;
 //集群模式下消息队列负载策略
private AllocateMessageQueueStrategy allocateMessageQueueStrategy;

//订阅信息
private Map&lt;String /* topic */, String /* sub expression */&gt; subscription = new HashMap&lt;String, String&gt;();

/**
* 消息业务监听器
*/
private MessageListener messageListener;

/**
* 消息消费进度存储器
*/
private OffsetStore offsetStore;

/**
* 消息者最新线程数
*/
private int consumeThreadMin = 20;

/**
* 消费者最大线程数，由于消费者线程池使用无界队列，
* 故消费者线程个数其实最多只有 consumeThreadMin 个
*/
private int consumeThreadMax = 20;
/**
* 消费者最大线程数，由于消费者线程池使用无界队列，
* 故消费者线程个数其实最多只有 consumeThreadMin 个
*/
private int consumeThreadMax = 20;

/**
* Threshold for dynamic adjustment of the number of thread pool
*/
private long adjustThreadPoolNumsThreshold = 100000;

/**
* 并发消息消费时处理队列最大跨度，默认 2000,
* 表示如果消息处理队列中偏移量最大的消息与偏移量最小的消息的跨度超过 2000则延迟到毫秒后再拉取消息
*/
private int consumeConcurrentlyMaxSpan = 2000;
//默认值1000， 每1000次流控后打印流控日志
private int pullThresholdForQueue = 1000;

/**
* 推模式下拉取任务间隔时间，默认一次拉取任务完成继续拉取。
*/
private long pullInterval = 0;

/**
* 消息并发消费时一次消费消息条数，通俗点说 就是每次传入MessageListtener#consumeMessage中的消息条数
*/
private int consumeMessageBatchMaxSize = 1;

/**
* 每次消息拉取所拉取的条数，默认32条
*/
private int pullBatchSize = 32;
//是否每次拉取消息都更新订阅信息，默认为 false
private boolean postSubscriptionWhenPull = false;
//最大消费重试次数。如果消息消费次数超过 maxReconsumeTimes还未成功，则将该消息转移到一个失败队列,等待被删除
private int maxReconsumeTimes = -1;
/**
* 延迟将该队列的消息提交到消费者线程的等待时间，默认延迟ls
*/
private long suspendCurrentQueueTimeMillis = 1000;
/**
* 消息消费超时时间，默认为15，单位为分钟 
*/
private long consumeTimeout = 15;
</code></pre>
<h3 id="53-消费者启动流程">5.3 消费者启动流程</h3>
<p>消息消费者是如何启动的，分析 DefaultMQPushConsumerlmpl 的start方法，具体代码如下。</p>
<blockquote>
<p>DefaultMQPushConsumelmpl#copySubscription</p>
</blockquote>
<pre><code class="language-java">private void copySubscription() throws MQClientException {
    try {
        Map&lt;String, String&gt; sub = this.defaultMQPushConsumer.getSubscription();
        if (sub != null) {
            for (final Map.Entry&lt;String, String&gt; entry : sub.entrySet()) {
                final String topic = entry.getKey();
                final String subString = entry.getValue();
                SubscriptionData subscriptionData = FilterAPI.buildSubscriptionData(topic, subString);
                this.rebalanceImpl.getSubscriptionInner().put(topic, subscriptionData);
            }
        }

        if (null == this.messageListenerInner) {
            this.messageListenerInner = this.defaultMQPushConsumer.getMessageListener();
        }

        switch (this.defaultMQPushConsumer.getMessageModel()) {
            case BROADCASTING:
                break;
            case CLUSTERING:
                final String retryTopic = MixAll.getRetryTopic(this.defaultMQPushConsumer.getConsumerGroup());
                SubscriptionData subscriptionData = FilterAPI.buildSubscriptionData(retryTopic, SubscriptionData.SUB_ALL);
                this.rebalanceImpl.getSubscriptionInner().put(retryTopic, subscriptionData);
                break;
            default:
                break;
        }
    } catch (Exception e) {
        throw new MQClientException(&quot;subscription exception&quot;, e);
    }
}
</code></pre>
<p>Step1 :构建主题订阅信息 SubscriptionData 并加入到 Rebalancelmpl 的订阅消息中。 订阅关系来源主要有两个。<br>
1)通过调用 DefaultMQPushConsumerlmpl#subscrib巳( String topic, String subExpression) 方法。<br>
2)订阅重试主题消息。从这里可以看出，RocketMQ消息重试是以消费组为单位，而不是主题，消息重试主题名为 %RETRY%+消费组名。消费者在启动的时候会自动订阅该主题，参与该主题的消息队列负载。</p>
<blockquote>
<p>DefaultMQPushConsumelmpl#start</p>
</blockquote>
<pre><code class="language-java">if (this.defaultMQPushConsumer.getMessageModel() == MessageModel.CLUSTERING) {
    this.defaultMQPushConsumer.changeInstanceNameToPID();
}

this.mQClientFactory = MQClientManager.getInstance().getOrCreateMQClientInstance(this.defaultMQPushConsumer, this.rpcHook);

this.rebalanceImpl.setConsumerGroup(this.defaultMQPushConsumer.getConsumerGroup());
this.rebalanceImpl.setMessageModel(this.defaultMQPushConsumer.getMessageModel());
this.rebalanceImpl.setAllocateMessageQueueStrategy(this.defaultMQPushConsumer.getAllocateMessageQueueStrategy());
this.rebalanceImpl.setmQClientFactory(this.mQClientFactory);

if (this.pullAPIWrapper == null) {
    this.pullAPIWrapper = new PullAPIWrapper(
        mQClientFactory,
        this.defaultMQPushConsumer.getConsumerGroup(), isUnitMode());
}
this.pullAPIWrapper.registerFilterMessageHook(filterMessageHookList);
</code></pre>
<p>Step2:初始化 MQClientlnstance、 Rebalancelmple (消息重新负载实现类)等。</p>
<blockquote>
<p>DefaultMQPushConsumerlmpl#start</p>
</blockquote>
<pre><code class="language-java">if (this.defaultMQPushConsumer.getOffsetStore() != null) {
    this.offsetStore = this.defaultMQPushConsumer.getOffsetStore();
} else {
    switch (this.defaultMQPushConsumer.getMessageModel()) {
        case BROADCASTING:
            this.offsetStore = new LocalFileOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup());
            break;
        case CLUSTERING:
            this.offsetStore = new RemoteBrokerOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup());
            break;
        default:
            break;
    }
    this.defaultMQPushConsumer.setOffsetStore(this.offsetStore);
}
this.offsetStore.load();
</code></pre>
<p>Step3 : 初始化消息进度。如果消息消费是集群模式，那么消息进度保存在 Broker上; 如果是广播模式，那么消息消费进度存储在消费端。</p>
<blockquote>
<p>DefaultMQPushConsumerlmpl#start</p>
</blockquote>
<pre><code class="language-java">if (this.getMessageListenerInner() instanceof MessageListenerOrderly) {
this.consumeOrderly = true;
this.consumeMessageService =
    new ConsumeMessageOrderlyService(this, (MessageListenerOrderly) this.getMessageListenerInner());
//POPTODO reuse Executor ?
this.consumeMessagePopService = new ConsumeMessagePopOrderlyService(this, (MessageListenerOrderly) this.getMessageListenerInner());
} else if (this.getMessageListenerInner() instanceof MessageListenerConcurrently) {
this.consumeOrderly = false;
this.consumeMessageService =
    new ConsumeMessageConcurrentlyService(this, (MessageListenerConcurrently) this.getMessageListenerInner());
//POPTODO reuse Executor ?
this.consumeMessagePopService =
    new ConsumeMessagePopConcurrentlyService(this, (MessageListenerConcurrently) this.getMessageListenerInner());
}

this.consumeMessageService.start();
</code></pre>
<p>Step4 :根据是否是顺序消费，创建消费端消费线程服务。 ConsumeMessageService 主要负责消息消费，内部维护一个线程池。</p>
<blockquote>
<p>DefaultMQPushConsumerlmpl#start</p>
</blockquote>
<pre><code class="language-java">boolean registerOK = mQClientFactory.registerConsumer(this.defaultMQPushConsumer.getConsumerGroup(), this);
if (!registerOK) {
    this.serviceState = ServiceState.CREATE_JUST;
    this.consumeMessageService.shutdown(defaultMQPushConsumer.getAwaitTerminationMillisWhenShutdown());
    throw new MQClientException(&quot;The consumer group[&quot; + this.defaultMQPushConsumer.getConsumerGroup()
        + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL),
        null);
}

mQClientFactory.start();
</code></pre>
<p>Step5 :向 MQClientlnstance注册消费者，并启动MQClientlnstance，在一个JVM中的所有消费者、生产者持有同一个 MQClientlnstance, MQClientlnstance 只会启动一次。</p>
<h3 id="54-消息拉取">5.4 消息拉取</h3>
]]></content>
    </entry>
</feed>