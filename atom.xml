<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://q456qq520.github.io</id>
    <title>LIKE CAT</title>
    <updated>2022-09-06T08:36:42.463Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://q456qq520.github.io"/>
    <link rel="self" href="https://q456qq520.github.io/atom.xml"/>
    <subtitle>一条小咸鱼</subtitle>
    <logo>https://q456qq520.github.io/images/avatar.png</logo>
    <icon>https://q456qq520.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, LIKE CAT</rights>
    <entry>
        <title type="html"><![CDATA[Java并发 - 锁]]></title>
        <id>https://q456qq520.github.io/post/java-bing-fa-suo/</id>
        <link href="https://q456qq520.github.io/post/java-bing-fa-suo/">
        </link>
        <updated>2022-09-06T07:57:36.000Z</updated>
        <summary type="html"><![CDATA[<p>Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。</p>
]]></summary>
        <content type="html"><![CDATA[<p>Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。</p>
<!-- more -->
<h1 id="1-乐观锁-vs-悲观锁">1. 乐观锁 VS 悲观锁</h1>
<blockquote>
<p>乐观锁与悲观锁是一种广义上的概念，体现了看待线程同步的不同角度。在Java和数据库中都有此概念对应的实际应用。</p>
</blockquote>
<p>对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，<strong>synchronized关键字</strong>和<strong>Lock</strong>的实现类都是悲观锁。</p>
<p>而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。</p>
<p>乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。</p>
<p>根据从上面的概念描述我们可以发现：</p>
<ul>
<li>悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。</li>
<li>乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。</li>
</ul>
<pre><code class="language-java">// ------------------------- 悲观锁的调用方式 -------------------------
// synchronized
public synchronized void testMethod() {
	// 操作同步资源
}
// ReentrantLock
private ReentrantLock lock = new ReentrantLock(); // 需要保证多个线程使用的是同一个锁
public void modifyPublicResources() {
	lock.lock();
	// 操作同步资源
	lock.unlock();
}

// ------------------------- 乐观锁的调用方式 -------------------------
private AtomicInteger atomicInteger = new AtomicInteger();  // 需要保证多个线程使用的是同一个AtomicInteger
atomicInteger.incrementAndGet(); //执行自增1
</code></pre>
<h1 id="2-自旋锁-vs-适应性自旋锁">2. 自旋锁 VS 适应性自旋锁</h1>
<p>阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。</p>
<p>在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。</p>
<p>而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。</p>
<p>自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。</p>
<p>自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。</p>
<h1 id="3-无锁-vs-偏向锁-vs-轻量级锁-vs-重量级锁">3. 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁</h1>
<p>这四种锁是指锁的状。</p>
<p>偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。</p>
<p>锁膨胀方向： 无锁 → 偏向锁 → 轻量级锁 → 重量级锁 (此过程是不可逆的)</p>
<p>参考链接:<a href="/post/java-bing-fa">Java并发(一)</a></p>
<h1 id="4-公平锁-vs-非公平锁">4. 公平锁 VS 非公平锁</h1>
<p>公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。</p>
<p>非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。</p>
<h1 id="5-可重入锁-vs-非可重入锁">5. 可重入锁 VS 非可重入锁</h1>
<p>可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。下面用示例代码来进行分析：</p>
<pre><code class="language-java">public class Widget {
    public synchronized void doSomething() {
        System.out.println(&quot;方法1执行...&quot;);
        doOthers();
    }

    public synchronized void doOthers() {
        System.out.println(&quot;方法2执行...&quot;);
    }
}
</code></pre>
<p>在上面的代码中，类中的两个方法都是被内置锁synchronized修饰的，doSomething()方法中调用doOthers()方法。因为内置锁是可重入的，所以同一个线程在调用doOthers()时可以直接获得当前对象的锁，进入doOthers()进行操作。</p>
<p>如果是一个不可重入锁，那么当前线程在调用doOthers()之前需要将执行doSomething()时获取当前对象的锁释放掉，实际上该对象锁已被当前线程所持有，且无法释放。所以此时会出现死锁。</p>
<p>ReentrantLock和synchronized都是重入锁。</p>
<p>首先ReentrantLock和NonReentrantLock都继承父类AQS，其父类AQS中维护了一个同步状态status来计数重入次数，status初始值为0。</p>
<p>当线程尝试获取锁时，可重入锁先尝试获取并更新status值，如果status == 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。而非可重入锁是直接去获取并尝试更新当前status的值，如果status != 0的话会导致其获取锁失败，当前线程阻塞。</p>
<p>释放锁时，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放。</p>
<h1 id="6-独享锁排他锁-vs-共享锁">6. 独享锁(排他锁) VS 共享锁</h1>
<p>独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。</p>
<p>共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。</p>
<p>独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。</p>
<p>ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。</p>
<p>在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java基础 - LinkedHashSet&Map]]></title>
        <id>https://q456qq520.github.io/post/java-ji-chu-linkedhashsetandmap/</id>
        <link href="https://q456qq520.github.io/post/java-ji-chu-linkedhashsetandmap/">
        </link>
        <updated>2022-09-06T07:19:31.000Z</updated>
        <content type="html"><![CDATA[<h1 id="总体介绍">总体介绍</h1>
<p>LinkedHashSet和LinkedHashMap在Java里也有着相同的实现，前者仅仅是对后者做了一层包装，也就是说LinkedHashSet里面有一个LinkedHashMap(适配器模式)。</p>
<p>LinkedHashMap实现了Map接口，即允许放入key为null的元素，也允许插入value为null的元素。从名字上可以看出该容器是linked list和HashMap的混合体，也就是说它同时满足HashMap和linked list的某些特性。可将LinkedHashMap看作采用linked list增强的HashMap。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662449233623.png" alt="base" loading="lazy"></figure>
<p>事实上LinkedHashMap是HashMap的直接子类，<strong>二者唯一的区别是LinkedHashMap在HashMap的基础上，采用双向链表(doubly-linked list)的形式将所有entry连接起来，这样是为保证元素的迭代顺序跟插入顺序相同</strong>。上图给出了LinkedHashMap的结构图，主体部分跟HashMap完全一样，多了header指向双向链表的头部(是一个哑元)，该双向链表的迭代顺序就是entry的插入顺序。</p>
<p>除了可以保迭代历顺序，这种结构还有一个好处 :  <strong>迭代LinkedHashMap时不需要像HashMap那样遍历整个table，而只需要直接遍历header指向的双向链表即可</strong>，也就是说LinkedHashMap的迭代时间就只跟entry的个数相关，而跟table的大小无关。</p>
<p>有两个参数可以影响LinkedHashMap的性能: 初始容量(inital capacity)和负载系数(load factor)。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。</p>
<p>将对象放入到LinkedHashMap或LinkedHashSet中时，有两个方法需要特别关心: hashCode()和equals()。hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到LinkedHashMap或LinkedHashSet中，需要@Override hashCode()和equals()方法。</p>
<p>出于性能原因，LinkedHashMap是非同步的(not synchronized)，如果需要在多线程环境使用，需要程序员手动同步；或者通过如下方式将LinkedHashMap包装成(wrapped)同步的:</p>
<pre><code class="language-java">Map m = Collections.synchronizedMap(new LinkedHashMap(...));
</code></pre>
<h1 id="方法剖析">方法剖析</h1>
<h2 id="get">get()</h2>
<p>get(Object key)方法根据指定的key值返回对应的value。该方法跟HashMap.get()方法的流程几乎完全一样，参考链接:<a href="/post/java-ji-chu-hashmap">Java基础-HashMap</a></p>
<h2 id="put">put()</h2>
<p>put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于get()方法；如果没有找到，则会通过addEntry(int hash, K key, V value, int bucketIndex)方法插入新的entry。</p>
<p>注意，这里的插入有两重含义:</p>
<blockquote>
<p>从table的角度看，新的entry需要插入到对应的bucket里，当有哈希冲突时，采用头插法将新的entry插入到冲突链表的头部。<br>
从header的角度看，新的entry需要插入到双向链表的尾部。</p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662449865619.png" alt="addEntry" loading="lazy"></figure>
<pre><code class="language-java">// LinkedHashMap.addEntry()
void addEntry(int hash, K key, V value, int bucketIndex) {
    if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) {
        resize(2 * table.length);// 自动扩容，并重新哈希
        hash = (null != key) ? hash(key) : 0;
        bucketIndex = hash &amp; (table.length-1);// hash%table.length
    }
    // 1.在冲突链表头部插入新的entry
    HashMap.Entry&lt;K,V&gt; old = table[bucketIndex];
    Entry&lt;K,V&gt; e = new Entry&lt;&gt;(hash, key, value, old);
    table[bucketIndex] = e;
    // 2.在双向链表的尾部插入新的entry
    e.addBefore(header);
    size++;
}
</code></pre>
<p>上述代码中用到了addBefore()方法将新entry e插入到双向链表头引用header的前面，这样e就成为双向链表中的最后一个元素。addBefore()的代码如下:</p>
<pre><code class="language-java">// LinkedHashMap.Entry.addBefor()，将this插入到existingEntry的前面
private void addBefore(Entry&lt;K,V&gt; existingEntry) {
    after  = existingEntry;
    before = existingEntry.before;
    before.after = this;
    after.before = this;
}
</code></pre>
<p>上述代码只是简单修改相关entry的引用而已。</p>
<h2 id="remove">remove()</h2>
<p>remove(Object key)的作用是删除key值对应的entry，该方法的具体逻辑是在removeEntryForKey(Object key)里实现的。removeEntryForKey()方法会首先找到key值对应的entry，然后删除该entry(修改链表的相应引用)。查找过程跟get()方法类似。</p>
<p>注意，这里的删除也有两重含义:</p>
<blockquote>
<p>从table的角度看，需要将该entry从对应的bucket里删除，如果对应的冲突链表不空，需要修改冲突链表的相应引用。<br>
从header的角度来看，需要将该entry从双向链表中删除，同时修改链表中前面以及后面元素的相应引用。</p>
</blockquote>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1662450018650.png" alt="remove" loading="lazy"></figure>
<pre><code class="language-java">// LinkedHashMap.removeEntryForKey()，删除key值对应的entry
final Entry&lt;K,V&gt; removeEntryForKey(Object key) {
	......
	int hash = (key == null) ? 0 : hash(key);
    int i = indexFor(hash, table.length);// hash&amp;(table.length-1)
    Entry&lt;K,V&gt; prev = table[i];// 得到冲突链表
    Entry&lt;K,V&gt; e = prev;
    while (e != null) {// 遍历冲突链表
        Entry&lt;K,V&gt; next = e.next;
        Object k;
        if (e.hash == hash &amp;&amp;
            ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) {// 找到要删除的entry
            modCount++; size--;
            // 1. 将e从对应bucket的冲突链表中删除
            if (prev == e) table[i] = next;
            else prev.next = next;
            // 2. 将e从双向链表中删除
            e.before.after = e.after;
            e.after.before = e.before;
            return e;
        }
        prev = e; e = next;
    }
    return e;
}
</code></pre>
<h1 id="linkedhashset">LinkedHashSet</h1>
<pre><code class="language-java">public class LinkedHashSet&lt;E&gt;
    extends HashSet&lt;E&gt;
    implements Set&lt;E&gt;, Cloneable, java.io.Serializable {
    ......
    // LinkedHashSet里面有一个LinkedHashMap
    public LinkedHashSet(int initialCapacity, float loadFactor) {
        map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);
    }
	......
    public boolean add(E e) {//简单的方法转换
        return map.put(e, PRESENT)==null;
    }
    ......
}
</code></pre>
<h1 id="linkedhashmap经典用法">LinkedHashMap经典用法</h1>
<p>LinkedHashMap除了可以保证迭代顺序外，还有一个非常有用的用法: 可以轻松实现一个采用了FIFO替换策略的缓存。具体说来，LinkedHashMap有一个子类方法protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest)，该方法的作用是告诉Map是否要删除“最老”的Entry，所谓最老就是当前Map中最早插入的Entry，如果该方法返回true，最老的那个元素就会被删除。在每次插入新元素的之后LinkedHashMap会自动询问removeEldestEntry()是否要删除最老的元素。这样只需要在子类中重载该方法，当元素个数超过一定数量时让removeEldestEntry()返回true，就能够实现一个固定大小的FIFO策略的缓存。示例代码如下:</p>
<pre><code class="language-java">/** 一个固定大小的FIFO替换策略的缓存 */
class FIFOCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt;{
    private final int cacheSize;
    public FIFOCache(int cacheSize){
        this.cacheSize = cacheSize;
    }

    // 当Entry个数超过cacheSize时，删除最老的Entry
    @Override
    protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) {
       return size() &gt; cacheSize;
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java基础 - TreeMap]]></title>
        <id>https://q456qq520.github.io/post/java-ji-chu-treemap/</id>
        <link href="https://q456qq520.github.io/post/java-ji-chu-treemap/">
        </link>
        <updated>2022-09-06T06:30:51.000Z</updated>
        <content type="html"><![CDATA[<h1 id="总体介绍">总体介绍</h1>
<p>TreeSet和TreeMap，前者仅仅是对后者做了一层包装，也就是说TreeSet里面有一个TreeMap**(适配器模式)**。</p>
<p>Java TreeMap实现了<strong>SortedMap</strong>接口，也就是说会按照key的大小顺序对Map中的元素进行排序，key大小的评判可以通过其本身的自然顺序(natural ordering)，也可以通过构造时传入的比较器(Comparator)。</p>
<p>TreeMap底层通过红黑树(Red-Black tree)实现，也就意味着containsKey(), get(), put(), remove()都有着log(n)的时间复杂度。</p>
<p>![红黑树(https://q456qq520.github.io/post-images/1662446050114.png)</p>
<p>出于性能原因，TreeMap是非同步的(not synchronized)，如果需要在多线程环境使用，需要程序员手动同步；或者通过如下方式将TreeMap包装成(wrapped)同步的:</p>
<pre><code class="language-java"> SortedMap m = Collections.synchronizedSortedMap(new TreeMap(...));
</code></pre>
<p>红黑树是一种近似平衡的二叉查找树，它能够确保任何一个节点的左右子树的高度差不会超过二者中较低那个的一倍。具体来说，红黑树是满足如下条件的二叉查找树(binary search tree):</p>
<ol>
<li>每个节点要么是红色，要么是黑色。</li>
<li>根节点必须是黑色</li>
<li>红色节点不能连续(也即是，红色节点的孩子和父亲都不能是红色)。</li>
<li>对于每个节点，从该点至null(树尾端)的任何路径，都含有相同个数的黑色节点。</li>
</ol>
<p>在树的结构发生改变时(插入或者删除操作)，往往会破坏上述条件3或条件4，需要通过调整使得查找树重新满足红黑树的约束条件。</p>
<h1 id="预备知识">预备知识</h1>
<p>当查找树的结构发生改变时，红黑树的约束条件可能被破坏，需要通过调整使得查找树重新满足红黑树的约束条件。调整可以分为两类: 一类是颜色调整，即改变某个节点的颜色；另一类是结构调整，集改变检索树的结构关系。结构调整过程包含两个基本操作:<strong>左旋(Rotate Left)，右旋(RotateRight)</strong>。</p>
<h2 id="左旋">左旋</h2>
<p>左旋的过程是将x的右子树绕x逆时针旋转，使得x的右子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的属性仍然满足。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662447037690.png" alt="左旋" loading="lazy"></figure>
<pre><code class="language-java">//Rotate Left
private void rotateLeft(Entry&lt;K,V&gt; p) {
    if (p != null) {
        Entry&lt;K,V&gt; r = p.right;
        p.right = r.left;
        if (r.left != null)
            r.left.parent = p;
        r.parent = p.parent;
        if (p.parent == null)
            root = r;
        else if (p.parent.left == p)
            p.parent.left = r;
        else
            p.parent.right = r;
        r.left = p;
        p.parent = r;
    }
}
</code></pre>
<h2 id="右旋">右旋</h2>
<p>右旋的过程是将x的左子树绕x顺时针旋转，使得x的左子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的属性仍然满足。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662447192164.png" alt="右旋" loading="lazy"></figure>
<pre><code class="language-java">//Rotate Right
private void rotateRight(Entry&lt;K,V&gt; p) {
    if (p != null) {
        Entry&lt;K,V&gt; l = p.left;
        p.left = l.right;
        if (l.right != null) l.right.parent = p;
        l.parent = p.parent;
        if (p.parent == null)
            root = l;
        else if (p.parent.right == p)
            p.parent.right = l;
        else p.parent.left = l;
        l.right = p;
        p.parent = l;
    }
}
</code></pre>
<h2 id="寻找节点后继">寻找节点后继</h2>
<p>对于一棵二叉查找树，给定节点t，其后继(树中比大于t的最小的那个元素)可以通过如下方式找到:</p>
<blockquote>
<p>t的右子树不空，则t的后继是其右子树中最小的那个元素。<br>
t的右孩子为空，则t的后继是其第一个向左走的祖先。</p>
</blockquote>
<p>后继节点在红黑树的删除操作中将会用到。</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1662447570182.png" alt="后继" loading="lazy"></figure>
<p>TreeMap中寻找节点后继的代码如下:</p>
<pre><code class="language-java">// 寻找节点后继函数successor()
static &lt;K,V&gt; TreeMap.Entry&lt;K,V&gt; successor(Entry&lt;K,V&gt; t) {
    if (t == null)
        return null;
    else if (t.right != null) {// 1. t的右子树不空，则t的后继是其右子树中最小的那个元素
        Entry&lt;K,V&gt; p = t.right;
        while (p.left != null)
            p = p.left;
        return p;
    } else {// 2. t的右孩子为空，则t的后继是其第一个向左走的祖先
        Entry&lt;K,V&gt; p = t.parent;
        Entry&lt;K,V&gt; ch = t;
        while (p != null &amp;&amp; ch == p.right) {
            ch = p;
            p = p.parent;
        }
        return p;
    }
}
</code></pre>
<h1 id="方法剖析">方法剖析</h1>
<h2 id="get">get()</h2>
<p>get(Object key)方法根据指定的key值返回对应的value，该方法调用了getEntry(Object key)得到相应的entry，然后返回entry.value。因此getEntry()是算法的核心。算法思想是根据key的自然顺序(或者比较器顺序)对二叉查找树进行查找，直到找到满足k.compareTo(p.key) == 0的entry。</p>
<p>![get(https://q456qq520.github.io/post-images/1662447909864.png)</p>
<pre><code class="language-java">//getEntry()方法
final Entry&lt;K,V&gt; getEntry(Object key) {
    ......
    if (key == null)//不允许key值为null
        throw new NullPointerException();
    Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key;//使用元素的自然顺序
    Entry&lt;K,V&gt; p = root;
    while (p != null) {
        int cmp = k.compareTo(p.key);
        if (cmp &lt; 0)//向左找
            p = p.left;
        else if (cmp &gt; 0)//向右找
            p = p.right;
        else
            return p;
    }
    return null;
}
</code></pre>
<h2 id="put">put()</h2>
<p>put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于getEntry()方法；如果没有找到则会在红黑树中插入新的entry，如果插入之后破坏了红黑树的约束条件，还需要进行调整(旋转，改变某些节点的颜色)。</p>
<pre><code class="language-java">public V put(K key, V value) {
	......
    int cmp;
    Entry&lt;K,V&gt; parent;
    if (key == null)
        throw new NullPointerException();
    Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key;//使用元素的自然顺序
    do {
        parent = t;
        cmp = k.compareTo(t.key);
        if (cmp &lt; 0) t = t.left;//向左找
        else if (cmp &gt; 0) t = t.right;//向右找
        else return t.setValue(value);
    } while (t != null);
    Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent);//创建并插入新的entry
    if (cmp &lt; 0) parent.left = e;
    else parent.right = e;
    fixAfterInsertion(e);//调整
    size++;
    return null;
}
</code></pre>
<p>首先在红黑树上找到合适的位置，然后创建新的entry并插入(当然，新插入的节点一定是树的叶子)。难点是调整函数fixAfterInsertion()，前面已经说过，调整往往需要1.改变某些节点的颜色，2.对某些节点进行旋转。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1662448057289.png" alt="put" loading="lazy"></figure>
<p>调整函数fixAfterInsertion()的具体代码如下，其中用到了上文中提到的rotateLeft()和rotateRight()函数。通过代码我们能够看到，情况2其实是落在情况3内的。情况4～情况6跟前三种情况是对称的，因此图解中并没有画出后三种情况，读者可以参考代码自行理解。</p>
<pre><code class="language-java">//红黑树调整函数fixAfterInsertion()
private void fixAfterInsertion(Entry&lt;K,V&gt; x) {
    x.color = RED;
    while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) {
        if (parentOf(x) == leftOf(parentOf(parentOf(x)))) {
            Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x)));
            if (colorOf(y) == RED) {
                setColor(parentOf(x), BLACK);              // 情况1
                setColor(y, BLACK);                        // 情况1
                setColor(parentOf(parentOf(x)), RED);      // 情况1
                x = parentOf(parentOf(x));                 // 情况1
            } else {
                if (x == rightOf(parentOf(x))) {
                    x = parentOf(x);                       // 情况2
                    rotateLeft(x);                         // 情况2
                }
                setColor(parentOf(x), BLACK);              // 情况3
                setColor(parentOf(parentOf(x)), RED);      // 情况3
                rotateRight(parentOf(parentOf(x)));        // 情况3
            }
        } else {
            Entry&lt;K,V&gt; y = leftOf(parentOf(parentOf(x)));
            if (colorOf(y) == RED) {
                setColor(parentOf(x), BLACK);              // 情况4
                setColor(y, BLACK);                        // 情况4
                setColor(parentOf(parentOf(x)), RED);      // 情况4
                x = parentOf(parentOf(x));                 // 情况4
            } else {
                if (x == leftOf(parentOf(x))) {
                    x = parentOf(x);                       // 情况5
                    rotateRight(x);                        // 情况5
                }
                setColor(parentOf(x), BLACK);              // 情况6
                setColor(parentOf(parentOf(x)), RED);      // 情况6
                rotateLeft(parentOf(parentOf(x)));         // 情况6
            }
        }
    }
    root.color = BLACK;
}
</code></pre>
<p>##remove()<br>
remove(Object key)的作用是删除key值对应的entry，该方法首先通过上文中提到的getEntry(Object key)方法找到key值对应的entry，然后调用deleteEntry(Entry&lt;K,V&gt; entry)删除对应的entry。由于删除操作会改变红黑树的结构，有可能破坏红黑树的约束条件，因此有可能要进行调整。</p>
<p>getEntry()函数前面已经讲解过，这里重点放deleteEntry()上，该函数删除指定的entry并在红黑树的约束被破坏时进行调用fixAfterDeletion(Entry&lt;K,V&gt; x)进行调整。 由于红黑树是一棵增强版的二叉查找树，红黑树的删除操作跟普通二叉查找树的删除操作也就非常相似，唯一的区别是红黑树在节点删除之后可能需要进行调整。现在考虑一棵普通二叉查找树的删除过程，可以简单分为两种情况:</p>
<blockquote>
<p>删除点p的左右子树都为空，或者只有一棵子树非空。<br>
删除点p的左右子树都非空。</p>
</blockquote>
<p>对于上述情况1，处理起来比较简单，直接将p删除(左右子树都为空时)，或者用非空子树替代p(只有一棵子树非空时)；对于情况2，可以用p的后继s(树中大于x的最小的那个元素)代替p，然后使用情况1删除。 基于以上逻辑，红黑树的节点删除函数deleteEntry()代码如下:</p>
<pre><code class="language-java">// 红黑树entry删除函数deleteEntry()
private void deleteEntry(Entry&lt;K,V&gt; p) {
    modCount++;
    size--;
    if (p.left != null &amp;&amp; p.right != null) {// 2. 删除点p的左右子树都非空。
        Entry&lt;K,V&gt; s = successor(p);// 后继
        p.key = s.key;
        p.value = s.value;
        p = s;
    }
    Entry&lt;K,V&gt; replacement = (p.left != null ? p.left : p.right);
    if (replacement != null) {// 1. 删除点p只有一棵子树非空。
        replacement.parent = p.parent;
        if (p.parent == null)
            root = replacement;
        else if (p == p.parent.left)
            p.parent.left  = replacement;
        else
            p.parent.right = replacement;
        p.left = p.right = p.parent = null;
        if (p.color == BLACK)
            fixAfterDeletion(replacement);// 调整
    } else if (p.parent == null) {
        root = null;
    } else { // 1. 删除点p的左右子树都为空
        if (p.color == BLACK)
            fixAfterDeletion(p);// 调整
        if (p.parent != null) {
            if (p == p.parent.left)
                p.parent.left = null;
            else if (p == p.parent.right)
                p.parent.right = null;
            p.parent = null;
        }
    }
}
</code></pre>
<p>上述代码中占据大量代码行的，是用来修改父子节点间引用关系的代码，其逻辑并不难理解。下面着重讲解删除后调整函数fixAfterDeletion()。首先请思考一下，删除了哪些点才会导致调整？只有删除点是BLACK的时候，才会触发调整函数，因为删除RED节点不会破坏红黑树的任何约束，而删除BLACK节点会破坏规则4。</p>
<p>跟fixAfterInsertion()函数一样，这里也要分成若干种情况。记住，无论有多少情况，具体的调整操作只有两种: ** 1.改变某些节点的颜色，2.对某些节点进行旋转。**</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1662448600339.png" alt="remove" loading="lazy"></figure>
<p>上述图解的总体思想是: 将情况1首先转换成情况2，或者转换成情况3和情况4。当然，该图解并不意味着调整过程一定是从情况1开始。通过后续代码我们还会发现几个有趣的规则: a).如果是由情况1之后紧接着进入的情况2，那么情况2之后一定会退出循环(因为x为红色)；b).一旦进入情况3和情况4，一定会退出循环(因为x为root)。</p>
<p>删除后调整函数fixAfterDeletion()的具体代码如下，其中用到了上文中提到的rotateLeft()和rotateRight()函数。通过代码我们能够看到，情况3其实是落在情况4内的。情况5～情况8跟前四种情况是对称的。</p>
<pre><code class="language-java">private void fixAfterDeletion(Entry&lt;K,V&gt; x) {
    while (x != root &amp;&amp; colorOf(x) == BLACK) {
        if (x == leftOf(parentOf(x))) {
            Entry&lt;K,V&gt; sib = rightOf(parentOf(x));
            if (colorOf(sib) == RED) {
                setColor(sib, BLACK);                   // 情况1
                setColor(parentOf(x), RED);             // 情况1
                rotateLeft(parentOf(x));                // 情况1
                sib = rightOf(parentOf(x));             // 情况1
            }
            if (colorOf(leftOf(sib))  == BLACK &amp;&amp;
                colorOf(rightOf(sib)) == BLACK) {
                setColor(sib, RED);                     // 情况2
                x = parentOf(x);                        // 情况2
            } else {
                if (colorOf(rightOf(sib)) == BLACK) {
                    setColor(leftOf(sib), BLACK);       // 情况3
                    setColor(sib, RED);                 // 情况3
                    rotateRight(sib);                   // 情况3
                    sib = rightOf(parentOf(x));         // 情况3
                }
                setColor(sib, colorOf(parentOf(x)));    // 情况4
                setColor(parentOf(x), BLACK);           // 情况4
                setColor(rightOf(sib), BLACK);          // 情况4
                rotateLeft(parentOf(x));                // 情况4
                x = root;                               // 情况4
            }
        } else { // 跟前四种情况对称
            Entry&lt;K,V&gt; sib = leftOf(parentOf(x));
            if (colorOf(sib) == RED) {
                setColor(sib, BLACK);                   // 情况5
                setColor(parentOf(x), RED);             // 情况5
                rotateRight(parentOf(x));               // 情况5
                sib = leftOf(parentOf(x));              // 情况5
            }
            if (colorOf(rightOf(sib)) == BLACK &amp;&amp;
                colorOf(leftOf(sib)) == BLACK) {
                setColor(sib, RED);                     // 情况6
                x = parentOf(x);                        // 情况6
            } else {
                if (colorOf(leftOf(sib)) == BLACK) {
                    setColor(rightOf(sib), BLACK);      // 情况7
                    setColor(sib, RED);                 // 情况7
                    rotateLeft(sib);                    // 情况7
                    sib = leftOf(parentOf(x));          // 情况7
                }
                setColor(sib, colorOf(parentOf(x)));    // 情况8
                setColor(parentOf(x), BLACK);           // 情况8
                setColor(leftOf(sib), BLACK);           // 情况8
                rotateRight(parentOf(x));               // 情况8
                x = root;                               // 情况8
            }
        }
    }
    setColor(x, BLACK);
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java 基础 - HashMap]]></title>
        <id>https://q456qq520.github.io/post/java-ji-chu-hashmap/</id>
        <link href="https://q456qq520.github.io/post/java-ji-chu-hashmap/">
        </link>
        <updated>2022-09-06T06:17:44.000Z</updated>
        <content type="html"><![CDATA[<h1 id="java7-hashmap">Java7 HashMap</h1>
<h2 id="概述">概述</h2>
<p>HashMap实现了Map接口，即允许放入key为null的元素，也允许插入value为null的元素；除该类未实现同步外，其余跟Hashtable大致相同；跟TreeMap不同，该容器不保证元素顺序，根据需要该容器可能会对元素重新哈希，元素的顺序也会被重新打散，因此不同时间迭代同一个HashMap的顺序可能会不同。<br>
根据对冲突的处理方式不同，哈希表有两种实现方式，一种<strong>开放地址方式(Open addressing)</strong>，另一种是<strong>冲突链表方式(Separate chaining with linked lists)</strong>。Java7 HashMap采用的是冲突链表方式。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662445311067.png" alt="HaspMap" loading="lazy"></figure>
<p>从上图容易看出，如果选择合适的哈希函数，put()和get()方法可以在常数时间内完成。但在对HashMap进行迭代时，需要遍历整个table以及后面跟的冲突链表。因此对于迭代比较频繁的场景，不宜将HashMap的初始大小设的过大。</p>
<p>有两个参数可以影响HashMap的性能: 初始容量(inital capacity)和负载系数(load factor)。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。</p>
<p>将对象放入到HashMap或HashSet中时，有两个方法需要特别关心: hashCode()和equals()。hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到HashMap或HashSet中，需要**@Override** hashCode()和equals()方法。</p>
<h1 id="java8-hashmap">Java8 HashMap</h1>
<p>Java8利用了红黑树，由 数组+链表+红黑树 组成。</p>
<p>查找的时候，根据 hash 值我们能够快速定位到数组的具体下标，但是之后的话，需要顺着链表一个个比较下去才能找到我们需要的，时间复杂度取决于链表的长度，为 O(n)。 为了降低这部分的开销，在 Java8 中，当链表中的元素达到了 8 个时，会将链表转换为红黑树，在这些位置进行查找的时候可以降低时间复杂度为 O(logN)。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662445189410.png" alt="hashmap结构" loading="lazy"></figure>
<p>著作权归https://pdai.tech所有。<br>
链接：https://pdai.tech/md/java/collection/java-map-HashMap&amp;HashSet.html</p>
<p>Java7 中使用 Entry 来代表每个 HashMap 中的数据节点，Java8 中使用 Node，基本没有区别，都是 key，value，hash 和 next 这四个属性，不过，Node 只能用于链表的情况，红黑树的情况需要使用 TreeNode。</p>
<p>根据数组元素中，第一个节点数据类型是 Node 还是 TreeNode 来判断该位置下是链表还是红黑树的。</p>
<h2 id="put过程">put过程</h2>
<pre><code class="language-java">public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}

// 第四个参数 onlyIfAbsent 如果是 true，那么只有在不存在该 key 时才会进行 put 操作
// 第五个参数 evict 我们这里不关心
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;
    // 第一次 put 值的时候，会触发下面的 resize()，类似 java7 的第一次 put 也要初始化数组长度
    // 第一次 resize 和后续的扩容有些不一样，因为这次是数组从 null 初始化到默认的 16 或自定义的初始容量
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    // 找到具体的数组下标，如果此位置没有值，那么直接初始化一下 Node 并放置在这个位置就可以了
    if ((p = tab[i = (n - 1) &amp; hash]) == null)
        tab[i] = newNode(hash, key, value, null);

    else {// 数组该位置有数据
        Node&lt;K,V&gt; e; K k;
        // 首先，判断该位置的第一个数据和我们要插入的数据，key 是不是&quot;相等&quot;，如果是，取出这个节点
        if (p.hash == hash &amp;&amp;
            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))
            e = p;
        // 如果该节点是代表红黑树的节点，调用红黑树的插值方法，本文不展开说红黑树
        else if (p instanceof TreeNode)
            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);
        else {
            // 到这里，说明数组该位置上是一个链表
            for (int binCount = 0; ; ++binCount) {
                // 插入到链表的最后面(Java7 是插入到链表的最前面)
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    // TREEIFY_THRESHOLD 为 8，所以，如果新插入的值是链表中的第 8 个
                    // 会触发下面的 treeifyBin，也就是将链表转换为红黑树
                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                // 如果在该链表中找到了&quot;相等&quot;的 key(== 或 equals)
                if (e.hash == hash &amp;&amp;
                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                    // 此时 break，那么 e 为链表中[与要插入的新值的 key &quot;相等&quot;]的 node
                    break;
                p = e;
            }
        }
        // e!=null 说明存在旧值的key与要插入的key&quot;相等&quot;
        // 对于我们分析的put操作，下面这个 if 其实就是进行 &quot;值覆盖&quot;，然后返回旧值
        if (e != null) {
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    // 如果 HashMap 由于新插入这个值导致 size 已经超过了阈值，需要进行扩容
    if (++size &gt; threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
</code></pre>
<h2 id="数组扩容">数组扩容</h2>
<p>resize() 方法用于初始化数组或数组扩容，每次扩容后，容量为原来的 2 倍，并进行数据迁移。</p>
<pre><code class="language-java">final Node&lt;K,V&gt;[] resize() {
    Node&lt;K,V&gt;[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap &gt; 0) { // 对应数组扩容
        if (oldCap &gt;= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        // 将数组大小扩大一倍
        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;
                 oldCap &gt;= DEFAULT_INITIAL_CAPACITY)
            // 将阈值扩大一倍
            newThr = oldThr &lt;&lt; 1; // double threshold
    }
    else if (oldThr &gt; 0) // 对应使用 new HashMap(int initialCapacity) 初始化后，第一次 put 的时候
        newCap = oldThr;
    else {// 对应使用 new HashMap() 初始化后，第一次 put 的时候
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }

    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;

    // 用新的数组大小初始化新的数组
    Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];
    table = newTab; // 如果是初始化数组，到这里就结束了，返回 newTab 即可

    if (oldTab != null) {
        // 开始遍历原数组，进行数据迁移。
        for (int j = 0; j &lt; oldCap; ++j) {
            Node&lt;K,V&gt; e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                // 如果该数组位置上只有单个元素，那就简单了，简单迁移这个元素就可以了
                if (e.next == null)
                    newTab[e.hash &amp; (newCap - 1)] = e;
                // 如果是红黑树，具体我们就不展开了
                else if (e instanceof TreeNode)
                    ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);
                else { 
                    // 这块是处理链表的情况，
                    // 需要将此链表拆成两个链表，放到新的数组中，并且保留原来的先后顺序
                    // loHead、loTail 对应一条链表，hiHead、hiTail 对应另一条链表，代码还是比较简单的
                    Node&lt;K,V&gt; loHead = null, loTail = null;
                    Node&lt;K,V&gt; hiHead = null, hiTail = null;
                    Node&lt;K,V&gt; next;
                    do {
                        next = e.next;
                        if ((e.hash &amp; oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        // 第一条链表
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        // 第二条链表的新的位置是 j + oldCap，这个很好理解
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
</code></pre>
<h2 id="get-过程">get 过程</h2>
<ol>
<li>计算 key 的 hash 值，根据 hash 值找到对应数组下标: hash &amp; (length-1)</li>
<li>判断数组该位置处的元素是否刚好就是我们要找的，如果不是，走第三步</li>
<li>判断该元素类型是否是 TreeNode，如果是，用红黑树的方法取数据，如果不是，走第四步</li>
<li>遍历链表，直到找到相等(==或equals)的 key</li>
</ol>
<pre><code class="language-java">public V get(Object key) {
    Node&lt;K,V&gt; e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}
final Node&lt;K,V&gt; getNode(int hash, Object key) {
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;
    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;
        (first = tab[(n - 1) &amp; hash]) != null) {
        // 判断第一个节点是不是就是需要的
        if (first.hash == hash &amp;&amp; // always check first node
            ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))
            return first;
        if ((e = first.next) != null) {
            // 判断是否是红黑树
            if (first instanceof TreeNode)
                return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);

            // 链表遍历
            do {
                if (e.hash == hash &amp;&amp;
                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java 基础 - 泛型机制详解]]></title>
        <id>https://q456qq520.github.io/post/java-ji-chu-fan-xing-ji-zhi-xiang-jie/</id>
        <link href="https://q456qq520.github.io/post/java-ji-chu-fan-xing-ji-zhi-xiang-jie/">
        </link>
        <updated>2022-09-05T07:45:31.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>Java泛型这个特性是从JDK 1.5才开始加入的，因此为了兼容之前的版本，Java泛型的实现采取了“伪泛型”的策略，即Java在语法上支持泛型，但是在编译阶段会进行所谓的“类型擦除”（Type Erasure），将所有的泛型表示（尖括号中的内容）都替换为具体的类型（其对应的原生态类型），就像完全没有泛型一样。</p>
</blockquote>
<h1 id="1为什么会引入泛型">1.为什么会引入泛型</h1>
<blockquote>
<p>泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。</p>
</blockquote>
<p>引入泛型的意义在于：</p>
<p><strong>适用于多种数据类型执行相同的代码（代码复用）</strong></p>
<p>我们通过一个例子来阐述，先看下下面的代码：</p>
<pre><code class="language-java">private static int add(int a, int b) {
    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b));
    return a + b;
}

private static float add(float a, float b) {
    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b));
    return a + b;
}

private static double add(double a, double b) {
    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b));
    return a + b;
}
</code></pre>
<p>如果没有泛型，要实现不同类型的加法，每种类型都需要重载一个add方法；通过泛型，我们可以复用为一个方法：</p>
<pre><code class="language-java">private static &lt;T extends Number&gt; double add(T a, T b) {
    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a.doubleValue() + b.doubleValue()));
    return a.doubleValue() + b.doubleValue();
}
</code></pre>
<p>泛型中的类型在使用时指定，不需要强制类型转换（类型安全，编译器会检查类型）</p>
<h1 id="2泛型的基本使用">2.泛型的基本使用</h1>
<p>泛型有三种使用方式，分别为：泛型类、泛型接口、泛型方法。</p>
<h2 id="21-泛型类">2.1 泛型类</h2>
<p>从一个简单的泛型类看起：</p>
<pre><code class="language-java">class Point&lt;T&gt;{         // 此处可以随便写标识符号，T是type的简称  
    private T var ;     // var的类型由T指定，即：由外部指定  
    public T getVar(){  // 返回值的类型由外部决定  
        return var ;  
    }  
    public void setVar(T var){  // 设置的类型也由外部决定  
        this.var = var ;  
    }  
}  
public class GenericsDemo06{  
    public static void main(String args[]){  
        Point&lt;String&gt; p = new Point&lt;String&gt;() ;     // 里面的var类型为String类型  
        p.setVar(&quot;it&quot;) ;                            // 设置字符串  
        System.out.println(p.getVar().length()) ;   // 取得字符串的长度  
    }  
}
</code></pre>
<p>多元泛型</p>
<pre><code class="language-java">class Notepad&lt;K,V&gt;{       // 此处指定了两个泛型类型  
    private K key ;     // 此变量的类型由外部决定  
    private V value ;   // 此变量的类型由外部决定  
    public K getKey(){  
        return this.key ;  
    }  
    public V getValue(){  
        return this.value ;  
    }  
    public void setKey(K key){  
        this.key = key ;  
    }  
    public void setValue(V value){  
        this.value = value ;  
    }  
} 
public class GenericsDemo09{  
    public static void main(String args[]){  
        Notepad&lt;String,Integer&gt; t = null ;        // 定义两个泛型类型的对象  
        t = new Notepad&lt;String,Integer&gt;() ;       // 里面的key为String，value为Integer  
        t.setKey(&quot;汤姆&quot;) ;        // 设置第一个内容  
        t.setValue(20) ;            // 设置第二个内容  
        System.out.print(&quot;姓名；&quot; + t.getKey()) ;      // 取得信息  
        System.out.print(&quot;，年龄；&quot; + t.getValue()) ;       // 取得信息  
  
    }  
}
</code></pre>
<h2 id="22-泛型接口">2.2 泛型接口</h2>
<pre><code class="language-java">interface Info&lt;T&gt;{        // 在接口上定义泛型  
    public T getVar() ; // 定义抽象方法，抽象方法的返回值就是泛型类型  
}  
class InfoImpl&lt;T&gt; implements Info&lt;T&gt;{   // 定义泛型接口的子类  
    private T var ;             // 定义属性  
    public InfoImpl(T var){     // 通过构造方法设置属性内容  
        this.setVar(var) ;    
    }  
    public void setVar(T var){  
        this.var = var ;  
    }  
    public T getVar(){  
        return this.var ;  
    }  
} 
public class GenericsDemo24{  
    public static void main(String arsg[]){  
        Info&lt;String&gt; i = null;        // 声明接口对象  
        i = new InfoImpl&lt;String&gt;(&quot;汤姆&quot;) ;  // 通过子类实例化对象  
        System.out.println(&quot;内容：&quot; + i.getVar()) ;  
    }  
}  
</code></pre>
<h2 id="23-泛型方法">2.3 泛型方法</h2>
<p>泛型方法，是在调用方法的时候指明泛型的具体类型。</p>
<p>定义泛型方法语法格式</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662364711146.png" alt="定义泛型方法语法格式" loading="lazy"></figure>
<p>调用泛型方法语法格式<br>
<img src="https://q456qq520.github.io/post-images/1662364736330.png" alt="调用泛型方法语法格式" loading="lazy"></p>
<p>说明一下，定义泛型方法时，必须在返回值前边加一个<T>，来声明这是一个泛型方法，持有一个泛型T，然后才可以用泛型T作为方法的返回值。 Class<T>的作用就是指明泛型的具体类型，而Class<T>类型的变量c，可以用来创建泛型类的对象。</p>
<p>为什么要用变量c来创建对象呢？既然是泛型方法，就代表着我们不知道具体的类型是什么，也不知道构造方法如何，因此没有办法去new一个对象，但可以利用变量c的newInstance方法去创建对象，也就是利用反射创建对象。</p>
<p>泛型方法要求的参数是Class<T>类型，而Class.forName()方法的返回值也是Class<T>，因此可以用Class.forName()作为参数。其中，forName()方法中的参数是何种类型，返回的Class<T>就是何种类型。在本例中，forName()方法中传入的是User类的完整路径，因此返回的是Class<User>类型的对象，因此调用泛型方法时，变量c的类型就是Class<User>，因此泛型方法中的泛型T就被指明为User，因此变量obj的类型为User。 当然，泛型方法不是仅仅可以有一个参数Class<T>，可以根据需要添加其他参数。</p>
<p>为什么要使用泛型方法呢？因为泛型类要在实例化的时候就指明类型，如果想换一种类型，不得不重新new一次，可能不够灵活；而泛型方法可以在调用的时候指明类型，更加灵活。</p>
<h2 id="24-泛型的上下限">2.4 泛型的上下限</h2>
<pre><code class="language-java">class A{}
class B extends A {}

// 如下两个方法不会报错
public static void funA(A a) {
    // ...          
}
public static void funB(B b) {
    funA(b);
    // ...             
}

// 如下funD方法会报错
public static void funC(List&lt;A&gt; listA) {
    // ...          
}
public static void funD(List&lt;B&gt; listB) {
    funC(listB); // Unresolved compilation problem: The method doPrint(List&lt;A&gt;) in the type test is not applicable for the arguments (List&lt;B&gt;)
    // ...             
}

那么如何解决呢？ 为了解决泛型中隐含的转换问题，Java泛型加入了类型参数的上下边界机制。&lt;? extends A&gt;表示该类型参数可以是A(上边界)或者A的子类类型。编译时擦除到类型A，即用A类型代替类型参数。这种方法可以解决开始遇到的问题，编译器知道类型参数的范围，如果传入的实例类型B是在这个范围内的话允许转换，这时只要一次类型转换就可以了，运行时会把对象当做A的实例看待。

```java
public static void funC(List&lt;? extends A&gt; listA) {
    // ...          
}
public static void funD(List&lt;B&gt; listB) {
    funC(listB); // OK
    // ...             
}
</code></pre>
<p><strong>泛型上下限的引入</strong><br>
在使用泛型的时候，我们可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。</p>
<ol>
<li>上限</li>
</ol>
<pre><code class="language-java">class Info&lt;T extends Number&gt;{    // 此处泛型只能是数字类型
    private T var ;        // 定义泛型变量
    public void setVar(T var){
        this.var = var ;
    }
    public T getVar(){
        return this.var ;
    }
    public String toString(){    // 直接打印
        return this.var.toString() ;
    }
}
public class demo1{
    public static void main(String args[]){
        Info&lt;Integer&gt; i1 = new Info&lt;Integer&gt;() ;        // 声明Integer的泛型对象
    }
}
</code></pre>
<ol start="2">
<li>下限</li>
</ol>
<pre><code class="language-java">class Info&lt;T&gt;{
    private T var ;        // 定义泛型变量
    public void setVar(T var){
        this.var = var ;
    }
    public T getVar(){
        return this.var ;
    }
    public String toString(){    // 直接打印
        return this.var.toString() ;
    }
}
public class GenericsDemo21{
    public static void main(String args[]){
        Info&lt;String&gt; i1 = new Info&lt;String&gt;() ;        // 声明String的泛型对象
        Info&lt;Object&gt; i2 = new Info&lt;Object&gt;() ;        // 声明Object的泛型对象
        i1.setVar(&quot;hello&quot;) ;
        i2.setVar(new Object()) ;
        fun(i1) ;
        fun(i2) ;
    }
    public static void fun(Info&lt;? super String&gt; temp){    // 只能接收String或Object类型的泛型，String类的父类只有Object类
        System.out.print(temp + &quot;, &quot;) ;
    }
}
</code></pre>
<p><strong>小结</strong></p>
<blockquote>
<?> 无限制通配符
<? extends E> extends 关键字声明了类型的上界，表示参数化的类型可能是所指定的类型，或者是此类型的子类
<? super E> super 关键字声明了类型的下界，表示参数化的类型可能是指定的类型，或者是此类型的父类
1. 如果参数化类型表示一个 T 的生产者，使用 < ? extends T>;
2. 如果它表示一个 T 的消费者，就使用 < ? super T>；
3. 如果既是生产又是消费，那使用通配符就没什么意义了，因为你需要的是精确的参数类型。
</blockquote>
<h2 id="25泛型数组">2.5.泛型数组</h2>
<pre><code class="language-java">List&lt;String&gt;[] list11 = new ArrayList&lt;String&gt;[10]; //编译错误，非法创建 
List&lt;String&gt;[] list12 = new ArrayList&lt;?&gt;[10]; //编译错误，需要强转类型 
List&lt;String&gt;[] list13 = (List&lt;String&gt;[]) new ArrayList&lt;?&gt;[10]; //OK，但是会有警告 
List&lt;?&gt;[] list14 = new ArrayList&lt;String&gt;[10]; //编译错误，非法创建 
List&lt;?&gt;[] list15 = new ArrayList&lt;?&gt;[10]; //OK 
List&lt;String&gt;[] list6 = new ArrayList[10]; //OK，但是会有警告
</code></pre>
<h1 id="3深入理解泛型">3.深入理解泛型</h1>
<h2 id="31-如何理解java中的泛型是伪泛型泛型中类型擦除">3.1 如何理解Java中的泛型是伪泛型？泛型中类型擦除</h2>
<blockquote>
<p>java泛型这个特性是从JDK 1.5才开始加入的，因此为了兼容之前的版本，Java泛型的实现采取了“伪泛型”的策略，即Java在语法上支持泛型，但是在编译阶段会进行所谓的“类型擦除”（Type Erasure），将所有的泛型表示（尖括号中的内容）都替换为具体的类型（其对应的原生态类型），就像完全没有泛型一样。理解类型擦除对于用好泛型是很有帮助的，尤其是一些看起来“疑难杂症”的问题，弄明白了类型擦除也就迎刃而解了。</p>
</blockquote>
<p>泛型的类型擦除原则是：<br>
- 消除类型参数声明，即删除&lt;&gt;及其包围的部分。<br>
- 根据类型参数的上下界推断并替换所有的类型参数为原生态类型：如果类型参数是无限制通配符或没有上下界限定则替换为Object，如果存在上下界限定则根据子类替换原则取类型参数的最左边限定类型（即父类）。<br>
- 为了保证类型安全，必要时插入强制类型转换代码。<br>
- 自动产生“桥接方法”以保证擦除类型后的代码仍然具有泛型的“多态性”。</p>
<h2 id="32-那么如何进行擦除的呢">3.2 那么如何进行擦除的呢？</h2>
<ul>
<li>擦除类定义中的类型参数 - 无限制类型擦除</li>
</ul>
<p>当类定义中的类型参数没有任何限制时，在类型擦除中直接被替换为Object，即形如<T>和&lt;?&gt;的类型参数都被替换为Object。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662369716778.png" alt="无限制类型擦除" loading="lazy"></figure>
<ul>
<li>擦除类定义中的类型参数 - 有限制类型擦除</li>
</ul>
<p>当类定义中的类型参数存在限制（上下界）时，在类型擦除中替换为类型参数的上界或者下界，比如形如<T extends Number>和&lt;? extends Number&gt;的类型参数被替换为Number，&lt;? super Number&gt;被替换为Object。</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1662369723517.png" alt="有限制类型擦除" loading="lazy"></figure>
<ul>
<li>擦除方法定义中的类型参数</li>
</ul>
<p>擦除方法定义中的类型参数原则和擦除类定义中的类型参数是一样的，这里仅以擦除方法定义中的有限制类型参数为例。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1662369746834.png" alt="擦除方法定义中的类型参数" loading="lazy"></figure>
<p>如何证明类型的擦除呢？</p>
<ol>
<li>原始类型相等</li>
</ol>
<pre><code class="language-java">public class Test {

    public static void main(String[] args) {

        ArrayList&lt;String&gt; list1 = new ArrayList&lt;String&gt;();
        list1.add(&quot;abc&quot;);

        ArrayList&lt;Integer&gt; list2 = new ArrayList&lt;Integer&gt;();
        list2.add(123);

        System.out.println(list1.getClass() == list2.getClass()); // true
    }
}
</code></pre>
<ol start="2">
<li>通过反射添加其它类型元素</li>
</ol>
<pre><code class="language-java">public class Test {

    public static void main(String[] args) throws Exception {

        ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();

        list.add(1);  //这样调用 add 方法只能存储整形，因为泛型类型的实例为 Integer

        list.getClass().getMethod(&quot;add&quot;, Object.class).invoke(list, &quot;asd&quot;);

        for (int i = 0; i &lt; list.size(); i++) {
            System.out.println(list.get(i));
        }
    }

}
</code></pre>
<h2 id="33-如何理解类型擦除后保留的原始类型">3.3 如何理解类型擦除后保留的原始类型?</h2>
<p>原始类型 就是擦除去了泛型信息，最后在字节码中的类型变量的真正类型，无论何时定义一个泛型，相应的原始类型都会被自动提供，类型变量擦除，并使用其限定类型（无限定的变量用Object）替换。</p>
<h2 id="34-如何理解泛型的编译期检查">3.4 如何理解泛型的编译期检查？</h2>
<blockquote>
<p>既然说类型变量会在编译的时候擦除掉，那为什么我们往 ArrayList 创建的对象中添加整数会报错呢？不是说泛型变量String会在编译的时候变为Object类型吗？为什么不能存别的类型呢？既然类型擦除了，如何保证我们只能使用泛型变量限定的类型呢？</p>
</blockquote>
<p><strong>Java编译器是通过先检查代码中泛型的类型，然后在进行类型擦除，再进行编译。</strong></p>
<pre><code class="language-java">public class Test {  

    public static void main(String[] args) {  

        ArrayList&lt;String&gt; list1 = new ArrayList();  
        list1.add(&quot;1&quot;); //编译通过  
        list1.add(1); //编译错误  
        String str1 = list1.get(0); //返回类型就是String  

        ArrayList list2 = new ArrayList&lt;String&gt;();  
        list2.add(&quot;1&quot;); //编译通过  
        list2.add(1); //编译通过  
        Object object = list2.get(0); //返回类型就是Object  

        new ArrayList&lt;String&gt;().add(&quot;11&quot;); //编译通过  
        new ArrayList&lt;String&gt;().add(22); //编译错误  

        String str2 = new ArrayList&lt;String&gt;().get(0); //返回类型就是String  
    }  
} 
</code></pre>
<p>通过上面的例子，我们可以明白，<strong>类型检查就是针对引用的，谁是一个引用，用这个引用调用泛型方法，就会对这个引用调用的方法进行类型检测，而无关它真正引用的对象。</strong></p>
<p>泛型中参数话类型为什么不考虑继承关系？</p>
<h2 id="35-如何理解泛型的多态泛型的桥接方法">3.5 如何理解泛型的多态？泛型的桥接方法</h2>
<blockquote>
<p>类型擦除会造成多态的冲突，而JVM解决方法就是桥接方法。</p>
</blockquote>
<h2 id="36-如何理解基本类型不能作为泛型类型">3.6 如何理解基本类型不能作为泛型类型？</h2>
<blockquote>
<p>比如，我们没有ArrayList<int>，只有ArrayList<Integer>, 为何？</p>
</blockquote>
<p>因为当类型擦除后，ArrayList的原始类型变为Object，但是Object类型不能存储int值，只能引用Integer的值。</p>
<p>另外需要注意，我们能够使用list.add(1)是因为Java基础类型的自动装箱拆箱操作。</p>
<h2 id="37-如何理解泛型类型不能实例化">3.7 如何理解泛型类型不能实例化？</h2>
<blockquote>
<p>不能实例化泛型类型, 这本质上是由于类型擦除决定的：</p>
</blockquote>
<p>T test = new T(); // ERROR</p>
<p>因为在 Java 编译期没法确定泛型参数化类型，也就找不到对应的类字节码文件，所以自然就不行了，此外由于T 被擦除为 Object，如果可以 new T() 则就变成了 new Object()，失去了本意。<br>
   <br>
如果我们确实需要实例化一个泛型，应该如何做呢？可以通过反射实现</p>
<pre><code class="language-java">static &lt;T&gt; T newTclass (Class &lt; T &gt; clazz) throws InstantiationException, IllegalAccessException {
    T obj = clazz.newInstance();
    return obj;
}
</code></pre>
<h2 id="38-泛型数组能不能采用具体的泛型类型进行初始化">3.8 泛型数组：能不能采用具体的泛型类型进行初始化？</h2>
<h2 id="39-泛型数组如何正确的初始化泛型数组实例">3.9 泛型数组：如何正确的初始化泛型数组实例</h2>
<pre><code class="language-java">public class ArrayWithTypeToken&lt;T&gt; {
    private T[] array;

    public ArrayWithTypeToken(Class&lt;T&gt; type, int size) {
        array = (T[]) Array.newInstance(type, size);
    }

    public void put(int index, T item) {
        array[index] = item;
    }

    public T get(int index) {
        return array[index];
    }

    public T[] create() {
        return array;
    }
}
//...

ArrayWithTypeToken&lt;Integer&gt; arrayToken = new ArrayWithTypeToken&lt;Integer&gt;(Integer.class, 100);
Integer[] array = arrayToken.create();
</code></pre>
<p>所以使用反射来初始化泛型数组算是优雅实现，因为泛型类型 T在运行时才能被确定下来，我们能创建泛型数组也必然是在 Java 运行时想办法，而运行时能起作用的技术最好的就是反射了。</p>
<p>参考链接：https://pdai.tech/md/java/basic/java-basic-x-generic.html</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JAVA并发（四）]]></title>
        <id>https://q456qq520.github.io/post/java-bing-fa-si/</id>
        <link href="https://q456qq520.github.io/post/java-bing-fa-si/">
        </link>
        <updated>2022-08-18T10:13:51.000Z</updated>
        <content type="html"><![CDATA[<h1 id="6-java中的13个原子操作类">6 Java中的13个原子操作类</h1>
<p>Atomic包里一共提供了13个类，属于4种类型的原子更新方式，分别是原子更新基本类型、原子更新数组、原子更新引用和原子更新属性（字段）。Atomic包里的类基本都是使用Unsafe实现的包装类。</p>
<h2 id="61-原子更新基本类型类">6.1 原子更新基本类型类</h2>
<p>使用原子的方式更新基本类型，Atomic包提供了以下3个类。</p>
<pre><code>AtomicBoolean：原子更新布尔类型。
AtomicInteger：原子更新整型。
AtomicLong：原子更新长整型。
</code></pre>
<p>以上3个类提供的方法几乎一模一样，下面以AtomicInteger为例，AtomicInteger的常用方法如下。</p>
<ol>
<li>int addAndGet（int delta）：以原子方式将输入的数值与实例中的值（AtomicInteger里的value）相加，并返回结果。</li>
<li>boolean compareAndSet（int expect，int update）：如果输入的数值等于预期值，则以原子方式将该值设置为输入的值。</li>
<li>int getAndIncrement()：以原子方式将当前值加1，注意，这里返回的是自增前的值。</li>
<li>void lazySet（int newValue）：最终会设置成newValue，使用lazySet设置值后，可能导致其他<br>
线程在之后的一小段时间内还是可以读到旧的值。</li>
<li>int getAndSet（int newValue）：以原子方式设置为newValue的值，并返回旧值。</li>
</ol>
<p>那么getAndIncrement是如何实现原子操作的呢？</p>
<blockquote>
<p>AtomicInteger</p>
</blockquote>
<pre><code class="language-java">  public final int getAndIncrement() {
        return unsafe.getAndAddInt(this, valueOffset, 1);
    }
</code></pre>
<p>Atomic包里的类基本都是使用Unsafe实现的，Unsafe只提供了3种CAS方法：compareAndSwapObject、compareAndSwapInt和compareAndSwapLong，都是native方法。</p>
<h2 id="62-原子更新数组">6.2 原子更新数组</h2>
<p>通过原子的方式更新数组里的某个元素，Atomic包提供了以下3个类。</p>
<pre><code>AtomicIntegerArray：原子更新整型数组里的元素。
AtomicLongArray：原子更新长整型数组里的元素。
AtomicReferenceArray：原子更新引用类型数组里的元素。
</code></pre>
<p>AtomicIntegerArray类主要是提供原子的方式更新数组里的整型，其常用方法如下。</p>
<pre><code>int addAndGet（int i，int delta）：以原子方式将输入值与数组中索引i的元素相加。
boolean compareAndSet（int i，int expect，int update）：如果当前值等于预期值，则以原子方式将数组位置i的元素设置成update值。
</code></pre>
<p>以上几个类提供的方法几乎一样</p>
<h2 id="63-原子更新引用类型">6.3 原子更新引用类型</h2>
<p>原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下3个类。</p>
<pre><code>AtomicReference：原子更新引用类型。
AtomicReferenceFieldUpdater：原子更新引用类型里的字段。
AtomicMarkableReference：原子更新带有标记位的引用类型。可以原子更新一个布尔类型的标记位和引用类型。
</code></pre>
<h2 id="64-原子更新字段类">6.4 原子更新字段类</h2>
<p>如果需原子地更新某个类里的某个字段时，就需要使用原子更新字段类，Atomic包提供了以下3个类进行原子字段更新。</p>
<pre><code>AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。
AtomicLongFieldUpdater：原子更新长整型字段的更新器。
AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于原子的更新数据和数据的版本号，可以解决使用CAS进行原子更新时可能出现的ABA问题。
</code></pre>
<p>要想原子地更新字段类需要两步。第一步，因为原子更新字段类都是抽象类，每次使用的时候必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新类的字段（属性）必须使用public volatile修饰符。</p>
<h1 id="7-java中的并发工具类">7 Java中的并发工具类</h1>
<p>在JDK的并发包里提供了几个非常有用的并发工具类。CountDownLatch、CyclicBarrier和Semaphore工具类提供了一种并发流程控制的手段，Exchanger工具类则提供了在线程间交换数据的一种手段。</p>
<h2 id="71-等待多线程完成的countdownlatch">7.1 等待多线程完成的CountDownLatch</h2>
<p>CountDownLatch允许一个或多个线程等待其他线程完成操作</p>
<p>当我们调用CountDownLatch的countDown方法时，N就会减1，CountDownLatch的await方法会阻塞当前线程，直到N变成零。由于countDown方法可以用在任何地方，所以这里说的N个点，可以是N个线程，也可以是1个线程里的N个执行步骤。用在多个线程时，只需要把这个CountDownLatch的引用传递到线程里即可。</p>
<p>计数器必须大于等于0，只是等于0时候，计数器就是零，调用await方法时不会阻塞当前线程。CountDownLatch不可能重新初始化或者修改CountDownLatch对象的内部计数器的值。一个线程调用countDown方法happen-before，另外一个线程调用await方法。</p>
<h2 id="72-同步屏障cyclicbarrier">7.2 同步屏障CyclicBarrier</h2>
<p>CyclicBarrier的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。</p>
<h3 id="721-cyclicbarrier简介">7.2.1 CyclicBarrier简介</h3>
<p>CyclicBarrier默认的构造方法是CyclicBarrier（int parties），其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。示例代码如下所示。</p>
<blockquote>
<p>CyclicBarrier示例</p>
</blockquote>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.CyclicBarrier;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/19 17:00
 */
public class CyclicBarrierTest {
    static CyclicBarrier c = new CyclicBarrier(2);
    public static void main(String[] args) {
        new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    c.await();
                } catch (Exception e) {
                }
                System.out.println(1);
            }
        }).start();
        try {
            c.await();
        } catch (Exception e) {
        }
        System.out.println(2);
    }
}
</code></pre>
<p>因为主线程和子线程的调度是由CPU决定的，两个线程都有可能先执行，所以会产生两种输出。</p>
<p>如果把new CyclicBarrier(2)修改成new CyclicBarrier(3)，则主线程和子线程会永远等待，因为没有第三个线程执行await方法，即没有第三个线程到达屏障，所以之前到达屏障的两个线程都不会继续执行。</p>
<p>CyclicBarrier还提供一个更高级的构造函数CyclicBarrier（int parties，Runnable barrierAction），用于在线程到达屏障时，优先执行barrierAction，方便处理更复杂的业务场景，如下所示：</p>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.CyclicBarrier;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/19 17:03
 */
public class CyclicBarrierTest2 {
        static CyclicBarrier c = new CyclicBarrier(2, new A());
        public static void main(String[] args) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    try {
                        c.await();
                    } catch (Exception e) {
                    }
                    System.out.println(1);
                }
            }).start();
            try {
                c.await();
            } catch (Exception e) {
            }
            System.out.println(2);
        }
        static class A implements Runnable {
            @Override
            public void run() {
                System.out.println(3);
            }
        }
}
</code></pre>
<p>因为CyclicBarrier设置了拦截线程的数量是2，所以必须等代码中的第一个线程和线程A<br>
都执行完之后，才会继续执行主线程。</p>
<h3 id="722-cyclicbarrier的应用场景">7.2.2 CyclicBarrier的应用场景</h3>
<h3 id="723-cyclicbarrier和countdownlatch的区别">7.2.3 CyclicBarrier和CountDownLatch的区别</h3>
<p>CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置。所以CyclicBarrier能处理更为复杂的业务场景。例如，如果计算发生错误，可以重置计数器，并让线程重新执行一次。</p>
<p>CyclicBarrier还提供其他有用的方法，比如getNumberWaiting方法可以获得Cyclic-Barrier阻塞的线程数量。isBroken()方法用来了解阻塞的线程是否被中断。</p>
<h2 id="73-控制并发线程数的semaphore">7.3 控制并发线程数的Semaphore</h2>
<p>Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。</p>
<h5 id="1应用场景">1.应用场景</h5>
<p>Semaphore可以用于做流量控制，特别是公用资源有限的应用场景，比如数据库连接。假如有一个需求，要读取几万个文件的数据，因为都是IO密集型任务，我们可以启动几十个线程并发地读取，但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只有10个，这时我们必须控制只有10个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。这个时候，就可以使用Semaphore来做流量控制，示例如下：</p>
<blockquote>
<p>SemaphoreTest</p>
</blockquote>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Semaphore;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/22 15:33
 */
public class SemaphoreTest {
    private static final int THREAD_COUNT = 30;
    private static ExecutorService threadPool = Executors.newFixedThreadPool(THREAD_COUNT);
    private static Semaphore s = new Semaphore(10);
    public static void main(String[] args) {
        for (int i = 0; i&lt; THREAD_COUNT; i++) {
            threadPool.execute(new Runnable() {
                @Override
                public void run() {
                    try {
                        s.acquire();
                        System.out.println(&quot;save data&quot;);
                        s.release();
                    } catch (InterruptedException e) {
                    }
                }
            });
        }
        threadPool.shutdown();
    }
}
</code></pre>
<p>在代码中，虽然有30个线程在执行，但是只允许10个并发执行。Semaphore的构造方法Semaphore（int permits）接受一个整型的数字，表示可用的许可证数量。Semaphore（10）表示允许10个线程获取许可证，也就是最大并发数是10。Semaphore的用法也很简单，首先线程使用Semaphore的acquire()方法获取一个许可证，使用完之后调用release()方法归还许可证。还可以用tryAcquire()方法尝试获取许可证。</p>
<h5 id="2其他方法">2.其他方法</h5>
<p>Semaphore还提供一些其他方法，具体如下。</p>
<ol>
<li>intavailablePermits()：返回此信号量中当前可用的许可证数。</li>
<li>intgetQueueLength()：返回正在等待获取许可证的线程数。</li>
<li>booleanhasQueuedThreads()：是否有线程正在等待获取许可证。</li>
<li>void reducePermits（int reduction）：减少reduction个许可证，是个protected方法。</li>
<li>Collection getQueuedThreads()：返回所有等待获取许可证的线程集合，是个protected方<br>
法。</li>
</ol>
<h2 id="74-线程间交换数据的exchanger">7.4 线程间交换数据的Exchanger</h2>
<p>Exchanger（交换者）是一个用于线程间协作的工具类。Exchanger用于进行线程间的数据交换。</p>
<p>它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行exchange方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。</p>
<h3 id="71">7.1</h3>
<p>Exchanger可以用于遗传算法，遗传算法里需要选出两个人作为交配对象，这时候会交换两人的数据，并使用交叉规则得出2个交配结果。</p>
<p>Exchanger也可以用于校对工作，比如我们需要将纸制银行流水通过人工的方式录入成电子银行流水，为了避免错误，采用AB岗两人进行录入，录入到Excel之后，系统需要加载这两个Excel，并对两个Excel数据进行校对，看看是否录入一致。</p>
<blockquote>
<p>11</p>
</blockquote>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.Exchanger;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/22 15:55
 */
public class ExchangerTest {
    private static final Exchanger&lt;String&gt; exgr = new Exchanger&lt;String&gt;();
    private static ExecutorService threadPool = Executors.newFixedThreadPool(2);
    public static void main(String[] args) {
        threadPool.execute(new Runnable() {
            @Override
            public void run() {
                try {
                    String A = &quot;银行流水A&quot;; // A录入银行流水数据
                    exgr.exchange(A);

                    System.out.println(&quot;比较完成&quot;);
                } catch (InterruptedException e) {
                }
            }
        });
        threadPool.execute(new Runnable() {
            @Override
            public void run() {
                try {
                    String B = &quot;银行流水B&quot;; // B录入银行流水数据
                    String A = exgr.exchange(&quot;B&quot;);
                    System.out.println(&quot;A和B数据是否一致：&quot; + A.equals(B) + &quot;，A录入的是：&quot;
                            + A + &quot;，B录入是：&quot; + B);
                } catch (InterruptedException e) {
                }
            }
        });
        threadPool.shutdown();
    }
}
</code></pre>
<p>如果两个线程有一个没有执行exchange()方法，则会一直等待，如果担心有特殊情况发生，避免一直等待，可以使用exchange（V x，longtimeout，TimeUnit unit）设置最大等待时长。</p>
<h1 id="8-java中的线程池">8 Java中的线程池</h1>
<h2 id="81-线程池的实现原理">8.1 线程池的实现原理</h2>
<p>在开发过程中，合理地使用线程池能够带来3个好处。<br>
第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。<br>
第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。<br>
第三：提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。</p>
<p>ThreadPoolExecutor执行execute方法分下面4种情况。<br>
1）如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。<br>
2）如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。<br>
3）如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。<br>
4）如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用<br>
RejectedExecutionHandler.rejectedExecution()方法。</p>
<p>线程池执行任务的方法如下。</p>
<blockquote>
<p>execute()</p>
</blockquote>
<pre><code class="language-java">  public void execute(Runnable command) {
        if (command == null)
            throw new NullPointerException();
        int c = ctl.get();
        if (workerCountOf(c) &lt; corePoolSize) {
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
        if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
            int recheck = ctl.get();
            if (! isRunning(recheck) &amp;&amp; remove(command))
                reject(command);
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
        else if (!addWorker(command, false))
            reject(command);
    }
</code></pre>
<p>线程池中的线程执行任务分两种情况，如下。<br>
1）在execute()方法中创建一个线程时，会让这个线程执行当前任务。<br>
2）这个线程执行完上图中1的任务后，会反复从BlockingQueue获取任务来执行。</p>
<h2 id="82-线程池的使用">8.2 线程池的使用</h2>
<h3 id="821-线程池的创建">8.2.1 线程池的创建</h3>
<p>我们可以通过ThreadPoolExecutor来创建一个线程池</p>
<pre><code class="language-java">new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime,
milliseconds,runnableTaskQueue, handler);
</code></pre>
<p>1）corePoolSize（线程池的基本大小）：当提交一个任务到线程池时，线程池会创建一个线<br>
程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任<br>
务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads()方法，<br>
线程池会提前创建并启动所有基本线程。</p>
<p>2）runnableTaskQueue（任务队列）：用于保存等待执行的任务的阻塞队列。可以选择以下几<br>
个阻塞队列。<br>
ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按FIFO（先进先出）原则对元素进行排序。<br>
LinkedBlockingQueue：一个基于链表结构的阻塞队列，此队列按FIFO排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列。<br>
SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于Linked-BlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。<br>
PriorityBlockingQueue：一个具有优先级的无限阻塞队列。</p>
<p>3）maximumPoolSize（线程池最大数量）：线程池允许创建的最大线程数。如果队列满了，并<br>
且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是，如<br>
果使用了无界的任务队列这个参数就没什么效果。</p>
<p>4）ThreadFactory：用于设置创建线程的工厂。</p>
<p>5）RejectedExecutionHandler（拒绝策略）：当队列和线程池都满了，说明线程池处于饱和状<br>
态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法<br>
处理新任务时抛出异常。</p>
<pre><code>AbortPolicy：直接抛出异常。
CallerRunsPolicy：只用调用者所在线程来运行任务。
DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。
DiscardPolicy：不处理，丢弃掉。
</code></pre>
<h3 id="822-向线程池提交任务">8.2.2 向线程池提交任务</h3>
<p>可以使用两个方法向线程池提交任务，分别为execute()和submit()方法。</p>
<p>**execute()**方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功。通过以下代码可知execute()方法输入的任务是一个Runnable类的实例。</p>
<pre><code class="language-java">threadsPool.execute(new Runnable() {
    @Override
    public void run() {
    // TODO Auto-generated method stub
    }
});
</code></pre>
<p>submit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。</p>
<pre><code class="language-java">Future&lt;Object&gt; future = executor.submit(harReturnValuetask);
    try {
        Object s = future.get();
    } catch (InterruptedException e) {
    // 处理中断异常
    } catch (ExecutionException e) {
    // 处理无法执行任务异常
    } finally {
    // 关闭线程池
    executor.shutdown();
}
</code></pre>
<h3 id="823-关闭线程池">8.2.3 关闭线程池</h3>
<p>可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池。它们的原理是遍历线程池中的工作线程，然后逐个调用线程的interrupt方法来中断线程，所以无法响应中断的任务可能永远无法终止。</p>
<p>但是它们存在一定的区别，shutdownNow首先将线程池的状态设置成STOP，然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表，而shutdown只是将线程池的状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。</p>
<p>只要调用了这两个关闭方法中的任意一个，isShutdown方法就会返回true。当所有的任务都已关闭后，才表示线程池关闭成功，这时调用isTerminaed方法会返回true。至于应该调用哪一种方法来关闭线程池，应该由提交到线程池的任务特性决定，通常调用shutdown方法来关闭线程池，如果任务不一定要执行完，则可以调用shutdownNow方法。</p>
<h3 id="824-合理地配置线程池">8.2.4 合理地配置线程池</h3>
<h3 id="825-线程池的监控">8.2.5 线程池的监控</h3>
<p>果在系统中大量使用线程池，则有必要对线程池进行监控，方便在出现问题时，可以根<br>
据线程池的使用状况快速定位问题。可以通过线程池提供的参数进行监控，在监控线程池的<br>
时候可以使用以下属性。</p>
<p>taskCount：线程池需要执行的任务数量。<br>
completedTaskCount：线程池在运行过程中已完成的任务数量，小于或等于taskCount。<br>
largestPoolSize：线程池里曾经创建过的最大线程数量。通过这个数据可以知道线程池是<br>
否曾经满过。如该数值等于线程池的最大大小，则表示线程池曾经满过。<br>
getPoolSize：线程池的线程数量。如果线程池不销毁的话，线程池里的线程不会自动销<br>
毁，所以这个大小只增不减。<br>
getActiveCount：获取活动的线程数。</p>
<p>通过扩展线程池进行监控。可以通过继承线程池来自定义线程池，重写线程池的beforeExecute、afterExecute和terminated方法，也可以在任务执行前、执行后和线程池关闭前执行一些代码来进行监控。例如，监控任务的平均执行时间、最大执行时间和最小执行时间等。这几个方法在线程池里是空方法。</p>
<h1 id="9-executor框架">9 Executor框架</h1>
<p>Java的线程既是工作单元，也是执行机制。从JDK 5开始，把工作单元与执行机制分离开来。工作单元包括Runnable和Callable，而执行机制由Executor框架提供。</p>
<h2 id="91-executor框架简介">9..1 Executor框架简介</h2>
<h3 id="911-executor框架的两级调度模型">9.1.1 Executor框架的两级调度模型</h3>
<p>在HotSpot VM的线程模型中，Java线程（java.lang.Thread）被一对一映射为本地操作系统线程。Java线程启动时会创建一个本地操作系统线程；当该Java线程终止时，这个操作系统线程也会被回收。操作系统会调度所有线程并将它们分配给可用的CPU。</p>
<p>在上层，Java多线程程序通常把应用分解为若干个任务，然后使用用户级的调度器（Executor框架）将这些任务映射为固定数量的线程；在底层，操作系统内核将这些线程映射到硬件处理器上。</p>
<p>应用程序通过Executor框架控制上层的调度；而下层的调度由操作系统内核控制，下层的调度不受应用程序的控制。</p>
<h3 id="912-executor框架的结构与成员">9.1.2 Executor框架的结构与成员</h3>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1661163229274.png" alt="任务的两级调度模型" loading="lazy"></figure>
<h5 id="1executor框架的结构">1.Executor框架的结构</h5>
<p>Executor框架主要由3大部分组成如下。<br>
任务。包括被执行任务需要实现的接口：Runnable接口或Callable接口。<br>
任务的执行。包括任务执行机制的核心接口Executor，以及继承自Executor的ExecutorService接口。Executor框架有两个关键类实现了ExecutorService接口（ThreadPoolExecutor和ScheduledThreadPoolExecutor）。<br>
异步计算的结果。包括接口Future和实现Future接口的FutureTask类</p>
<p>下面是这些类和接口的简介。</p>
<ol>
<li>Executor是一个接口，它是Executor框架的基础，它将任务的提交与任务的执行分离开来。</li>
<li>ThreadPoolExecutor是线程池的核心实现类，用来执行被提交的任务</li>
<li>·ScheduledThreadPoolExecutor是一个实现类，可以在给定的延迟后运行命令，或者定期执行命令。ScheduledThreadPoolExecutor比Timer更灵活，功能更强大。</li>
<li>Future接口和实现Future接口的FutureTask类，代表异步计算的结果。</li>
<li>Runnable接口和Callable接口的实现类，都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行。</li>
</ol>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1661163737003.png" alt="Executor框架的使用示意图" loading="lazy"></figure>
<p>主线程首先要创建实现Runnable或者Callable接口的任务对象。工具类Executors可以把一个Runnable对象封装为一个Callable对象（Executors.callable（Runnable task）或Executors.callable（Runnable task，Object resule））。</p>
<p>然后可以把Runnable对象直接交给ExecutorService执行（ExecutorService.execute（Runnablecommand））；或者也可以把Runnable对象或Callable对象提交给ExecutorService执行（ExecutorService.submit（Runnable task）或ExecutorService.submit（Callable<T>task）。</p>
<p>如果执行ExecutorService.submit（…），ExecutorService将返回一个实现Future接口的对象（到目前为止的JDK中，返回的是FutureTask对象）。由于FutureTask实现了Runnable，程序员也可以创建FutureTask，然后直接交给ExecutorService执行。</p>
<p>最后，主线程可以执行FutureTask.get()方法来等待任务执行完成。主线程也可以执FutureTask.cancel（boolean mayInterruptIfRunning）来取消此任务的执行。</p>
<h5 id="2executor框架的成员">2.Executor框架的成员</h5>
<p>Executor框架的主要成员：ThreadPoolExecutor、ScheduledThreadPoolExecutor、Future接口、Runnable接口、Callable接口和Executors。</p>
<p>（1）ThreadPoolExecutor</p>
<p>ThreadPoolExecutor通常使用工厂类Executors来创建。Executors可以创建3种类型的ThreadPoolExecutor：SingleThreadExecutor、FixedThreadPool和CachedThreadPool。</p>
<ol>
<li>FixedThreadPool。下面是Executors提供的，创建使用固定线程数的FixedThreadPool的API。</li>
</ol>
<pre><code class="language-java"> public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue&lt;Runnable&gt;());
    }

    public static ExecutorService newWorkStealingPool(int parallelism) {
        return new ForkJoinPool
            (parallelism,
             ForkJoinPool.defaultForkJoinWorkerThreadFactory,
             null, true);
    }
</code></pre>
<p>FixedThreadPool适用于为了满足资源管理的需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。</p>
<ol start="2">
<li>SingleThreadExecutor。下面是Executors提供的，创建使用单个线程的SingleThreadExecutor的API。</li>
</ol>
<pre><code class="language-java">    public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue&lt;Runnable&gt;()));
    }

    public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue&lt;Runnable&gt;(),
                                    threadFactory));
    }
</code></pre>
<p>SingleThreadExecutor适用于需要保证顺序地执行各个任务；并且在任意时间点，不会有多个线程是活动的应用场景。</p>
<ol start="3">
<li>CachedThreadPool。下面是Executors提供的，创建一个会根据需要创建新线程的CachedThreadPool的API。</li>
</ol>
<pre><code class="language-java">   public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue&lt;Runnable&gt;());
    }

    public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue&lt;Runnable&gt;(),
                                      threadFactory);
    }
</code></pre>
<p>CachedThreadPool是大小无界的线程池，适用于执行很多的短期异步任务的小程序，或者是负载较轻的服务器。</p>
<p>（2）ScheduledThreadPoolExecutor</p>
<p>ScheduledThreadPoolExecutor通常使用工厂类Executors来创建。Executors可以创建2种类型的ScheduledThreadPoolExecutor，如下。</p>
<ol>
<li>ScheduledThreadPoolExecutor。包含若干个线程的ScheduledThreadPoolExecutor。</li>
<li>SingleThreadScheduledExecutor。只包含一个线程的ScheduledThreadPoolExecutor。</li>
</ol>
<p>ScheduledThreadPoolExecutor适用于需要多个后台线程执行周期任务，同时为了满足资源管理的需求而需要限制后台线程的数量的应用场景。</p>
<p>SingleThreadScheduledExecutor适用于需要单个后台线程执行周期任务，同时需要保证顺序地执行各个任务的应用场景。</p>
<p>（3）Future接口</p>
<p>Future接口和实现Future接口的FutureTask类用来表示异步计算的结果。当我们把Runnable接口或Callable接口的实现类提交（submit）给ThreadPoolExecutor或ScheduledThreadPoolExecutor时，ThreadPoolExecutor或ScheduledThreadPoolExecutor会向我们返回一个FutureTask对象。下面是对应的API。</p>
<pre><code class="language-java">&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);


&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);

Future&lt;?&gt; submit(Runnable task);
</code></pre>
<p>（4）Runnable接口和Callable接口</p>
<p>Runnable接口和Callable接口的实现类，都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行。它们之间的区别是Runnable不会返回结果，而Callable可以返回结果。</p>
<p>除了可以自己创建实现Callable接口的对象外，还可以使用工厂类Executors来把一个Runnable包装成一个Callable。</p>
<h2 id="92-threadpoolexecutor详解">9.2 ThreadPoolExecutor详解</h2>
<p>Executor框架最核心的类是ThreadPoolExecutor，它是线程池的实现类，主要由下列4个组件构成。</p>
<ol>
<li>corePool：核心线程池的大小。</li>
<li>maximumPool：最大线程池的大小。</li>
<li>BlockingQueue：用来暂时保存任务的工作队列。</li>
<li>RejectedExecutionHandler：当ThreadPoolExecutor已经关闭或ThreadPoolExecutor已经饱和时（达到了最大线程池大小且工作队列已满），execute()方法将要调用的Handler。</li>
</ol>
<p>通过Executor框架的工具类Executors，可以创建3种类型的ThreadPoolExecutor。<br>
FixedThreadPool<br>
SingleThreadExecutor<br>
CachedThreadPool</p>
<h3 id="921-fixedthreadpool详解">9.2.1 FixedThreadPool详解</h3>
<p>FixedThreadPool被称为可重用固定线程数的线程池。</p>
<p>FixedThreadPool的corePoolSize和maximumPoolSize都被设置为创建FixedThreadPool时指定的参数nThreads。</p>
<p>当线程池中的线程数大于corePoolSize时，keepAliveTime为多余的空闲线程等待新任务的最长时间，超过这个时间后多余的线程将被终止。这里把keepAliveTime设置为0L，意味着多余的空闲线程会被立即终止。</p>
<p>FixedThreadPool使用无界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer.MAX_VALUE）。使用无界队列作为工作队列会对线程池带来如下影响。</p>
<p>1）当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中<br>
的线程数不会超过corePoolSize。<br>
2）由于1，使用无界队列时maximumPoolSize将是一个无效参数。<br>
3）由于1和2，使用无界队列时keepAliveTime将是一个无效参数。<br>
4）由于使用无界队列，运行中的FixedThreadPool（未执行方法shutdown()或shutdownNow()）不会拒绝任务（不会调用RejectedExecutionHandler.rejectedExecution方法）。</p>
<h3 id="922-singlethreadexecutor详解">9.2.2 SingleThreadExecutor详解</h3>
<p>SingleThreadExecutor是使用单个worker线程的Executor。</p>
<p>SingleThreadExecutor的corePoolSize和maximumPoolSize被设置为1。其他参数与<br>
FixedThreadPool相同。SingleThreadExecutor使用无界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer.MAX_VALUE）。SingleThreadExecutor使用无界队列作为工作队列对线程池带来的影响与FixedThreadPool相同。</p>
<h3 id="923-cachedthreadpool详解">9.2.3 CachedThreadPool详解</h3>
<p>CachedThreadPool是一个会根据需要创建新线程的线程池。</p>
<p>CachedThreadPool的corePoolSize被设置为0，即corePool为空；maximumPoolSize被设置为<br>
Integer.MAX_VALUE，即maximumPool是无界的。这里把keepAliveTime设置为60L，意味着CachedThreadPool中的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。</p>
<p>CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列，但<br>
CachedThreadPool的maximumPool是无界的。这意味着，如果主线程提交任务的速度高于<br>
maximumPool中线程处理任务的速度时，CachedThreadPool会不断创建新线程。极端情况下，CachedThreadPool会因为创建过多线程而耗尽CPU和内存资源。</p>
<p>SynchronousQueue是一个没有容量的阻塞队列。每个插入操作必须等待另一个线程的对应移除操作，反之亦然。CachedThreadPool使用SynchronousQueue，把主线程提交的任务传递给空闲线程执行。</p>
<h2 id="93-scheduledthreadpoolexecutor详解">9.3 ScheduledThreadPoolExecutor详解</h2>
<p>ScheduledThreadPoolExecutor继承自ThreadPoolExecutor。它主要用来在给定的延迟之后运行任务，或者定期执行任务。</p>
<h2 id="94-futuretask详解">9.4 FutureTask详解</h2>
<p>Future接口和实现Future接口的FutureTask类，代表异步计算的结果。</p>
<h3 id="941-futuretask简介">9.4.1 FutureTask简介</h3>
<p>FutureTask除了实现Future接口外，还实现了Runnable接口。因此，FutureTask可以交给Executor执行，也可以由调用线程直接执行（FutureTask.run()）。根据FutureTask.run()方法被执行的时机，FutureTask可以处于下面3种状态。</p>
<p>1）未启动。FutureTask.run()方法还没有被执行之前，FutureTask处于未启动状态。当创建一个FutureTask，且没有执行FutureTask.run()方法之前，这个FutureTask处于未启动状态。<br>
2）已启动。FutureTask.run()方法被执行的过程中，FutureTask处于已启动状态。<br>
3）已完成。FutureTask.run()方法执行完后正常结束，或被取消（FutureTask.cancel（…）），或执行FutureTask.run()方法时抛出异常而异常结束，FutureTask处于已完成状态。</p>
<p>当FutureTask处于未启动或已启动状态时，执行FutureTask.get()方法将导致调用线程阻塞；当FutureTask处于已完成状态时，执行FutureTask.get()方法将导致调用线程立即返回结果或抛出异常。</p>
<p>当FutureTask处于未启动状态时，执行FutureTask.cancel()方法将导致此任务永远不会被执行；当FutureTask处于已启动状态时，执行FutureTask.cancel（true）方法将以中断执行此任务线程的方式来试图停止任务；当FutureTask处于已启动状态时，执行FutureTask.cancel（false）方法将不会对正在执行此任务的线程产生影响（让正在执行的任务运行完成）；当FutureTask处于已完成状态时，执行FutureTask.cancel（…）方法将返回false。</p>
<h3 id="942-futuretask的使用">9.4.2 FutureTask的使用</h3>
<p>可以把FutureTask交给Executor执行；也可以通过ExecutorService.submit（…）方法返回一个FutureTask，然后执行FutureTask.get()方法或FutureTask.cancel（…）方法。除此以外，还可以单独使用FutureTask。</p>
<p>当一个线程需要等待另一个线程把某个任务执行完后它才能继续执行，此时可以使用FutureTask。假设有多个线程执行若干任务，每个任务最多只能被执行一次。当多个线程试图同时执行同一个任务时，只允许一个线程执行任务，其他线程需要等待这个任务执行完后才能继续执行。下面是对应的示例代码。</p>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.*;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/23 17:34
 */
public class FutureTaskTest {

    private final ConcurrentMap&lt;Object, Future&lt;String&gt;&gt; taskCache =
            new ConcurrentHashMap&lt;Object, Future&lt;String&gt;&gt;();

    private String executionTask(final String taskName)
            throws ExecutionException, InterruptedException {
        while (true) {
            Future&lt;String&gt; future = taskCache.get(taskName); // 1.1,2.1
            if (future == null) {
                Callable&lt;String&gt; task = new Callable&lt;String&gt;() {
                    public String call() throws InterruptedException {
                        return taskName;
                    }
                };

                FutureTask&lt;String&gt; futureTask = new FutureTask&lt;String&gt;(task);
                future = taskCache.putIfAbsent(taskName, futureTask); // 1.3
                if (future == null) {
                    future = futureTask;
                    futureTask.run(); // 1.4执行任务
                }
                try {
                    return future.get(); // 1.5,
                } catch (CancellationException e) {
                    taskCache.remove(taskName, future);
                }
            }
        }
    }
}
</code></pre>
<p>当两个线程试图同时执行同一个任务时，如果Thread 1执行1.3后Thread 2执行2.1，那么接下来Thread 2将在2.2等待，直到Thread 1执行完1.4后Thread 2才能从2.2（FutureTask.get()）返回。</p>
<h3 id="943-futuretask的实现">9.4.3 FutureTask的实现</h3>
<p>FutureTask的实现基于AbstractQueuedSynchronizer（以下简称为AQS）。java.util.concurrent中的很多可阻塞类（比如ReentrantLock）都是基于AQS来实现的。AQS是一个同步框架，它提供通用机制来原子性管理同步状态、阻塞和唤醒线程，以及维护被阻塞线程的队列。</p>
<p>每一个基于AQS实现的同步器都会包含两种类型的操作，如下。</p>
<p>至少一个acquire操作。这个操作阻塞调用线程，除非/直到AQS的状态允许这个线程继续执行。FutureTask的acquire操作为get()/get（long timeout，TimeUnit unit）方法调用。</p>
<p>至少一个release操作。这个操作改变AQS的状态，改变后的状态可允许一个或多个阻塞线程被解除阻塞。FutureTask的release操作包括run()方法和cancel（…）方法。</p>
<p>基于“复合优先于继承”的原则，FutureTask声明了一个内部私有的继承于AQS的子类Sync，对FutureTask所有公有方法的调用都会委托给这个内部子类。</p>
<p>FutureTask.run()的执行过程如下。</p>
<p>1）执行在构造函数中指定的任务（Callable.call()）。<br>
2）以原子方式来更新同步状态（调用AQS.compareAndSetState（int expect，int update），设置<br>
state为执行完成状态RAN）。如果这个原子操作成功，就设置代表计算结果的变量result的值为Callable.call()的返回值，然后调用AQS.releaseShared（int arg）。<br>
3）AQS.releaseShared（int arg）首先会回调在子类Sync中实现的tryReleaseShared（arg）来执行release操作（设置运行任务的线程runner为null，然会返回true）；AQS.releaseShared（int arg，<br>
然后唤醒线程等待队列中的第一个线程。<br>
4）调用FutureTask.done()。<br>
当执行FutureTask.get()方法时，如果FutureTask不是处于执行完成状态RAN或已取消状态CANCELLED，当前执行线程将到AQS的线程等待队列中等待。当某个线程执行FutureTask.run()方法或FutureTask.cancel（...）方法时，会唤醒线程等待队列的第一个线程。</p>
<h1 id="10-java并发编程实践">10 Java并发编程实践</h1>
<h2 id="101-生产者和消费者模式">10.1 生产者和消费者模式</h2>
<p>在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序整体处理数据的速度。</p>
<p>什么是生产者和消费者模式?</p>
<p>生产者和消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通信，而是通过<strong>阻塞队列</strong>来进行通信，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。</p>
<h3 id="1011-生产者消费者模式实战">10.1.1 生产者消费者模式实战</h3>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JAVA并发（三）]]></title>
        <id>https://q456qq520.github.io/post/java-bing-fa-san/</id>
        <link href="https://q456qq520.github.io/post/java-bing-fa-san/">
        </link>
        <updated>2022-08-16T03:20:47.000Z</updated>
        <content type="html"><![CDATA[<h1 id="5-java并发容器和框架">5 Java并发容器和框架、</h1>
<h2 id="51-concurrenthashmap的实现原理与使用">5.1 ConcurrentHashMap的实现原理与使用</h2>
<h3 id="511-为什么要使用concurrenthashmap">5.1.1 为什么要使用ConcurrentHashMap</h3>
<p>在并发编程中使用HashMap可能导致程序死循环。而使用线程安全的HashTable效率又非常低下，基于以上两个原因，便有了ConcurrentHashMap的登场机会。</p>
<h5 id="1线程不安全的hashmap">（1）线程不安全的HashMap</h5>
<p>在多线程环境下，使用HashMap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap。如下所示：</p>
<pre><code class="language-java">final HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(2);
Thread t = new Thread(new Runnable() {
    @Override
    public void run() {
        for (int i = 0; i &lt; 10000; i++) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    map.put(UUID.randomUUID().toString(), &quot;&quot;);
                }
            }, &quot;ftf&quot; + i).start();
        }
    }
}, &quot;ftf&quot;);
t.start();
t.join();
</code></pre>
<p>HashMap在并发执行put操作时会引起死循环，<strong>是因为多线程会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry。</strong></p>
<h5 id="2效率低下的hashtable">（2）效率低下的HashTable</h5>
<p>HashTable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法，其他线程也访问HashTable的同步方法时，会进入阻塞或轮询状态。如线程1使用put进行元素添加，线程2不但不能使用put方法添加元素，也不能使用get方法来获取元素，所以竞争越激烈效率越低。</p>
<h5 id="3concurrenthashmap的锁分段技术可有效提升并发访问率">（3）ConcurrentHashMap的锁分段技术可有效提升并发访问率</h5>
<p>ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段地存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。</p>
<h3 id="512-concurrenthashmap的结构">5.1.2 ConcurrentHashMap的结构</h3>
<p>在JDK1.5~1.7版本，Java使用了分段锁机制实现ConcurrentHashMap.</p>
<p>简而言之，ConcurrentHashMap在对象中保存了一个Segment数组，即将整个Hash表划分为多个分段；而每个Segment元素，即每个分段则类似于一个Hashtable；这样，在执行put操作时首先根据hash算法定位到元素属于哪个Segment，然后对该Segment加锁即可。因此，ConcurrentHashMap在多线程并发编程中可是实现多线程put操作。</p>
<p>在JDK1.7之前，ConcurrentHashMap是通过分段锁机制来实现的，所以其最大并发度受Segment的个数限制。因此，在JDK1.8中，ConcurrentHashMap的实现原理摒弃了这种设计，而是选择了与HashMap类似的数组+链表+红黑树的方式实现，而加锁则采用CAS和synchronized实现。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1660640046350.png" alt="" loading="lazy"></figure>
<h3 id="513-初始化">5.1.3 初始化</h3>
<pre><code class="language-java">// 这构造函数里，什么都不干
public ConcurrentHashMap() {
}
public ConcurrentHashMap(int initialCapacity) {
    if (initialCapacity &lt; 0)
        throw new IllegalArgumentException();
    int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ?
               MAXIMUM_CAPACITY :
               tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1));
    this.sizeCtl = cap;
}
</code></pre>
<p>通过提供初始容量，计算了 sizeCtl，sizeCtl = 【 (1.5 * initialCapacity + 1)，然后向上取最近的 2 的 n 次方】。如 initialCapacity 为 10，那么得到 sizeCtl 为 16，如果 initialCapacity 为 11，得到 sizeCtl 为 32。</p>
<h3 id="514-concurrenthashmap的操作">5.1.4 ConcurrentHashMap的操作</h3>
<h5 id="1put">1.put</h5>
<pre><code class="language-java">public V put(K key, V value) {
    return putVal(key, value, false);
}
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    // 得到 hash 值
    int hash = spread(key.hashCode());
    // 用于记录相应链表的长度
    int binCount = 0;
    for (Node&lt;K,V&gt;[] tab = table;;) {
        Node&lt;K,V&gt; f; int n, i, fh;
        // 如果数组&quot;空&quot;，进行数组初始化
        if (tab == null || (n = tab.length) == 0)
            // 初始化数组，后面会详细介绍
            tab = initTable();

        // 找该 hash 值对应的数组下标，得到第一个节点 f
        else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) {
            // 如果数组该位置为空，
            //    用一次 CAS 操作将这个新值放入其中即可，这个 put 操作差不多就结束了，可以拉到最后面了
            //          如果 CAS 失败，那就是有并发操作，进到下一个循环就好了
            if (casTabAt(tab, i, null,
                         new Node&lt;K,V&gt;(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        // hash 居然可以等于 MOVED，这个需要到后面才能看明白，不过从名字上也能猜到，肯定是因为在扩容
        else if ((fh = f.hash) == MOVED)
            // 帮助数据迁移，这个等到看完数据迁移部分的介绍后，再理解这个就很简单了
            tab = helpTransfer(tab, f);

        else { // 到这里就是说，f 是该位置的头节点，而且不为空

            V oldVal = null;
            // 获取数组该位置的头节点的监视器锁
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    if (fh &gt;= 0) { // 头节点的 hash 值大于 0，说明是链表
                        // 用于累加，记录链表的长度
                        binCount = 1;
                        // 遍历链表
                        for (Node&lt;K,V&gt; e = f;; ++binCount) {
                            K ek;
                            // 如果发现了&quot;相等&quot;的 key，判断是否要进行值覆盖，然后也就可以 break 了
                            if (e.hash == hash &amp;&amp;
                                ((ek = e.key) == key ||
                                 (ek != null &amp;&amp; key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            // 到了链表的最末端，将这个新值放到链表的最后面
                            Node&lt;K,V&gt; pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node&lt;K,V&gt;(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) { // 红黑树
                        Node&lt;K,V&gt; p;
                        binCount = 2;
                        // 调用红黑树的插值方法插入新节点
                        if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }

            if (binCount != 0) {
                // 判断是否要将链表转换为红黑树，临界值和 HashMap 一样，也是 8
                if (binCount &gt;= TREEIFY_THRESHOLD)
                    // 这个方法和 HashMap 中稍微有一点点不同，那就是它不是一定会进行红黑树转换，
                    // 如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树
                    //    具体源码我们就不看了，扩容部分后面说
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    // 
    addCount(1L, binCount);
    return null;
}
</code></pre>
<p>初始化数组: initTable<br>
这个比较简单，主要就是初始化一个合适大小的数组，然后会设置 sizeCtl。</p>
<p>初始化方法中的并发问题是通过对 sizeCtl 进行一个 CAS 操作来控制的</p>
<pre><code class="language-java">private final Node&lt;K,V&gt;[] initTable() {
    Node&lt;K,V&gt;[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        if ((sc = sizeCtl) &lt; 0)
            Thread.yield(); // lost initialization race; just spin
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            try {
                if ((tab = table) == null || tab.length == 0) {
                    int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings(&quot;unchecked&quot;)
                    Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
                    table = tab = nt;
                    sc = n - (n &gt;&gt;&gt; 2);
                }
            } finally {
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
</code></pre>
<p><strong>链表转红黑树: treeifyBin</strong><br>
treeifyBin 不一定就会进行红黑树转换，也可能是仅仅做数组扩容。</p>
<pre><code class="language-java">private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) {
    Node&lt;K,V&gt; b; int n, sc;
    if (tab != null) {
        // MIN_TREEIFY_CAPACITY 为 64
        // 所以，如果数组长度小于 64 的时候，其实也就是 32 或者 16 或者更小的时候，会进行数组扩容
        if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY)
            // 后面我们再详细分析这个方法
            tryPresize(n &lt;&lt; 1);
        // b 是头节点
        else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) {
            // 加锁
            synchronized (b) {

                if (tabAt(tab, index) == b) {
                    // 下面就是遍历链表，建立一颗红黑树
                    TreeNode&lt;K,V&gt; hd = null, tl = null;
                    for (Node&lt;K,V&gt; e = b; e != null; e = e.next) {
                        TreeNode&lt;K,V&gt; p =
                            new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val,
                                              null, null);
                        if ((p.prev = tl) == null)
                            hd = p;
                        else
                            tl.next = p;
                        tl = p;
                    }
                    // 将红黑树设置到数组相应位置中
                    setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd));
                }
            }
        }
    }
}
</code></pre>
<p><strong>扩容: tryPresize</strong></p>
<pre><code class="language-java"> // 首先要说明的是，方法参数 size 传进来的时候就已经翻了倍了
private final void tryPresize(int size) {
    // c: size 的 1.5 倍，再加 1，再往上取最近的 2 的 n 次方。
    int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY :
        tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1);
    int sc;
    while ((sc = sizeCtl) &gt;= 0) {
        Node&lt;K,V&gt;[] tab = table; int n;

        // 这个 if 分支和之前说的初始化数组的代码基本上是一样的，在这里，我们可以不用管这块代码
        if (tab == null || (n = tab.length) == 0) {
            n = (sc &gt; c) ? sc : c;
            if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
                try {
                    if (table == tab) {
                        @SuppressWarnings(&quot;unchecked&quot;)
                        Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
                        table = nt;
                        sc = n - (n &gt;&gt;&gt; 2); // 0.75 * n
                    }
                } finally {
                    sizeCtl = sc;
                }
            }
        }
        else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY)
            break;
        else if (tab == table) {
            // 我没看懂 rs 的真正含义是什么，不过也关系不大
            int rs = resizeStamp(n);

            if (sc &lt; 0) {
                Node&lt;K,V&gt;[] nt;
                if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                    sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||
                    transferIndex &lt;= 0)
                    break;
                // 2. 用 CAS 将 sizeCtl 加 1，然后执行 transfer 方法
                //    此时 nextTab 不为 null
                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))
                    transfer(tab, nt);
            }
            // 1. 将 sizeCtl 设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)
            //     我是没看懂这个值真正的意义是什么? 不过可以计算出来的是，结果是一个比较大的负数
            //  调用 transfer 方法，此时 nextTab 参数为 null
            else if (U.compareAndSwapInt(this, SIZECTL, sc,
                                         (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2))
                transfer(tab, null);
        }
    }
}
</code></pre>
<p>这个方法的核心在于 sizeCtl 值的操作，首先将其设置为一个负数，然后执行 transfer(tab, null)，再下一个循环将 sizeCtl 加 1，并执行 transfer(tab, nt)，之后可能是继续 sizeCtl 加 1，并执行 transfer(tab, nt)。 所以，可能的操作就是执行 1 次 transfer(tab, null) + 多次 transfer(tab, nt)。</p>
<p><strong>数据迁移: transfer</strong></p>
<p>著作权归https://pdai.tech所有。<br>
链接：https://pdai.tech/md/java/thread/java-thread-x-juc-collection-ConcurrentHashMap.html</p>
<p>原数组长度为 n，所以我们有 n 个迁移任务，让每个线程每次负责一个小任务是最简单的，每做完一个任务再检测是否有其他没做完的任务，帮助迁移就可以了，而这里使用了一个 stride，简单理解就是步长，每个线程每次负责迁移其中的一部分，如每次迁移 16 个小任务。所以，我们就需要一个全局的调度者来安排哪个线程执行哪几个任务，这个就是属性 transferIndex 的作用。</p>
<p>第一个发起数据迁移的线程会将 transferIndex 指向原数组最后的位置，然后从后往前的 stride 个任务属于第一个线程，然后将 transferIndex 指向新的位置，再往前的 stride 个任务属于第二个线程，依此类推。当然，这里说的第二个线程不是真的一定指代了第二个线程，也可以是同一个线程，其实就是将一个大的迁移任务分为了一个个任务包。</p>
<pre><code class="language-java">
private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) {
    int n = tab.length, stride;

    // stride 在单核下直接等于 n，多核模式下为 (n&gt;&gt;&gt;3)/NCPU，最小值是 16
    // stride 可以理解为”步长“，有 n 个位置是需要进行迁移的，
    //   将这 n 个任务分为多个任务包，每个任务包有 stride 个任务
    if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)
        stride = MIN_TRANSFER_STRIDE; // subdivide range

    // 如果 nextTab 为 null，先进行一次初始化
    //    前面我们说了，外围会保证第一个发起迁移的线程调用此方法时，参数 nextTab 为 null
    //       之后参与迁移的线程调用此方法时，nextTab 不会为 null
    if (nextTab == null) {
        try {
            // 容量翻倍
            Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1];
            nextTab = nt;
        } catch (Throwable ex) {      // try to cope with OOME
            sizeCtl = Integer.MAX_VALUE;
            return;
        }
        // nextTable 是 ConcurrentHashMap 中的属性
        nextTable = nextTab;
        // transferIndex 也是 ConcurrentHashMap 的属性，用于控制迁移的位置
        transferIndex = n;
    }

    int nextn = nextTab.length;

    // ForwardingNode 翻译过来就是正在被迁移的 Node
    // 这个构造方法会生成一个Node，key、value 和 next 都为 null，关键是 hash 为 MOVED
    // 后面我们会看到，原数组中位置 i 处的节点完成迁移工作后，
    //    就会将位置 i 处设置为这个 ForwardingNode，用来告诉其他线程该位置已经处理过了
    //    所以它其实相当于是一个标志。
    ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab);


    // advance 指的是做完了一个位置的迁移工作，可以准备做下一个位置的了
    boolean advance = true;
    boolean finishing = false; // to ensure sweep before committing nextTab

    /*
     * 下面这个 for 循环，最难理解的在前面，而要看懂它们，应该先看懂后面的，然后再倒回来看
     * 
     */

    // i 是位置索引，bound 是边界，注意是从后往前
    for (int i = 0, bound = 0;;) {
        Node&lt;K,V&gt; f; int fh;

        // 下面这个 while 真的是不好理解
        // advance 为 true 表示可以进行下一个位置的迁移了
        //   简单理解结局: i 指向了 transferIndex，bound 指向了 transferIndex-stride
        while (advance) {
            int nextIndex, nextBound;
            if (--i &gt;= bound || finishing)
                advance = false;

            // 将 transferIndex 值赋给 nextIndex
            // 这里 transferIndex 一旦小于等于 0，说明原数组的所有位置都有相应的线程去处理了
            else if ((nextIndex = transferIndex) &lt;= 0) {
                i = -1;
                advance = false;
            }
            else if (U.compareAndSwapInt
                     (this, TRANSFERINDEX, nextIndex,
                      nextBound = (nextIndex &gt; stride ?
                                   nextIndex - stride : 0))) {
                // 看括号中的代码，nextBound 是这次迁移任务的边界，注意，是从后往前
                bound = nextBound;
                i = nextIndex - 1;
                advance = false;
            }
        }
        if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) {
            int sc;
            if (finishing) {
                // 所有的迁移操作已经完成
                nextTable = null;
                // 将新的 nextTab 赋值给 table 属性，完成迁移
                table = nextTab;
                // 重新计算 sizeCtl: n 是原数组长度，所以 sizeCtl 得出的值将是新数组长度的 0.75 倍
                sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1);
                return;
            }

            // 之前我们说过，sizeCtl 在迁移前会设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2
            // 然后，每有一个线程参与迁移就会将 sizeCtl 加 1，
            // 这里使用 CAS 操作对 sizeCtl 进行减 1，代表做完了属于自己的任务
            if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
                // 任务结束，方法退出
                if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT)
                    return;

                // 到这里，说明 (sc - 2) == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT，
                // 也就是说，所有的迁移任务都做完了，也就会进入到上面的 if(finishing){} 分支了
                finishing = advance = true;
                i = n; // recheck before commit
            }
        }
        // 如果位置 i 处是空的，没有任何节点，那么放入刚刚初始化的 ForwardingNode ”空节点“
        else if ((f = tabAt(tab, i)) == null)
            advance = casTabAt(tab, i, null, fwd);
        // 该位置处是一个 ForwardingNode，代表该位置已经迁移过了
        else if ((fh = f.hash) == MOVED)
            advance = true; // already processed
        else {
            // 对数组该位置处的结点加锁，开始处理数组该位置处的迁移工作
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    Node&lt;K,V&gt; ln, hn;
                    // 头节点的 hash 大于 0，说明是链表的 Node 节点
                    if (fh &gt;= 0) {
                        // 下面这一块和 Java7 中的 ConcurrentHashMap 迁移是差不多的，
                        // 需要将链表一分为二，
                        //   找到原链表中的 lastRun，然后 lastRun 及其之后的节点是一起进行迁移的
                        //   lastRun 之前的节点需要进行克隆，然后分到两个链表中
                        int runBit = fh &amp; n;
                        Node&lt;K,V&gt; lastRun = f;
                        for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) {
                            int b = p.hash &amp; n;
                            if (b != runBit) {
                                runBit = b;
                                lastRun = p;
                            }
                        }
                        if (runBit == 0) {
                            ln = lastRun;
                            hn = null;
                        }
                        else {
                            hn = lastRun;
                            ln = null;
                        }
                        for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) {
                            int ph = p.hash; K pk = p.key; V pv = p.val;
                            if ((ph &amp; n) == 0)
                                ln = new Node&lt;K,V&gt;(ph, pk, pv, ln);
                            else
                                hn = new Node&lt;K,V&gt;(ph, pk, pv, hn);
                        }
                        // 其中的一个链表放在新数组的位置 i
                        setTabAt(nextTab, i, ln);
                        // 另一个链表放在新数组的位置 i+n
                        setTabAt(nextTab, i + n, hn);
                        // 将原数组该位置处设置为 fwd，代表该位置已经处理完毕，
                        //    其他线程一旦看到该位置的 hash 值为 MOVED，就不会进行迁移了
                        setTabAt(tab, i, fwd);
                        // advance 设置为 true，代表该位置已经迁移完毕
                        advance = true;
                    }
                    else if (f instanceof TreeBin) {
                        // 红黑树的迁移
                        TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;
                        TreeNode&lt;K,V&gt; lo = null, loTail = null;
                        TreeNode&lt;K,V&gt; hi = null, hiTail = null;
                        int lc = 0, hc = 0;
                        for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) {
                            int h = e.hash;
                            TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;
                                (h, e.key, e.val, null, null);
                            if ((h &amp; n) == 0) {
                                if ((p.prev = loTail) == null)
                                    lo = p;
                                else
                                    loTail.next = p;
                                loTail = p;
                                ++lc;
                            }
                            else {
                                if ((p.prev = hiTail) == null)
                                    hi = p;
                                else
                                    hiTail.next = p;
                                hiTail = p;
                                ++hc;
                            }
                        }
                        // 如果一分为二后，节点数小于等于6，那么将红黑树转换回链表
                        ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                            (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t;
                        hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                            (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t;

                        // 将 ln 放置在新数组的位置 i
                        setTabAt(nextTab, i, ln);
                        // 将 hn 放置在新数组的位置 i+n
                        setTabAt(nextTab, i + n, hn);
                        // 将原数组该位置处设置为 fwd，代表该位置已经处理完毕，
                        //    其他线程一旦看到该位置的 hash 值为 MOVED，就不会进行迁移了
                        setTabAt(tab, i, fwd);
                        // advance 设置为 true，代表该位置已经迁移完毕
                        advance = true;
                    }
                }
            }
        }
    }
}
</code></pre>
<p><strong>get 过程分析</strong></p>
<ul>
<li>计算 hash 值</li>
<li>根据 hash 值找到数组对应位置: (n - 1) &amp; h</li>
<li>根据该位置处结点性质进行相应查找<br>
如果该位置为 null，那么直接返回 null 就可以了<br>
如果该位置处的节点刚好就是我们需要的，返回该节点的值即可<br>
如果该位置节点的 hash 值小于 0，说明正在扩容，或者是红黑树<br>
如果以上 3 条都不满足，那就是链表，进行遍历比对即可</li>
</ul>
<h2 id="52-concurrentlinkedqueue">5.2 ConcurrentLinkedQueue</h2>
<p>在并发编程中，有时候需要使用线程安全的队列。如果要实现一个线程安全的队列有两种方式：一种是使用阻塞算法，另一种是使用非阻塞算法。使用阻塞算法的队列可以用一个锁（入队和出队用同一把锁）或两个锁（入队和出队用不同的锁）等方式来实现。非阻塞的实现方式则可以使用循环CAS的方式来实现。</p>
<p>ConcurrentLinkedQueue是一个使用非阻塞算法的基于链接节点的无界线程安全队列，它采用先进先出的规<br>
则对节点进行排序，当我们添加一个元素的时候，它会添加到队列的尾部；当我们获取一个元素时，它会返回队列头部的元素。它采用了“wait-free”算法（即CAS算法）来实现。</p>
<pre><code class="language-java">public class ConcurrentLinkedQueue&lt;E&gt; extends AbstractQueue&lt;E&gt;
        implements Queue&lt;E&gt;, java.io.Serializable {}
</code></pre>
<p>ConcurrentLinkedQueue继承了抽象类AbstractQueue，AbstractQueue定义了对队列的基本操作；同时实现了Queue接口，Queue定义了对队列的基本操作，同时，还实现了Serializable接口，表示可以被序列化。</p>
<p>类的属性如下：</p>
<blockquote>
<p>属性中包含了head域和tail域，表示链表的头节点和尾结点，同时，ConcurrentLinkedQueue也使用了反射机制和CAS机制来更新头节点和尾结点，保证原子性。</p>
</blockquote>
<pre><code class="language-java">public class ConcurrentLinkedQueue&lt;E&gt; extends AbstractQueue&lt;E&gt;
        implements Queue&lt;E&gt;, java.io.Serializable {
    // 版本序列号        
    private static final long serialVersionUID = 196745693267521676L;
    // 反射机制
    private static final sun.misc.Unsafe UNSAFE;
    // head域的偏移量
    private static final long headOffset;
    // tail域的偏移量
    private static final long tailOffset;
    static {
        try {
            UNSAFE = sun.misc.Unsafe.getUnsafe();
            Class&lt;?&gt; k = ConcurrentLinkedQueue.class;
            headOffset = UNSAFE.objectFieldOffset
                (k.getDeclaredField(&quot;head&quot;));
            tailOffset = UNSAFE.objectFieldOffset
                (k.getDeclaredField(&quot;tail&quot;));
        } catch (Exception e) {
            throw new Error(e);
        }
    }
    
    // 头节点
    private transient volatile Node&lt;E&gt; head;
    // 尾结点
    private transient volatile Node&lt;E&gt; tail;
}
</code></pre>
<h3 id="521-concurrentlinkedqueue的结构">5.2.1 ConcurrentLinkedQueue的结构</h3>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1660644979695.png" alt="ConcurrentLinkedQueue的类图" loading="lazy"></figure>
<p>ConcurrentLinkedQueue由head节点和tail节点组成，每个节点（Node）由节点元素（item）和指向下一个节点（next）的引用组成，节点与节点之间就是通过这个next关联起来，从而组成一张链表结构的队列。默认情况下head节点存储的元素为空，tail节点等于head节点。</p>
<pre><code class="language-java">private static class Node&lt;E&gt; {
    // 元素
    volatile E item;
    // next域
    volatile Node&lt;E&gt; next;

    /**
        * Constructs a new node.  Uses relaxed write because item can
        * only be seen after publication via casNext.
        */
    // 构造函数
    Node(E item) {
        // 设置item的值
        UNSAFE.putObject(this, itemOffset, item);
    }
    // 比较并替换item值
    boolean casItem(E cmp, E val) {
        return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val);
    }
    
    void lazySetNext(Node&lt;E&gt; val) {
        // 设置next域的值，并不会保证修改对其他线程立即可见
        UNSAFE.putOrderedObject(this, nextOffset, val);
    }
    // 比较并替换next域的值
    boolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) {
        return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val);
    }

    // Unsafe mechanics
    // 反射机制
    private static final sun.misc.Unsafe UNSAFE;
    // item域的偏移量
    private static final long itemOffset;
    // next域的偏移量
    private static final long nextOffset;

    static {
        try {
            UNSAFE = sun.misc.Unsafe.getUnsafe();
            Class&lt;?&gt; k = Node.class;
            itemOffset = UNSAFE.objectFieldOffset
                (k.getDeclaredField(&quot;item&quot;));
            nextOffset = UNSAFE.objectFieldOffset
                (k.getDeclaredField(&quot;next&quot;));
        } catch (Exception e) {
            throw new Error(e);
        }
    }
}
</code></pre>
<h3 id="522-入队列">5.2.2 入队列</h3>
<h5 id="1入队列的过程">1.入队列的过程</h5>
<p>入队列就是将入队节点添加到队列的尾部。</p>
<p>入队主要做两件事情：第一是将入队节点设置成当前队列尾节点的下一个节点；第二是更新tail节点，如果tail节点的next节点不为空，则将入队节点设置成tail节点，<strong>如果tail节点的next节点为空，则将入队节点设置成tail的next节点，所以tail节点不总是尾节点。</strong></p>
<p>多个线程同时进行入队的情况就变得更加复杂了，因为可能会出现其他线程插队的情况。如果有一个线程正在<br>
入队，那么它必须先获取尾节点，然后设置尾节点的下一个节点为入队节点，但这时可能有另外一个线程插队了，那么队列的尾节点就会发生变化，这时当前线程要暂停入队操作，然后重新获取尾节点。</p>
<blockquote>
<p>offer接口</p>
</blockquote>
<pre><code class="language-java">public boolean offer(E e) {
    // 元素不为null
    checkNotNull(e);
    // 新生一个结点
    final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e);

    for (Node&lt;E&gt; t = tail, p = t;;) { // 无限循环
        // q为p结点的下一个结点
        Node&lt;E&gt; q = p.next;
        if (q == null) { // q结点为null
            // p is last node
            if (p.casNext(null, newNode)) { // 比较并进行替换p结点的next域
                // Successful CAS is the linearization point
                // for e to become an element of this queue,
                // and for newNode to become &quot;live&quot;.
                if (p != t) // p不等于t结点，不一致    // hop two nodes at a time
                    // 比较并替换尾结点
                    casTail(t, newNode);  // Failure is OK.
                // 返回
                return true;
            }
            // Lost CAS race to another thread; re-read next
        }
        else if (p == q) // p结点等于q结点
            // We have fallen off list.  If tail is unchanged, it
            // will also be off-list, in which case we need to
            // jump to head, from which all live nodes are always
            // reachable.  Else the new tail is a better bet.
            // 原来的尾结点与现在的尾结点是否相等，若相等，则p赋值为head，否则，赋值为现在的尾结点
            p = (t != (t = tail)) ? t : head;
        else
            // Check for tail updates after two hops.
            // 重新赋值p结点
            p = (p != t &amp;&amp; t != (t = tail)) ? t : q;
    }
}
</code></pre>
<p>整个入队过程主要做两件事情：第一是定位出尾节点；第二是使用CAS算法将入队节点设置成尾节点的next节点，如不成功则重试。</p>
<h3 id="523-出队列">5.2.3 出队列</h3>
<p>出队列的就是从队列里返回一个节点元素，并清空该节点对元素的引用。</p>
<p>并不是每次出队时都更新head节点，当head节点里有元素时，直接弹出head节点里的元素，而不会更新head节点。只有当head节点里没有元素时，出队操作才会更新head节点。这种做法也是通过<strong>hops变量</strong>来减少使用CAS更新head节点的消耗，从而提高出队效率。</p>
<pre><code class="language-java">public E poll() {
    restartFromHead:
    for (;;) { // 无限循环
        for (Node&lt;E&gt; h = head, p = h, q;;) { // 保存头节点
            // item项
            E item = p.item;

            if (item != null &amp;&amp; p.casItem(item, null)) { // item不为null并且比较并替换item成功
                // Successful CAS is the linearization point
                // for item to be removed from this queue.
                if (p != h) // p不等于h    // hop two nodes at a time
                    // 更新头节点
                    updateHead(h, ((q = p.next) != null) ? q : p); 
                // 返回item
                return item;
            }
            else if ((q = p.next) == null) { // q结点为null
                // 更新头节点
                updateHead(h, p);
                return null;
            }
            else if (p == q) // p等于q
                // 继续循环
                continue restartFromHead;
            else
                // p赋值为q
                p = q;
        }
    }
}
</code></pre>
<p>首先获取头节点的元素，然后判断头节点元素是否为空，如果为空，表示另外一个线程已经进行了一次出队操作将该节点的元素取走，如果不为空，则使用CAS的方式将头节点的引用设置成null，如果CAS成功，则直接返回头节点的元素，如果不成功，表示另外一个线程已经进行了一次出队操作更新了head节点，导致元素发生了变化，需要重新获取头节点。</p>
<h3 id="524-remove">5.2.4 remove</h3>
<pre><code class="language-java">public boolean remove(Object o) {
    // 元素为null，返回
    if (o == null) return false;
    Node&lt;E&gt; pred = null;
    for (Node&lt;E&gt; p = first(); p != null; p = succ(p)) { // 获取第一个存活的结点
        // 第一个存活结点的item值
        E item = p.item;
        if (item != null &amp;&amp;
            o.equals(item) &amp;&amp;
            p.casItem(item, null)) { // 找到item相等的结点，并且将该结点的item设置为null
            // p的后继结点
            Node&lt;E&gt; next = succ(p);
            if (pred != null &amp;&amp; next != null) // pred不为null并且next不为null
                // 比较并替换next域
                pred.casNext(p, next);
            return true;
        }
        // pred赋值为p
        pred = p;
    }
    return false;
}
</code></pre>
<h3 id="525-hops延迟更新的策略的设计">5.2.5 HOPS(延迟更新的策略)的设计</h3>
<p>通过上面对offer和poll方法的分析，我们发现tail和head是延迟更新的，两者更新触发时机为：</p>
<p><strong>tail更新触发时机</strong>：当tail指向的节点的下一个节点不为null的时候，会执行定位队列真正的队尾节点的操作，找到队尾节点后完成插入之后才会通过casTail进行tail更新；当tail指向的节点的下一个节点为null的时候，只插入节点不更新tail。</p>
<p><strong>head更新触发时机</strong>：当head指向的节点的item域为null的时候，会执行定位队列真正的队头节点的操作，找到队头节点后完成删除之后才会通过updateHead进行head更新；当head指向的节点的item域不为null的时候，只删除节点不更新head。</p>
<p>如果让tail永远作为队列的队尾节点，实现的代码量会更少，而且逻辑更易懂。但是，这样做有一个缺点，如果大量的入队操作，每次都要执行CAS进行tail的更新，汇总起来对性能也会是大大的损耗。如果能减少CAS更新的操作，无疑可以大大提升入队的操作效率，所以每间隔1次(tail和队尾节点的距离为1)进行才利用CAS更新tail。对head的更新也是同样的道理，虽然，这样设计会多出在循环中定位队尾节点，但总体来说读的操作效率要远远高于写的性能，因此，多出来的在循环中定位尾节点的操作的性能损耗相对而言是很小的。</p>
<h2 id="53-java中的阻塞队列">5.3 Java中的阻塞队列</h2>
<h3 id="531-什么是阻塞队列">5.3.1 什么是阻塞队列</h3>
<p>阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作支持阻塞的插入和移除方法。</p>
<pre><code>1）支持阻塞的插入方法：意思是当队列满时，队列会阻塞插入元素的线程，直到队列不满。
2）支持阻塞的移除方法：意思是在队列为空时，获取元素的线程会等待队列变为非空
</code></pre>
<p>阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器。</p>
<p>在阻塞队列不可用时，这两个附加操作提供了4种处理方式，如下所示：</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1660707761776.png" alt="插入和移除操作的4中处理方式" loading="lazy"></figure>
<ol>
<li>抛出异常：当队列满时，如果再往队列里插入元素，会抛出IllegalStateException（&quot;Queue full&quot;）异常。当队列空时，从队列里获取元素会抛出NoSuchElementException异常。</li>
<li>返回特殊值：当往队列插入元素时，会返回元素是否插入成功，成功返回true。如果是移除方法，则是从队列里取出一个元素，如果没有则返回null。</li>
<li>一直阻塞：当阻塞队列满时，如果生产者线程往队列里put元素，队列会一直阻塞生产者线程，直到队列可用或者响应中断退出。当队列空时，如果消费者线程从队列里take元素，队列会阻塞住消费者线程，直到队列不为空。</li>
<li>超时退出：当阻塞队列满时，如果生产者线程往队列里插入元素，队列会阻塞生产者线程一段时间，如果超过了指定的时间，生产者线程就会退出。</li>
</ol>
<p><em><strong>注意 如果是无界阻塞队列，队列不可能会出现满的情况，所以使用put或offer方法永远不会被阻塞，而且使用offer方法时，该方法永远返回true。</strong></em></p>
<h3 id="532-java里的阻塞队列">5.3.2 Java里的阻塞队列</h3>
<ol>
<li>ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列。</li>
<li>LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列。</li>
<li>PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。</li>
<li>DelayQueue：一个使用优先级队列实现的无界阻塞队列。</li>
<li>SynchronousQueue：一个不存储元素的阻塞队列。</li>
<li>LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。</li>
<li>LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。</li>
</ol>
<h3 id="533-阻塞队列的实现原理">5.3.3 阻塞队列的实现原理</h3>
<p>如果队列是空的，消费者会一直等待，当生产者添加元素时，消费者是如何知道当前队列有元素的呢？</p>
<p>使用通知模式实现。所谓通知模式，就是当生产者往满的队列里添加元素时会阻塞住生产者，当消费者消费了一个队列中的元素后，会通知生产者当前队列可用。</p>
<blockquote>
<p>ArrayBlockingQueue</p>
</blockquote>
<pre><code class="language-java"> public ArrayBlockingQueue(int capacity, boolean fair) {
    if (capacity &lt;= 0)
        throw new IllegalArgumentException();
    this.items = new Object[capacity];
    lock = new ReentrantLock(fair);
    notEmpty = lock.newCondition();
    notFull =  lock.newCondition();
}

public void put(E e) throws InterruptedException {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == items.length)
            notFull.await();
        enqueue(e);
    } finally {
        lock.unlock();
    }
}

public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == 0)
            notEmpty.await();
        return dequeue();
    } finally {
        lock.unlock();
    }
}

private void enqueue(E x) {
    // assert lock.getHoldCount() == 1;
    // assert items[putIndex] == null;
    final Object[] items = this.items;
    items[putIndex] = x;
    if (++putIndex == items.length)
        putIndex = 0;
    count++;
    notEmpty.signal();
}
</code></pre>
<p>当往队列里插入一个元素时，如果队列不可用，那么阻塞生产者主要通过LockSupport.park（this）来实现。</p>
<blockquote>
<p>awiat()</p>
</blockquote>
<pre><code class="language-java"> public final void await() throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    Node node = addConditionWaiter();
    int savedState = fullyRelease(node);
    int interruptMode = 0;
    while (!isOnSyncQueue(node)) {
        LockSupport.park(this);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null) // clean up if cancelled
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
}
</code></pre>
<p>继续进入源码，发现调用setBlocker先保存一下将要阻塞的线程，然后调用unsafe.park阻塞当前线程。</p>
<blockquote>
<p>park</p>
</blockquote>
<pre><code class="language-java"> public static void park(Object blocker) {
    Thread t = Thread.currentThread();
    setBlocker(t, blocker);
    UNSAFE.park(false, 0L);
    setBlocker(t, null);
}
</code></pre>
<p>park这个方法会阻塞当前线程，只有以下4种情况中的一种发生时，该方法才会返回。</p>
<ol>
<li>与park对应的unpark执行或已经执行时。“已经执行”是指unpark先执行，然后再执行park的情况。</li>
<li>线程被中断时。</li>
<li>等待完time参数指定的毫秒数时。</li>
<li>异常现象发生时，这个异常现象没有任何原因。</li>
</ol>
<h2 id="54-forkjoin框架">5.4 Fork/Join框架</h2>
<h3 id="541-什么是forkjoin框架">5.4.1 什么是Fork/Join框架</h3>
<p>Fork/Join框架是Java 7提供的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。</p>
<p>Fork就是把一个大任务切分为若干子任务并行的执行，Join就是合并这些子任务的执行结果，最后得到这个大任务的结果。比如计算1+2+…+10000，可以分割成10个子任务，每个子任务分别对1000个数进行求和，最终汇总这10个子任务的结果。Fork/Join的运行流程如下：</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1660805395353.png" alt="Fork Join的运行流程图" loading="lazy"></figure>
<h3 id="542-工作窃取算法">5.4.2 工作窃取算法</h3>
<p>工作窃取（work-stealing）算法是指某个线程从其他队列里窃取任务来执行。那么，为什么需要使用工作窃取算法呢？</p>
<p>假如我们需要做一个比较大的任务，可以把这个任务分割为若干互不依赖的子任务，为了减少线程间的竞争，把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应。比如A线程负责处理A队列里的任务。但是，有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务等待处理。干完活的线程与其等着，不如去帮其他线程干活，于是它就去其他线程的队列<br>
里窃取一个任务来执行。而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。</p>
<p><strong>工作窃取算法的优点</strong>：充分利用线程进行并行计算，减少了线程间的竞争。<br>
<strong>工作窃取算法的缺点</strong>：在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且该算法会消耗了更多的系统资源，比如创建多个线程和多个双端队列。</p>
<h3 id="543-forkjoin框架的设计">5.4.3 Fork/Join框架的设计</h3>
<p>步骤1 分割任务。首先我们需要有一个fork类来把大任务分割成子任务，有可能子任务还是很大，所以还需要不停地分割，直到分割出的子任务足够小。</p>
<p>步骤2 执行任务并合并结果。分割的子任务分别放在双端队列里，然后几个启动线程分别从双端队列里获取任务执行。子任务执行完的结果都统一放在一个队列里，启动一个线程从队列里拿数据，然后合并这些数据。</p>
<p>Fork/Join使用两个类来完成以上两件事情。<br>
①ForkJoinTask：我们要使用ForkJoin框架，必须首先创建一个ForkJoin任务。它提供在任务中执行fork()和join()操作的机制。通常情况下，我们不需要直接继承ForkJoinTask类，只需要继承它的子类，Fork/Join框架提供了以下两个子类。</p>
<pre><code>RecursiveAction：用于没有返回结果的任务。
RecursiveTask：用于有返回结果的任务。
</code></pre>
<p>②ForkJoinPool：ForkJoinTask需要通过ForkJoinPool来执行。</p>
<p>任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列的头部。当一个工作线程的队列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务。</p>
<h3 id="544-使用forkjoin框架">5.4.4 使用Fork/Join框架</h3>
<p>让我们通过一个简单的需求来使用Fork/Join框架，需求是：计算1+2+3+4的结果。</p>
<p>使用Fork/Join框架首先要考虑到的是如何分割任务，如果希望每个子任务最多执行两个数的相加，那么我们设置分割的阈值是2，由于是4个数字相加，所以Fork/Join框架会把这个任务fork成两个子任务，子任务一负责计算1+2，子任务二负责计算3+4，然后再join两个子任务的结果。因为是有结果的任务，所以必须继承RecursiveTask，实现代码如下。</p>
<blockquote>
<p>计算1+2+3+4</p>
</blockquote>
<pre><code class="language-java">package cm.forkjoin;

import java.util.concurrent.ExecutionException;
import java.util.concurrent.ForkJoinPool;
import java.util.concurrent.Future;
import java.util.concurrent.RecursiveTask;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/18 15:01
 */
public class TestForkJoin extends RecursiveTask&lt;Integer&gt; {
    private static final int THRESHOLD = 2; // 阈值

    private int start;
    private int end;
    public TestForkJoin(int start, int end) {
        this.start = start;
        this.end = end;
    }

    @Override
    protected Integer compute() {
        int sum = 0;
        // 如果任务足够小就计算任务
        boolean canCompute = (end - start) &lt;= THRESHOLD;

        if (canCompute) {
            System.out.println(&quot;计算&quot; + start + &quot;-&quot; + end);
            for (int i = start; i &lt;= end; i++) {
                sum += i;
            }
        }else {
            // 如果任务大于阈值，就分裂成两个子任务计算
            System.out.println(&quot;拆分&quot; + start + &quot;-&quot; + end);
            int middle = (start + end) / 2;
            TestForkJoin leftTask = new TestForkJoin(start, middle);
            TestForkJoin rightTask = new TestForkJoin(middle + 1, end);
            // 执行子任务
            leftTask.fork();
            rightTask.fork();
            // 等待子任务执行完，并得到其结果
            int leftResult = leftTask.join();
            int rightResult = rightTask.join();
            // 合并子任务
            sum = leftResult + rightResult;
        }
        return sum;
    }

    public static void main(String[] args) {
        ForkJoinPool forkJoinPool = new ForkJoinPool();
        // 生成一个计算任务，负责计算1+2+3+4
        TestForkJoin task = new TestForkJoin(1, 4);
        // 执行一个任务
        Future&lt;Integer&gt; result = forkJoinPool.submit(task);
        try {
            System.out.println(result.get());
        } catch (InterruptedException e) {
        } catch (ExecutionException e) {
        }
    }
}
</code></pre>
<p>ForkJoinTask与一般任务的主要区别在于它需要实现compute方法，在这个方法里，首先需要判断任务是否足够小，如果足够小就直接执行任务。如果不足够小，就必须分割成两个子任务，每个子任务在调用fork方法时，又会进入compute方法，看看当前子任务是否需要继续分割成子任务，如果不需要继续分割，则执行当<br>
前子任务并返回结果。使用join方法会等待子任务执行完并得到其结果。</p>
<h3 id="545-forkjoin框架的异常处理">5.4.5 Fork/Join框架的异常处理</h3>
<p>ForkJoinTask在执行的时候可能会抛出异常，但是我们没办法在主线程里直接捕获异常，所以ForkJoinTask提供了isCompletedAbnormally()方法来检查任务是否已经抛出异常或已经被取消了，并且可以通过ForkJoinTask的getException方法获取异常。</p>
<pre><code class="language-java"> if(this.isCompletedAbnormally())
    {
        System.out.println(this.getException());
    }
</code></pre>
<h3 id="546-forkjoin框架的实现原理">5.4.6 Fork/Join框架的实现原理</h3>
<p>ForkJoinPool由ForkJoinTask数组和ForkJoinWorkerThread数组组成，ForkJoinTask数组负责将存放程序提交给ForkJoinPool的任务，而ForkJoinWorkerThread数组负责执行这些任务。</p>
<h5 id="1forkjointask的fork方法实现原理">（1）ForkJoinTask的fork方法实现原理</h5>
<p>当我们调用ForkJoinTask的fork方法时，程序会调用ForkJoinWorkerThread的push方法异步地执行这个任务，然后立即返回结果。代码如下。</p>
<blockquote>
<p>fork()</p>
</blockquote>
<pre><code class="language-java"> public final ForkJoinTask&lt;V&gt; fork() {
    Thread t;
    if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread)
        ((ForkJoinWorkerThread)t).workQueue.push(this);
    else
        ForkJoinPool.common.externalPush(this);
    return this;
}
</code></pre>
<p>push方法把当前任务存放在ForkJoinTask数组队列里。然后再调用ForkJoinPool的signalWork()方法唤醒或创建一个工作线程来执行任务。代码如下。</p>
<blockquote>
<p>push()</p>
</blockquote>
<pre><code class="language-java"> final void push(ForkJoinTask&lt;?&gt; task) {
            ForkJoinTask&lt;?&gt;[] a; ForkJoinPool p;
            int b = base, s = top, n;
            if ((a = array) != null) {    // ignore if queue removed
                int m = a.length - 1;     // fenced write for task visibility
                U.putOrderedObject(a, ((m &amp; s) &lt;&lt; ASHIFT) + ABASE, task);
                U.putOrderedInt(this, QTOP, s + 1);
                if ((n = s - b) &lt;= 1) {
                    if ((p = pool) != null)
                        p.signalWork(p.workQueues, this);
                }
                else if (n &gt;= m)
                    growArray();
            }
        }
</code></pre>
<h5 id="2forkjointask的join方法实现原理">（2）ForkJoinTask的join方法实现原理</h5>
<p>Join方法的主要作用是阻塞当前线程并等待获取结果，代码如下。</p>
<blockquote>
<p>join()</p>
</blockquote>
<pre><code class="language-java">  public final V join() {
    int s;
    if ((s = doJoin() &amp; DONE_MASK) != NORMAL)
        reportException(s);
    return getRawResult();
}
</code></pre>
<p>首先，它调用了doJoin()方法，通过doJoin()方法得到当前任务的状态来判断返回什么结果，任务状态有4种：已完成（NORMAL）、被取消（CANCELLED）、信号（SIGNAL）和出现异常（EXCEPTIONAL）。</p>
<pre><code>- 如果任务状态是已完成，则直接返回任务结果。
- 如果任务状态是被取消，则直接抛出CancellationException。
- 如果任务状态是抛出异常，则直接抛出对应的异常。
</code></pre>
<blockquote>
<p>doJoin()</p>
</blockquote>
<pre><code class="language-java">  private int doJoin() {
    int s; Thread t; ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue w;
    return (s = status) &lt; 0 ? s :
        ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ?
        (w = (wt = (ForkJoinWorkerThread)t).workQueue).
        tryUnpush(this) &amp;&amp; (s = doExec()) &lt; 0 ? s :
        wt.pool.awaitJoin(w, this, 0L) :
        externalAwaitDone();
}
</code></pre>
<p>在doJoin()方法里，首先通过查看任务的状态，看任务是否已经执行完成，如果执行完成，则直接返回任务状态；如果没有执行完，则从任务数组里取出任务并执行。如果任务顺利执行完成，则设置任务状态为NORMAL，如果出现异常，则记录异常，并将任务状态设置为EXCEPTIONAL。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Netty (一)]]></title>
        <id>https://q456qq520.github.io/post/netty-yi/</id>
        <link href="https://q456qq520.github.io/post/netty-yi/">
        </link>
        <updated>2022-08-14T14:29:06.000Z</updated>
        <content type="html"><![CDATA[<h1 id="一-nio-基础">一. NIO 基础</h1>
<p>non-blocking io 非阻塞 IO</p>
<h2 id="1-三大组件">1. 三大组件</h2>
<h3 id="11-channel-buffer">1.1 Channel &amp; Buffer</h3>
<p>channel 有一点类似于 stream，它就是读写数据的<strong>双向通道</strong>，可以从 channel 将数据读入buffer，也可以将 buffer 的数据写入 channel，而之前的 stream 要么是输入，要么是输出，channel 比stream 更为底层</p>
<p>常见的 Channel 有</p>
<ul>
<li>FileChannel</li>
<li>DatagramChannel （udp）</li>
<li>SocketChannel （tcp）</li>
<li>ServerSocketChannel （tcp）</li>
</ul>
<p>buffer 则用来缓冲读写数据，常见的 buffer 有</p>
<ul>
<li>ByteBuffer
<ul>
<li>MappedByteBuffer</li>
<li>DirectByteBuffer</li>
<li>HeapByteBuffer</li>
</ul>
</li>
<li>ShortBuffer</li>
<li>IntBuffer</li>
<li>LongBuffer</li>
<li>FloatBuffer</li>
<li>DoubleBuffer</li>
<li>CharBuffer</li>
</ul>
<h3 id="12-selector">1.2 Selector</h3>
<p>selector 单从字面意思不好理解，需要结合服务器的设计演化来理解它的用途</p>
<h4 id="多线程版设计">多线程版设计</h4>
<p>一个线程对应一个socket，这样设计会有如下缺点</p>
<h4 id="️-多线程版缺点">⚠️ 多线程版缺点</h4>
<ul>
<li>内存占用高</li>
<li>线程上下文切换成本高</li>
<li>只适合连接数少的场景</li>
</ul>
<h4 id="线程池版设计">线程池版设计</h4>
<p>一个线程对应多个socket。</p>
<h4 id="️-线程池版缺点">⚠️ 线程池版缺点</h4>
<ul>
<li>阻塞模式下，线程仅能处理一个 socket 连接</li>
<li>仅适合短连接场景</li>
</ul>
<h4 id="selector-版设计">selector 版设计</h4>
<p>selector 的作用就是配合一个线程来管理多个 channel，获取这些 channel 上发生的事件，这些 channel 工作在非阻塞模式下，不会让线程吊死在一个 channel 上。适合连接数特别多，但流量低的场景（low traffic）</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1660489074106.png" alt="selector 版设计" loading="lazy"></figure>
<p>调用 selector 的 select() 会阻塞直到 channel 发生了读写就绪事件，这些事件发生，select 方法就会返回这些事件交给 thread 来处理</p>
<h2 id="2-bytebuffer">2. ByteBuffer</h2>
<p>有一普通文本文件 data.txt，内容为</p>
<pre><code>1234567890abcd
</code></pre>
<p>使用 FileChannel 来读取文件内容</p>
<pre><code class="language-java">@Slf4j
public class ChannelDemo1 {
    public static void main(String[] args) {
        try (RandomAccessFile file = new RandomAccessFile(&quot;helloword/data.txt&quot;, &quot;rw&quot;)) {
            FileChannel channel = file.getChannel();
            ByteBuffer buffer = ByteBuffer.allocate(10);
            do {
                // 向 buffer 写入
                int len = channel.read(buffer);
                log.debug(&quot;读到字节数：{}&quot;, len);
                if (len == -1) {
                    break;
                }
                // 切换 buffer 读模式
                buffer.flip();
                while(buffer.hasRemaining()) {
                    log.debug(&quot;{}&quot;, (char)buffer.get());
                }
                // 切换 buffer 写模式
                buffer.clear();
            } while (true);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<h3 id="21-bytebuffer-正确使用姿势">2.1  ByteBuffer 正确使用姿势</h3>
<ol>
<li>向 buffer 写入数据，例如调用 channel.read(buffer)</li>
<li>调用 flip() 切换至<strong>读模式</strong></li>
<li>从 buffer 读取数据，例如调用 buffer.get()</li>
<li>调用 clear() 或 compact() 切换至<strong>写模式</strong></li>
<li>重复 1~4 步骤</li>
</ol>
<h3 id="22-bytebuffer-结构">2.2 ByteBuffer 结构</h3>
<p>ByteBuffer 有以下重要属性</p>
<ul>
<li>capacity（容量）</li>
<li>position（位置）</li>
<li>limit</li>
</ul>
<p>一开始</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1660492137807.png" alt="" loading="lazy"></figure>
<p>写模式下，position 是写入位置，limit 等于容量，下图表示写入了 4 个字节后的状态<br>
<img src="https://q456qq520.github.io/post-images/1660492145738.png" alt="" loading="lazy"></p>
<p>flip 动作发生后，position 切换为读取位置，limit 切换为读取限制<br>
<img src="https://q456qq520.github.io/post-images/1660492152484.png" alt="" loading="lazy"></p>
<p>读取 4 个字节后，状态</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1660492162158.png" alt="" loading="lazy"></figure>
<p>clear 动作发生后，<br>
<img src="https://q456qq520.github.io/post-images/1660492170703.png" alt="" loading="lazy"></p>
<p>compact 方法，是把未读完的部分向前压缩，然后切换至写模式<br>
<img src="https://q456qq520.github.io/post-images/1660492179063.png" alt="" loading="lazy"></p>
<h4 id="调试工具类">💡 调试工具类</h4>
<pre><code class="language-java">public class ByteBufferUtil {
    private static final char[] BYTE2CHAR = new char[256];
    private static final char[] HEXDUMP_TABLE = new char[256 * 4];
    private static final String[] HEXPADDING = new String[16];
    private static final String[] HEXDUMP_ROWPREFIXES = new String[65536 &gt;&gt;&gt; 4];
    private static final String[] BYTE2HEX = new String[256];
    private static final String[] BYTEPADDING = new String[16];

    static {
        final char[] DIGITS = &quot;0123456789abcdef&quot;.toCharArray();
        for (int i = 0; i &lt; 256; i++) {
            HEXDUMP_TABLE[i &lt;&lt; 1] = DIGITS[i &gt;&gt;&gt; 4 &amp; 0x0F];
            HEXDUMP_TABLE[(i &lt;&lt; 1) + 1] = DIGITS[i &amp; 0x0F];
        }

        int i;

        // Generate the lookup table for hex dump paddings
        for (i = 0; i &lt; HEXPADDING.length; i++) {
            int padding = HEXPADDING.length - i;
            StringBuilder buf = new StringBuilder(padding * 3);
            for (int j = 0; j &lt; padding; j++) {
                buf.append(&quot;   &quot;);
            }
            HEXPADDING[i] = buf.toString();
        }

        // Generate the lookup table for the start-offset header in each row (up to 64KiB).
        for (i = 0; i &lt; HEXDUMP_ROWPREFIXES.length; i++) {
            StringBuilder buf = new StringBuilder(12);
            buf.append(NEWLINE);
            buf.append(Long.toHexString(i &lt;&lt; 4 &amp; 0xFFFFFFFFL | 0x100000000L));
            buf.setCharAt(buf.length() - 9, '|');
            buf.append('|');
            HEXDUMP_ROWPREFIXES[i] = buf.toString();
        }

        // Generate the lookup table for byte-to-hex-dump conversion
        for (i = 0; i &lt; BYTE2HEX.length; i++) {
            BYTE2HEX[i] = ' ' + StringUtil.byteToHexStringPadded(i);
        }

        // Generate the lookup table for byte dump paddings
        for (i = 0; i &lt; BYTEPADDING.length; i++) {
            int padding = BYTEPADDING.length - i;
            StringBuilder buf = new StringBuilder(padding);
            for (int j = 0; j &lt; padding; j++) {
                buf.append(' ');
            }
            BYTEPADDING[i] = buf.toString();
        }

        // Generate the lookup table for byte-to-char conversion
        for (i = 0; i &lt; BYTE2CHAR.length; i++) {
            if (i &lt;= 0x1f || i &gt;= 0x7f) {
                BYTE2CHAR[i] = '.';
            } else {
                BYTE2CHAR[i] = (char) i;
            }
        }
    }

    /**
     * 打印所有内容
     * @param buffer
     */
    public static void debugAll(ByteBuffer buffer) {
        int oldlimit = buffer.limit();
        buffer.limit(buffer.capacity());
        StringBuilder origin = new StringBuilder(256);
        appendPrettyHexDump(origin, buffer, 0, buffer.capacity());
        System.out.println(&quot;+--------+-------------------- all ------------------------+----------------+&quot;);
        System.out.printf(&quot;position: [%d], limit: [%d]\n&quot;, buffer.position(), oldlimit);
        System.out.println(origin);
        buffer.limit(oldlimit);
    }

    /**
     * 打印可读取内容
     * @param buffer
     */
    public static void debugRead(ByteBuffer buffer) {
        StringBuilder builder = new StringBuilder(256);
        appendPrettyHexDump(builder, buffer, buffer.position(), buffer.limit() - buffer.position());
        System.out.println(&quot;+--------+-------------------- read -----------------------+----------------+&quot;);
        System.out.printf(&quot;position: [%d], limit: [%d]\n&quot;, buffer.position(), buffer.limit());
        System.out.println(builder);
    }

    private static void appendPrettyHexDump(StringBuilder dump, ByteBuffer buf, int offset, int length) {
        if (isOutOfBounds(offset, length, buf.capacity())) {
            throw new IndexOutOfBoundsException(
                    &quot;expected: &quot; + &quot;0 &lt;= offset(&quot; + offset + &quot;) &lt;= offset + length(&quot; + length
                            + &quot;) &lt;= &quot; + &quot;buf.capacity(&quot; + buf.capacity() + ')');
        }
        if (length == 0) {
            return;
        }
        dump.append(
                &quot;         +-------------------------------------------------+&quot; +
                        NEWLINE + &quot;         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |&quot; +
                        NEWLINE + &quot;+--------+-------------------------------------------------+----------------+&quot;);

        final int startIndex = offset;
        final int fullRows = length &gt;&gt;&gt; 4;
        final int remainder = length &amp; 0xF;

        // Dump the rows which have 16 bytes.
        for (int row = 0; row &lt; fullRows; row++) {
            int rowStartIndex = (row &lt;&lt; 4) + startIndex;

            // Per-row prefix.
            appendHexDumpRowPrefix(dump, row, rowStartIndex);

            // Hex dump
            int rowEndIndex = rowStartIndex + 16;
            for (int j = rowStartIndex; j &lt; rowEndIndex; j++) {
                dump.append(BYTE2HEX[getUnsignedByte(buf, j)]);
            }
            dump.append(&quot; |&quot;);

            // ASCII dump
            for (int j = rowStartIndex; j &lt; rowEndIndex; j++) {
                dump.append(BYTE2CHAR[getUnsignedByte(buf, j)]);
            }
            dump.append('|');
        }

        // Dump the last row which has less than 16 bytes.
        if (remainder != 0) {
            int rowStartIndex = (fullRows &lt;&lt; 4) + startIndex;
            appendHexDumpRowPrefix(dump, fullRows, rowStartIndex);

            // Hex dump
            int rowEndIndex = rowStartIndex + remainder;
            for (int j = rowStartIndex; j &lt; rowEndIndex; j++) {
                dump.append(BYTE2HEX[getUnsignedByte(buf, j)]);
            }
            dump.append(HEXPADDING[remainder]);
            dump.append(&quot; |&quot;);

            // Ascii dump
            for (int j = rowStartIndex; j &lt; rowEndIndex; j++) {
                dump.append(BYTE2CHAR[getUnsignedByte(buf, j)]);
            }
            dump.append(BYTEPADDING[remainder]);
            dump.append('|');
        }

        dump.append(NEWLINE +
                &quot;+--------+-------------------------------------------------+----------------+&quot;);
    }

    private static void appendHexDumpRowPrefix(StringBuilder dump, int row, int rowStartIndex) {
        if (row &lt; HEXDUMP_ROWPREFIXES.length) {
            dump.append(HEXDUMP_ROWPREFIXES[row]);
        } else {
            dump.append(NEWLINE);
            dump.append(Long.toHexString(rowStartIndex &amp; 0xFFFFFFFFL | 0x100000000L));
            dump.setCharAt(dump.length() - 9, '|');
            dump.append('|');
        }
    }

    public static short getUnsignedByte(ByteBuffer buffer, int index) {
        return (short) (buffer.get(index) &amp; 0xFF);
    }
}
</code></pre>
<h3 id="23-bytebuffer-常见方法">2.3 ByteBuffer 常见方法</h3>
<h4 id="分配空间">分配空间</h4>
<p>可以使用 allocate 方法为 ByteBuffer 分配空间，其它 buffer 类也有该方法</p>
<pre><code class="language-java"> //HeapByteBuffer 堆内存
//读写效率低，受gc影响
System.out.println(ByteBuffer.allocate(16).getClass());

//DirectByteBuffer 直接内存
//读写效率高，少一次拷贝，分配效率低
System.out.println(ByteBuffer.allocateDirect(16).getClass());
</code></pre>
<h4 id="向-buffer-写入数据">向 buffer 写入数据</h4>
<p>有两种办法</p>
<ul>
<li>调用 channel 的 read 方法</li>
<li>调用 buffer 自己的 put 方法</li>
</ul>
<pre><code class="language-java">int readBytes = channel.read(buf);
</code></pre>
<p>和</p>
<pre><code class="language-java">buf.put((byte)127);
</code></pre>
<h4 id="从-buffer-读取数据">从 buffer 读取数据</h4>
<p>同样有两种办法</p>
<ul>
<li>调用 channel 的 write 方法</li>
<li>调用 buffer 自己的 get 方法</li>
</ul>
<pre><code class="language-java">int writeBytes = channel.write(buf);
</code></pre>
<p>和</p>
<pre><code class="language-java">byte b = buf.get();
</code></pre>
<p>get 方法会让 position 读指针向后走，如果想重复读取数据</p>
<ul>
<li>可以调用 rewind 方法将 position 重新置为 0</li>
<li>或者调用 get(int i) 方法获取索引 i 的内容，它不会移动读指针</li>
</ul>
<h4 id="mark-和-reset">mark 和 reset</h4>
<p>mark 是在读取时，做一个标记，即使 position 改变，只要调用 reset 就能回到 mark 的位置</p>
<blockquote>
<p><strong>注意</strong></p>
<p>rewind 和 flip 都会清除 mark 位置</p>
</blockquote>
<h4 id="字符串与-bytebuffer-互转">字符串与 ByteBuffer 互转</h4>
<pre><code class="language-java">ByteBuffer buffer1 = StandardCharsets.UTF_8.encode(&quot;你好&quot;);
ByteBuffer buffer2 = Charset.forName(&quot;utf-8&quot;).encode(&quot;你好&quot;);

debug(buffer1);
debug(buffer2);

CharBuffer buffer3 = StandardCharsets.UTF_8.decode(buffer1);
System.out.println(buffer3.getClass());
System.out.println(buffer3.toString());
</code></pre>
<p>输出</p>
<pre><code>         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| e4 bd a0 e5 a5 bd                               |......          |
+--------+-------------------------------------------------+----------------+
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| e4 bd a0 e5 a5 bd                               |......          |
+--------+-------------------------------------------------+----------------+
class java.nio.HeapCharBuffer
你好
</code></pre>
<h4 id="️-buffer-的线程安全">⚠️ Buffer 的线程安全</h4>
<blockquote>
<p>Buffer 是<strong>非线程安全的</strong></p>
</blockquote>
<h3 id="24-scattering-reads">2.4 Scattering Reads</h3>
<p>分散读取，有一个文本文件 3parts.txt</p>
<pre><code>onetwothree
</code></pre>
<p>使用如下方式读取，可以将数据填充至多个 buffer</p>
<pre><code class="language-java">try (RandomAccessFile file = new RandomAccessFile(&quot;helloword/3parts.txt&quot;, &quot;rw&quot;)) {
    FileChannel channel = file.getChannel();
    ByteBuffer a = ByteBuffer.allocate(3);
    ByteBuffer b = ByteBuffer.allocate(3);
    ByteBuffer c = ByteBuffer.allocate(5);
    channel.read(new ByteBuffer[]{a, b, c});
    a.flip();
    b.flip();
    c.flip();
    debug(a);
    debug(b);
    debug(c);
} catch (IOException e) {
    e.printStackTrace();
}
</code></pre>
<p>结果</p>
<pre><code>         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 6f 6e 65                                        |one             |
+--------+-------------------------------------------------+----------------+
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 74 77 6f                                        |two             |
+--------+-------------------------------------------------+----------------+
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 74 68 72 65 65                                  |three           |
+--------+-------------------------------------------------+----------------+
</code></pre>
<h3 id="25-gathering-writes">2.5 Gathering Writes</h3>
<p>使用如下方式写入，可以将多个 buffer 的数据填充至 channel</p>
<pre><code class="language-java">try (RandomAccessFile file = new RandomAccessFile(&quot;helloword/3parts.txt&quot;, &quot;rw&quot;)) {
    FileChannel channel = file.getChannel();
    ByteBuffer d = ByteBuffer.allocate(4);
    ByteBuffer e = ByteBuffer.allocate(4);
    channel.position(11);

    d.put(new byte[]{'f', 'o', 'u', 'r'});
    e.put(new byte[]{'f', 'i', 'v', 'e'});
    d.flip();
    e.flip();
    debug(d);
    debug(e);
    channel.write(new ByteBuffer[]{d, e});
} catch (IOException e) {
    e.printStackTrace();
}
</code></pre>
<p>输出</p>
<pre><code>         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 66 6f 75 72                                     |four            |
+--------+-------------------------------------------------+----------------+
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 66 69 76 65                                     |five            |
+--------+-------------------------------------------------+----------------+
</code></pre>
<p>文件内容</p>
<pre><code>onetwothreefourfive
</code></pre>
<h3 id="26-练习">2.6 练习</h3>
<p>网络上有多条数据发送给服务端，数据之间使用 \n 进行分隔<br>
但由于某种原因这些数据在接收时，被进行了重新组合，例如原始数据有3条为</p>
<ul>
<li>Hello,world\n</li>
<li>I'm zhangsan\n</li>
<li>How are you?\n</li>
</ul>
<p>变成了下面的两个 byteBuffer (黏包，半包)</p>
<ul>
<li>Hello,world\nI'm zhangsan\nHo</li>
<li>w are you?\n</li>
</ul>
<p>现在要求你编写程序，将错乱的数据恢复成原始的按 \n 分隔的数据</p>
<pre><code class="language-java">public static void main(String[] args) {
    ByteBuffer source = ByteBuffer.allocate(32);
    //                     11            24
    source.put(&quot;Hello,world\nI'm zhangsan\nHo&quot;.getBytes());
    split(source);

    source.put(&quot;w are you?\nhaha!\n&quot;.getBytes());
    split(source);
}

private static void split(ByteBuffer source) {
    source.flip();
    int oldLimit = source.limit();
    for (int i = 0; i &lt; oldLimit; i++) {
        if (source.get(i) == '\n') {
            System.out.println(i);
            ByteBuffer target = ByteBuffer.allocate(i + 1 - source.position());
            // 0 ~ limit
            source.limit(i + 1);
            target.put(source); // 从source 读，向 target 写
            debugAll(target);
            source.limit(oldLimit);
        }
    }
    source.compact();
}
</code></pre>
<h2 id="3-文件编程">3. 文件编程</h2>
<h3 id="31-filechannel">3.1 FileChannel</h3>
<h4 id="️-filechannel-工作模式">⚠️ FileChannel 工作模式</h4>
<blockquote>
<p>FileChannel 只能工作在阻塞模式下</p>
</blockquote>
<h4 id="获取">获取</h4>
<p>不能直接打开 FileChannel，必须通过 FileInputStream、FileOutputStream 或者 RandomAccessFile 来获取 FileChannel，它们都有 getChannel 方法</p>
<ul>
<li>通过 FileInputStream 获取的 channel 只能读</li>
<li>通过 FileOutputStream 获取的 channel 只能写</li>
<li>通过 RandomAccessFile 是否能读写根据构造 RandomAccessFile 时的读写模式决定</li>
</ul>
<h4 id="读取">读取</h4>
<p>会从 channel 读取数据填充 ByteBuffer，返回值表示读到了多少字节，-1 表示到达了文件的末尾</p>
<pre><code class="language-java">int readBytes = channel.read(buffer);
</code></pre>
<h4 id="写入">写入</h4>
<p>写入的正确姿势如下， SocketChannel</p>
<pre><code class="language-java">ByteBuffer buffer = ...;
buffer.put(...); // 存入数据
buffer.flip();   // 切换读模式

while(buffer.hasRemaining()) {
    channel.write(buffer);
}
</code></pre>
<p>在 while 中调用 channel.write 是因为 write 方法并不能保证一次将 buffer 中的内容全部写入 channel</p>
<h4 id="关闭">关闭</h4>
<p>channel 必须关闭，不过调用了 FileInputStream、FileOutputStream 或者 RandomAccessFile 的 close 方法会间接地调用 channel 的 close 方法</p>
<h4 id="位置">位置</h4>
<p>获取当前位置</p>
<pre><code class="language-java">long pos = channel.position();
</code></pre>
<p>设置当前位置</p>
<pre><code class="language-java">long newPos = ...;
channel.position(newPos);
</code></pre>
<p>设置当前位置时，如果设置为文件的末尾</p>
<ul>
<li>这时读取会返回 -1</li>
<li>这时写入，会追加内容，但要注意如果 position 超过了文件末尾，再写入时在新内容和原末尾之间会有空洞（00）</li>
</ul>
<h4 id="大小">大小</h4>
<p>使用 size 方法获取文件的大小</p>
<h4 id="强制写入">强制写入</h4>
<p>操作系统出于性能的考虑，会将数据缓存，不是立刻写入磁盘。可以调用 force(true)  方法将文件内容和元数据（文件的权限等信息）立刻写入磁盘</p>
<h3 id="32-两个-channel-传输数据">3.2 两个 Channel 传输数据</h3>
<pre><code class="language-java">String FROM = &quot;helloword/data.txt&quot;;
String TO = &quot;helloword/to.txt&quot;;
long start = System.nanoTime();
try (FileChannel from = new FileInputStream(FROM).getChannel();
     FileChannel to = new FileOutputStream(TO).getChannel();
    ) {
    from.transferTo(0, from.size(), to);
} catch (IOException e) {
    e.printStackTrace();
}
long end = System.nanoTime();
System.out.println(&quot;transferTo 用时：&quot; + (end - start) / 1000_000.0);
</code></pre>
<p>输出</p>
<pre><code>transferTo 用时：8.2011
</code></pre>
<p>超过 2g 大小的文件传输</p>
<pre><code class="language-java">public class TestFileChannelTransferTo {
    public static void main(String[] args) {
        try (
                FileChannel from = new FileInputStream(&quot;data.txt&quot;).getChannel();
                FileChannel to = new FileOutputStream(&quot;to.txt&quot;).getChannel();
        ) {
            // 效率高，底层会利用操作系统的零拷贝进行优化
            long size = from.size();
            // left 变量代表还剩余多少字节
            for (long left = size; left &gt; 0; ) {
                System.out.println(&quot;position:&quot; + (size - left) + &quot; left:&quot; + left);
                left -= from.transferTo((size - left), left, to);
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>实际传输一个超大文件</p>
<pre><code>position:0 left:7769948160
position:2147483647 left:5622464513
position:4294967294 left:3474980866
position:6442450941 left:1327497219
</code></pre>
<h3 id="33-path">3.3 Path</h3>
<p>jdk7 引入了 Path 和 Paths 类</p>
<ul>
<li>Path 用来表示文件路径</li>
<li>Paths 是工具类，用来获取 Path 实例</li>
</ul>
<pre><code class="language-java">Path source = Paths.get(&quot;1.txt&quot;); // 相对路径 使用 user.dir 环境变量来定位 1.txt

Path source = Paths.get(&quot;d:\\1.txt&quot;); // 绝对路径 代表了  d:\1.txt

Path source = Paths.get(&quot;d:/1.txt&quot;); // 绝对路径 同样代表了  d:\1.txt

Path projects = Paths.get(&quot;d:\\data&quot;, &quot;projects&quot;); // 代表了  d:\data\projects
</code></pre>
<ul>
<li><code>.</code> 代表了当前路径</li>
<li><code>..</code> 代表了上一级路径</li>
</ul>
<p>例如目录结构如下</p>
<pre><code>d:
	|- data
		|- projects
			|- a
			|- b
</code></pre>
<p>代码</p>
<pre><code class="language-java">Path path = Paths.get(&quot;d:\\data\\projects\\a\\..\\b&quot;);
System.out.println(path);
System.out.println(path.normalize()); // 正常化路径
</code></pre>
<p>会输出</p>
<pre><code>d:\data\projects\a\..\b
d:\data\projects\b
</code></pre>
<h3 id="34-files">3.4 Files</h3>
<p>检查文件是否存在</p>
<pre><code class="language-java">Path path = Paths.get(&quot;helloword/data.txt&quot;);
System.out.println(Files.exists(path));
</code></pre>
<p>创建一级目录</p>
<pre><code class="language-java">Path path = Paths.get(&quot;helloword/d1&quot;);
Files.createDirectory(path);
</code></pre>
<ul>
<li>如果目录已存在，会抛异常 FileAlreadyExistsException</li>
<li>不能一次创建多级目录，否则会抛异常 NoSuchFileException</li>
</ul>
<p>创建多级目录用</p>
<pre><code class="language-java">Path path = Paths.get(&quot;helloword/d1/d2&quot;);
Files.createDirectories(path);
</code></pre>
<p>拷贝文件</p>
<pre><code class="language-java">Path source = Paths.get(&quot;helloword/data.txt&quot;);
Path target = Paths.get(&quot;helloword/target.txt&quot;);

Files.copy(source, target);
</code></pre>
<ul>
<li>如果文件已存在，会抛异常 FileAlreadyExistsException</li>
</ul>
<p>如果希望用 source 覆盖掉 target，需要用 StandardCopyOption 来控制</p>
<pre><code class="language-java">Files.copy(source, target, StandardCopyOption.REPLACE_EXISTING);
</code></pre>
<p>移动文件</p>
<pre><code class="language-java">Path source = Paths.get(&quot;helloword/data.txt&quot;);
Path target = Paths.get(&quot;helloword/data.txt&quot;);

Files.move(source, target, StandardCopyOption.ATOMIC_MOVE);
</code></pre>
<ul>
<li>StandardCopyOption.ATOMIC_MOVE 保证文件移动的原子性</li>
</ul>
<p>删除文件</p>
<pre><code class="language-java">Path target = Paths.get(&quot;helloword/target.txt&quot;);

Files.delete(target);
</code></pre>
<ul>
<li>如果文件不存在，会抛异常 NoSuchFileException</li>
</ul>
<p>删除目录</p>
<pre><code class="language-java">Path target = Paths.get(&quot;helloword/d1&quot;);

Files.delete(target);
</code></pre>
<ul>
<li>如果目录还有内容，会抛异常 DirectoryNotEmptyException</li>
</ul>
<p>遍历目录文件</p>
<pre><code class="language-java">public static void main(String[] args) throws IOException {
    Path path = Paths.get(&quot;C:\\Program Files\\Java\\jdk1.8.0_91&quot;);
    AtomicInteger dirCount = new AtomicInteger();
    AtomicInteger fileCount = new AtomicInteger();
    Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;(){
        @Override
        public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) 
            throws IOException {
            System.out.println(dir);
            dirCount.incrementAndGet();
            return super.preVisitDirectory(dir, attrs);
        }

        @Override
        public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) 
            throws IOException {
            System.out.println(file);
            fileCount.incrementAndGet();
            return super.visitFile(file, attrs);
        }
    });
    System.out.println(dirCount); // 133
    System.out.println(fileCount); // 1479
}
</code></pre>
<p>统计 jar 的数目</p>
<pre><code class="language-java">Path path = Paths.get(&quot;C:\\Program Files\\Java\\jdk1.8.0_91&quot;);
AtomicInteger fileCount = new AtomicInteger();
Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;(){
    @Override
    public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) 
        throws IOException {
        if (file.toFile().getName().endsWith(&quot;.jar&quot;)) {
            fileCount.incrementAndGet();
        }
        return super.visitFile(file, attrs);
    }
});
System.out.println(fileCount); // 724
</code></pre>
<p>删除多级目录</p>
<pre><code class="language-java">Path path = Paths.get(&quot;d:\\a&quot;);
Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;(){
    @Override
    public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) 
        throws IOException {
        Files.delete(file);
        return super.visitFile(file, attrs);
    }

    @Override
    public FileVisitResult postVisitDirectory(Path dir, IOException exc) 
        throws IOException {
        Files.delete(dir);
        return super.postVisitDirectory(dir, exc);
    }
});
</code></pre>
<h4 id="️-删除很危险">⚠️ 删除很危险</h4>
<blockquote>
<p>删除是危险操作，确保要递归删除的文件夹没有重要内容</p>
</blockquote>
<p>拷贝多级目录</p>
<pre><code class="language-java">long start = System.currentTimeMillis();
String source = &quot;D:\\Snipaste-1.16.2-x64&quot;;
String target = &quot;D:\\Snipaste-1.16.2-x64aaa&quot;;

Files.walk(Paths.get(source)).forEach(path -&gt; {
    try {
        String targetName = path.toString().replace(source, target);
        // 是目录
        if (Files.isDirectory(path)) {
            Files.createDirectory(Paths.get(targetName));
        }
        // 是普通文件
        else if (Files.isRegularFile(path)) {
            Files.copy(path, Paths.get(targetName));
        }
    } catch (IOException e) {
        e.printStackTrace();
    }
});
long end = System.currentTimeMillis();
System.out.println(end - start);
</code></pre>
<h2 id="4-网络编程">4. 网络编程</h2>
<h3 id="41-非阻塞-vs-阻塞">4.1 非阻塞 vs 阻塞</h3>
<h4 id="阻塞">阻塞</h4>
<ul>
<li>阻塞模式下，相关方法都会导致线程暂停
<ul>
<li>ServerSocketChannel.accept 会在没有连接建立时让线程暂停</li>
<li>SocketChannel.read 会在没有数据可读时让线程暂停</li>
<li>阻塞的表现其实就是线程暂停了，暂停期间不会占用 cpu，但线程相当于闲置</li>
</ul>
</li>
<li>单线程下，阻塞方法之间相互影响，几乎不能正常工作，需要多线程支持</li>
<li>但多线程下，有新的问题，体现在以下方面
<ul>
<li>32 位 jvm 一个线程 320k，64 位 jvm 一个线程 1024k，如果连接数过多，必然导致 OOM，并且线程太多，反而会因为频繁上下文切换导致性能降低</li>
<li>可以采用线程池技术来减少线程数和线程上下文切换，但治标不治本，如果有很多连接建立，但长时间 inactive，会阻塞线程池中所有线程，因此不适合长连接，只适合短连接</li>
</ul>
</li>
</ul>
<p>服务器端</p>
<pre><code class="language-java">// 使用 nio 来理解阻塞模式, 单线程
// 0. ByteBuffer
ByteBuffer buffer = ByteBuffer.allocate(16);
// 1. 创建了服务器
ServerSocketChannel ssc = ServerSocketChannel.open();

// 2. 绑定监听端口
ssc.bind(new InetSocketAddress(8080));

// 3. 连接集合
List&lt;SocketChannel&gt; channels = new ArrayList&lt;&gt;();
while (true) {
    // 4. accept 建立与客户端连接， SocketChannel 用来与客户端之间通信
    log.debug(&quot;connecting...&quot;);
    SocketChannel sc = ssc.accept(); // 阻塞方法，线程停止运行
    log.debug(&quot;connected... {}&quot;, sc);
    channels.add(sc);
    for (SocketChannel channel : channels) {
        // 5. 接收客户端发送的数据
        log.debug(&quot;before read... {}&quot;, channel);
        channel.read(buffer); // 阻塞方法，线程停止运行
        buffer.flip();
        debugRead(buffer);
        buffer.clear();
        log.debug(&quot;after read...{}&quot;, channel);
    }
}
</code></pre>
<p>客户端</p>
<pre><code class="language-java">SocketChannel sc = SocketChannel.open();
sc.connect(new InetSocketAddress(&quot;localhost&quot;, 8080));
System.out.println(&quot;waiting...&quot;);
</code></pre>
<h4 id="非阻塞">非阻塞</h4>
<ul>
<li>非阻塞模式下，相关方法都会不会让线程暂停
<ul>
<li>在 ServerSocketChannel.accept 在没有连接建立时，会返回 null，继续运行</li>
<li>SocketChannel.read 在没有数据可读时，会返回 0，但线程不必阻塞，可以去执行其它 SocketChannel 的 read 或是去执行 ServerSocketChannel.accept</li>
<li>写数据时，线程只是等待数据写入 Channel 即可，无需等 Channel 通过网络把数据发送出去</li>
</ul>
</li>
<li>但非阻塞模式下，即使没有连接建立，和可读数据，线程仍然在不断运行，白白浪费了 cpu</li>
<li>数据复制过程中，线程实际还是阻塞的（AIO 改进的地方）</li>
</ul>
<p>服务器端，客户端代码不变</p>
<pre><code class="language-java">// 使用 nio 来理解非阻塞模式, 单线程
// 0. ByteBuffer
ByteBuffer buffer = ByteBuffer.allocate(16);
// 1. 创建了服务器
ServerSocketChannel ssc = ServerSocketChannel.open();
ssc.configureBlocking(false); // 非阻塞模式
// 2. 绑定监听端口
ssc.bind(new InetSocketAddress(8080));
// 3. 连接集合
List&lt;SocketChannel&gt; channels = new ArrayList&lt;&gt;();
while (true) {
    // 4. accept 建立与客户端连接， SocketChannel 用来与客户端之间通信
    SocketChannel sc = ssc.accept(); // 非阻塞，线程还会继续运行，如果没有连接建立，但sc是null
    if (sc != null) {
        log.debug(&quot;connected... {}&quot;, sc);
        sc.configureBlocking(false); // 非阻塞模式
        channels.add(sc);
    }
    for (SocketChannel channel : channels) {
        // 5. 接收客户端发送的数据
        int read = channel.read(buffer);// 非阻塞，线程仍然会继续运行，如果没有读到数据，read 返回 0
        if (read &gt; 0) {
            buffer.flip();
            debugRead(buffer);
            buffer.clear();
            log.debug(&quot;after read...{}&quot;, channel);
        }
    }
}
</code></pre>
<h4 id="多路复用">多路复用</h4>
<p>单线程可以配合 Selector 完成对多个 Channel 可读写事件的监控，这称之为<strong>多路复用</strong></p>
<ul>
<li>多路复用仅针对网络 IO、普通文件 IO 没法利用多路复用</li>
<li>如果不用 Selector 的非阻塞模式，线程大部分时间都在做无用功，而 Selector 能够保证
<ul>
<li>有可连接事件时才去连接</li>
<li>有可读事件才去读取</li>
<li>有可写事件才去写入
<ul>
<li>限于网络传输能力，Channel 未必时时可写，一旦 Channel 可写，会触发 Selector 的可写事件</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="42-selector">4.2 Selector</h3>
<pre><code class="language-mermaid">graph TD
subgraph selector 版
thread --&gt; selector
selector --&gt; c1(channel)
selector --&gt; c2(channel)
selector --&gt; c3(channel)
end
</code></pre>
<p>好处</p>
<ul>
<li>一个线程配合 selector 就可以监控多个 channel 的事件，事件发生线程才去处理。避免非阻塞模式下所做无用功</li>
<li>让这个线程能够被充分利用</li>
<li>节约了线程的数量</li>
<li>减少了线程上下文切换</li>
</ul>
<h4 id="创建">创建</h4>
<pre><code class="language-java">Selector selector = Selector.open();
</code></pre>
<h4 id="绑定-channel-事件">绑定 Channel 事件</h4>
<p>也称之为注册事件，绑定的事件 selector 才会关心</p>
<pre><code class="language-java">channel.configureBlocking(false);
SelectionKey key = channel.register(selector, 绑定事件);
</code></pre>
<ul>
<li>channel 必须工作在非阻塞模式</li>
<li>FileChannel 没有非阻塞模式，因此不能配合 selector 一起使用</li>
<li>绑定的事件类型可以有
<ul>
<li>connect - 客户端连接成功时触发</li>
<li>accept - 服务器端成功接受连接时触发</li>
<li>read - 数据可读入时触发，有因为接收能力弱，数据暂不能读入的情况</li>
<li>write - 数据可写出时触发，有因为发送能力弱，数据暂不能写出的情况</li>
</ul>
</li>
</ul>
<h4 id="监听-channel-事件">监听 Channel 事件</h4>
<p>可以通过下面三种方法来监听是否有事件发生，方法的返回值代表有多少 channel 发生了事件</p>
<p>方法1，阻塞直到绑定事件发生</p>
<pre><code class="language-java">int count = selector.select();
</code></pre>
<p>方法2，阻塞直到绑定事件发生，或是超时（时间单位为 ms）</p>
<pre><code class="language-java">int count = selector.select(long timeout);
</code></pre>
<p>方法3，不会阻塞，也就是不管有没有事件，立刻返回，自己根据返回值检查是否有事件</p>
<pre><code class="language-java">int count = selector.selectNow();
</code></pre>
<h4 id="select-何时不阻塞">💡 select 何时不阻塞</h4>
<blockquote>
<ul>
<li>事件发生时
<ul>
<li>客户端发起连接请求，会触发 accept 事件</li>
<li>客户端发送数据过来，客户端正常、异常关闭时，都会触发 read 事件，另外如果发送的数据大于 buffer 缓冲区，会触发多次读取事件</li>
<li>channel 可写，会触发 write 事件</li>
<li>在 linux 下 nio bug 发生时</li>
</ul>
</li>
<li>调用 selector.wakeup()</li>
<li>调用 selector.close()</li>
<li>selector 所在线程 interrupt</li>
</ul>
</blockquote>
<h3 id="43-处理-accept-事件">4.3 处理 accept 事件</h3>
<p>客户端代码为</p>
<pre><code class="language-java">public class Client {
    public static void main(String[] args) {
        try (Socket socket = new Socket(&quot;localhost&quot;, 8080)) {
            System.out.println(socket);
            socket.getOutputStream().write(&quot;world&quot;.getBytes());
            System.in.read();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>服务器端代码为</p>
<pre><code class="language-java">@Slf4j
public class ChannelDemo6 {
    public static void main(String[] args) {
        try (ServerSocketChannel channel = ServerSocketChannel.open()) {
            channel.bind(new InetSocketAddress(8080));
            System.out.println(channel);
            Selector selector = Selector.open();
            channel.configureBlocking(false);
            channel.register(selector, SelectionKey.OP_ACCEPT);

            while (true) {
                int count = selector.select();
//                int count = selector.selectNow();
                log.debug(&quot;select count: {}&quot;, count);
//                if(count &lt;= 0) {
//                    continue;
//                }

                // 获取所有事件
                Set&lt;SelectionKey&gt; keys = selector.selectedKeys();

                // 遍历所有事件，逐一处理
                Iterator&lt;SelectionKey&gt; iter = keys.iterator();
                while (iter.hasNext()) {
                    SelectionKey key = iter.next();
                    // 判断事件类型
                    if (key.isAcceptable()) {
                        ServerSocketChannel c = (ServerSocketChannel) key.channel();
                        // 必须处理
                        SocketChannel sc = c.accept();
                        log.debug(&quot;{}&quot;, sc);
                    }
                    // 处理完毕，必须将事件移除
                    iter.remove();
                }
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<h4 id="事件发生后能否不处理">💡 事件发生后能否不处理</h4>
<blockquote>
<p>事件发生后，要么处理，要么取消（cancel），不能什么都不做，否则下次该事件仍会触发，这是因为 nio 底层使用的是水平触发</p>
</blockquote>
<h3 id="44-处理-read-事件">4.4 处理 read 事件</h3>
<pre><code class="language-java">@Slf4j
public class ChannelDemo6 {
    public static void main(String[] args) {
        try (ServerSocketChannel channel = ServerSocketChannel.open()) {
            channel.bind(new InetSocketAddress(8080));
            System.out.println(channel);
            Selector selector = Selector.open();
            channel.configureBlocking(false);
            channel.register(selector, SelectionKey.OP_ACCEPT);

            while (true) {
                int count = selector.select();
//                int count = selector.selectNow();
                log.debug(&quot;select count: {}&quot;, count);
//                if(count &lt;= 0) {
//                    continue;
//                }

                // 获取所有事件
                Set&lt;SelectionKey&gt; keys = selector.selectedKeys();

                // 遍历所有事件，逐一处理
                Iterator&lt;SelectionKey&gt; iter = keys.iterator();
                while (iter.hasNext()) {
                    SelectionKey key = iter.next();
                    // 判断事件类型
                    if (key.isAcceptable()) {
                        ServerSocketChannel c = (ServerSocketChannel) key.channel();
                        // 必须处理
                        SocketChannel sc = c.accept();
                        sc.configureBlocking(false);
                        sc.register(selector, SelectionKey.OP_READ);
                        log.debug(&quot;连接已建立: {}&quot;, sc);
                    } else if (key.isReadable()) {
                        SocketChannel sc = (SocketChannel) key.channel();
                        ByteBuffer buffer = ByteBuffer.allocate(128);
                        int read = sc.read(buffer);
                        if(read == -1) {
                            key.cancel();
                            sc.close();
                        } else {
                            buffer.flip();
                            debug(buffer);
                        }
                    }
                    // 处理完毕，必须将事件移除
                    iter.remove();
                }
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>开启两个客户端，修改一下发送文字，输出</p>
<pre><code>sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:8080]
21:16:39 [DEBUG] [main] c.i.n.ChannelDemo6 - select count: 1
21:16:39 [DEBUG] [main] c.i.n.ChannelDemo6 - 连接已建立: java.nio.channels.SocketChannel[connected local=/127.0.0.1:8080 remote=/127.0.0.1:60367]
21:16:39 [DEBUG] [main] c.i.n.ChannelDemo6 - select count: 1
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 68 65 6c 6c 6f                                  |hello           |
+--------+-------------------------------------------------+----------------+
21:16:59 [DEBUG] [main] c.i.n.ChannelDemo6 - select count: 1
21:16:59 [DEBUG] [main] c.i.n.ChannelDemo6 - 连接已建立: java.nio.channels.SocketChannel[connected local=/127.0.0.1:8080 remote=/127.0.0.1:60378]
21:16:59 [DEBUG] [main] c.i.n.ChannelDemo6 - select count: 1
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 77 6f 72 6c 64                                  |world           |
+--------+-------------------------------------------------+----------------+
</code></pre>
<h4 id="为何要-iterremove">💡 为何要 iter.remove()</h4>
<blockquote>
<p>因为 select 在事件发生后，就会将相关的 key 放入 selectedKeys 集合，但不会在处理完后从 selectedKeys 集合中移除，需要我们自己编码删除。例如</p>
<ul>
<li>第一次触发了 ssckey 上的 accept 事件，没有移除 ssckey</li>
<li>第二次触发了 sckey 上的 read 事件，但这时 selectedKeys 中还有上次的 ssckey ，在处理时因为没有真正的 serverSocket 连上了，就会导致空指针异常</li>
</ul>
</blockquote>
<h4 id="cancel-的作用">💡 cancel 的作用</h4>
<blockquote>
<p>cancel 会取消注册在 selector 上的 channel，并从 keys 集合中删除 key 后续不会再监听事件</p>
</blockquote>
<h4 id="️-不处理边界的问题">⚠️  不处理边界的问题</h4>
<p>以前有同学写过这样的代码，思考注释中两个问题，以 bio 为例，其实 nio 道理是一样的</p>
<pre><code class="language-java">public class Server {
    public static void main(String[] args) throws IOException {
        ServerSocket ss=new ServerSocket(9000);
        while (true) {
            Socket s = ss.accept();
            InputStream in = s.getInputStream();
            // 这里这么写，有没有问题
            byte[] arr = new byte[4];
            while(true) {
                int read = in.read(arr);
                // 这里这么写，有没有问题
                if(read == -1) {
                    break;
                }
                System.out.println(new String(arr, 0, read));
            }
        }
    }
}
</code></pre>
<p>客户端</p>
<pre><code class="language-java">public class Client {
    public static void main(String[] args) throws IOException {
        Socket max = new Socket(&quot;localhost&quot;, 9000);
        OutputStream out = max.getOutputStream();
        out.write(&quot;hello&quot;.getBytes());
        out.write(&quot;world&quot;.getBytes());
        out.write(&quot;你好&quot;.getBytes());
        max.close();
    }
}
</code></pre>
<p>输出</p>
<pre><code>hell
owor
ld�
�好

</code></pre>
<p>为什么？</p>
<h4 id="处理消息的边界">处理消息的边界</h4>
<figure data-type="image" tabindex="4"><img src="img/0023.png" alt="" loading="lazy"></figure>
<ul>
<li>一种思路是固定消息长度，数据包大小一样，服务器按预定长度读取，缺点是浪费带宽</li>
<li>另一种思路是按分隔符拆分，缺点是效率低</li>
<li>TLV 格式，即 Type 类型、Length 长度、Value 数据，类型和长度已知的情况下，就可以方便获取消息大小，分配合适的 buffer，缺点是 buffer 需要提前分配，如果内容过大，则影响 server 吞吐量
<ul>
<li>Http 1.1 是 TLV 格式</li>
<li>Http 2.0 是 LTV 格式</li>
</ul>
</li>
</ul>
<pre><code class="language-mermaid">sequenceDiagram 
participant c1 as 客户端1
participant s as 服务器
participant b1 as ByteBuffer1
participant b2 as ByteBuffer2
c1 -&gt;&gt; s: 发送 01234567890abcdef3333\r
s -&gt;&gt; b1: 第一次 read 存入 01234567890abcdef
s -&gt;&gt; b2: 扩容
b1 -&gt;&gt; b2: 拷贝 01234567890abcdef
s -&gt;&gt; b2: 第二次 read 存入 3333\r
b2 -&gt;&gt; b2: 01234567890abcdef3333\r
</code></pre>
<p>服务器端</p>
<pre><code class="language-java">private static void split(ByteBuffer source) {
    source.flip();
    for (int i = 0; i &lt; source.limit(); i++) {
        // 找到一条完整消息
        if (source.get(i) == '\n') {
            int length = i + 1 - source.position();
            // 把这条完整消息存入新的 ByteBuffer
            ByteBuffer target = ByteBuffer.allocate(length);
            // 从 source 读，向 target 写
            for (int j = 0; j &lt; length; j++) {
                target.put(source.get());
            }
            debugAll(target);
        }
    }
    source.compact(); // 0123456789abcdef  position 16 limit 16
}

public static void main(String[] args) throws IOException {
    // 1. 创建 selector, 管理多个 channel
    Selector selector = Selector.open();
    ServerSocketChannel ssc = ServerSocketChannel.open();
    ssc.configureBlocking(false);
    // 2. 建立 selector 和 channel 的联系（注册）
    // SelectionKey 就是将来事件发生后，通过它可以知道事件和哪个channel的事件
    SelectionKey sscKey = ssc.register(selector, 0, null);
    // key 只关注 accept 事件
    sscKey.interestOps(SelectionKey.OP_ACCEPT);
    log.debug(&quot;sscKey:{}&quot;, sscKey);
    ssc.bind(new InetSocketAddress(8080));
    while (true) {
        // 3. select 方法, 没有事件发生，线程阻塞，有事件，线程才会恢复运行
        // select 在事件未处理时，它不会阻塞, 事件发生后要么处理，要么取消，不能置之不理
        selector.select();
        // 4. 处理事件, selectedKeys 内部包含了所有发生的事件
        Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator(); // accept, read
        while (iter.hasNext()) {
            SelectionKey key = iter.next();
            // 处理key 时，要从 selectedKeys 集合中删除，否则下次处理就会有问题
            iter.remove();
            log.debug(&quot;key: {}&quot;, key);
            // 5. 区分事件类型
            if (key.isAcceptable()) { // 如果是 accept
                ServerSocketChannel channel = (ServerSocketChannel) key.channel();
                SocketChannel sc = channel.accept();
                sc.configureBlocking(false);
                ByteBuffer buffer = ByteBuffer.allocate(16); // attachment
                // 将一个 byteBuffer 作为附件关联到 selectionKey 上
                SelectionKey scKey = sc.register(selector, 0, buffer);
                scKey.interestOps(SelectionKey.OP_READ);
                log.debug(&quot;{}&quot;, sc);
                log.debug(&quot;scKey:{}&quot;, scKey);
            } else if (key.isReadable()) { // 如果是 read
                try {
                    SocketChannel channel = (SocketChannel) key.channel(); // 拿到触发事件的channel
                    // 获取 selectionKey 上关联的附件
                    ByteBuffer buffer = (ByteBuffer) key.attachment();
                    int read = channel.read(buffer); // 如果是正常断开，read 的方法的返回值是 -1
                    if(read == -1) {
                        key.cancel();
                    } else {
                        split(buffer);
                        // 需要扩容
                        if (buffer.position() == buffer.limit()) {
                            ByteBuffer newBuffer = ByteBuffer.allocate(buffer.capacity() * 2);
                            buffer.flip();
                            newBuffer.put(buffer); // 0123456789abcdef3333\n
                            key.attach(newBuffer);
                        }
                    }

                } catch (IOException e) {
                    e.printStackTrace();
                    key.cancel();  // 因为客户端断开了,因此需要将 key 取消（从 selector 的 keys 集合中真正删除 key）
                }
            }
        }
    }
}
</code></pre>
<p>客户端</p>
<pre><code class="language-java">SocketChannel sc = SocketChannel.open();
sc.connect(new InetSocketAddress(&quot;localhost&quot;, 8080));
SocketAddress address = sc.getLocalAddress();
// sc.write(Charset.defaultCharset().encode(&quot;hello\nworld\n&quot;));
sc.write(Charset.defaultCharset().encode(&quot;0123\n456789abcdef&quot;));
sc.write(Charset.defaultCharset().encode(&quot;0123456789abcdef3333\n&quot;));
System.in.read();
</code></pre>
<h4 id="bytebuffer-大小分配">ByteBuffer 大小分配</h4>
<ul>
<li>每个 channel 都需要记录可能被切分的消息，因为 ByteBuffer 不能被多个 channel 共同使用，因此需要为每个 channel 维护一个独立的 ByteBuffer</li>
<li>ByteBuffer 不能太大，比如一个 ByteBuffer 1Mb 的话，要支持百万连接就要 1Tb 内存，因此需要设计大小可变的 ByteBuffer
<ul>
<li>一种思路是首先分配一个较小的 buffer，例如 4k，如果发现数据不够，再分配 8k 的 buffer，将 4k buffer 内容拷贝至 8k buffer，优点是消息连续容易处理，缺点是数据拷贝耗费性能，参考实现 <a href="http://tutorials.jenkov.com/java-performance/resizable-array.html">http://tutorials.jenkov.com/java-performance/resizable-array.html</a></li>
<li>另一种思路是用多个数组组成 buffer，一个数组不够，把多出来的内容写入新的数组，与前面的区别是消息存储不连续解析复杂，优点是避免了拷贝引起的性能损耗</li>
</ul>
</li>
</ul>
<h3 id="45-处理-write-事件">4.5 处理 write 事件</h3>
<h4 id="一次无法写完例子">一次无法写完例子</h4>
<ul>
<li>非阻塞模式下，无法保证把 buffer 中所有数据都写入 channel，因此需要追踪 write 方法的返回值（代表实际写入字节数）</li>
<li>用 selector 监听所有 channel 的可写事件，每个 channel 都需要一个 key 来跟踪 buffer，但这样又会导致占用内存过多，就有两阶段策略
<ul>
<li>当消息处理器第一次写入消息时，才将 channel 注册到 selector 上</li>
<li>selector 检查 channel 上的可写事件，如果所有的数据写完了，就取消 channel 的注册</li>
<li>如果不取消，会每次可写均会触发 write 事件</li>
</ul>
</li>
</ul>
<pre><code class="language-java">public class WriteServer {

    public static void main(String[] args) throws IOException {
        ServerSocketChannel ssc = ServerSocketChannel.open();
        ssc.configureBlocking(false);
        ssc.bind(new InetSocketAddress(8080));

        Selector selector = Selector.open();
        ssc.register(selector, SelectionKey.OP_ACCEPT);

        while(true) {
            selector.select();

            Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator();
            while (iter.hasNext()) {
                SelectionKey key = iter.next();
                iter.remove();
                if (key.isAcceptable()) {
                    SocketChannel sc = ssc.accept();
                    sc.configureBlocking(false);
                    SelectionKey sckey = sc.register(selector, SelectionKey.OP_READ);
                    // 1. 向客户端发送内容
                    StringBuilder sb = new StringBuilder();
                    for (int i = 0; i &lt; 3000000; i++) {
                        sb.append(&quot;a&quot;);
                    }
                    ByteBuffer buffer = Charset.defaultCharset().encode(sb.toString());
                    int write = sc.write(buffer);
                    // 3. write 表示实际写了多少字节
                    System.out.println(&quot;实际写入字节:&quot; + write);
                    // 4. 如果有剩余未读字节，才需要关注写事件
                    if (buffer.hasRemaining()) {
                        // read 1  write 4
                        // 在原有关注事件的基础上，多关注 写事件
                        sckey.interestOps(sckey.interestOps() + SelectionKey.OP_WRITE);
                        // 把 buffer 作为附件加入 sckey
                        sckey.attach(buffer);
                    }
                } else if (key.isWritable()) {
                    ByteBuffer buffer = (ByteBuffer) key.attachment();
                    SocketChannel sc = (SocketChannel) key.channel();
                    int write = sc.write(buffer);
                    System.out.println(&quot;实际写入字节:&quot; + write);
                    if (!buffer.hasRemaining()) { // 写完了
                        key.interestOps(key.interestOps() - SelectionKey.OP_WRITE);
                        key.attach(null);
                    }
                }
            }
        }
    }
}
</code></pre>
<p>客户端</p>
<pre><code class="language-java">public class WriteClient {
    public static void main(String[] args) throws IOException {
        Selector selector = Selector.open();
        SocketChannel sc = SocketChannel.open();
        sc.configureBlocking(false);
        sc.register(selector, SelectionKey.OP_CONNECT | SelectionKey.OP_READ);
        sc.connect(new InetSocketAddress(&quot;localhost&quot;, 8080));
        int count = 0;
        while (true) {
            selector.select();
            Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator();
            while (iter.hasNext()) {
                SelectionKey key = iter.next();
                iter.remove();
                if (key.isConnectable()) {
                    System.out.println(sc.finishConnect());
                } else if (key.isReadable()) {
                    ByteBuffer buffer = ByteBuffer.allocate(1024 * 1024);
                    count += sc.read(buffer);
                    buffer.clear();
                    System.out.println(count);
                }
            }
        }
    }
}
</code></pre>
<h4 id="write-为何要取消">💡 write 为何要取消</h4>
<p>只要向 channel 发送数据时，socket 缓冲可写，这个事件会频繁触发，因此应当只在 socket 缓冲区写不下时再关注可写事件，数据写完之后再取消关注</p>
<h3 id="46-更进一步">4.6 更进一步</h3>
<h4 id="利用多线程优化">💡 利用多线程优化</h4>
<blockquote>
<p>现在都是多核 cpu，设计时要充分考虑别让 cpu 的力量被白白浪费</p>
</blockquote>
<p>前面的代码只有一个选择器，没有充分利用多核 cpu，如何改进呢？</p>
<p>分两组选择器</p>
<ul>
<li>单线程配一个选择器，专门处理 accept 事件</li>
<li>创建 cpu 核心数的线程，每个线程配一个选择器，轮流处理 read 事件</li>
</ul>
<pre><code class="language-java">public class ChannelDemo7 {
    public static void main(String[] args) throws IOException {
        new BossEventLoop().register();
    }


    @Slf4j
    static class BossEventLoop implements Runnable {
        private Selector boss;
        private WorkerEventLoop[] workers;
        private volatile boolean start = false;
        AtomicInteger index = new AtomicInteger();

        public void register() throws IOException {
            if (!start) {
                ServerSocketChannel ssc = ServerSocketChannel.open();
                ssc.bind(new InetSocketAddress(8080));
                ssc.configureBlocking(false);
                boss = Selector.open();
                SelectionKey ssckey = ssc.register(boss, 0, null);
                ssckey.interestOps(SelectionKey.OP_ACCEPT);
                workers = initEventLoops();
                new Thread(this, &quot;boss&quot;).start();
                log.debug(&quot;boss start...&quot;);
                start = true;
            }
        }

        public WorkerEventLoop[] initEventLoops() {
//        EventLoop[] eventLoops = new EventLoop[Runtime.getRuntime().availableProcessors()];
            WorkerEventLoop[] workerEventLoops = new WorkerEventLoop[2];
            for (int i = 0; i &lt; workerEventLoops.length; i++) {
                workerEventLoops[i] = new WorkerEventLoop(i);
            }
            return workerEventLoops;
        }

        @Override
        public void run() {
            while (true) {
                try {
                    boss.select();
                    Iterator&lt;SelectionKey&gt; iter = boss.selectedKeys().iterator();
                    while (iter.hasNext()) {
                        SelectionKey key = iter.next();
                        iter.remove();
                        if (key.isAcceptable()) {
                            ServerSocketChannel c = (ServerSocketChannel) key.channel();
                            SocketChannel sc = c.accept();
                            sc.configureBlocking(false);
                            log.debug(&quot;{} connected&quot;, sc.getRemoteAddress());
                            workers[index.getAndIncrement() % workers.length].register(sc);
                        }
                    }
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
    }

    @Slf4j
    static class WorkerEventLoop implements Runnable {
        private Selector worker;
        private volatile boolean start = false;
        private int index;

        private final ConcurrentLinkedQueue&lt;Runnable&gt; tasks = new ConcurrentLinkedQueue&lt;&gt;();

        public WorkerEventLoop(int index) {
            this.index = index;
        }

        public void register(SocketChannel sc) throws IOException {
            if (!start) {
                worker = Selector.open();
                new Thread(this, &quot;worker-&quot; + index).start();
                start = true;
            }
            tasks.add(() -&gt; {
                try {
                    SelectionKey sckey = sc.register(worker, 0, null);
                    sckey.interestOps(SelectionKey.OP_READ);
                    worker.selectNow();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            });
            worker.wakeup();
        }

        @Override
        public void run() {
            while (true) {
                try {
                    worker.select();
                    Runnable task = tasks.poll();
                    if (task != null) {
                        task.run();
                    }
                    Set&lt;SelectionKey&gt; keys = worker.selectedKeys();
                    Iterator&lt;SelectionKey&gt; iter = keys.iterator();
                    while (iter.hasNext()) {
                        SelectionKey key = iter.next();
                        if (key.isReadable()) {
                            SocketChannel sc = (SocketChannel) key.channel();
                            ByteBuffer buffer = ByteBuffer.allocate(128);
                            try {
                                int read = sc.read(buffer);
                                if (read == -1) {
                                    key.cancel();
                                    sc.close();
                                } else {
                                    buffer.flip();
                                    log.debug(&quot;{} message:&quot;, sc.getRemoteAddress());
                                    debugAll(buffer);
                                }
                            } catch (IOException e) {
                                e.printStackTrace();
                                key.cancel();
                                sc.close();
                            }
                        }
                        iter.remove();
                    }
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
    }
}
</code></pre>
<h4 id="如何拿到-cpu-个数">💡 如何拿到 cpu 个数</h4>
<blockquote>
<ul>
<li>Runtime.getRuntime().availableProcessors() 如果工作在 docker 容器下，因为容器不是物理隔离的，会拿到物理 cpu 个数，而不是容器申请时的个数</li>
<li>这个问题直到 jdk 10 才修复，使用 jvm 参数 UseContainerSupport 配置， 默认开启</li>
</ul>
</blockquote>
<h3 id="47-udp">4.7 UDP</h3>
<ul>
<li>UDP 是无连接的，client 发送数据不会管 server 是否开启</li>
<li>server 这边的 receive 方法会将接收到的数据存入 byte buffer，但如果数据报文超过 buffer 大小，多出来的数据会被默默抛弃</li>
</ul>
<p>首先启动服务器端</p>
<pre><code class="language-java">public class UdpServer {
    public static void main(String[] args) {
        try (DatagramChannel channel = DatagramChannel.open()) {
            channel.socket().bind(new InetSocketAddress(9999));
            System.out.println(&quot;waiting...&quot;);
            ByteBuffer buffer = ByteBuffer.allocate(32);
            channel.receive(buffer);
            buffer.flip();
            debug(buffer);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>输出</p>
<pre><code>waiting...
</code></pre>
<p>运行客户端</p>
<pre><code class="language-java">public class UdpClient {
    public static void main(String[] args) {
        try (DatagramChannel channel = DatagramChannel.open()) {
            ByteBuffer buffer = StandardCharsets.UTF_8.encode(&quot;hello&quot;);
            InetSocketAddress address = new InetSocketAddress(&quot;localhost&quot;, 9999);
            channel.send(buffer, address);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>接下来服务器端输出</p>
<pre><code>         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 68 65 6c 6c 6f                                  |hello           |
+--------+-------------------------------------------------+----------------+
</code></pre>
<h2 id="5-nio-vs-bio">5. NIO vs BIO</h2>
<h3 id="51-stream-vs-channel">5.1 stream vs channel</h3>
<ul>
<li>stream 不会自动缓冲数据，channel 会利用系统提供的发送缓冲区、接收缓冲区（更为底层）</li>
<li>stream 仅支持阻塞 API，channel 同时支持阻塞、非阻塞 API，网络 channel 可配合 selector 实现多路复用</li>
<li>二者均为全双工，即读写可以同时进行</li>
</ul>
<h3 id="52-io-模型">5.2 IO 模型</h3>
<p>同步阻塞、同步非阻塞、同步多路复用、异步阻塞（没有此情况）、异步非阻塞</p>
<ul>
<li>同步：线程自己去获取结果（一个线程）</li>
<li>异步：线程自己不去获取结果，而是由其它线程送结果（至少两个线程）</li>
</ul>
<p>当调用一次 channel.read 或 stream.read 后，会切换至操作系统内核态来完成真正数据读取，而读取又分为两个阶段，分别为：</p>
<ul>
<li>等待数据阶段</li>
<li>复制数据阶段</li>
</ul>
<figure data-type="image" tabindex="5"><img src="img/0033.png" alt="" loading="lazy"></figure>
<ul>
<li>
<p>阻塞 IO</p>
<figure data-type="image" tabindex="6"><img src="img/0039.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>非阻塞  IO</p>
<figure data-type="image" tabindex="7"><img src="img/0035.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>多路复用</p>
<figure data-type="image" tabindex="8"><img src="img/0038.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>信号驱动</p>
</li>
<li>
<p>异步 IO</p>
<figure data-type="image" tabindex="9"><img src="img/0037.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>阻塞 IO vs 多路复用</p>
<figure data-type="image" tabindex="10"><img src="img/0034.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="11"><img src="img/0036.png" alt="" loading="lazy"></figure>
</li>
</ul>
<h4 id="参考">🔖 参考</h4>
<p>UNIX 网络编程 - 卷 I</p>
<h3 id="53-零拷贝">5.3 零拷贝</h3>
<h4 id="传统-io-问题">传统 IO 问题</h4>
<p>传统的 IO 将一个文件通过 socket 写出</p>
<pre><code class="language-java">File f = new File(&quot;helloword/data.txt&quot;);
RandomAccessFile file = new RandomAccessFile(file, &quot;r&quot;);

byte[] buf = new byte[(int)f.length()];
file.read(buf);

Socket socket = ...;
socket.getOutputStream().write(buf);
</code></pre>
<p>内部工作流程是这样的：</p>
<figure data-type="image" tabindex="12"><img src="img/0024.png" alt="" loading="lazy"></figure>
<ol>
<li>
<p>java 本身并不具备 IO 读写能力，因此 read 方法调用后，要从 java 程序的<strong>用户态</strong>切换至<strong>内核态</strong>，去调用操作系统（Kernel）的读能力，将数据读入<strong>内核缓冲区</strong>。这期间用户线程阻塞，操作系统使用 DMA（Direct Memory Access）来实现文件读，其间也不会使用 cpu</p>
<blockquote>
<p>DMA 也可以理解为硬件单元，用来解放 cpu 完成文件 IO</p>
</blockquote>
</li>
<li>
<p>从<strong>内核态</strong>切换回<strong>用户态</strong>，将数据从<strong>内核缓冲区</strong>读入<strong>用户缓冲区</strong>（即 byte[] buf），这期间 cpu 会参与拷贝，无法利用 DMA</p>
</li>
<li>
<p>调用 write 方法，这时将数据从<strong>用户缓冲区</strong>（byte[] buf）写入 <strong>socket 缓冲区</strong>，cpu 会参与拷贝</p>
</li>
<li>
<p>接下来要向网卡写数据，这项能力 java 又不具备，因此又得从<strong>用户态</strong>切换至<strong>内核态</strong>，调用操作系统的写能力，使用 DMA 将 <strong>socket 缓冲区</strong>的数据写入网卡，不会使用 cpu</p>
</li>
</ol>
<p>可以看到中间环节较多，java 的 IO 实际不是物理设备级别的读写，而是缓存的复制，底层的真正读写是操作系统来完成的</p>
<ul>
<li>用户态与内核态的切换发生了 3 次，这个操作比较重量级</li>
<li>数据拷贝了共 4 次</li>
</ul>
<h4 id="nio-优化">NIO 优化</h4>
<p>通过 DirectByteBuf</p>
<ul>
<li>ByteBuffer.allocate(10)  HeapByteBuffer 使用的还是 java 内存</li>
<li>ByteBuffer.allocateDirect(10)  DirectByteBuffer 使用的是操作系统内存</li>
</ul>
<figure data-type="image" tabindex="13"><img src="img/0025.png" alt="" loading="lazy"></figure>
<p>大部分步骤与优化前相同，不再赘述。唯有一点：java 可以使用 DirectByteBuf 将堆外内存映射到 jvm 内存中来直接访问使用</p>
<ul>
<li>这块内存不受 jvm 垃圾回收的影响，因此内存地址固定，有助于 IO 读写</li>
<li>java 中的 DirectByteBuf 对象仅维护了此内存的虚引用，内存回收分成两步
<ul>
<li>DirectByteBuf 对象被垃圾回收，将虚引用加入引用队列</li>
<li>通过专门线程访问引用队列，根据虚引用释放堆外内存</li>
</ul>
</li>
<li>减少了一次数据拷贝，用户态与内核态的切换次数没有减少</li>
</ul>
<p>进一步优化（底层采用了 linux 2.1 后提供的 sendFile 方法），java 中对应着两个 channel 调用 transferTo/transferFrom 方法拷贝数据</p>
<figure data-type="image" tabindex="14"><img src="img/0026.png" alt="" loading="lazy"></figure>
<ol>
<li>java 调用 transferTo 方法后，要从 java 程序的<strong>用户态</strong>切换至<strong>内核态</strong>，使用 DMA将数据读入<strong>内核缓冲区</strong>，不会使用 cpu</li>
<li>数据从<strong>内核缓冲区</strong>传输到 <strong>socket 缓冲区</strong>，cpu 会参与拷贝</li>
<li>最后使用 DMA 将 <strong>socket 缓冲区</strong>的数据写入网卡，不会使用 cpu</li>
</ol>
<p>可以看到</p>
<ul>
<li>只发生了一次用户态与内核态的切换</li>
<li>数据拷贝了 3 次</li>
</ul>
<p>进一步优化（linux 2.4）</p>
<figure data-type="image" tabindex="15"><img src="img/0027.png" alt="" loading="lazy"></figure>
<ol>
<li>java 调用 transferTo 方法后，要从 java 程序的<strong>用户态</strong>切换至<strong>内核态</strong>，使用 DMA将数据读入<strong>内核缓冲区</strong>，不会使用 cpu</li>
<li>只会将一些 offset 和 length 信息拷入 <strong>socket 缓冲区</strong>，几乎无消耗</li>
<li>使用 DMA 将 <strong>内核缓冲区</strong>的数据写入网卡，不会使用 cpu</li>
</ol>
<p>整个过程仅只发生了一次用户态与内核态的切换，数据拷贝了 2 次。所谓的【零拷贝】，并不是真正无拷贝，而是在不会拷贝重复数据到 jvm 内存中，零拷贝的优点有</p>
<ul>
<li>更少的用户态与内核态的切换</li>
<li>不利用 cpu 计算，减少 cpu 缓存伪共享</li>
<li>零拷贝适合小文件传输</li>
</ul>
<h3 id="53-aio">5.3 AIO</h3>
<p>AIO 用来解决数据复制阶段的阻塞问题</p>
<ul>
<li>同步意味着，在进行读写操作时，线程需要等待结果，还是相当于闲置</li>
<li>异步意味着，在进行读写操作时，线程不必等待结果，而是将来由操作系统来通过回调方式由另外的线程来获得结果</li>
</ul>
<blockquote>
<p>异步模型需要底层操作系统（Kernel）提供支持</p>
<ul>
<li>Windows 系统通过 IOCP 实现了真正的异步 IO</li>
<li>Linux 系统异步 IO 在 2.6 版本引入，但其底层实现还是用多路复用模拟了异步 IO，性能没有优势</li>
</ul>
</blockquote>
<h4 id="文件-aio">文件 AIO</h4>
<p>先来看看 AsynchronousFileChannel</p>
<pre><code class="language-java">@Slf4j
public class AioDemo1 {
    public static void main(String[] args) throws IOException {
        try{
            AsynchronousFileChannel s = 
                AsynchronousFileChannel.open(
                	Paths.get(&quot;1.txt&quot;), StandardOpenOption.READ);
            ByteBuffer buffer = ByteBuffer.allocate(2);
            log.debug(&quot;begin...&quot;);
            s.read(buffer, 0, null, new CompletionHandler&lt;Integer, ByteBuffer&gt;() {
                @Override
                public void completed(Integer result, ByteBuffer attachment) {
                    log.debug(&quot;read completed...{}&quot;, result);
                    buffer.flip();
                    debug(buffer);
                }

                @Override
                public void failed(Throwable exc, ByteBuffer attachment) {
                    log.debug(&quot;read failed...&quot;);
                }
            });

        } catch (IOException e) {
            e.printStackTrace();
        }
        log.debug(&quot;do other things...&quot;);
        System.in.read();
    }
}
</code></pre>
<p>输出</p>
<pre><code>13:44:56 [DEBUG] [main] c.i.aio.AioDemo1 - begin...
13:44:56 [DEBUG] [main] c.i.aio.AioDemo1 - do other things...
13:44:56 [DEBUG] [Thread-5] c.i.aio.AioDemo1 - read completed...2
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 61 0d                                           |a.              |
+--------+-------------------------------------------------+----------------+
</code></pre>
<p>可以看到</p>
<ul>
<li>响应文件读取成功的是另一个线程 Thread-5</li>
<li>主线程并没有 IO 操作阻塞</li>
</ul>
<h4 id="守护线程">💡 守护线程</h4>
<p>默认文件 AIO 使用的线程都是守护线程，所以最后要执行 <code>System.in.read()</code> 以避免守护线程意外结束</p>
<h4 id="网络-aio">网络 AIO</h4>
<pre><code class="language-java">public class AioServer {
    public static void main(String[] args) throws IOException {
        AsynchronousServerSocketChannel ssc = AsynchronousServerSocketChannel.open();
        ssc.bind(new InetSocketAddress(8080));
        ssc.accept(null, new AcceptHandler(ssc));
        System.in.read();
    }

    private static void closeChannel(AsynchronousSocketChannel sc) {
        try {
            System.out.printf(&quot;[%s] %s close\n&quot;, Thread.currentThread().getName(), sc.getRemoteAddress());
            sc.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    private static class ReadHandler implements CompletionHandler&lt;Integer, ByteBuffer&gt; {
        private final AsynchronousSocketChannel sc;

        public ReadHandler(AsynchronousSocketChannel sc) {
            this.sc = sc;
        }

        @Override
        public void completed(Integer result, ByteBuffer attachment) {
            try {
                if (result == -1) {
                    closeChannel(sc);
                    return;
                }
                System.out.printf(&quot;[%s] %s read\n&quot;, Thread.currentThread().getName(), sc.getRemoteAddress());
                attachment.flip();
                System.out.println(Charset.defaultCharset().decode(attachment));
                attachment.clear();
                // 处理完第一个 read 时，需要再次调用 read 方法来处理下一个 read 事件
                sc.read(attachment, attachment, this);
            } catch (IOException e) {
                e.printStackTrace();
            }
        }

        @Override
        public void failed(Throwable exc, ByteBuffer attachment) {
            closeChannel(sc);
            exc.printStackTrace();
        }
    }

    private static class WriteHandler implements CompletionHandler&lt;Integer, ByteBuffer&gt; {
        private final AsynchronousSocketChannel sc;

        private WriteHandler(AsynchronousSocketChannel sc) {
            this.sc = sc;
        }

        @Override
        public void completed(Integer result, ByteBuffer attachment) {
            // 如果作为附件的 buffer 还有内容，需要再次 write 写出剩余内容
            if (attachment.hasRemaining()) {
                sc.write(attachment);
            }
        }

        @Override
        public void failed(Throwable exc, ByteBuffer attachment) {
            exc.printStackTrace();
            closeChannel(sc);
        }
    }

    private static class AcceptHandler implements CompletionHandler&lt;AsynchronousSocketChannel, Object&gt; {
        private final AsynchronousServerSocketChannel ssc;

        public AcceptHandler(AsynchronousServerSocketChannel ssc) {
            this.ssc = ssc;
        }

        @Override
        public void completed(AsynchronousSocketChannel sc, Object attachment) {
            try {
                System.out.printf(&quot;[%s] %s connected\n&quot;, Thread.currentThread().getName(), sc.getRemoteAddress());
            } catch (IOException e) {
                e.printStackTrace();
            }
            ByteBuffer buffer = ByteBuffer.allocate(16);
            // 读事件由 ReadHandler 处理
            sc.read(buffer, buffer, new ReadHandler(sc));
            // 写事件由 WriteHandler 处理
            sc.write(Charset.defaultCharset().encode(&quot;server hello!&quot;), ByteBuffer.allocate(16), new WriteHandler(sc));
            // 处理完第一个 accpet 时，需要再次调用 accept 方法来处理下一个 accept 事件
            ssc.accept(null, this);
        }

        @Override
        public void failed(Throwable exc, Object attachment) {
            exc.printStackTrace();
        }
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JAVA并发（二）]]></title>
        <id>https://q456qq520.github.io/post/java-bing-fa-er/</id>
        <link href="https://q456qq520.github.io/post/java-bing-fa-er/">
        </link>
        <updated>2022-08-10T06:52:00.000Z</updated>
        <content type="html"><![CDATA[<h1 id="4-java中的锁">4、Java中的锁</h1>
<h2 id="41-lock接口">4.1 Lock接口</h2>
<p>锁是用来控制多个线程访问共享资源的方式，一般来说，一个锁能够防止多个线程同时访问共享资源（但是有些锁可以允许多个线程并发的访问共享资源，比如读写锁）。在Lock接口出现之前，Java程序是靠synchronized关键字实现锁功能的，而Java SE 5之后，并发包中新增了<strong>Lock接口</strong>（以及相关实现类）用来实现锁功能，它提供了与<strong>synchronized</strong>关键字类似的同步功能，只是在使用时需要显式地获取和释放锁。虽然它缺少了（通过synchronized块或者方法所提供的）隐式获取释放锁的便捷性，但是却拥有了锁获取与释放的可操作性、可中断的获取锁以及超时获取锁等多种synchronized关键字所不具备的同步特性。</p>
<p>使用synchronized关键字将会隐式地获取锁，但是它将锁的获取和释放固化了，也就是先获取再释放。当然，这种方式简化了同步的管理，可是扩展性没有显示的锁获取和释放来的好。例如，针对一个场景，手把手进行锁获取和释放，先获得锁A，然后再获取锁B，当锁B获得后，释放锁A同时获取锁C，当锁C获得后，再释放B同时获取锁D，以此类推。这种场景下，synchronized关键字就不那么容易实现了，而使用Lock却容易许多。</p>
<p>Lock的使用也很简单，代码清单4-1是Lock的使用的方式。</p>
<blockquote>
<p>代码清单4-1 LockUseCase.java</p>
</blockquote>
<pre><code class="language-java">Lock lock = new ReentrantLock();
lock.lock();
try {
            
} finally {
    lock.unlock();
}
</code></pre>
<p>在finally块中释放锁，目的是保证在获取到锁之后，最终能够被释放。<em>不要将获取锁的过程写在try块中，因为如果在获取锁（自定义锁的实现）时发生了异常，异常抛出的同时，也会导致锁无故释放。</em></p>
<p>Lock接口提供的synchronized关键字所不具备的主要特性如下所示。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1660118700493.png" alt="Lock接口提供的synchronized关键字不具备的主要特性" loading="lazy"></figure>
<p>Lock是一个接口，它定义了锁获取和释放的基本操作，Lock的API如下所示。</p>
<blockquote>
<p>Lock的API</p>
</blockquote>
<pre><code class="language-java">
//获取锁，调用该方法当前线程会获取锁，当锁获得后，返回
void lock();

//可中断获取锁，即在锁的获取中可中断当前线程
void lockInterruptibly() throws InterruptedException;

//尝试非阻塞的获取锁，调用该方法后立即返回，如果能够获取则返回ture，反之false
boolean tryLock();

//超时获取锁，当前线程在以下三种情况会返回
//1、当前线程在超时时间内获得锁
//2、当前线程在超时时间内被中断
//3、超时时间结束,返回false
boolean tryLock(long time, TimeUnit unit) throws InterruptedException;

//释放锁
void unlock();

//获取等待通知组件，该组件和当前锁绑定。当前线程只有获取了锁，才能调用该组件大wait()，而调用后当前线程释放锁
Condition newCondition();
</code></pre>
<p>Lock接口的实现基本都是通过聚合了一个同步器的子类来完成线程访问控制的。</p>
<h2 id="42-队列同步器">4.2 队列同步器</h2>
<p>队列同步器AbstractQueuedSynchronizer（以下简称同步器），是用来构建锁或者其他同步组件的基础框架，它使用了一个<strong>int成员变量</strong>表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。</p>
<p>同步器的主要使用方式是继承，子类通过继承同步器并实现它的抽象方法来管理同步状态，在抽象方法的实现过程中免不了要对同步状态进行更改，这时就需要使用同步器提供的3个方法（getState()、setState(int newState)和compareAndSetState(int expect,int update)）来进行操作，因为它们能够保证状态的改变是安全的。</p>
<p>同步器自身没有实现任何同步接口，它仅仅是定义了若干同步状态获取和释放的方法来供自定义同步组件使用，同步器既可以支持独占式地获取同步状态，也可以支持共享式地获取同步状态，这样就可以方便实现不同类型的同步组件（ReentrantLock、ReentrantReadWriteLock和CountDownLatch等）。</p>
<p>同步器是实现锁（也可以是任意同步组件）的关键，在锁的实现中聚合同步器，利用同步器实现锁的语义。可以这样理解二者之间的关系：<strong>锁是面向使用者的，它定义了使用者与锁交互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。</strong></p>
<h3 id="421-队列同步器的接口与示例">4.2.1 队列同步器的接口与示例</h3>
<p>同步器的设计是基于<strong>模板方法模式</strong>的，也就是说，使用者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。</p>
<p>重写同步器指定的方法时，需要使用同步器提供的如下3个方法来访问或修改同步状态。</p>
<p>getState()：获取当前同步状态。<br>
setState(int newState)：设置当前同步状态。<br>
compareAndSetState(int expect,int update)：使用CAS设置当前状态，该方法能够保证状态设置的原子性。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1660120867568.png" alt="同步器可重写的方法" loading="lazy"></figure>
<p>实现自定义同步组件时，将会调用同步器提供的模板方法。</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1660121528935.png" alt="同步器提供的模板方法" loading="lazy"></figure>
<p>同步器提供的模板方法基本上分为3类：<strong>独占式获取与释放同步状态</strong>、<strong>共享式获取与释放同步状态</strong>和<strong>查询同步队列中的等待线程情况</strong>。自定义同步组件将使用同步器提供的模板方法来实现自己的同步语义。</p>
<p>只有掌握了同步器的工作原理才能更加深入地理解并发包中其他的并发组件，所以下面通过一个独占锁的示例来深入了解一下同步器的工作原理。</p>
<p>顾名思义，<strong>独占锁就是在同一时刻只能有一个线程获取到锁，而其他获取锁的线程只能处于同步队列中等待，只有获取锁的线程释放了锁，后继的线程才能够获取锁</strong>，如代码清单如下：</p>
<pre><code class="language-java">package cm.lock;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.AbstractQueuedSynchronizer;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;

/**
 * 独占锁
 * @author likecat
 * @version 1.0
 * @date 2022/8/10 16:58
 */
public class Mutex implements Lock {
    // 静态内部类，自定义同步器
    private static class Sync extends AbstractQueuedSynchronizer {
        // 是否处于占用状态
        protected boolean isHeldExclusively() {
            return getState() == 1;
        }
        // 当状态为0的时候获取锁
        public boolean tryAcquire(int acquires) {
            if (compareAndSetState(0, 1)) {
                ////设置拥有线程为当前线程
                setExclusiveOwnerThread(Thread.currentThread());
                return true;
            }
            return false;
        }
        // 释放锁，将状态设置为0
        protected boolean tryRelease(int releases) {
            if (getState() == 0) throw new
                    IllegalMonitorStateException();
            setExclusiveOwnerThread(null);
            setState(0);
            return true;
        }
        // 返回一个Condition，每个condition都包含了一个condition队列
        Condition newCondition() { return new ConditionObject(); }
    }
    // 仅需要将操作代理到Sync上即可
    private final Sync sync = new Sync();
    public void lock() { sync.acquire(1); }
    public boolean tryLock() { return sync.tryAcquire(1); }
    public void unlock() { sync.release(1); }
    public Condition newCondition() { return sync.newCondition(); }
    public boolean isLocked() { return sync.isHeldExclusively(); }
    public boolean hasQueuedThreads() { return sync.hasQueuedThreads(); }
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireInterruptibly(1);
    }
    public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
        return sync.tryAcquireNanos(1, unit.toNanos(timeout));
    }
}
</code></pre>
<p>上述示例中，独占锁Mutex是一个自定义同步组件，它在同一时刻只允许一个线程占有锁。Mutex中定义了一个静态内部类，该内部类继承了同步器并实现了独占式获取和释放同步状态。</p>
<p>在tryAcquire(int acquires)方法中，如果经过CAS设置成功（同步状态设置为1），则代表获取了同步状态，而在tryRelease(int releases)方法中只是将同步状态重置为0。用户使用Mutex时并不会直接和内部同步器的实现打交道，而是调用Mutex提供的方法，在Mutex的实现中，以获取锁的lock()方法为例，只需要在方法实现中调用同步器的模板方法acquire(int args)即可，当前线程调用该方法获取同步状态失败后会被加入到同步队列中等待，这样就大大降低了实现一个可靠自定义同步组件的门槛。</p>
<h3 id="422-队列同步器的实现分析">4.2.2 队列同步器的实现分析</h3>
<p>同步器是如何完成线程同步的步骤主要包括：同步队列、独占式同步状态获取与释放、共享式同步状态获取与释放以及超时获取同步状态等同步器的核心数据结构与模板方法</p>
<h5 id="1同步队列">1.同步队列</h5>
<p>同步器依赖内部的同步队列（一个FIFO双向队列）来完成同步状态的管理，当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。</p>
<p>同步队列中的节点（Node）用来保存<strong>获取同步状态失败的线程引用</strong>、<strong>等待状态</strong>以及<strong>前驱</strong>和<br>
<strong>后继节点</strong>，节点的属性类型与名称以及描述如下：</p>
<pre><code class="language-java">static final class Node {
    static final int CANCELLED =  1;
    static final int SIGNAL =       -1;
    static final int CONDITION = -2;
    static final int PROPAGATE = -3;
    //等待状态，包含如下状态
    //CANCELLED,值为1,由于在同步队列中等待的线程等待超时或者被中断，需要从同步队列中取消等待，节点进入该状态将不会变化
    //SIGNAL,值为-1,后继节点的线程处于等待状态，而当前节点的线程如果释放了同步状态或者被取消，将会通知后继节点，使后继节点的线程得以运行
    //CONDITION,值为-2,节点在等待队列中，节点线程等待在Condition上，而当其他线程对Condition调用了 signal。方法后，该节点将会从等待队列中转移到同步队列中，加入到对同步状态的获取中
    //PROPAGATE,值为-3.表示下一次共享式同步状态获取将会无条件地被传播下去
    //INITIAL,值为0,初始状态
    volatile int waitStatus;

    //前驱结点，当前结点加入同步队列时被设置
    volatile Node prev;

    //后继结点
    volatile Node next;

    //等待队列中的后继结点，如果当前结点是共享的，那么这个字段将是一个SHARED常量，也就是说结点类型（独占和共享）和等待队列中的后继结点公用一个字段
    Node nextWaiter;

    //获取同步状态的线程
     volatile Thread thread;
}
</code></pre>
<p>节点是构成同步队列的基础，同步器拥有首节点（head）和尾节点（tail），没有成功获取同步状态的线程将会成为节点加入该队列的尾部，同步队列的基本结构如图下所示。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1660147528285.png" alt="同步队列的基本结构" loading="lazy"></figure>
<p>同步器包含了两个节点类型的引用，一个指向头节点，而另一个指向尾节点。试想一下，当一个线程成功地获取了同步状态（或者锁），其他线程将无法获取到同步状态，转而被构造成为节点并加入到同步队列中，而这个加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect,Nodeupdate)，，它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。</p>
<p>同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点。</p>
<p>设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证，它只需要将首节点设置成为原首节点的后继节点并断开原首节点的next引用即可。</p>
<h5 id="2独占式同步状态获取与释放">2.独占式同步状态获取与释放</h5>
<p>通过调用同步器的acquire(int arg)方法可以获取同步状态，该方法对中断不敏感，也就是由于线程获取同步状态失败后进入同步队列中，后续对线程进行中断操作时，线程不会从同步队列中移出。</p>
<blockquote>
<p>同步器的acquire方法</p>
</blockquote>
<pre><code class="language-java">public final void acquire(int arg) {
        if (!tryAcquire(arg) &amp;&amp;
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }
</code></pre>
<p>上述代码主要完成了同步状态获取、节点构造、加入同步队列以及在同步队列中自旋等待的相关工作，其主要逻辑是：首先调用自定义同步器实现的tryAcquire(int arg)方法，该方法保证线程安全的获取同步状态，如果同步状态获取失败，则构造同步节点（独占式Node.EXCLUSIVE，同一时刻只能有一个线程成功获取同步状态）并通过addWaiter(Node node)方法将该节点加入到同步队列的尾部，最后调用acquireQueued(Node node,int arg)方法，使得该节点以“死循环”的方式获取同步状态。如果获取不到则阻塞节点中的线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现。</p>
<p>下面分析一下相关工作。首先是节点的构造以及加入同步队列，如下：</p>
<blockquote>
<p>同步器的addWaiter和enq方法</p>
</blockquote>
<pre><code class="language-java">private Node addWaiter(Node mode) {
    Node node = new Node(Thread.currentThread(), mode);
    // Try the fast path of enq; backup to full enq on failure
    Node pred = tail;
    if (pred != null) {
        node.prev = pred;
        //通过使用compareAndSetTail(Node expect,Node update)方法来确保节点能够被线程安全添加
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    enq(node);
    return node;
}

    private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}
</code></pre>
<p>在enq(final Node node)方法中，同步器通过“死循环”来保证节点的正确添加，在“死循环”中只有通过CAS将节点设置成为尾节点之后，当前线程才能从该方法返回，否则，当前线程不断地尝试设置。可以看出，enq(final Node node)方法将并发添加节点的请求通过CAS变得“串行化”了。</p>
<blockquote>
<p>同步器的acquireQueued方法</p>
</blockquote>
<pre><code class="language-java">@ReservedStackAccess
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head &amp;&amp; tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
} 
</code></pre>
<p>在acquireQueued(final Node node,int arg)方法中，当前线程在“死循环”中尝试获取同步状态，而只有前驱节点是头节点才能够尝试获取同步状态，这是为什么？原因有两个，如下。</p>
<p>第一，头节点是成功获取到同步状态的节点，而头节点的线程释放了同步状态之后，将会<br>
唤醒其后继节点，后继节点的线程被唤醒后需要检查自己的前驱节点是否是头节点。</p>
<p>第二，维护同步队列的FIFO原则。该方法中，节点自旋获取同步状态的行为如下图所示。</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1660187742025.png" alt="节点自旋获取同步状态" loading="lazy"></figure>
<p>由于非首节点线程前驱节点出队或者被中断而从等待状态返回，随后检查自己的前驱是否是头节点，如果是则尝试获取同步状态。可以看到节点和节点之间在循环检查的过程中基本不相互通信，而是简单地判断自己的前驱是否为头节点，这样就使得节点的释放规则符合FIFO，并且也便于对过早通知的处理（过早通知是指前驱节点不是头节点的线程由于中断而被唤醒）。</p>
<p>独占式同步状态获取流程，也就是acquire(int arg)方法调用流程，如下所示。</p>
<figure data-type="image" tabindex="6"><img src="https://q456qq520.github.io/post-images/1660187831672.png" alt="独占式同步状态获取流程" loading="lazy"></figure>
<p>前驱节点为头节点且能够获取同步状态的判断条件和线程进入等待状态是获取同步状态的自旋过程。当同步状态获取成功之后，当前线程从acquire(int arg)方法返回，如果对于锁这种并发组件而言，代表着当前线程获取了锁。</p>
<p>当前线程获取同步状态并执行了相应逻辑之后，就需要释放同步状态，使得后续节点能够继续获取同步状态。通过调用同步器的**release(int arg)**方法可以释放同步状态，该方法在释放了同步状态之后，会唤醒其后继节点（进而使后继节点重新尝试获取同步状态）。该方法代码如下所示。</p>
<pre><code class="language-java">@ReservedStackAccess
public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;
        if (h != null &amp;&amp; h.waitStatus != 0)
            unparkSuccessor(h);
        return true;
    }
    return false;
}
</code></pre>
<p>该方法执行时，会唤醒头节点的后继节点线程，unparkSuccessor(Node node)方法使用LockSupport来唤醒处于等待状态的线程。</p>
<p>分析了独占式同步状态获取和释放过程后，适当做个总结：在获取同步状态时，同步器维护一个同步队列，获取状态失败的线程都会被加入到队列中并在队列中进行自旋；移出队列（或停止自旋）的条件是前驱节点为头节点且成功获取了同步状态。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态，然后唤醒头节点的后继节点。</p>
<h5 id="3共享式同步状态获取与释放">3.共享式同步状态获取与释放</h5>
<p>共享式获取与独占式获取最主要的区别在于<strong>同一时刻能否有多个线程同时获取到同步状态。</strong></p>
<p>以文件的读写为例，如果一个程序在对文件进行读操作，那么这一时刻对于该文件的写操作均被阻塞，而读操作能够同时进行。写操作要求对资源的独占式访问，而读操作可以是共享式访问，两种不同的访问模式在同一时刻对文件或资源的访问情况。</p>
<p>通过调用同步器的acquireShared(int arg)方法可以共享式地获取同步状态，该方法代码如下所示。</p>
<blockquote>
<p>同步器的acquireShared和doAcquireShared方法</p>
</blockquote>
<pre><code class="language-java">public final void acquireShared(int arg) {
    //返回值大于等于0时，表示能够获取到同步状态
    if (tryAcquireShared(arg) &lt; 0)
        doAcquireShared(arg);
}

private void doAcquireShared(int arg) {
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head) {
                int r = tryAcquireShared(arg);
                //如果返回值大于等于0，表示该次获取同步状态成功并从自旋过程中退出
                if (r &gt;= 0) {
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    if (interrupted)
                        selfInterrupt();
                    failed = false;
                    return;
                }
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
</code></pre>
<p>在acquireShared(int arg)方法中，同步器调用tryAcquireShared(int arg)方法尝试获取同步状态，tryAcquireShared(int arg)方法返回值为int类型，当返回值大于等于0时，表示能够获取到同步状态。因此，在共享式获取的自旋过程中，成功获取到同步状态并退出自旋的条件就是tryAcquireShared(int arg)方法返回值大于等于0。可以看到，在doAcquireShared(int arg)方法的自旋过程中，如果当前节的前驱为头节点时，尝试获取同步状态，如果返回值大于等于0，表示该次获取同步状态成功并从自旋过程中退出。</p>
<p>与独占式一样，共享式获取也需要释放同步状态，通过调用releaseShared(int arg)方法可以释放同步状态，该方法代码如下所示。</p>
<blockquote>
<p>同步器的releaseShared方法</p>
</blockquote>
<pre><code class="language-java">@ReservedStackAccess
public final boolean releaseShared(int arg) {
    if (tryReleaseShared(arg)) {
        doReleaseShared();
        return true;
    }
    return false;
}
</code></pre>
<p>该方法在释放同步状态之后，将会唤醒后续处于等待状态的节点。对于能够支持多个线程同时访问的并发组件（比如Semaphore），它和独占式主要区别在于tryReleaseShared(int arg)方法必须确保同步状态（或者资源数）线程安全释放，一般是通过循环和CAS来保证的，因为释放同步状态的操作会同时来自多个线程。</p>
<blockquote>
<p>同步器的tryReleaseShared方法</p>
</blockquote>
<pre><code class="language-java">protected boolean tryReleaseShared(int releases) {
    // Decrement count; signal when transition to zero
    for (;;) {
        int c = getState();
        if (c == 0)
            return false;
        int nextc = c-1;
        if (compareAndSetState(c, nextc))
            return nextc == 0;
    }
}
</code></pre>
<h5 id="4独占式超时获取同步状态">4.独占式超时获取同步状态</h5>
<p>通过调用同步器的doAcquireNanos(int arg,long nanosTimeout)方法可以超时获取同步状态，**即在指定的时间段内获取同步状态，如果获取到同步状态则返回true，否则，返回false。**该方法提供了传统Java同步操作（比如synchronized关键字）所不具备的特性。</p>
<p>doAcquireNanos(int arg,long nanosTimeout)方法在支持响应中断的基础上，增加了超时获取的特性。针对超时获取，主要需要计算出需要睡眠的时间间隔nanosTimeout，如果nanosTimeout大于0则表示超时时间未到，需要继续睡眠nanosTimeout纳秒，反之，表示已经超时，</p>
<blockquote>
<p>同步器的doAcquireNanos方法</p>
</blockquote>
<pre><code class="language-java">private boolean doAcquireNanos(int arg, long nanosTimeout)
    throws InterruptedException {
if (nanosTimeout &lt;= 0L)
    return false;
final long deadline = System.nanoTime() + nanosTimeout;
final Node node = addWaiter(Node.EXCLUSIVE);
boolean failed = true;
try {
    for (;;) {
        final Node p = node.predecessor();
        if (p == head &amp;&amp; tryAcquire(arg)) {
            setHead(node);
            p.next = null; // help GC
            failed = false;
            return true;
        }
        nanosTimeout = deadline - System.nanoTime();
        if (nanosTimeout &lt;= 0L)
            return false;
        if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
            nanosTimeout &gt; spinForTimeoutThreshold)
            LockSupport.parkNanos(this, nanosTimeout);
        if (Thread.interrupted())
            throw new InterruptedException();
    }
} finally {
    if (failed)
        cancelAcquire(node);
}
}
</code></pre>
<p>该方法在自旋过程中，当节点的前驱节点为头节点时尝试获取同步状态，如果获取成功则从该方法返回，这个过程和独占式同步获取的过程类似，但是在同步状态获取失败的处理上有所不同。如果当前线程获取同步状态失败，则判断是否超时（nanosTimeout小于等于0表示已经超时），如果没有超时，重新计算超时间隔nanosTimeout，然后使当前线程等待nanosTimeout纳秒（当已到设置的超时时间，该线程会从LockSupport.parkNanos(Objectblocker,long nanos)方法返回）。</p>
<p>如果nanosTimeout小于等于spinForTimeoutThreshold（1000纳秒）时，将不会使该线程进行超时等待，而是进入快速的自旋过程。原因在于，非常短的超时等待无法做到十分精确，如果这时再进行超时等待，相反会让nanosTimeout的超时从整体上表现得反而不精确。因此，在超时非常短的场景下，同步器会进入无条件的快速自旋。</p>
<p>独占式超时获取同步状态doAcquireNanos(int arg,long nanosTimeout)和独占式获取同步状态acquire(int args)在流程上非常相似，其主要区别在于未获取到同步状态时的处理逻辑。acquire(int args)在未获取到同步状态时，将会使当前线程一直处于等待状态，而doAcquireNanos(int arg,long nanosTimeout)会使当前线程等待nanosTimeout纳秒，如果当前线程在nanosTimeout纳秒内没有获取到同步状态，将会从等待逻辑中自动返回。</p>
<figure data-type="image" tabindex="7"><img src="https://q456qq520.github.io/post-images/1660200122402.png" alt="独占式超时获取同步状态的流程" loading="lazy"></figure>
<h5 id="5自定义同步组件twinslock">5.自定义同步组件——TwinsLock</h5>
<p>设计一个同步工具：该工具在同一时刻，只允许至多两个线程同时访问，超过两个线程的访问将被阻塞，我们将这个同步工具命名为TwinsLock。</p>
<p>首先，确定访问模式。TwinsLock能够在同一时刻支持多个线程的访问，这显然是共享式访问，因此，需要使用同步器提供的acquireShared(int args)方法等和Shared相关的方法，这就要求TwinsLock必须重写tryAcquireShared(int args)方法和tryReleaseShared(int args)方法，这样才能保证同步器的共享式同步状态的获取与释放方法得以执行。</p>
<p>其次，定义资源数。TwinsLock在同一时刻允许至多两个线程的同时访问，表明同步资源数为2，这样可以设置初始状态status为2，当一个线程进行获取，status减1，该线程释放，则status加1，状态的合法范围为0、1和2，其中0表示当前已经有两个线程获取了同步资源，此时再有其他线程对同步状态进行获取，该线程只能被阻塞。在同步状态变更时，需要使用compareAndSet(int expect,int update)方法做原子性保障。</p>
<p>最后，组合自定义同步器。前面的章节提到，自定义同步组件通过组合自定义同步器来完成同步功能，一般情况下自定义同步器会被定义为自定义同步组件的内部类。</p>
<pre><code class="language-java">package cm.lock;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.AbstractQueuedSynchronizer;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;

/**
 * 自定义同步组件——TwinsLock
 * @author likecat
 * @version 1.0
 * @date 2022/8/11 15:00
 */
public class TwinsLock implements Lock {
    private final Sync sync = new Sync(2);
    private static final class Sync extends AbstractQueuedSynchronizer {
        Sync(int count) {
            if (count &lt;= 0) {
                throw new IllegalArgumentException(&quot;count must large than zero.&quot;);
            }
            setState(count);
        }
        public int tryAcquireShared(int reduceCount) {
            for (;;) {
                int current = getState();
                int newCount = current - reduceCount;
                if (newCount &gt;= 0 || compareAndSetState(current,
                        newCount)) {
                    return newCount;
                }
            }
        }
        public boolean tryReleaseShared(int returnCount) {
            for (;;) {
                int current = getState();
                int newCount = current + returnCount;
                if (compareAndSetState(current, newCount)) {
                    return true;
                }
            }
        }
    }
    public void lock() {
        sync.acquireShared(1);
    }

    @Override
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireInterruptibly(1);
    }

    @Override
    public boolean tryLock() {
        return sync.tryAcquireShared(1) &gt;= 0;
    }

    @Override
    public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {
        return sync.tryAcquireSharedNanos(1,time);
    }

    public void unlock() {
        sync.releaseShared(1);
    }

    @Override
    public Condition newCondition() {
        return null;
    }
}
</code></pre>
<p>TwinsLock实现了Lock接口，提供了面向使用者的接口，使用者调用lock()方法获取锁，随后调用unlock()方法释放锁，而同一时刻只能有两个线程同时获取到锁。TwinsLock同时包含了一个自定义同步器Sync，而该同步器面向线程访问和同步状态控制。以共享式获取同步状态为例：同步器会先计算出获取后的同步状态，然后通过CAS确保状态的正确设置，当tryAcquireShared(int reduceCount)方法返回值大于等于0时，当前线程才获取同步状态，对于上层的TwinsLock而言，则表示当前线程获得了锁。</p>
<p>同步器作为一个桥梁，连接线程访问以及同步状态控制等底层技术与不同并发组件（比如Lock、CountDownLatch等）的接口语义。</p>
<p>下面编写一个测试来验证TwinsLock是否能按照预期工作。在测试用例中，定义了工作者线程Worker，该线程在执行过程中获取锁，当获取锁之后使当前线程睡眠1秒（并不释放锁），随后打印当前线程名称，最后再次睡眠1秒并释放锁，测试用例如下所示。</p>
<pre><code class="language-java">package cm.lock;

import cm.SleepUtils;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/11 15:11
 */
public class TwinsLockTest {

    public static void main(String[] args) throws InterruptedException {
        TwinsLock lock = new TwinsLock();
         class Worker extends Thread {
            public void run() {
                while (true) {
                    lock.lock();
                    try {
                        SleepUtils.second(1);
                        System.out.println(Thread.currentThread().getName());
                        SleepUtils.second(1);
                    } finally {
                        lock.unlock();
                    }
                }
            }
        }
        // 启动10个线程
        for (int i = 0; i &lt; 10; i++) {
            Worker w = new Worker();
            w.setDaemon(true);
            w.start();
        }
//         每隔1秒换行
        for (int i = 0; i &lt; 10; i++) {
            SleepUtils.second(1);
            System.out.println();
        }
    }

}
</code></pre>
<p>运行该测试用例，可以看到线程名称成对输出，也就是在同一时刻只有两个线程能够获取到锁，这表明TwinsLock可以按照预期正确工作。</p>
<h2 id="43-重入锁">4.3 重入锁</h2>
<p>重入锁ReentrantLock，顾名思义，就是支持重进入的锁，<strong>它表示该锁能够支持一个线程对资源的重复加锁。除此之外，该锁的还支持获取锁时的公平和非公平性选择</strong>。</p>
<p>synchronized关键字隐式的支持重进入，比如一个synchronized修饰的递归方法，在方法执行时，执行线程在获取了锁之后仍能连续多次地获得该锁。</p>
<p>ReentrantLock虽然没能像synchronized关键字一样支持隐式的重进入，但是在调用lock()方法时，已经获取到锁的线程，能够再次调用lock()方法获取锁而不被阻塞。</p>
<p>这里提到一个锁获取的公平性问题，<strong>如果在绝对时间上，先对锁进行获取的请求一定先被满足，那么这个锁是公平的，反之，是不公平的</strong>。公平的获取锁，也就是等待时间最长的线程最优先获取锁，也可以说锁获取是顺序的。ReentrantLock提供了一个构造函数，能够控制锁是否是公平的。</p>
<p>事实上，公平的锁机制往往没有非公平的效率高，但是，并不是任何场景都是以TPS作为唯一的指标，公平锁能够减少“饥饿”发生的概率，等待越久的请求越是能够得到优先满足。</p>
<h5 id="1实现重进入">1.实现重进入</h5>
<p>重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞，该特性的实现需要解决以下两个问题。</p>
<blockquote>
<p>1）线程再次获取锁。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。</p>
</blockquote>
<blockquote>
<p>2）锁的最终释放。线程重复n次获取了锁，随后在第n次释放该锁后，其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于0时表示锁已经成功释放。</p>
</blockquote>
<p>ReentrantLock是通过组合自定义同步器来实现锁的获取与释放，以非公平性（默认的）实现为例，获取同步状态的代码如下所示。</p>
<blockquote>
<p>ReentrantLock的nonfairTryAcquire方法</p>
</blockquote>
<pre><code class="language-java">final boolean nonfairTryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            if (compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc &lt; 0) // overflow
                throw new Error(&quot;Maximum lock count exceeded&quot;);
            setState(nextc);
            return true;
        }
        return false;
    }
</code></pre>
<p>该方法增加了再次获取同步状态的处理逻辑：通过判断当前线程是否为获取锁的线程来决定获取操作是否成功，如果是获取锁的线程再次请求，则将同步状态值进行增加并返回true，表示获取同步状态成功。</p>
<p>成功获取锁的线程再次获取锁，只是增加了同步状态值，这也就要求ReentrantLock在释放同步状态时减少同步状态值，该方法的代码如下所示。</p>
<blockquote>
<p>ReentrantLock的tryRelease方法</p>
</blockquote>
<pre><code class="language-java">protected final boolean tryRelease(int releases) {
        int c = getState() - releases;
        if (Thread.currentThread() != getExclusiveOwnerThread())
            throw new IllegalMonitorStateException();
        boolean free = false;
        if (c == 0) {
            free = true;
            setExclusiveOwnerThread(null);
        }
        setState(c);
        return free;
    }
</code></pre>
<p>如果该锁被获取了n次，那么前(n-1)次tryRelease(int releases)方法必须返回false，而只有同步状态完全释放了，才能返回true。可以看到，该方法将同步状态是否为0作为最终释放的条件，当同步状态为0时，将占有线程设置为null，并返回true，表示释放成功。</p>
<h5 id="2公平与非公平获取锁的区别">2.公平与非公平获取锁的区别</h5>
<p>公平性与否是针对获取锁而言的，如果一个锁是公平的，那么锁的获取顺序就应该符合请求的绝对时间顺序，也就是FIFO。</p>
<p>对于非公平锁，只要CAS设置同步状态成功，则表示当前线程获取了锁，而公平锁则不同，代码如下所示。</p>
<blockquote>
<p>ReentrantLock的tryAcquire方法</p>
</blockquote>
<pre><code class="language-java">protected final boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            if (!hasQueuedPredecessors() &amp;&amp;
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc &lt; 0)
                throw new Error(&quot;Maximum lock count exceeded&quot;);
            setState(nextc);
            return true;
        }
        return false;
    }
    ```

该方法与nonfairTryAcquire(int acquires)比较，唯一不同的位置为判断条件多了hasQueuedPredecessors()方法，即加入了同步队列中当前节点是否有前驱节点的判断，如果该方法返回true，则表示有线程比当前线程更早地请求获取锁，因此需要等待前驱线程获取并释放锁之后才能继续获取锁。

下面编写一个测试来观察公平和非公平锁在获取锁时的区别，在测试用例中定义了内部类ReentrantLock2，该类主要公开了getQueuedThreads()方法，该方法返回正在等待获取锁的线程列表，由于列表是逆序输出，为了方便观察结果，将其进行反转，测试用例（部分）如下所示。

```java
package cm.lock;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/11 17:19
 */
public class FairAndUnfairTest {
    private static Lock fairLock = new ReentrantLock2(true);
    private static Lock unfairLock = new ReentrantLock2(false);

public static void main(String[] args) {
    testLock(unfairLock);
    System.out.println(&quot;--------&quot;);
    testLock(fairLock);
}

    private static void testLock(Lock lock) {
        // 启动5个Job
        for (int i = 0; i &lt; 5; i++) {
            Job job = new Job(lock);
            job.start();
        }
    }
    private static class Job extends Thread {
        private Lock lock;
        public Job(Lock lock) {
            this.lock = lock;
        }
        public void run() {
            // 连续2次打印当前的Thread和等待队列中的Thread
            for (int i = 0; i &lt; 2; i++) {
                lock.lock();
                try {
                        Thread.sleep(1000);
                        System.out.println(&quot;获取锁的当前线程[&quot; + Thread.currentThread().getName() + &quot;], 同步队列中的线程&quot; + ((ReentrantLock2)lock).getQueuedThreads() + &quot;&quot;);
                } catch (InterruptedException e) {
                     e.printStackTrace();
                } finally {
                 lock.unlock();
                }
            }
        }
    }
    private static class ReentrantLock2 extends ReentrantLock {
        public ReentrantLock2(boolean fair) {
            super(fair);
        }

        public Collection&lt;Thread&gt; getQueuedThreads() {
            List&lt;Thread&gt; arrayList = new ArrayList&lt;Thread&gt;(super.
                    getQueuedThreads());
            Collections.reverse(arrayList);
            return arrayList;
        }
    }
}
</code></pre>
<p>公平性锁每次都是从同步队列中的第一个节点获取到锁，而非公平性锁出现了一个线程连续获取锁的情况。</p>
<p>为什么会出现线程连续获取锁的情况呢？回顾nonfairTryAcquire(int acquires)方法，当一个线程请求锁时，只要获取了同步状态即成功获取锁。在这个前提下，刚释放锁的线程再次获取同步状态的几率会非常大，使得其他线程只能在同步队列中等待。<strong>非公平性锁可能使线程“饥饿”。</strong></p>
<p><em><strong>公平性锁保证了锁的获取按照FIFO原则，而代价是进行大量的线程切换。非公平性锁虽然可能造成线程“饥饿”，但极少的线程切换，保证了其更大的吞吐量。</strong></em></p>
<h2 id="54-读写锁">5.4 读写锁</h2>
<p>之前提到锁（如Mutex和ReentrantLock）基本都是排他锁，这些锁在同一时刻只允许一个线程进行访问，而读写锁在同一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程和其他写线程均被阻塞。<strong>读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大提升。</strong></p>
<p>一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的。在读多于写的情况下，读写锁能够提供比排它锁更好的并发性和吞吐量。Java并发包提供读写锁的实现是ReentrantReadWriteLock，它提供的特性如下所示。</p>
<figure data-type="image" tabindex="8"><img src="https://q456qq520.github.io/post-images/1660287490202.png" alt="ReentrantReadWriteLock的特性" loading="lazy"></figure>
<h3 id="441-读写锁的接口与示例">4.4.1 读写锁的接口与示例</h3>
<p>ReadWriteLock仅定义了获取读锁和写锁的两个方法，即readLock()方法和writeLock()方法，而其实现——ReentrantReadWriteLock，除了接口方法之外，还提供了一些便于外界监控其内部工作状态的方法，这些方法以及描述如下所示。</p>
<blockquote>
<p>ReentrantReadWriteLock展示内部工作状态的方法</p>
</blockquote>
<pre><code class="language-java">//返回当前度锁被获取的次数，该次数不能与获取读锁的线程数
int getReadLockCount() 

//返回当前线程获取读锁的次数
int getReadHoldCount()

//判断写锁是否被获取
boolean isWriteLocked()

//返回当前写锁被获取的次数
int getWriteHoldCount()
</code></pre>
<p>接下来，通过一个缓存示例说明读写锁的使用方式，示例代码如下所示：</p>
<pre><code class="language-java">package cm.lock;

import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

/**
 * 读写锁缓存示例
 * @author likecat
 * @version 1.0
 * @date 2022/8/12 15:06
 */
public class Cache {
    static Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();
    static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
    static Lock r = rwl.readLock();
    static Lock w = rwl.writeLock();
    // 获取一个key对应的value
    public static final Object get(String key) {
        r.lock();
        try {
            return map.get(key);
        } finally {
            r.unlock();
        }
    }
    // 设置key对应的value，并返回旧的value
    public static final Object put(String key, Object value) {
        w.lock();
        try {
            return map.put(key, value);
        } finally {
            w.unlock();
        }
    }
    
    // 清空所有的内容
    public static final void clear() {
        w.lock();
        try {
            map.clear();
        } finally {
            w.unlock();
        }
    }
}
</code></pre>
<p>上述示例中，Cache组合一个非线程安全的HashMap作为缓存的实现，同时使用读写锁的读锁和写锁来保证Cache是线程安全的。在读操作get(String key)方法中，需要获取读锁，这使得并发访问该方法时不会被阻塞。写操作put(String key,Object value)方法和clear()方法，在更新HashMap时必须提前获取写锁，当获取写锁后，其他线程对于读锁和写锁的获取均被阻塞，而只有写锁被释放之后，其他读写操作才能继续。Cache使用读写锁提升读操作的并发性，也保证每次写操作对所有的读写操作的可见性。</p>
<h3 id="442-读写锁的实现分析">4.4.2 读写锁的实现分析</h3>
<h5 id="1读写状态的设计">1.读写状态的设计</h5>
<p><em>读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。</em></p>
<p>回想ReentrantLock中自定义同步器的实现，同步状态表示锁被一个线程重复获取的次数，而读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状态。</p>
<p>如果在一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量，读写锁将变量切分成了两个部分，<strong>高16位表示读，低16位表示写</strong>，划分方式如下所示。</p>
<figure data-type="image" tabindex="9"><img src="https://q456qq520.github.io/post-images/1660288434069.png" alt="读写锁状态的划分方式" loading="lazy"></figure>
<p>当前同步状态表示一个线程已经获取了写锁，且重进入了两次，同时也连续获取了两次读锁。读写锁是如何迅速确定读和写各自的状态呢？答案是通过位运算。假设当前同步状态值为S，写状态等于S&amp;0x0000FFFF（将高16位全部抹去），读状态等于S&gt;&gt;&gt;16（无符号补0右移16位）。当写状态增加1时，等于S+1，当读状态增加1时，等于S+(1&lt;&lt;16)，也就是S+0x00010000。</p>
<p>根据状态的划分能得出一个推论：<em><strong>S不等于0时，当写状态（S&amp;0x0000FFFF）等于0时，则读状态（S&gt;&gt;&gt;16）大于0，即读锁已被获取。</strong></em></p>
<h5 id="2写锁的获取与释放">2.写锁的获取与释放</h5>
<p>写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态，获取写锁的代码如下所示。</p>
<blockquote>
<p>ReentrantReadWriteLock的tryAcquire方法</p>
</blockquote>
<pre><code class="language-java">protected final boolean tryAcquire(int acquires) {
    Thread current = Thread.currentThread();
    int c = getState();
    int w = exclusiveCount(c);
    if (c != 0) {
        // (Note: if c != 0 and w == 0 then shared count != 0)
        //// 存在读锁或者当前获取线程不是已经获取写锁的线程
        if (w == 0 || current != getExclusiveOwnerThread())
            return false;
        if (w + exclusiveCount(acquires) &gt; MAX_COUNT)
            throw new Error(&quot;Maximum lock count exceeded&quot;);
        // Reentrant acquire
        setState(c + acquires);
        return true;
    }
    if (writerShouldBlock() ||
        !compareAndSetState(c, c + acquires))
        return false;
    setExclusiveOwnerThread(current);
    return true;
}
</code></pre>
<p>该方法除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。</p>
<p>写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，从而等待的读写线程能够继续访问读写锁，同时前次写线程的修改对后续读写线程可见。</p>
<h5 id="3读锁的获取与释放">3.读锁的获取与释放</h5>
<p>读锁是一个支持重进入的共享锁，它能够被多个线程同时获取，在没有其他写线程访问（或者写状态为0）时，读锁总会被成功地获取，而所做的也只是（线程安全的）增加读状态。如果当前线程已经获取了读锁，则增加读状态。如果当前线程在获取读锁时，写锁已被其他线程获取，则进入等待状态。</p>
<blockquote>
<p>ReentrantReadWriteLock的tryAcquireShared方法</p>
</blockquote>
<pre><code class="language-java"> protected final int tryAcquireShared(int unused) {
    Thread current = Thread.currentThread();
    int c = getState();
    if (exclusiveCount(c) != 0 &amp;&amp;
        getExclusiveOwnerThread() != current)
        return -1;
    int r = sharedCount(c);
    if (!readerShouldBlock() &amp;&amp;
        r &lt; MAX_COUNT &amp;&amp;
        compareAndSetState(c, c + SHARED_UNIT)) {
        if (r == 0) {
            firstReader = current;
            firstReaderHoldCount = 1;
        } else if (firstReader == current) {
            firstReaderHoldCount++;
        } else {
            HoldCounter rh = cachedHoldCounter;
            if (rh == null || rh.tid != getThreadId(current))
                cachedHoldCounter = rh = readHolds.get();
            else if (rh.count == 0)
                readHolds.set(rh);
            rh.count++;
        }
        return 1;
    }
    return fullTryAcquireShared(current);
}
</code></pre>
<p>在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。</p>
<p>读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是（1 &lt;&lt; 16）。</p>
<h5 id="4锁降级">4.锁降级</h5>
<p>锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。<strong>锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。</strong></p>
<p>接下来看一个锁降级的示例。因为数据不常变化，所以多个线程可以并发地进行数据处理，当数据变更后，如果当前线程感知到数据变化，则进行数据的准备工作，同时其他处理线程被阻塞，直到当前线程完成数据的准备工作。</p>
<pre><code class="language-java"> public void processData() {
        readLock.lock();
        if (!update) {
            // 必须先释放读锁
            readLock.unlock();
            // 锁降级从写锁获取到开始
            writeLock.lock();
            try {
                if (!update) {
                    // 准备数据的流程（略）
                    update = true;
                }
                readLock.lock();
            } finally {
                writeLock.unlock();
            }
            // 锁降级完成，写锁降级为读锁
        }
        try {
            // 使用数据的流程（略）
        } finally {
            readLock.unlock();
        }
    }
</code></pre>
<p>上述示例中，当数据发生变更后，update变量（布尔类型且volatile修饰）被设置为false，此时所有访问processData()方法的线程都能够感知到变化，但只有一个线程能够获取到写锁，其他线程会被阻塞在读锁和写锁的lock()方法上。当前线程获取写锁完成数据准备之后，再获取读锁，随后释放写锁，完成锁降级。</p>
<p>RentrantReadWriteLock不支持锁升级（把持读锁、获取写锁，最后释放读锁的过程）。目的也是保证数据可见性，如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的。</p>
<h2 id="45-locksupport工具">4.5 LockSupport工具</h2>
<p>当需要阻塞或唤醒一个线程的时候，都会使用LockSupport工具类来完成相应工作。LockSupport定义了一组的公共静态方法，这些方法提供了最基本的线程阻塞和唤醒功能，而LockSupport也成为构建同步组件的基础工具。</p>
<p>LockSupport定义了一组以park开头的方法用来阻塞当前线程，以及unpark(Thread thread)方法来唤醒一个被阻塞的线程。</p>
<figure data-type="image" tabindex="10"><img src="https://q456qq520.github.io/post-images/1660616478713.png" alt="LockSupport提供的阻塞和唤醒方法" loading="lazy"></figure>
<h2 id="46-condition接口">4.6 Condition接口</h2>
<p>任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式。Condition接口也提供了类似Object的监视器方法，与Lock配合可以实现等待/通知模式，但是这两者在使用方式以及功能特性上还是有差别的。</p>
<figure data-type="image" tabindex="11"><img src="https://q456qq520.github.io/post-images/1660616790444.png" alt="Object的监视器方法与Condition接口的对比" loading="lazy"></figure>
<h3 id="461-condition接口与示例">4.6.1 Condition接口与示例</h3>
<p>Condition定义了等待/通知两种类型的方法，当前线程调用这些方法时，需要提前获取到Condition对象关联的锁。Condition对象是由Lock对象（调用Lock对象的newCondition()方法）创建出来的，换句话说，Condition是依赖Lock对象的。</p>
<p>Condition的使用方式比较简单，需要注意在调用方法前获取锁。</p>
<blockquote>
<p>ConditionUseCase</p>
</blockquote>
<pre><code class="language-java">Lock lock = new ReentrantLock();
    Condition condition = lock.newCondition();
    public void conditionWait() throws InterruptedException {
        lock.lock();
        try {
            condition.await();
        } finally {
            lock.unlock();
        }
    }
    public void conditionSignal() throws InterruptedException {
        lock.lock();
        try {
            condition.signal();
        } finally {
            lock.unlock();
        }
    }
</code></pre>
<p>一般都会将Condition对象作为成员变量。当调用await()方法后，当前线程会释放锁并在此等待，而其他线程调用Condition对象的signal()方法，通知当前线程后，当前线程才从await()方法返回，并且在返回前已经获取了锁。</p>
<h3 id="462-condition的实现分析">4.6.2 Condition的实现分析</h3>
<p>ConditionObject是同步器AbstractQueuedSynchronizer的内部类，因为Condition的操作需要获取相关联的锁，所以作为同步器的内部类也较为合理。每个Condition对象都包含着一个队列（以下称为等待队列），该队列是Condition对象实现等待/通知功能的关键。</p>
<h5 id="1等待队列">1.等待队列</h5>
<p>等待队列是一个FIFO的队列，在队列中的每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程，如果一个线程调用了Condition.await()方法，那么该线程将会释放锁、构造成节点加入等待队列并进入等待状态。</p>
<p>一个Condition包含一个等待队列，Condition拥有首节点（firstWaiter）和尾节点（lastWaiter）。当前线程调用Condition.await()方法，将会以当前线程构造节点，并将节点从尾部加入等待队列。</p>
<figure data-type="image" tabindex="12"><img src="https://q456qq520.github.io/post-images/1660617414829.png" alt="等待队列的基本结构" loading="lazy"></figure>
<p>如图所示，Condition拥有首尾节点的引用，而新增节点只需要将原有的尾节点nextWaiter指向它，并且更新尾节点即可。上述节点引用更新的过程并没有使用CAS保证，原因在于调用await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的。</p>
<p>在Object的监视器模型上，一个对象拥有一个同步队列和等待队列，而并发包中的Lock（更确切地说是同步器）拥有一个同步队列和多个等待队列。</p>
<figure data-type="image" tabindex="13"><img src="https://q456qq520.github.io/post-images/1660618808661.png" alt="同步队列与等待队列" loading="lazy"></figure>
<p>Condition的实现是同步器的内部类，因此每个Condition实例都能够访问同步器提供的方法，相当于每个Condition都拥有所属同步器的引用。</p>
<h5 id="2等待">2.等待</h5>
<p>调用Condition的await()方法（或者以await开头的方法），会使当前线程进入等待队列并释放锁，同时线程状态变为等待状态。当从await()方法返回时，当前线程一定获取了Condition相关联的锁。</p>
<p>如果从队列（同步队列和等待队列）的角度看await()方法，当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。</p>
<blockquote>
<p>ConditionObject的await方法</p>
</blockquote>
<pre><code class="language-java">public final void await() throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    // 当前线程加入等待队列
    Node node = addConditionWaiter();
    // 释放同步状态，也就是释放锁
    long savedState = fullyRelease(node);
    int interruptMode = 0;
    while (!isOnSyncQueue(node)) {
        LockSupport.park(this);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null) // clean up if cancelled
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
}
</code></pre>
<p>调用该方法的线程成功获取了锁的线程，也就是同步队列中的首节点，该方法会将当前线程构造成节点并加入等待队列中，然后释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态。</p>
<p>当等待队列中的节点被唤醒，则唤醒节点的线程开始尝试获取同步状态。如果不是通过其他线程调用Condition.signal()方法唤醒，而是对等待线程进行中断，则会抛出InterruptedException。</p>
<p>如果从队列的角度去看，当前线程加入Condition的等待队列，该过程如下图所示。</p>
<figure data-type="image" tabindex="14"><img src="https://q456qq520.github.io/post-images/1660619123259.png" alt="当前线程加入等待队列" loading="lazy"></figure>
<p>同步队列的首节点并不会直接加入等待队列，而是通过addConditionWaiter()方法把当前线程构造成一个新的节点并将其加入等待队列中。</p>
<h5 id="3通知">3.通知</h5>
<p>调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移到同步队列中。</p>
<blockquote>
<p>ConditionObject的signal方法</p>
</blockquote>
<pre><code class="language-java">public final void signal() {
    if (!isHeldExclusively())
        throw new IllegalMonitorStateException();
    Node first = firstWaiter;
    if (first != null)
        doSignal(first);
}
</code></pre>
<p>调用该方法的前置条件是当前线程必须获取了锁，可以看到signal()方法进行了isHeldExclusively()检查，也就是当前线程必须是获取了锁的线程。接着获取等待队列的首节点，将其移动到同步队列并使用LockSupport唤醒节点中的线程。</p>
<p>通过调用同步器的enq(Node node)方法，等待队列中的头节点线程安全地移动到同步队列。当节点移动到同步队列后，当前线程再使用LockSupport唤醒该节点的线程。</p>
<p>被唤醒后的线程，将从await()方法中的while循环中退出（isOnSyncQueue(Node node)方法返回true，节点已经在同步队列中），进而调用同步器的acquireQueued()方法加入到获取同步状态的竞争中。</p>
<p>成功获取同步状态（或者说锁）之后，被唤醒的线程将从先前调用的await()方法返回，此时该线程已经成功地获取了锁。</p>
<p>Condition的signalAll()方法，相当于对等待队列中的每个节点均执行一次signal()方法，效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[数据库连接池示例]]></title>
        <id>https://q456qq520.github.io/post/shu-ju-ku-lian-jie-chi-shi-li/</id>
        <link href="https://q456qq520.github.io/post/shu-ju-ku-lian-jie-chi-shi-li/">
        </link>
        <updated>2022-08-09T10:16:08.000Z</updated>
        <content type="html"><![CDATA[<p>我们使用等待超时模式来构造一个简单的数据库连接池，在示例中模拟从连接池中获取、使用和释放连接的过程，而客户端获取连接的过程被设定为等待超时的模式，也就是在1000毫秒内如果无法获取到可用连接，将会返回给客户端一个null。设定连接池的大小为10个，然后通过调节客户端的线程数来模拟无法获取连接的场景。</p>
<p>首先看一下连接池的定义。它通过构造函数初始化连接的最大上限，通过一个双向队列来维护连接，调用方需要先调用fetchConnection(long)方法来指定在多少毫秒内超时获取连接，当连接使用完成后，需要调用releaseConnection(Connection)方法将连接放回线程池，示例如下所示。</p>
<pre><code class="language-java">package cm.connectpool;

import java.sql.Connection;
import java.util.LinkedList;

/**
 * 连接池
 * @author likecat
 * @version 1.0
 * @date 2022/8/9 18:23
 */
public class ConnectionPool {
    private LinkedList&lt;Connection&gt; pool = new LinkedList&lt;Connection&gt;();
    public ConnectionPool(int initialSize) {
        if (initialSize &gt; 0) {
            for (int i = 0; i &lt; initialSize; i++) {
                pool.addLast(ConnectionDriver.createConnection());
            }
        }
    }
    public void releaseConnection(Connection connection) {
        if (connection != null) {
            synchronized (pool){
            // 连接释放后需要进行通知，这样其他消费者能够感知到连接池中已经归还了一个连接
                pool.addLast(connection);
                pool.notifyAll();
            }
        }
    }
    // 在mills内无法获取到连接，将会返回null
    public Connection fetchConnection(long mills) throws InterruptedException {
        synchronized (pool) {
        // 完全超时
            if (mills &lt;= 0) {
                while (pool.isEmpty()) {
                    pool.wait();
                }
                return pool.removeFirst();
            } else{
                long future = System.currentTimeMillis() + mills;
                long remaining = mills;
                while (pool.isEmpty() &amp;&amp; remaining &gt; 0) {
                    pool.wait(remaining);
                    remaining = future - System.currentTimeMillis();
                }
                Connection result = null;
                if (!pool.isEmpty()) {
                    result = pool.removeFirst();
                }
                return result;
            }
        }
    }
}

</code></pre>
<p>由于java.sql.Connection是一个接口，最终的实现是由数据库驱动提供方来实现的，考虑到只是个示例我们通过动态代理构造了一个Connection，该Connection的代理实现仅仅是在commit()方法调用时休眠100毫秒。</p>
<pre><code class="language-java">package cm.connectpool;

import java.lang.reflect.InvocationHandler;
import java.lang.reflect.Method;
import java.lang.reflect.Proxy;
import java.sql.Connection;
import java.util.concurrent.TimeUnit;

/**
 * 驱动
 * @author likecat
 * @version 1.0
 * @date 2022/8/9 18:24
 */
public class ConnectionDriver {
    static class ConnectionHandler implements InvocationHandler {

        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable{
            if (method.getName().equals(&quot;commit&quot;)) {
                TimeUnit.MILLISECONDS.sleep(100);
            }
            return null;
         }
    }
    // 创建一个Connection的代理，在commit时休眠100毫秒
    public static final Connection createConnection() {
        return (Connection) Proxy.newProxyInstance(ConnectionDriver.class.getClassLoader(), new Class&lt;?&gt;[] { Connection.class }, new ConnectionHandler());
    }
}
</code></pre>
<p>模拟客户端ConnectionRunner获取、使用、最后释放连接的过程，当它使用时连接将会增加获取到连接的数量，反之，将会增加未获取到连接的数量。</p>
<pre><code class="language-java">package cm.connectpool;

import java.sql.Connection;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/9 18:40
 */
public class ConnectionPoolTest {
    static ConnectionPool pool = new ConnectionPool(10);
    // 保证所有ConnectionRunner能够同时开始
    static CountDownLatch start = new CountDownLatch(1);
    // main线程将会等待所有ConnectionRunner结束后才能继续执行
    static CountDownLatch end;
    public static void main(String[] args) throws Exception {
// 线程数量，可以修改线程数量进行观察
        int threadCount = 10;
        end = new CountDownLatch(threadCount);
        int count = 20;
        AtomicInteger got = new AtomicInteger();
        AtomicInteger notGot = new AtomicInteger();
        for (int i = 0; i &lt; threadCount; i++) {
            Thread thread = new Thread(new ConnetionRunner(count, got, notGot),
                    &quot;ConnectionRunnerThread&quot;);
            thread.start();
        }
        start.countDown();
        end.await();
        System.out.println(&quot;total invoke: &quot; + (threadCount * count));
        System.out.println(&quot;got connection: &quot; + got);
        System.out.println(&quot;not got connection &quot; + notGot);
    }
    static class ConnetionRunner implements Runnable {
        int count;
        AtomicInteger got;
        AtomicInteger notGot;
        public ConnetionRunner(int count, AtomicInteger got, AtomicInteger notGot) {
            this.count = count;
            this.got = got;
            this.notGot = notGot;
        }
        public void run() {
            try {
                start.await();
            } catch (Exception ex) {
            }
            while (count &gt; 0) {
                try {
                    // 从线程池中获取连接，如果1000ms内无法获取到，将会返回null
                    // 分别统计连接获取的数量got和未获取到的数量notGot
                    Connection connection = pool.fetchConnection(1000);
                    if (connection != null) {
                        try {
                            connection.createStatement();
                            connection.commit();
                        } finally {
                            pool.releaseConnection(connection);
                            got.incrementAndGet();
                        }
                    } else {
                        notGot.incrementAndGet();
                    }
                } catch (Exception ex) {
                } finally {
                    count--;
                }
            }
            end.countDown();
        }
    }
}

</code></pre>
<p>上述示例中使用了CountDownLatch来确保ConnectionRunnerThread能够同时开始执行，并且在全部结束之后，才使main线程从等待状态中返回。</p>
<p>在资源一定的情况下（连接池中的10个连接），随着客户端线程的逐步增加，客户端出现超时无法获取连接的比率不断升高。虽然客户端线程在这种超时获取的模式下会出现连接无法获取的情况，但是它能够保证客户端线程不会一直挂在连接获取的操作上，而是“按时”返回，并告知客户端连接获取出现问题，是系统的一种自我保护机制。数据库连接池的设计也可以复用到其他的资源获取的场景，针对昂贵资源（比如数据库连接）的获取都应该加以超时限制。</p>
]]></content>
    </entry>
</feed>