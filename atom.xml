<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://q456qq520.github.io</id>
    <title>LIKE CAT</title>
    <updated>2022-09-06T07:35:41.388Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://q456qq520.github.io"/>
    <link rel="self" href="https://q456qq520.github.io/atom.xml"/>
    <subtitle>一条小咸鱼</subtitle>
    <logo>https://q456qq520.github.io/images/avatar.png</logo>
    <icon>https://q456qq520.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, LIKE CAT</rights>
    <entry>
        <title type="html"><![CDATA[Java基础 - LinkedHashSet&Map]]></title>
        <id>https://q456qq520.github.io/post/java-ji-chu-linkedhashsetandmap/</id>
        <link href="https://q456qq520.github.io/post/java-ji-chu-linkedhashsetandmap/">
        </link>
        <updated>2022-09-06T07:19:31.000Z</updated>
        <content type="html"><![CDATA[<h1 id="总体介绍">总体介绍</h1>
<p>LinkedHashSet和LinkedHashMap在Java里也有着相同的实现，前者仅仅是对后者做了一层包装，也就是说LinkedHashSet里面有一个LinkedHashMap(适配器模式)。</p>
<p>LinkedHashMap实现了Map接口，即允许放入key为null的元素，也允许插入value为null的元素。从名字上可以看出该容器是linked list和HashMap的混合体，也就是说它同时满足HashMap和linked list的某些特性。可将LinkedHashMap看作采用linked list增强的HashMap。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662449233623.png" alt="base" loading="lazy"></figure>
<p>事实上LinkedHashMap是HashMap的直接子类，<strong>二者唯一的区别是LinkedHashMap在HashMap的基础上，采用双向链表(doubly-linked list)的形式将所有entry连接起来，这样是为保证元素的迭代顺序跟插入顺序相同</strong>。上图给出了LinkedHashMap的结构图，主体部分跟HashMap完全一样，多了header指向双向链表的头部(是一个哑元)，该双向链表的迭代顺序就是entry的插入顺序。</p>
<p>除了可以保迭代历顺序，这种结构还有一个好处 :  <strong>迭代LinkedHashMap时不需要像HashMap那样遍历整个table，而只需要直接遍历header指向的双向链表即可</strong>，也就是说LinkedHashMap的迭代时间就只跟entry的个数相关，而跟table的大小无关。</p>
<p>有两个参数可以影响LinkedHashMap的性能: 初始容量(inital capacity)和负载系数(load factor)。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。</p>
<p>将对象放入到LinkedHashMap或LinkedHashSet中时，有两个方法需要特别关心: hashCode()和equals()。hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到LinkedHashMap或LinkedHashSet中，需要@Override hashCode()和equals()方法。</p>
<p>出于性能原因，LinkedHashMap是非同步的(not synchronized)，如果需要在多线程环境使用，需要程序员手动同步；或者通过如下方式将LinkedHashMap包装成(wrapped)同步的:</p>
<pre><code class="language-java">Map m = Collections.synchronizedMap(new LinkedHashMap(...));
</code></pre>
<h1 id="方法剖析">方法剖析</h1>
<h2 id="get">get()</h2>
<p>get(Object key)方法根据指定的key值返回对应的value。该方法跟HashMap.get()方法的流程几乎完全一样，参考链接:<a href="/post/java-ji-chu-hashmap">Java基础-HashMap</a></p>
<h2 id="put">put()</h2>
<h2 id="remove">remove()</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java基础 - TreeMap]]></title>
        <id>https://q456qq520.github.io/post/java-ji-chu-treemap/</id>
        <link href="https://q456qq520.github.io/post/java-ji-chu-treemap/">
        </link>
        <updated>2022-09-06T06:30:51.000Z</updated>
        <content type="html"><![CDATA[<h1 id="总体介绍">总体介绍</h1>
<p>TreeSet和TreeMap，前者仅仅是对后者做了一层包装，也就是说TreeSet里面有一个TreeMap**(适配器模式)**。</p>
<p>Java TreeMap实现了<strong>SortedMap</strong>接口，也就是说会按照key的大小顺序对Map中的元素进行排序，key大小的评判可以通过其本身的自然顺序(natural ordering)，也可以通过构造时传入的比较器(Comparator)。</p>
<p>TreeMap底层通过红黑树(Red-Black tree)实现，也就意味着containsKey(), get(), put(), remove()都有着log(n)的时间复杂度。</p>
<p>![红黑树(https://q456qq520.github.io/post-images/1662446050114.png)</p>
<p>出于性能原因，TreeMap是非同步的(not synchronized)，如果需要在多线程环境使用，需要程序员手动同步；或者通过如下方式将TreeMap包装成(wrapped)同步的:</p>
<pre><code class="language-java"> SortedMap m = Collections.synchronizedSortedMap(new TreeMap(...));
</code></pre>
<p>红黑树是一种近似平衡的二叉查找树，它能够确保任何一个节点的左右子树的高度差不会超过二者中较低那个的一倍。具体来说，红黑树是满足如下条件的二叉查找树(binary search tree):</p>
<ol>
<li>每个节点要么是红色，要么是黑色。</li>
<li>根节点必须是黑色</li>
<li>红色节点不能连续(也即是，红色节点的孩子和父亲都不能是红色)。</li>
<li>对于每个节点，从该点至null(树尾端)的任何路径，都含有相同个数的黑色节点。</li>
</ol>
<p>在树的结构发生改变时(插入或者删除操作)，往往会破坏上述条件3或条件4，需要通过调整使得查找树重新满足红黑树的约束条件。</p>
<h1 id="预备知识">预备知识</h1>
<p>当查找树的结构发生改变时，红黑树的约束条件可能被破坏，需要通过调整使得查找树重新满足红黑树的约束条件。调整可以分为两类: 一类是颜色调整，即改变某个节点的颜色；另一类是结构调整，集改变检索树的结构关系。结构调整过程包含两个基本操作:<strong>左旋(Rotate Left)，右旋(RotateRight)</strong>。</p>
<h2 id="左旋">左旋</h2>
<p>左旋的过程是将x的右子树绕x逆时针旋转，使得x的右子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的属性仍然满足。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662447037690.png" alt="左旋" loading="lazy"></figure>
<pre><code class="language-java">//Rotate Left
private void rotateLeft(Entry&lt;K,V&gt; p) {
    if (p != null) {
        Entry&lt;K,V&gt; r = p.right;
        p.right = r.left;
        if (r.left != null)
            r.left.parent = p;
        r.parent = p.parent;
        if (p.parent == null)
            root = r;
        else if (p.parent.left == p)
            p.parent.left = r;
        else
            p.parent.right = r;
        r.left = p;
        p.parent = r;
    }
}
</code></pre>
<h2 id="右旋">右旋</h2>
<p>右旋的过程是将x的左子树绕x顺时针旋转，使得x的左子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的属性仍然满足。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662447192164.png" alt="右旋" loading="lazy"></figure>
<pre><code class="language-java">//Rotate Right
private void rotateRight(Entry&lt;K,V&gt; p) {
    if (p != null) {
        Entry&lt;K,V&gt; l = p.left;
        p.left = l.right;
        if (l.right != null) l.right.parent = p;
        l.parent = p.parent;
        if (p.parent == null)
            root = l;
        else if (p.parent.right == p)
            p.parent.right = l;
        else p.parent.left = l;
        l.right = p;
        p.parent = l;
    }
}
</code></pre>
<h2 id="寻找节点后继">寻找节点后继</h2>
<p>对于一棵二叉查找树，给定节点t，其后继(树中比大于t的最小的那个元素)可以通过如下方式找到:</p>
<blockquote>
<p>t的右子树不空，则t的后继是其右子树中最小的那个元素。<br>
t的右孩子为空，则t的后继是其第一个向左走的祖先。</p>
</blockquote>
<p>后继节点在红黑树的删除操作中将会用到。</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1662447570182.png" alt="后继" loading="lazy"></figure>
<p>TreeMap中寻找节点后继的代码如下:</p>
<pre><code class="language-java">// 寻找节点后继函数successor()
static &lt;K,V&gt; TreeMap.Entry&lt;K,V&gt; successor(Entry&lt;K,V&gt; t) {
    if (t == null)
        return null;
    else if (t.right != null) {// 1. t的右子树不空，则t的后继是其右子树中最小的那个元素
        Entry&lt;K,V&gt; p = t.right;
        while (p.left != null)
            p = p.left;
        return p;
    } else {// 2. t的右孩子为空，则t的后继是其第一个向左走的祖先
        Entry&lt;K,V&gt; p = t.parent;
        Entry&lt;K,V&gt; ch = t;
        while (p != null &amp;&amp; ch == p.right) {
            ch = p;
            p = p.parent;
        }
        return p;
    }
}
</code></pre>
<h1 id="方法剖析">方法剖析</h1>
<h2 id="get">get()</h2>
<p>get(Object key)方法根据指定的key值返回对应的value，该方法调用了getEntry(Object key)得到相应的entry，然后返回entry.value。因此getEntry()是算法的核心。算法思想是根据key的自然顺序(或者比较器顺序)对二叉查找树进行查找，直到找到满足k.compareTo(p.key) == 0的entry。</p>
<p>![get(https://q456qq520.github.io/post-images/1662447909864.png)</p>
<pre><code class="language-java">//getEntry()方法
final Entry&lt;K,V&gt; getEntry(Object key) {
    ......
    if (key == null)//不允许key值为null
        throw new NullPointerException();
    Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key;//使用元素的自然顺序
    Entry&lt;K,V&gt; p = root;
    while (p != null) {
        int cmp = k.compareTo(p.key);
        if (cmp &lt; 0)//向左找
            p = p.left;
        else if (cmp &gt; 0)//向右找
            p = p.right;
        else
            return p;
    }
    return null;
}
</code></pre>
<h2 id="put">put()</h2>
<p>put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于getEntry()方法；如果没有找到则会在红黑树中插入新的entry，如果插入之后破坏了红黑树的约束条件，还需要进行调整(旋转，改变某些节点的颜色)。</p>
<pre><code class="language-java">public V put(K key, V value) {
	......
    int cmp;
    Entry&lt;K,V&gt; parent;
    if (key == null)
        throw new NullPointerException();
    Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key;//使用元素的自然顺序
    do {
        parent = t;
        cmp = k.compareTo(t.key);
        if (cmp &lt; 0) t = t.left;//向左找
        else if (cmp &gt; 0) t = t.right;//向右找
        else return t.setValue(value);
    } while (t != null);
    Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent);//创建并插入新的entry
    if (cmp &lt; 0) parent.left = e;
    else parent.right = e;
    fixAfterInsertion(e);//调整
    size++;
    return null;
}
</code></pre>
<p>首先在红黑树上找到合适的位置，然后创建新的entry并插入(当然，新插入的节点一定是树的叶子)。难点是调整函数fixAfterInsertion()，前面已经说过，调整往往需要1.改变某些节点的颜色，2.对某些节点进行旋转。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1662448057289.png" alt="put" loading="lazy"></figure>
<p>调整函数fixAfterInsertion()的具体代码如下，其中用到了上文中提到的rotateLeft()和rotateRight()函数。通过代码我们能够看到，情况2其实是落在情况3内的。情况4～情况6跟前三种情况是对称的，因此图解中并没有画出后三种情况，读者可以参考代码自行理解。</p>
<pre><code class="language-java">//红黑树调整函数fixAfterInsertion()
private void fixAfterInsertion(Entry&lt;K,V&gt; x) {
    x.color = RED;
    while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) {
        if (parentOf(x) == leftOf(parentOf(parentOf(x)))) {
            Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x)));
            if (colorOf(y) == RED) {
                setColor(parentOf(x), BLACK);              // 情况1
                setColor(y, BLACK);                        // 情况1
                setColor(parentOf(parentOf(x)), RED);      // 情况1
                x = parentOf(parentOf(x));                 // 情况1
            } else {
                if (x == rightOf(parentOf(x))) {
                    x = parentOf(x);                       // 情况2
                    rotateLeft(x);                         // 情况2
                }
                setColor(parentOf(x), BLACK);              // 情况3
                setColor(parentOf(parentOf(x)), RED);      // 情况3
                rotateRight(parentOf(parentOf(x)));        // 情况3
            }
        } else {
            Entry&lt;K,V&gt; y = leftOf(parentOf(parentOf(x)));
            if (colorOf(y) == RED) {
                setColor(parentOf(x), BLACK);              // 情况4
                setColor(y, BLACK);                        // 情况4
                setColor(parentOf(parentOf(x)), RED);      // 情况4
                x = parentOf(parentOf(x));                 // 情况4
            } else {
                if (x == leftOf(parentOf(x))) {
                    x = parentOf(x);                       // 情况5
                    rotateRight(x);                        // 情况5
                }
                setColor(parentOf(x), BLACK);              // 情况6
                setColor(parentOf(parentOf(x)), RED);      // 情况6
                rotateLeft(parentOf(parentOf(x)));         // 情况6
            }
        }
    }
    root.color = BLACK;
}
</code></pre>
<p>##remove()<br>
remove(Object key)的作用是删除key值对应的entry，该方法首先通过上文中提到的getEntry(Object key)方法找到key值对应的entry，然后调用deleteEntry(Entry&lt;K,V&gt; entry)删除对应的entry。由于删除操作会改变红黑树的结构，有可能破坏红黑树的约束条件，因此有可能要进行调整。</p>
<p>getEntry()函数前面已经讲解过，这里重点放deleteEntry()上，该函数删除指定的entry并在红黑树的约束被破坏时进行调用fixAfterDeletion(Entry&lt;K,V&gt; x)进行调整。 由于红黑树是一棵增强版的二叉查找树，红黑树的删除操作跟普通二叉查找树的删除操作也就非常相似，唯一的区别是红黑树在节点删除之后可能需要进行调整。现在考虑一棵普通二叉查找树的删除过程，可以简单分为两种情况:</p>
<blockquote>
<p>删除点p的左右子树都为空，或者只有一棵子树非空。<br>
删除点p的左右子树都非空。</p>
</blockquote>
<p>对于上述情况1，处理起来比较简单，直接将p删除(左右子树都为空时)，或者用非空子树替代p(只有一棵子树非空时)；对于情况2，可以用p的后继s(树中大于x的最小的那个元素)代替p，然后使用情况1删除。 基于以上逻辑，红黑树的节点删除函数deleteEntry()代码如下:</p>
<pre><code class="language-java">// 红黑树entry删除函数deleteEntry()
private void deleteEntry(Entry&lt;K,V&gt; p) {
    modCount++;
    size--;
    if (p.left != null &amp;&amp; p.right != null) {// 2. 删除点p的左右子树都非空。
        Entry&lt;K,V&gt; s = successor(p);// 后继
        p.key = s.key;
        p.value = s.value;
        p = s;
    }
    Entry&lt;K,V&gt; replacement = (p.left != null ? p.left : p.right);
    if (replacement != null) {// 1. 删除点p只有一棵子树非空。
        replacement.parent = p.parent;
        if (p.parent == null)
            root = replacement;
        else if (p == p.parent.left)
            p.parent.left  = replacement;
        else
            p.parent.right = replacement;
        p.left = p.right = p.parent = null;
        if (p.color == BLACK)
            fixAfterDeletion(replacement);// 调整
    } else if (p.parent == null) {
        root = null;
    } else { // 1. 删除点p的左右子树都为空
        if (p.color == BLACK)
            fixAfterDeletion(p);// 调整
        if (p.parent != null) {
            if (p == p.parent.left)
                p.parent.left = null;
            else if (p == p.parent.right)
                p.parent.right = null;
            p.parent = null;
        }
    }
}
</code></pre>
<p>上述代码中占据大量代码行的，是用来修改父子节点间引用关系的代码，其逻辑并不难理解。下面着重讲解删除后调整函数fixAfterDeletion()。首先请思考一下，删除了哪些点才会导致调整？只有删除点是BLACK的时候，才会触发调整函数，因为删除RED节点不会破坏红黑树的任何约束，而删除BLACK节点会破坏规则4。</p>
<p>跟fixAfterInsertion()函数一样，这里也要分成若干种情况。记住，无论有多少情况，具体的调整操作只有两种: ** 1.改变某些节点的颜色，2.对某些节点进行旋转。**</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1662448600339.png" alt="remove" loading="lazy"></figure>
<p>上述图解的总体思想是: 将情况1首先转换成情况2，或者转换成情况3和情况4。当然，该图解并不意味着调整过程一定是从情况1开始。通过后续代码我们还会发现几个有趣的规则: a).如果是由情况1之后紧接着进入的情况2，那么情况2之后一定会退出循环(因为x为红色)；b).一旦进入情况3和情况4，一定会退出循环(因为x为root)。</p>
<p>删除后调整函数fixAfterDeletion()的具体代码如下，其中用到了上文中提到的rotateLeft()和rotateRight()函数。通过代码我们能够看到，情况3其实是落在情况4内的。情况5～情况8跟前四种情况是对称的。</p>
<pre><code class="language-java">private void fixAfterDeletion(Entry&lt;K,V&gt; x) {
    while (x != root &amp;&amp; colorOf(x) == BLACK) {
        if (x == leftOf(parentOf(x))) {
            Entry&lt;K,V&gt; sib = rightOf(parentOf(x));
            if (colorOf(sib) == RED) {
                setColor(sib, BLACK);                   // 情况1
                setColor(parentOf(x), RED);             // 情况1
                rotateLeft(parentOf(x));                // 情况1
                sib = rightOf(parentOf(x));             // 情况1
            }
            if (colorOf(leftOf(sib))  == BLACK &amp;&amp;
                colorOf(rightOf(sib)) == BLACK) {
                setColor(sib, RED);                     // 情况2
                x = parentOf(x);                        // 情况2
            } else {
                if (colorOf(rightOf(sib)) == BLACK) {
                    setColor(leftOf(sib), BLACK);       // 情况3
                    setColor(sib, RED);                 // 情况3
                    rotateRight(sib);                   // 情况3
                    sib = rightOf(parentOf(x));         // 情况3
                }
                setColor(sib, colorOf(parentOf(x)));    // 情况4
                setColor(parentOf(x), BLACK);           // 情况4
                setColor(rightOf(sib), BLACK);          // 情况4
                rotateLeft(parentOf(x));                // 情况4
                x = root;                               // 情况4
            }
        } else { // 跟前四种情况对称
            Entry&lt;K,V&gt; sib = leftOf(parentOf(x));
            if (colorOf(sib) == RED) {
                setColor(sib, BLACK);                   // 情况5
                setColor(parentOf(x), RED);             // 情况5
                rotateRight(parentOf(x));               // 情况5
                sib = leftOf(parentOf(x));              // 情况5
            }
            if (colorOf(rightOf(sib)) == BLACK &amp;&amp;
                colorOf(leftOf(sib)) == BLACK) {
                setColor(sib, RED);                     // 情况6
                x = parentOf(x);                        // 情况6
            } else {
                if (colorOf(leftOf(sib)) == BLACK) {
                    setColor(rightOf(sib), BLACK);      // 情况7
                    setColor(sib, RED);                 // 情况7
                    rotateLeft(sib);                    // 情况7
                    sib = leftOf(parentOf(x));          // 情况7
                }
                setColor(sib, colorOf(parentOf(x)));    // 情况8
                setColor(parentOf(x), BLACK);           // 情况8
                setColor(leftOf(sib), BLACK);           // 情况8
                rotateRight(parentOf(x));               // 情况8
                x = root;                               // 情况8
            }
        }
    }
    setColor(x, BLACK);
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java 基础 - HashMap]]></title>
        <id>https://q456qq520.github.io/post/java-ji-chu-hashmap/</id>
        <link href="https://q456qq520.github.io/post/java-ji-chu-hashmap/">
        </link>
        <updated>2022-09-06T06:17:44.000Z</updated>
        <content type="html"><![CDATA[<h1 id="java7-hashmap">Java7 HashMap</h1>
<h2 id="概述">概述</h2>
<p>HashMap实现了Map接口，即允许放入key为null的元素，也允许插入value为null的元素；除该类未实现同步外，其余跟Hashtable大致相同；跟TreeMap不同，该容器不保证元素顺序，根据需要该容器可能会对元素重新哈希，元素的顺序也会被重新打散，因此不同时间迭代同一个HashMap的顺序可能会不同。<br>
根据对冲突的处理方式不同，哈希表有两种实现方式，一种<strong>开放地址方式(Open addressing)</strong>，另一种是<strong>冲突链表方式(Separate chaining with linked lists)</strong>。Java7 HashMap采用的是冲突链表方式。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662445311067.png" alt="HaspMap" loading="lazy"></figure>
<p>从上图容易看出，如果选择合适的哈希函数，put()和get()方法可以在常数时间内完成。但在对HashMap进行迭代时，需要遍历整个table以及后面跟的冲突链表。因此对于迭代比较频繁的场景，不宜将HashMap的初始大小设的过大。</p>
<p>有两个参数可以影响HashMap的性能: 初始容量(inital capacity)和负载系数(load factor)。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。</p>
<p>将对象放入到HashMap或HashSet中时，有两个方法需要特别关心: hashCode()和equals()。hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到HashMap或HashSet中，需要**@Override** hashCode()和equals()方法。</p>
<h1 id="java8-hashmap">Java8 HashMap</h1>
<p>Java8利用了红黑树，由 数组+链表+红黑树 组成。</p>
<p>查找的时候，根据 hash 值我们能够快速定位到数组的具体下标，但是之后的话，需要顺着链表一个个比较下去才能找到我们需要的，时间复杂度取决于链表的长度，为 O(n)。 为了降低这部分的开销，在 Java8 中，当链表中的元素达到了 8 个时，会将链表转换为红黑树，在这些位置进行查找的时候可以降低时间复杂度为 O(logN)。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662445189410.png" alt="hashmap结构" loading="lazy"></figure>
<p>著作权归https://pdai.tech所有。<br>
链接：https://pdai.tech/md/java/collection/java-map-HashMap&amp;HashSet.html</p>
<p>Java7 中使用 Entry 来代表每个 HashMap 中的数据节点，Java8 中使用 Node，基本没有区别，都是 key，value，hash 和 next 这四个属性，不过，Node 只能用于链表的情况，红黑树的情况需要使用 TreeNode。</p>
<p>根据数组元素中，第一个节点数据类型是 Node 还是 TreeNode 来判断该位置下是链表还是红黑树的。</p>
<h2 id="put过程">put过程</h2>
<pre><code class="language-java">public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}

// 第四个参数 onlyIfAbsent 如果是 true，那么只有在不存在该 key 时才会进行 put 操作
// 第五个参数 evict 我们这里不关心
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;
    // 第一次 put 值的时候，会触发下面的 resize()，类似 java7 的第一次 put 也要初始化数组长度
    // 第一次 resize 和后续的扩容有些不一样，因为这次是数组从 null 初始化到默认的 16 或自定义的初始容量
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    // 找到具体的数组下标，如果此位置没有值，那么直接初始化一下 Node 并放置在这个位置就可以了
    if ((p = tab[i = (n - 1) &amp; hash]) == null)
        tab[i] = newNode(hash, key, value, null);

    else {// 数组该位置有数据
        Node&lt;K,V&gt; e; K k;
        // 首先，判断该位置的第一个数据和我们要插入的数据，key 是不是&quot;相等&quot;，如果是，取出这个节点
        if (p.hash == hash &amp;&amp;
            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))
            e = p;
        // 如果该节点是代表红黑树的节点，调用红黑树的插值方法，本文不展开说红黑树
        else if (p instanceof TreeNode)
            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);
        else {
            // 到这里，说明数组该位置上是一个链表
            for (int binCount = 0; ; ++binCount) {
                // 插入到链表的最后面(Java7 是插入到链表的最前面)
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    // TREEIFY_THRESHOLD 为 8，所以，如果新插入的值是链表中的第 8 个
                    // 会触发下面的 treeifyBin，也就是将链表转换为红黑树
                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                // 如果在该链表中找到了&quot;相等&quot;的 key(== 或 equals)
                if (e.hash == hash &amp;&amp;
                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                    // 此时 break，那么 e 为链表中[与要插入的新值的 key &quot;相等&quot;]的 node
                    break;
                p = e;
            }
        }
        // e!=null 说明存在旧值的key与要插入的key&quot;相等&quot;
        // 对于我们分析的put操作，下面这个 if 其实就是进行 &quot;值覆盖&quot;，然后返回旧值
        if (e != null) {
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    // 如果 HashMap 由于新插入这个值导致 size 已经超过了阈值，需要进行扩容
    if (++size &gt; threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
</code></pre>
<h2 id="数组扩容">数组扩容</h2>
<p>resize() 方法用于初始化数组或数组扩容，每次扩容后，容量为原来的 2 倍，并进行数据迁移。</p>
<pre><code class="language-java">final Node&lt;K,V&gt;[] resize() {
    Node&lt;K,V&gt;[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap &gt; 0) { // 对应数组扩容
        if (oldCap &gt;= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        // 将数组大小扩大一倍
        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;
                 oldCap &gt;= DEFAULT_INITIAL_CAPACITY)
            // 将阈值扩大一倍
            newThr = oldThr &lt;&lt; 1; // double threshold
    }
    else if (oldThr &gt; 0) // 对应使用 new HashMap(int initialCapacity) 初始化后，第一次 put 的时候
        newCap = oldThr;
    else {// 对应使用 new HashMap() 初始化后，第一次 put 的时候
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }

    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;

    // 用新的数组大小初始化新的数组
    Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];
    table = newTab; // 如果是初始化数组，到这里就结束了，返回 newTab 即可

    if (oldTab != null) {
        // 开始遍历原数组，进行数据迁移。
        for (int j = 0; j &lt; oldCap; ++j) {
            Node&lt;K,V&gt; e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                // 如果该数组位置上只有单个元素，那就简单了，简单迁移这个元素就可以了
                if (e.next == null)
                    newTab[e.hash &amp; (newCap - 1)] = e;
                // 如果是红黑树，具体我们就不展开了
                else if (e instanceof TreeNode)
                    ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);
                else { 
                    // 这块是处理链表的情况，
                    // 需要将此链表拆成两个链表，放到新的数组中，并且保留原来的先后顺序
                    // loHead、loTail 对应一条链表，hiHead、hiTail 对应另一条链表，代码还是比较简单的
                    Node&lt;K,V&gt; loHead = null, loTail = null;
                    Node&lt;K,V&gt; hiHead = null, hiTail = null;
                    Node&lt;K,V&gt; next;
                    do {
                        next = e.next;
                        if ((e.hash &amp; oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        // 第一条链表
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        // 第二条链表的新的位置是 j + oldCap，这个很好理解
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
</code></pre>
<h2 id="get-过程">get 过程</h2>
<ol>
<li>计算 key 的 hash 值，根据 hash 值找到对应数组下标: hash &amp; (length-1)</li>
<li>判断数组该位置处的元素是否刚好就是我们要找的，如果不是，走第三步</li>
<li>判断该元素类型是否是 TreeNode，如果是，用红黑树的方法取数据，如果不是，走第四步</li>
<li>遍历链表，直到找到相等(==或equals)的 key</li>
</ol>
<pre><code class="language-java">public V get(Object key) {
    Node&lt;K,V&gt; e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}
final Node&lt;K,V&gt; getNode(int hash, Object key) {
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;
    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;
        (first = tab[(n - 1) &amp; hash]) != null) {
        // 判断第一个节点是不是就是需要的
        if (first.hash == hash &amp;&amp; // always check first node
            ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))
            return first;
        if ((e = first.next) != null) {
            // 判断是否是红黑树
            if (first instanceof TreeNode)
                return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);

            // 链表遍历
            do {
                if (e.hash == hash &amp;&amp;
                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java 基础 - 泛型机制详解]]></title>
        <id>https://q456qq520.github.io/post/java-ji-chu-fan-xing-ji-zhi-xiang-jie/</id>
        <link href="https://q456qq520.github.io/post/java-ji-chu-fan-xing-ji-zhi-xiang-jie/">
        </link>
        <updated>2022-09-05T07:45:31.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>Java泛型这个特性是从JDK 1.5才开始加入的，因此为了兼容之前的版本，Java泛型的实现采取了“伪泛型”的策略，即Java在语法上支持泛型，但是在编译阶段会进行所谓的“类型擦除”（Type Erasure），将所有的泛型表示（尖括号中的内容）都替换为具体的类型（其对应的原生态类型），就像完全没有泛型一样。</p>
</blockquote>
<h1 id="1为什么会引入泛型">1.为什么会引入泛型</h1>
<blockquote>
<p>泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。</p>
</blockquote>
<p>引入泛型的意义在于：</p>
<p><strong>适用于多种数据类型执行相同的代码（代码复用）</strong></p>
<p>我们通过一个例子来阐述，先看下下面的代码：</p>
<pre><code class="language-java">private static int add(int a, int b) {
    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b));
    return a + b;
}

private static float add(float a, float b) {
    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b));
    return a + b;
}

private static double add(double a, double b) {
    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b));
    return a + b;
}
</code></pre>
<p>如果没有泛型，要实现不同类型的加法，每种类型都需要重载一个add方法；通过泛型，我们可以复用为一个方法：</p>
<pre><code class="language-java">private static &lt;T extends Number&gt; double add(T a, T b) {
    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a.doubleValue() + b.doubleValue()));
    return a.doubleValue() + b.doubleValue();
}
</code></pre>
<p>泛型中的类型在使用时指定，不需要强制类型转换（类型安全，编译器会检查类型）</p>
<h1 id="2泛型的基本使用">2.泛型的基本使用</h1>
<p>泛型有三种使用方式，分别为：泛型类、泛型接口、泛型方法。</p>
<h2 id="21-泛型类">2.1 泛型类</h2>
<p>从一个简单的泛型类看起：</p>
<pre><code class="language-java">class Point&lt;T&gt;{         // 此处可以随便写标识符号，T是type的简称  
    private T var ;     // var的类型由T指定，即：由外部指定  
    public T getVar(){  // 返回值的类型由外部决定  
        return var ;  
    }  
    public void setVar(T var){  // 设置的类型也由外部决定  
        this.var = var ;  
    }  
}  
public class GenericsDemo06{  
    public static void main(String args[]){  
        Point&lt;String&gt; p = new Point&lt;String&gt;() ;     // 里面的var类型为String类型  
        p.setVar(&quot;it&quot;) ;                            // 设置字符串  
        System.out.println(p.getVar().length()) ;   // 取得字符串的长度  
    }  
}
</code></pre>
<p>多元泛型</p>
<pre><code class="language-java">class Notepad&lt;K,V&gt;{       // 此处指定了两个泛型类型  
    private K key ;     // 此变量的类型由外部决定  
    private V value ;   // 此变量的类型由外部决定  
    public K getKey(){  
        return this.key ;  
    }  
    public V getValue(){  
        return this.value ;  
    }  
    public void setKey(K key){  
        this.key = key ;  
    }  
    public void setValue(V value){  
        this.value = value ;  
    }  
} 
public class GenericsDemo09{  
    public static void main(String args[]){  
        Notepad&lt;String,Integer&gt; t = null ;        // 定义两个泛型类型的对象  
        t = new Notepad&lt;String,Integer&gt;() ;       // 里面的key为String，value为Integer  
        t.setKey(&quot;汤姆&quot;) ;        // 设置第一个内容  
        t.setValue(20) ;            // 设置第二个内容  
        System.out.print(&quot;姓名；&quot; + t.getKey()) ;      // 取得信息  
        System.out.print(&quot;，年龄；&quot; + t.getValue()) ;       // 取得信息  
  
    }  
}
</code></pre>
<h2 id="22-泛型接口">2.2 泛型接口</h2>
<pre><code class="language-java">interface Info&lt;T&gt;{        // 在接口上定义泛型  
    public T getVar() ; // 定义抽象方法，抽象方法的返回值就是泛型类型  
}  
class InfoImpl&lt;T&gt; implements Info&lt;T&gt;{   // 定义泛型接口的子类  
    private T var ;             // 定义属性  
    public InfoImpl(T var){     // 通过构造方法设置属性内容  
        this.setVar(var) ;    
    }  
    public void setVar(T var){  
        this.var = var ;  
    }  
    public T getVar(){  
        return this.var ;  
    }  
} 
public class GenericsDemo24{  
    public static void main(String arsg[]){  
        Info&lt;String&gt; i = null;        // 声明接口对象  
        i = new InfoImpl&lt;String&gt;(&quot;汤姆&quot;) ;  // 通过子类实例化对象  
        System.out.println(&quot;内容：&quot; + i.getVar()) ;  
    }  
}  
</code></pre>
<h2 id="23-泛型方法">2.3 泛型方法</h2>
<p>泛型方法，是在调用方法的时候指明泛型的具体类型。</p>
<p>定义泛型方法语法格式</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662364711146.png" alt="定义泛型方法语法格式" loading="lazy"></figure>
<p>调用泛型方法语法格式<br>
<img src="https://q456qq520.github.io/post-images/1662364736330.png" alt="调用泛型方法语法格式" loading="lazy"></p>
<p>说明一下，定义泛型方法时，必须在返回值前边加一个<T>，来声明这是一个泛型方法，持有一个泛型T，然后才可以用泛型T作为方法的返回值。 Class<T>的作用就是指明泛型的具体类型，而Class<T>类型的变量c，可以用来创建泛型类的对象。</p>
<p>为什么要用变量c来创建对象呢？既然是泛型方法，就代表着我们不知道具体的类型是什么，也不知道构造方法如何，因此没有办法去new一个对象，但可以利用变量c的newInstance方法去创建对象，也就是利用反射创建对象。</p>
<p>泛型方法要求的参数是Class<T>类型，而Class.forName()方法的返回值也是Class<T>，因此可以用Class.forName()作为参数。其中，forName()方法中的参数是何种类型，返回的Class<T>就是何种类型。在本例中，forName()方法中传入的是User类的完整路径，因此返回的是Class<User>类型的对象，因此调用泛型方法时，变量c的类型就是Class<User>，因此泛型方法中的泛型T就被指明为User，因此变量obj的类型为User。 当然，泛型方法不是仅仅可以有一个参数Class<T>，可以根据需要添加其他参数。</p>
<p>为什么要使用泛型方法呢？因为泛型类要在实例化的时候就指明类型，如果想换一种类型，不得不重新new一次，可能不够灵活；而泛型方法可以在调用的时候指明类型，更加灵活。</p>
<h2 id="24-泛型的上下限">2.4 泛型的上下限</h2>
<pre><code class="language-java">class A{}
class B extends A {}

// 如下两个方法不会报错
public static void funA(A a) {
    // ...          
}
public static void funB(B b) {
    funA(b);
    // ...             
}

// 如下funD方法会报错
public static void funC(List&lt;A&gt; listA) {
    // ...          
}
public static void funD(List&lt;B&gt; listB) {
    funC(listB); // Unresolved compilation problem: The method doPrint(List&lt;A&gt;) in the type test is not applicable for the arguments (List&lt;B&gt;)
    // ...             
}

那么如何解决呢？ 为了解决泛型中隐含的转换问题，Java泛型加入了类型参数的上下边界机制。&lt;? extends A&gt;表示该类型参数可以是A(上边界)或者A的子类类型。编译时擦除到类型A，即用A类型代替类型参数。这种方法可以解决开始遇到的问题，编译器知道类型参数的范围，如果传入的实例类型B是在这个范围内的话允许转换，这时只要一次类型转换就可以了，运行时会把对象当做A的实例看待。

```java
public static void funC(List&lt;? extends A&gt; listA) {
    // ...          
}
public static void funD(List&lt;B&gt; listB) {
    funC(listB); // OK
    // ...             
}
</code></pre>
<p><strong>泛型上下限的引入</strong><br>
在使用泛型的时候，我们可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。</p>
<ol>
<li>上限</li>
</ol>
<pre><code class="language-java">class Info&lt;T extends Number&gt;{    // 此处泛型只能是数字类型
    private T var ;        // 定义泛型变量
    public void setVar(T var){
        this.var = var ;
    }
    public T getVar(){
        return this.var ;
    }
    public String toString(){    // 直接打印
        return this.var.toString() ;
    }
}
public class demo1{
    public static void main(String args[]){
        Info&lt;Integer&gt; i1 = new Info&lt;Integer&gt;() ;        // 声明Integer的泛型对象
    }
}
</code></pre>
<ol start="2">
<li>下限</li>
</ol>
<pre><code class="language-java">class Info&lt;T&gt;{
    private T var ;        // 定义泛型变量
    public void setVar(T var){
        this.var = var ;
    }
    public T getVar(){
        return this.var ;
    }
    public String toString(){    // 直接打印
        return this.var.toString() ;
    }
}
public class GenericsDemo21{
    public static void main(String args[]){
        Info&lt;String&gt; i1 = new Info&lt;String&gt;() ;        // 声明String的泛型对象
        Info&lt;Object&gt; i2 = new Info&lt;Object&gt;() ;        // 声明Object的泛型对象
        i1.setVar(&quot;hello&quot;) ;
        i2.setVar(new Object()) ;
        fun(i1) ;
        fun(i2) ;
    }
    public static void fun(Info&lt;? super String&gt; temp){    // 只能接收String或Object类型的泛型，String类的父类只有Object类
        System.out.print(temp + &quot;, &quot;) ;
    }
}
</code></pre>
<p><strong>小结</strong></p>
<blockquote>
<?> 无限制通配符
<? extends E> extends 关键字声明了类型的上界，表示参数化的类型可能是所指定的类型，或者是此类型的子类
<? super E> super 关键字声明了类型的下界，表示参数化的类型可能是指定的类型，或者是此类型的父类
1. 如果参数化类型表示一个 T 的生产者，使用 < ? extends T>;
2. 如果它表示一个 T 的消费者，就使用 < ? super T>；
3. 如果既是生产又是消费，那使用通配符就没什么意义了，因为你需要的是精确的参数类型。
</blockquote>
<h2 id="25泛型数组">2.5.泛型数组</h2>
<pre><code class="language-java">List&lt;String&gt;[] list11 = new ArrayList&lt;String&gt;[10]; //编译错误，非法创建 
List&lt;String&gt;[] list12 = new ArrayList&lt;?&gt;[10]; //编译错误，需要强转类型 
List&lt;String&gt;[] list13 = (List&lt;String&gt;[]) new ArrayList&lt;?&gt;[10]; //OK，但是会有警告 
List&lt;?&gt;[] list14 = new ArrayList&lt;String&gt;[10]; //编译错误，非法创建 
List&lt;?&gt;[] list15 = new ArrayList&lt;?&gt;[10]; //OK 
List&lt;String&gt;[] list6 = new ArrayList[10]; //OK，但是会有警告
</code></pre>
<h1 id="3深入理解泛型">3.深入理解泛型</h1>
<h2 id="31-如何理解java中的泛型是伪泛型泛型中类型擦除">3.1 如何理解Java中的泛型是伪泛型？泛型中类型擦除</h2>
<blockquote>
<p>java泛型这个特性是从JDK 1.5才开始加入的，因此为了兼容之前的版本，Java泛型的实现采取了“伪泛型”的策略，即Java在语法上支持泛型，但是在编译阶段会进行所谓的“类型擦除”（Type Erasure），将所有的泛型表示（尖括号中的内容）都替换为具体的类型（其对应的原生态类型），就像完全没有泛型一样。理解类型擦除对于用好泛型是很有帮助的，尤其是一些看起来“疑难杂症”的问题，弄明白了类型擦除也就迎刃而解了。</p>
</blockquote>
<p>泛型的类型擦除原则是：<br>
- 消除类型参数声明，即删除&lt;&gt;及其包围的部分。<br>
- 根据类型参数的上下界推断并替换所有的类型参数为原生态类型：如果类型参数是无限制通配符或没有上下界限定则替换为Object，如果存在上下界限定则根据子类替换原则取类型参数的最左边限定类型（即父类）。<br>
- 为了保证类型安全，必要时插入强制类型转换代码。<br>
- 自动产生“桥接方法”以保证擦除类型后的代码仍然具有泛型的“多态性”。</p>
<h2 id="32-那么如何进行擦除的呢">3.2 那么如何进行擦除的呢？</h2>
<ul>
<li>擦除类定义中的类型参数 - 无限制类型擦除</li>
</ul>
<p>当类定义中的类型参数没有任何限制时，在类型擦除中直接被替换为Object，即形如<T>和&lt;?&gt;的类型参数都被替换为Object。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662369716778.png" alt="无限制类型擦除" loading="lazy"></figure>
<ul>
<li>擦除类定义中的类型参数 - 有限制类型擦除</li>
</ul>
<p>当类定义中的类型参数存在限制（上下界）时，在类型擦除中替换为类型参数的上界或者下界，比如形如<T extends Number>和&lt;? extends Number&gt;的类型参数被替换为Number，&lt;? super Number&gt;被替换为Object。</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1662369723517.png" alt="有限制类型擦除" loading="lazy"></figure>
<ul>
<li>擦除方法定义中的类型参数</li>
</ul>
<p>擦除方法定义中的类型参数原则和擦除类定义中的类型参数是一样的，这里仅以擦除方法定义中的有限制类型参数为例。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1662369746834.png" alt="擦除方法定义中的类型参数" loading="lazy"></figure>
<p>如何证明类型的擦除呢？</p>
<ol>
<li>原始类型相等</li>
</ol>
<pre><code class="language-java">public class Test {

    public static void main(String[] args) {

        ArrayList&lt;String&gt; list1 = new ArrayList&lt;String&gt;();
        list1.add(&quot;abc&quot;);

        ArrayList&lt;Integer&gt; list2 = new ArrayList&lt;Integer&gt;();
        list2.add(123);

        System.out.println(list1.getClass() == list2.getClass()); // true
    }
}
</code></pre>
<ol start="2">
<li>通过反射添加其它类型元素</li>
</ol>
<pre><code class="language-java">public class Test {

    public static void main(String[] args) throws Exception {

        ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();

        list.add(1);  //这样调用 add 方法只能存储整形，因为泛型类型的实例为 Integer

        list.getClass().getMethod(&quot;add&quot;, Object.class).invoke(list, &quot;asd&quot;);

        for (int i = 0; i &lt; list.size(); i++) {
            System.out.println(list.get(i));
        }
    }

}
</code></pre>
<h2 id="33-如何理解类型擦除后保留的原始类型">3.3 如何理解类型擦除后保留的原始类型?</h2>
<p>原始类型 就是擦除去了泛型信息，最后在字节码中的类型变量的真正类型，无论何时定义一个泛型，相应的原始类型都会被自动提供，类型变量擦除，并使用其限定类型（无限定的变量用Object）替换。</p>
<h2 id="34-如何理解泛型的编译期检查">3.4 如何理解泛型的编译期检查？</h2>
<blockquote>
<p>既然说类型变量会在编译的时候擦除掉，那为什么我们往 ArrayList 创建的对象中添加整数会报错呢？不是说泛型变量String会在编译的时候变为Object类型吗？为什么不能存别的类型呢？既然类型擦除了，如何保证我们只能使用泛型变量限定的类型呢？</p>
</blockquote>
<p><strong>Java编译器是通过先检查代码中泛型的类型，然后在进行类型擦除，再进行编译。</strong></p>
<pre><code class="language-java">public class Test {  

    public static void main(String[] args) {  

        ArrayList&lt;String&gt; list1 = new ArrayList();  
        list1.add(&quot;1&quot;); //编译通过  
        list1.add(1); //编译错误  
        String str1 = list1.get(0); //返回类型就是String  

        ArrayList list2 = new ArrayList&lt;String&gt;();  
        list2.add(&quot;1&quot;); //编译通过  
        list2.add(1); //编译通过  
        Object object = list2.get(0); //返回类型就是Object  

        new ArrayList&lt;String&gt;().add(&quot;11&quot;); //编译通过  
        new ArrayList&lt;String&gt;().add(22); //编译错误  

        String str2 = new ArrayList&lt;String&gt;().get(0); //返回类型就是String  
    }  
} 
</code></pre>
<p>通过上面的例子，我们可以明白，<strong>类型检查就是针对引用的，谁是一个引用，用这个引用调用泛型方法，就会对这个引用调用的方法进行类型检测，而无关它真正引用的对象。</strong></p>
<p>泛型中参数话类型为什么不考虑继承关系？</p>
<h2 id="35-如何理解泛型的多态泛型的桥接方法">3.5 如何理解泛型的多态？泛型的桥接方法</h2>
<blockquote>
<p>类型擦除会造成多态的冲突，而JVM解决方法就是桥接方法。</p>
</blockquote>
<h2 id="36-如何理解基本类型不能作为泛型类型">3.6 如何理解基本类型不能作为泛型类型？</h2>
<blockquote>
<p>比如，我们没有ArrayList<int>，只有ArrayList<Integer>, 为何？</p>
</blockquote>
<p>因为当类型擦除后，ArrayList的原始类型变为Object，但是Object类型不能存储int值，只能引用Integer的值。</p>
<p>另外需要注意，我们能够使用list.add(1)是因为Java基础类型的自动装箱拆箱操作。</p>
<h2 id="37-如何理解泛型类型不能实例化">3.7 如何理解泛型类型不能实例化？</h2>
<blockquote>
<p>不能实例化泛型类型, 这本质上是由于类型擦除决定的：</p>
</blockquote>
<p>T test = new T(); // ERROR</p>
<p>因为在 Java 编译期没法确定泛型参数化类型，也就找不到对应的类字节码文件，所以自然就不行了，此外由于T 被擦除为 Object，如果可以 new T() 则就变成了 new Object()，失去了本意。<br>
   <br>
如果我们确实需要实例化一个泛型，应该如何做呢？可以通过反射实现</p>
<pre><code class="language-java">static &lt;T&gt; T newTclass (Class &lt; T &gt; clazz) throws InstantiationException, IllegalAccessException {
    T obj = clazz.newInstance();
    return obj;
}
</code></pre>
<h2 id="38-泛型数组能不能采用具体的泛型类型进行初始化">3.8 泛型数组：能不能采用具体的泛型类型进行初始化？</h2>
<h2 id="39-泛型数组如何正确的初始化泛型数组实例">3.9 泛型数组：如何正确的初始化泛型数组实例</h2>
<pre><code class="language-java">public class ArrayWithTypeToken&lt;T&gt; {
    private T[] array;

    public ArrayWithTypeToken(Class&lt;T&gt; type, int size) {
        array = (T[]) Array.newInstance(type, size);
    }

    public void put(int index, T item) {
        array[index] = item;
    }

    public T get(int index) {
        return array[index];
    }

    public T[] create() {
        return array;
    }
}
//...

ArrayWithTypeToken&lt;Integer&gt; arrayToken = new ArrayWithTypeToken&lt;Integer&gt;(Integer.class, 100);
Integer[] array = arrayToken.create();
</code></pre>
<p>所以使用反射来初始化泛型数组算是优雅实现，因为泛型类型 T在运行时才能被确定下来，我们能创建泛型数组也必然是在 Java 运行时想办法，而运行时能起作用的技术最好的就是反射了。</p>
<p>参考链接：https://pdai.tech/md/java/basic/java-basic-x-generic.html</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JAVA并发（四）]]></title>
        <id>https://q456qq520.github.io/post/java-bing-fa-si/</id>
        <link href="https://q456qq520.github.io/post/java-bing-fa-si/">
        </link>
        <updated>2022-08-18T10:13:51.000Z</updated>
        <content type="html"><![CDATA[<h1 id="6-java中的13个原子操作类">6 Java中的13个原子操作类</h1>
<p>Atomic包里一共提供了13个类，属于4种类型的原子更新方式，分别是原子更新基本类型、原子更新数组、原子更新引用和原子更新属性（字段）。Atomic包里的类基本都是使用Unsafe实现的包装类。</p>
<h2 id="61-原子更新基本类型类">6.1 原子更新基本类型类</h2>
<p>使用原子的方式更新基本类型，Atomic包提供了以下3个类。</p>
<pre><code>AtomicBoolean：原子更新布尔类型。
AtomicInteger：原子更新整型。
AtomicLong：原子更新长整型。
</code></pre>
<p>以上3个类提供的方法几乎一模一样，下面以AtomicInteger为例，AtomicInteger的常用方法如下。</p>
<ol>
<li>int addAndGet（int delta）：以原子方式将输入的数值与实例中的值（AtomicInteger里的value）相加，并返回结果。</li>
<li>boolean compareAndSet（int expect，int update）：如果输入的数值等于预期值，则以原子方式将该值设置为输入的值。</li>
<li>int getAndIncrement()：以原子方式将当前值加1，注意，这里返回的是自增前的值。</li>
<li>void lazySet（int newValue）：最终会设置成newValue，使用lazySet设置值后，可能导致其他<br>
线程在之后的一小段时间内还是可以读到旧的值。</li>
<li>int getAndSet（int newValue）：以原子方式设置为newValue的值，并返回旧值。</li>
</ol>
<p>那么getAndIncrement是如何实现原子操作的呢？</p>
<blockquote>
<p>AtomicInteger</p>
</blockquote>
<pre><code class="language-java">  public final int getAndIncrement() {
        return unsafe.getAndAddInt(this, valueOffset, 1);
    }
</code></pre>
<p>Atomic包里的类基本都是使用Unsafe实现的，Unsafe只提供了3种CAS方法：compareAndSwapObject、compareAndSwapInt和compareAndSwapLong，都是native方法。</p>
<h2 id="62-原子更新数组">6.2 原子更新数组</h2>
<p>通过原子的方式更新数组里的某个元素，Atomic包提供了以下3个类。</p>
<pre><code>AtomicIntegerArray：原子更新整型数组里的元素。
AtomicLongArray：原子更新长整型数组里的元素。
AtomicReferenceArray：原子更新引用类型数组里的元素。
</code></pre>
<p>AtomicIntegerArray类主要是提供原子的方式更新数组里的整型，其常用方法如下。</p>
<pre><code>int addAndGet（int i，int delta）：以原子方式将输入值与数组中索引i的元素相加。
boolean compareAndSet（int i，int expect，int update）：如果当前值等于预期值，则以原子方式将数组位置i的元素设置成update值。
</code></pre>
<p>以上几个类提供的方法几乎一样</p>
<h2 id="63-原子更新引用类型">6.3 原子更新引用类型</h2>
<p>原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下3个类。</p>
<pre><code>AtomicReference：原子更新引用类型。
AtomicReferenceFieldUpdater：原子更新引用类型里的字段。
AtomicMarkableReference：原子更新带有标记位的引用类型。可以原子更新一个布尔类型的标记位和引用类型。
</code></pre>
<h2 id="64-原子更新字段类">6.4 原子更新字段类</h2>
<p>如果需原子地更新某个类里的某个字段时，就需要使用原子更新字段类，Atomic包提供了以下3个类进行原子字段更新。</p>
<pre><code>AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。
AtomicLongFieldUpdater：原子更新长整型字段的更新器。
AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于原子的更新数据和数据的版本号，可以解决使用CAS进行原子更新时可能出现的ABA问题。
</code></pre>
<p>要想原子地更新字段类需要两步。第一步，因为原子更新字段类都是抽象类，每次使用的时候必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新类的字段（属性）必须使用public volatile修饰符。</p>
<h1 id="7-java中的并发工具类">7 Java中的并发工具类</h1>
<p>在JDK的并发包里提供了几个非常有用的并发工具类。CountDownLatch、CyclicBarrier和Semaphore工具类提供了一种并发流程控制的手段，Exchanger工具类则提供了在线程间交换数据的一种手段。</p>
<h2 id="71-等待多线程完成的countdownlatch">7.1 等待多线程完成的CountDownLatch</h2>
<p>CountDownLatch允许一个或多个线程等待其他线程完成操作</p>
<p>当我们调用CountDownLatch的countDown方法时，N就会减1，CountDownLatch的await方法会阻塞当前线程，直到N变成零。由于countDown方法可以用在任何地方，所以这里说的N个点，可以是N个线程，也可以是1个线程里的N个执行步骤。用在多个线程时，只需要把这个CountDownLatch的引用传递到线程里即可。</p>
<p>计数器必须大于等于0，只是等于0时候，计数器就是零，调用await方法时不会阻塞当前线程。CountDownLatch不可能重新初始化或者修改CountDownLatch对象的内部计数器的值。一个线程调用countDown方法happen-before，另外一个线程调用await方法。</p>
<h2 id="72-同步屏障cyclicbarrier">7.2 同步屏障CyclicBarrier</h2>
<p>CyclicBarrier的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。</p>
<h3 id="721-cyclicbarrier简介">7.2.1 CyclicBarrier简介</h3>
<p>CyclicBarrier默认的构造方法是CyclicBarrier（int parties），其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。示例代码如下所示。</p>
<blockquote>
<p>CyclicBarrier示例</p>
</blockquote>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.CyclicBarrier;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/19 17:00
 */
public class CyclicBarrierTest {
    static CyclicBarrier c = new CyclicBarrier(2);
    public static void main(String[] args) {
        new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    c.await();
                } catch (Exception e) {
                }
                System.out.println(1);
            }
        }).start();
        try {
            c.await();
        } catch (Exception e) {
        }
        System.out.println(2);
    }
}
</code></pre>
<p>因为主线程和子线程的调度是由CPU决定的，两个线程都有可能先执行，所以会产生两种输出。</p>
<p>如果把new CyclicBarrier(2)修改成new CyclicBarrier(3)，则主线程和子线程会永远等待，因为没有第三个线程执行await方法，即没有第三个线程到达屏障，所以之前到达屏障的两个线程都不会继续执行。</p>
<p>CyclicBarrier还提供一个更高级的构造函数CyclicBarrier（int parties，Runnable barrierAction），用于在线程到达屏障时，优先执行barrierAction，方便处理更复杂的业务场景，如下所示：</p>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.CyclicBarrier;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/19 17:03
 */
public class CyclicBarrierTest2 {
        static CyclicBarrier c = new CyclicBarrier(2, new A());
        public static void main(String[] args) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    try {
                        c.await();
                    } catch (Exception e) {
                    }
                    System.out.println(1);
                }
            }).start();
            try {
                c.await();
            } catch (Exception e) {
            }
            System.out.println(2);
        }
        static class A implements Runnable {
            @Override
            public void run() {
                System.out.println(3);
            }
        }
}
</code></pre>
<p>因为CyclicBarrier设置了拦截线程的数量是2，所以必须等代码中的第一个线程和线程A<br>
都执行完之后，才会继续执行主线程。</p>
<h3 id="722-cyclicbarrier的应用场景">7.2.2 CyclicBarrier的应用场景</h3>
<h3 id="723-cyclicbarrier和countdownlatch的区别">7.2.3 CyclicBarrier和CountDownLatch的区别</h3>
<p>CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置。所以CyclicBarrier能处理更为复杂的业务场景。例如，如果计算发生错误，可以重置计数器，并让线程重新执行一次。</p>
<p>CyclicBarrier还提供其他有用的方法，比如getNumberWaiting方法可以获得Cyclic-Barrier阻塞的线程数量。isBroken()方法用来了解阻塞的线程是否被中断。</p>
<h2 id="73-控制并发线程数的semaphore">7.3 控制并发线程数的Semaphore</h2>
<p>Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。</p>
<h5 id="1应用场景">1.应用场景</h5>
<p>Semaphore可以用于做流量控制，特别是公用资源有限的应用场景，比如数据库连接。假如有一个需求，要读取几万个文件的数据，因为都是IO密集型任务，我们可以启动几十个线程并发地读取，但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只有10个，这时我们必须控制只有10个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。这个时候，就可以使用Semaphore来做流量控制，示例如下：</p>
<blockquote>
<p>SemaphoreTest</p>
</blockquote>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Semaphore;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/22 15:33
 */
public class SemaphoreTest {
    private static final int THREAD_COUNT = 30;
    private static ExecutorService threadPool = Executors.newFixedThreadPool(THREAD_COUNT);
    private static Semaphore s = new Semaphore(10);
    public static void main(String[] args) {
        for (int i = 0; i&lt; THREAD_COUNT; i++) {
            threadPool.execute(new Runnable() {
                @Override
                public void run() {
                    try {
                        s.acquire();
                        System.out.println(&quot;save data&quot;);
                        s.release();
                    } catch (InterruptedException e) {
                    }
                }
            });
        }
        threadPool.shutdown();
    }
}
</code></pre>
<p>在代码中，虽然有30个线程在执行，但是只允许10个并发执行。Semaphore的构造方法Semaphore（int permits）接受一个整型的数字，表示可用的许可证数量。Semaphore（10）表示允许10个线程获取许可证，也就是最大并发数是10。Semaphore的用法也很简单，首先线程使用Semaphore的acquire()方法获取一个许可证，使用完之后调用release()方法归还许可证。还可以用tryAcquire()方法尝试获取许可证。</p>
<h5 id="2其他方法">2.其他方法</h5>
<p>Semaphore还提供一些其他方法，具体如下。</p>
<ol>
<li>intavailablePermits()：返回此信号量中当前可用的许可证数。</li>
<li>intgetQueueLength()：返回正在等待获取许可证的线程数。</li>
<li>booleanhasQueuedThreads()：是否有线程正在等待获取许可证。</li>
<li>void reducePermits（int reduction）：减少reduction个许可证，是个protected方法。</li>
<li>Collection getQueuedThreads()：返回所有等待获取许可证的线程集合，是个protected方<br>
法。</li>
</ol>
<h2 id="74-线程间交换数据的exchanger">7.4 线程间交换数据的Exchanger</h2>
<p>Exchanger（交换者）是一个用于线程间协作的工具类。Exchanger用于进行线程间的数据交换。</p>
<p>它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行exchange方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。</p>
<h3 id="71">7.1</h3>
<p>Exchanger可以用于遗传算法，遗传算法里需要选出两个人作为交配对象，这时候会交换两人的数据，并使用交叉规则得出2个交配结果。</p>
<p>Exchanger也可以用于校对工作，比如我们需要将纸制银行流水通过人工的方式录入成电子银行流水，为了避免错误，采用AB岗两人进行录入，录入到Excel之后，系统需要加载这两个Excel，并对两个Excel数据进行校对，看看是否录入一致。</p>
<blockquote>
<p>11</p>
</blockquote>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.Exchanger;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/22 15:55
 */
public class ExchangerTest {
    private static final Exchanger&lt;String&gt; exgr = new Exchanger&lt;String&gt;();
    private static ExecutorService threadPool = Executors.newFixedThreadPool(2);
    public static void main(String[] args) {
        threadPool.execute(new Runnable() {
            @Override
            public void run() {
                try {
                    String A = &quot;银行流水A&quot;; // A录入银行流水数据
                    exgr.exchange(A);

                    System.out.println(&quot;比较完成&quot;);
                } catch (InterruptedException e) {
                }
            }
        });
        threadPool.execute(new Runnable() {
            @Override
            public void run() {
                try {
                    String B = &quot;银行流水B&quot;; // B录入银行流水数据
                    String A = exgr.exchange(&quot;B&quot;);
                    System.out.println(&quot;A和B数据是否一致：&quot; + A.equals(B) + &quot;，A录入的是：&quot;
                            + A + &quot;，B录入是：&quot; + B);
                } catch (InterruptedException e) {
                }
            }
        });
        threadPool.shutdown();
    }
}
</code></pre>
<p>如果两个线程有一个没有执行exchange()方法，则会一直等待，如果担心有特殊情况发生，避免一直等待，可以使用exchange（V x，longtimeout，TimeUnit unit）设置最大等待时长。</p>
<h1 id="8-java中的线程池">8 Java中的线程池</h1>
<h2 id="81-线程池的实现原理">8.1 线程池的实现原理</h2>
<p>在开发过程中，合理地使用线程池能够带来3个好处。<br>
第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。<br>
第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。<br>
第三：提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。</p>
<p>ThreadPoolExecutor执行execute方法分下面4种情况。<br>
1）如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。<br>
2）如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。<br>
3）如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。<br>
4）如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用<br>
RejectedExecutionHandler.rejectedExecution()方法。</p>
<p>线程池执行任务的方法如下。</p>
<blockquote>
<p>execute()</p>
</blockquote>
<pre><code class="language-java">  public void execute(Runnable command) {
        if (command == null)
            throw new NullPointerException();
        int c = ctl.get();
        if (workerCountOf(c) &lt; corePoolSize) {
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
        if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
            int recheck = ctl.get();
            if (! isRunning(recheck) &amp;&amp; remove(command))
                reject(command);
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
        else if (!addWorker(command, false))
            reject(command);
    }
</code></pre>
<p>线程池中的线程执行任务分两种情况，如下。<br>
1）在execute()方法中创建一个线程时，会让这个线程执行当前任务。<br>
2）这个线程执行完上图中1的任务后，会反复从BlockingQueue获取任务来执行。</p>
<h2 id="82-线程池的使用">8.2 线程池的使用</h2>
<h3 id="821-线程池的创建">8.2.1 线程池的创建</h3>
<p>我们可以通过ThreadPoolExecutor来创建一个线程池</p>
<pre><code class="language-java">new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime,
milliseconds,runnableTaskQueue, handler);
</code></pre>
<p>1）corePoolSize（线程池的基本大小）：当提交一个任务到线程池时，线程池会创建一个线<br>
程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任<br>
务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads()方法，<br>
线程池会提前创建并启动所有基本线程。</p>
<p>2）runnableTaskQueue（任务队列）：用于保存等待执行的任务的阻塞队列。可以选择以下几<br>
个阻塞队列。<br>
ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按FIFO（先进先出）原则对元素进行排序。<br>
LinkedBlockingQueue：一个基于链表结构的阻塞队列，此队列按FIFO排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列。<br>
SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于Linked-BlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。<br>
PriorityBlockingQueue：一个具有优先级的无限阻塞队列。</p>
<p>3）maximumPoolSize（线程池最大数量）：线程池允许创建的最大线程数。如果队列满了，并<br>
且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是，如<br>
果使用了无界的任务队列这个参数就没什么效果。</p>
<p>4）ThreadFactory：用于设置创建线程的工厂。</p>
<p>5）RejectedExecutionHandler（拒绝策略）：当队列和线程池都满了，说明线程池处于饱和状<br>
态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法<br>
处理新任务时抛出异常。</p>
<pre><code>AbortPolicy：直接抛出异常。
CallerRunsPolicy：只用调用者所在线程来运行任务。
DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。
DiscardPolicy：不处理，丢弃掉。
</code></pre>
<h3 id="822-向线程池提交任务">8.2.2 向线程池提交任务</h3>
<p>可以使用两个方法向线程池提交任务，分别为execute()和submit()方法。</p>
<p>**execute()**方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功。通过以下代码可知execute()方法输入的任务是一个Runnable类的实例。</p>
<pre><code class="language-java">threadsPool.execute(new Runnable() {
    @Override
    public void run() {
    // TODO Auto-generated method stub
    }
});
</code></pre>
<p>submit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。</p>
<pre><code class="language-java">Future&lt;Object&gt; future = executor.submit(harReturnValuetask);
    try {
        Object s = future.get();
    } catch (InterruptedException e) {
    // 处理中断异常
    } catch (ExecutionException e) {
    // 处理无法执行任务异常
    } finally {
    // 关闭线程池
    executor.shutdown();
}
</code></pre>
<h3 id="823-关闭线程池">8.2.3 关闭线程池</h3>
<p>可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池。它们的原理是遍历线程池中的工作线程，然后逐个调用线程的interrupt方法来中断线程，所以无法响应中断的任务可能永远无法终止。</p>
<p>但是它们存在一定的区别，shutdownNow首先将线程池的状态设置成STOP，然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表，而shutdown只是将线程池的状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。</p>
<p>只要调用了这两个关闭方法中的任意一个，isShutdown方法就会返回true。当所有的任务都已关闭后，才表示线程池关闭成功，这时调用isTerminaed方法会返回true。至于应该调用哪一种方法来关闭线程池，应该由提交到线程池的任务特性决定，通常调用shutdown方法来关闭线程池，如果任务不一定要执行完，则可以调用shutdownNow方法。</p>
<h3 id="824-合理地配置线程池">8.2.4 合理地配置线程池</h3>
<h3 id="825-线程池的监控">8.2.5 线程池的监控</h3>
<p>果在系统中大量使用线程池，则有必要对线程池进行监控，方便在出现问题时，可以根<br>
据线程池的使用状况快速定位问题。可以通过线程池提供的参数进行监控，在监控线程池的<br>
时候可以使用以下属性。</p>
<p>taskCount：线程池需要执行的任务数量。<br>
completedTaskCount：线程池在运行过程中已完成的任务数量，小于或等于taskCount。<br>
largestPoolSize：线程池里曾经创建过的最大线程数量。通过这个数据可以知道线程池是<br>
否曾经满过。如该数值等于线程池的最大大小，则表示线程池曾经满过。<br>
getPoolSize：线程池的线程数量。如果线程池不销毁的话，线程池里的线程不会自动销<br>
毁，所以这个大小只增不减。<br>
getActiveCount：获取活动的线程数。</p>
<p>通过扩展线程池进行监控。可以通过继承线程池来自定义线程池，重写线程池的beforeExecute、afterExecute和terminated方法，也可以在任务执行前、执行后和线程池关闭前执行一些代码来进行监控。例如，监控任务的平均执行时间、最大执行时间和最小执行时间等。这几个方法在线程池里是空方法。</p>
<h1 id="9-executor框架">9 Executor框架</h1>
<p>Java的线程既是工作单元，也是执行机制。从JDK 5开始，把工作单元与执行机制分离开来。工作单元包括Runnable和Callable，而执行机制由Executor框架提供。</p>
<h2 id="91-executor框架简介">9..1 Executor框架简介</h2>
<h3 id="911-executor框架的两级调度模型">9.1.1 Executor框架的两级调度模型</h3>
<p>在HotSpot VM的线程模型中，Java线程（java.lang.Thread）被一对一映射为本地操作系统线程。Java线程启动时会创建一个本地操作系统线程；当该Java线程终止时，这个操作系统线程也会被回收。操作系统会调度所有线程并将它们分配给可用的CPU。</p>
<p>在上层，Java多线程程序通常把应用分解为若干个任务，然后使用用户级的调度器（Executor框架）将这些任务映射为固定数量的线程；在底层，操作系统内核将这些线程映射到硬件处理器上。</p>
<p>应用程序通过Executor框架控制上层的调度；而下层的调度由操作系统内核控制，下层的调度不受应用程序的控制。</p>
<h3 id="912-executor框架的结构与成员">9.1.2 Executor框架的结构与成员</h3>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1661163229274.png" alt="任务的两级调度模型" loading="lazy"></figure>
<h5 id="1executor框架的结构">1.Executor框架的结构</h5>
<p>Executor框架主要由3大部分组成如下。<br>
任务。包括被执行任务需要实现的接口：Runnable接口或Callable接口。<br>
任务的执行。包括任务执行机制的核心接口Executor，以及继承自Executor的ExecutorService接口。Executor框架有两个关键类实现了ExecutorService接口（ThreadPoolExecutor和ScheduledThreadPoolExecutor）。<br>
异步计算的结果。包括接口Future和实现Future接口的FutureTask类</p>
<p>下面是这些类和接口的简介。</p>
<ol>
<li>Executor是一个接口，它是Executor框架的基础，它将任务的提交与任务的执行分离开来。</li>
<li>ThreadPoolExecutor是线程池的核心实现类，用来执行被提交的任务</li>
<li>·ScheduledThreadPoolExecutor是一个实现类，可以在给定的延迟后运行命令，或者定期执行命令。ScheduledThreadPoolExecutor比Timer更灵活，功能更强大。</li>
<li>Future接口和实现Future接口的FutureTask类，代表异步计算的结果。</li>
<li>Runnable接口和Callable接口的实现类，都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行。</li>
</ol>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1661163737003.png" alt="Executor框架的使用示意图" loading="lazy"></figure>
<p>主线程首先要创建实现Runnable或者Callable接口的任务对象。工具类Executors可以把一个Runnable对象封装为一个Callable对象（Executors.callable（Runnable task）或Executors.callable（Runnable task，Object resule））。</p>
<p>然后可以把Runnable对象直接交给ExecutorService执行（ExecutorService.execute（Runnablecommand））；或者也可以把Runnable对象或Callable对象提交给ExecutorService执行（ExecutorService.submit（Runnable task）或ExecutorService.submit（Callable<T>task）。</p>
<p>如果执行ExecutorService.submit（…），ExecutorService将返回一个实现Future接口的对象（到目前为止的JDK中，返回的是FutureTask对象）。由于FutureTask实现了Runnable，程序员也可以创建FutureTask，然后直接交给ExecutorService执行。</p>
<p>最后，主线程可以执行FutureTask.get()方法来等待任务执行完成。主线程也可以执FutureTask.cancel（boolean mayInterruptIfRunning）来取消此任务的执行。</p>
<h5 id="2executor框架的成员">2.Executor框架的成员</h5>
<p>Executor框架的主要成员：ThreadPoolExecutor、ScheduledThreadPoolExecutor、Future接口、Runnable接口、Callable接口和Executors。</p>
<p>（1）ThreadPoolExecutor</p>
<p>ThreadPoolExecutor通常使用工厂类Executors来创建。Executors可以创建3种类型的ThreadPoolExecutor：SingleThreadExecutor、FixedThreadPool和CachedThreadPool。</p>
<ol>
<li>FixedThreadPool。下面是Executors提供的，创建使用固定线程数的FixedThreadPool的API。</li>
</ol>
<pre><code class="language-java"> public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue&lt;Runnable&gt;());
    }

    public static ExecutorService newWorkStealingPool(int parallelism) {
        return new ForkJoinPool
            (parallelism,
             ForkJoinPool.defaultForkJoinWorkerThreadFactory,
             null, true);
    }
</code></pre>
<p>FixedThreadPool适用于为了满足资源管理的需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。</p>
<ol start="2">
<li>SingleThreadExecutor。下面是Executors提供的，创建使用单个线程的SingleThreadExecutor的API。</li>
</ol>
<pre><code class="language-java">    public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue&lt;Runnable&gt;()));
    }

    public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue&lt;Runnable&gt;(),
                                    threadFactory));
    }
</code></pre>
<p>SingleThreadExecutor适用于需要保证顺序地执行各个任务；并且在任意时间点，不会有多个线程是活动的应用场景。</p>
<ol start="3">
<li>CachedThreadPool。下面是Executors提供的，创建一个会根据需要创建新线程的CachedThreadPool的API。</li>
</ol>
<pre><code class="language-java">   public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue&lt;Runnable&gt;());
    }

    public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue&lt;Runnable&gt;(),
                                      threadFactory);
    }
</code></pre>
<p>CachedThreadPool是大小无界的线程池，适用于执行很多的短期异步任务的小程序，或者是负载较轻的服务器。</p>
<p>（2）ScheduledThreadPoolExecutor</p>
<p>ScheduledThreadPoolExecutor通常使用工厂类Executors来创建。Executors可以创建2种类型的ScheduledThreadPoolExecutor，如下。</p>
<ol>
<li>ScheduledThreadPoolExecutor。包含若干个线程的ScheduledThreadPoolExecutor。</li>
<li>SingleThreadScheduledExecutor。只包含一个线程的ScheduledThreadPoolExecutor。</li>
</ol>
<p>ScheduledThreadPoolExecutor适用于需要多个后台线程执行周期任务，同时为了满足资源管理的需求而需要限制后台线程的数量的应用场景。</p>
<p>SingleThreadScheduledExecutor适用于需要单个后台线程执行周期任务，同时需要保证顺序地执行各个任务的应用场景。</p>
<p>（3）Future接口</p>
<p>Future接口和实现Future接口的FutureTask类用来表示异步计算的结果。当我们把Runnable接口或Callable接口的实现类提交（submit）给ThreadPoolExecutor或ScheduledThreadPoolExecutor时，ThreadPoolExecutor或ScheduledThreadPoolExecutor会向我们返回一个FutureTask对象。下面是对应的API。</p>
<pre><code class="language-java">&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);


&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);

Future&lt;?&gt; submit(Runnable task);
</code></pre>
<p>（4）Runnable接口和Callable接口</p>
<p>Runnable接口和Callable接口的实现类，都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行。它们之间的区别是Runnable不会返回结果，而Callable可以返回结果。</p>
<p>除了可以自己创建实现Callable接口的对象外，还可以使用工厂类Executors来把一个Runnable包装成一个Callable。</p>
<h2 id="92-threadpoolexecutor详解">9.2 ThreadPoolExecutor详解</h2>
<p>Executor框架最核心的类是ThreadPoolExecutor，它是线程池的实现类，主要由下列4个组件构成。</p>
<ol>
<li>corePool：核心线程池的大小。</li>
<li>maximumPool：最大线程池的大小。</li>
<li>BlockingQueue：用来暂时保存任务的工作队列。</li>
<li>RejectedExecutionHandler：当ThreadPoolExecutor已经关闭或ThreadPoolExecutor已经饱和时（达到了最大线程池大小且工作队列已满），execute()方法将要调用的Handler。</li>
</ol>
<p>通过Executor框架的工具类Executors，可以创建3种类型的ThreadPoolExecutor。<br>
FixedThreadPool<br>
SingleThreadExecutor<br>
CachedThreadPool</p>
<h3 id="921-fixedthreadpool详解">9.2.1 FixedThreadPool详解</h3>
<p>FixedThreadPool被称为可重用固定线程数的线程池。</p>
<p>FixedThreadPool的corePoolSize和maximumPoolSize都被设置为创建FixedThreadPool时指定的参数nThreads。</p>
<p>当线程池中的线程数大于corePoolSize时，keepAliveTime为多余的空闲线程等待新任务的最长时间，超过这个时间后多余的线程将被终止。这里把keepAliveTime设置为0L，意味着多余的空闲线程会被立即终止。</p>
<p>FixedThreadPool使用无界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer.MAX_VALUE）。使用无界队列作为工作队列会对线程池带来如下影响。</p>
<p>1）当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中<br>
的线程数不会超过corePoolSize。<br>
2）由于1，使用无界队列时maximumPoolSize将是一个无效参数。<br>
3）由于1和2，使用无界队列时keepAliveTime将是一个无效参数。<br>
4）由于使用无界队列，运行中的FixedThreadPool（未执行方法shutdown()或shutdownNow()）不会拒绝任务（不会调用RejectedExecutionHandler.rejectedExecution方法）。</p>
<h3 id="922-singlethreadexecutor详解">9.2.2 SingleThreadExecutor详解</h3>
<p>SingleThreadExecutor是使用单个worker线程的Executor。</p>
<p>SingleThreadExecutor的corePoolSize和maximumPoolSize被设置为1。其他参数与<br>
FixedThreadPool相同。SingleThreadExecutor使用无界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer.MAX_VALUE）。SingleThreadExecutor使用无界队列作为工作队列对线程池带来的影响与FixedThreadPool相同。</p>
<h3 id="923-cachedthreadpool详解">9.2.3 CachedThreadPool详解</h3>
<p>CachedThreadPool是一个会根据需要创建新线程的线程池。</p>
<p>CachedThreadPool的corePoolSize被设置为0，即corePool为空；maximumPoolSize被设置为<br>
Integer.MAX_VALUE，即maximumPool是无界的。这里把keepAliveTime设置为60L，意味着CachedThreadPool中的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。</p>
<p>CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列，但<br>
CachedThreadPool的maximumPool是无界的。这意味着，如果主线程提交任务的速度高于<br>
maximumPool中线程处理任务的速度时，CachedThreadPool会不断创建新线程。极端情况下，CachedThreadPool会因为创建过多线程而耗尽CPU和内存资源。</p>
<p>SynchronousQueue是一个没有容量的阻塞队列。每个插入操作必须等待另一个线程的对应移除操作，反之亦然。CachedThreadPool使用SynchronousQueue，把主线程提交的任务传递给空闲线程执行。</p>
<h2 id="93-scheduledthreadpoolexecutor详解">9.3 ScheduledThreadPoolExecutor详解</h2>
<p>ScheduledThreadPoolExecutor继承自ThreadPoolExecutor。它主要用来在给定的延迟之后运行任务，或者定期执行任务。</p>
<h2 id="94-futuretask详解">9.4 FutureTask详解</h2>
<p>Future接口和实现Future接口的FutureTask类，代表异步计算的结果。</p>
<h3 id="941-futuretask简介">9.4.1 FutureTask简介</h3>
<p>FutureTask除了实现Future接口外，还实现了Runnable接口。因此，FutureTask可以交给Executor执行，也可以由调用线程直接执行（FutureTask.run()）。根据FutureTask.run()方法被执行的时机，FutureTask可以处于下面3种状态。</p>
<p>1）未启动。FutureTask.run()方法还没有被执行之前，FutureTask处于未启动状态。当创建一个FutureTask，且没有执行FutureTask.run()方法之前，这个FutureTask处于未启动状态。<br>
2）已启动。FutureTask.run()方法被执行的过程中，FutureTask处于已启动状态。<br>
3）已完成。FutureTask.run()方法执行完后正常结束，或被取消（FutureTask.cancel（…）），或执行FutureTask.run()方法时抛出异常而异常结束，FutureTask处于已完成状态。</p>
<p>当FutureTask处于未启动或已启动状态时，执行FutureTask.get()方法将导致调用线程阻塞；当FutureTask处于已完成状态时，执行FutureTask.get()方法将导致调用线程立即返回结果或抛出异常。</p>
<p>当FutureTask处于未启动状态时，执行FutureTask.cancel()方法将导致此任务永远不会被执行；当FutureTask处于已启动状态时，执行FutureTask.cancel（true）方法将以中断执行此任务线程的方式来试图停止任务；当FutureTask处于已启动状态时，执行FutureTask.cancel（false）方法将不会对正在执行此任务的线程产生影响（让正在执行的任务运行完成）；当FutureTask处于已完成状态时，执行FutureTask.cancel（…）方法将返回false。</p>
<h3 id="942-futuretask的使用">9.4.2 FutureTask的使用</h3>
<p>可以把FutureTask交给Executor执行；也可以通过ExecutorService.submit（…）方法返回一个FutureTask，然后执行FutureTask.get()方法或FutureTask.cancel（…）方法。除此以外，还可以单独使用FutureTask。</p>
<p>当一个线程需要等待另一个线程把某个任务执行完后它才能继续执行，此时可以使用FutureTask。假设有多个线程执行若干任务，每个任务最多只能被执行一次。当多个线程试图同时执行同一个任务时，只允许一个线程执行任务，其他线程需要等待这个任务执行完后才能继续执行。下面是对应的示例代码。</p>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.*;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/23 17:34
 */
public class FutureTaskTest {

    private final ConcurrentMap&lt;Object, Future&lt;String&gt;&gt; taskCache =
            new ConcurrentHashMap&lt;Object, Future&lt;String&gt;&gt;();

    private String executionTask(final String taskName)
            throws ExecutionException, InterruptedException {
        while (true) {
            Future&lt;String&gt; future = taskCache.get(taskName); // 1.1,2.1
            if (future == null) {
                Callable&lt;String&gt; task = new Callable&lt;String&gt;() {
                    public String call() throws InterruptedException {
                        return taskName;
                    }
                };

                FutureTask&lt;String&gt; futureTask = new FutureTask&lt;String&gt;(task);
                future = taskCache.putIfAbsent(taskName, futureTask); // 1.3
                if (future == null) {
                    future = futureTask;
                    futureTask.run(); // 1.4执行任务
                }
                try {
                    return future.get(); // 1.5,
                } catch (CancellationException e) {
                    taskCache.remove(taskName, future);
                }
            }
        }
    }
}
</code></pre>
<p>当两个线程试图同时执行同一个任务时，如果Thread 1执行1.3后Thread 2执行2.1，那么接下来Thread 2将在2.2等待，直到Thread 1执行完1.4后Thread 2才能从2.2（FutureTask.get()）返回。</p>
<h3 id="943-futuretask的实现">9.4.3 FutureTask的实现</h3>
<p>FutureTask的实现基于AbstractQueuedSynchronizer（以下简称为AQS）。java.util.concurrent中的很多可阻塞类（比如ReentrantLock）都是基于AQS来实现的。AQS是一个同步框架，它提供通用机制来原子性管理同步状态、阻塞和唤醒线程，以及维护被阻塞线程的队列。</p>
<p>每一个基于AQS实现的同步器都会包含两种类型的操作，如下。</p>
<p>至少一个acquire操作。这个操作阻塞调用线程，除非/直到AQS的状态允许这个线程继续执行。FutureTask的acquire操作为get()/get（long timeout，TimeUnit unit）方法调用。</p>
<p>至少一个release操作。这个操作改变AQS的状态，改变后的状态可允许一个或多个阻塞线程被解除阻塞。FutureTask的release操作包括run()方法和cancel（…）方法。</p>
<p>基于“复合优先于继承”的原则，FutureTask声明了一个内部私有的继承于AQS的子类Sync，对FutureTask所有公有方法的调用都会委托给这个内部子类。</p>
<p>FutureTask.run()的执行过程如下。</p>
<p>1）执行在构造函数中指定的任务（Callable.call()）。<br>
2）以原子方式来更新同步状态（调用AQS.compareAndSetState（int expect，int update），设置<br>
state为执行完成状态RAN）。如果这个原子操作成功，就设置代表计算结果的变量result的值为Callable.call()的返回值，然后调用AQS.releaseShared（int arg）。<br>
3）AQS.releaseShared（int arg）首先会回调在子类Sync中实现的tryReleaseShared（arg）来执行release操作（设置运行任务的线程runner为null，然会返回true）；AQS.releaseShared（int arg，<br>
然后唤醒线程等待队列中的第一个线程。<br>
4）调用FutureTask.done()。<br>
当执行FutureTask.get()方法时，如果FutureTask不是处于执行完成状态RAN或已取消状态CANCELLED，当前执行线程将到AQS的线程等待队列中等待。当某个线程执行FutureTask.run()方法或FutureTask.cancel（...）方法时，会唤醒线程等待队列的第一个线程。</p>
<h1 id="10-java并发编程实践">10 Java并发编程实践</h1>
<h2 id="101-生产者和消费者模式">10.1 生产者和消费者模式</h2>
<p>在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序整体处理数据的速度。</p>
<p>什么是生产者和消费者模式?</p>
<p>生产者和消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通信，而是通过<strong>阻塞队列</strong>来进行通信，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。</p>
<h3 id="1011-生产者消费者模式实战">10.1.1 生产者消费者模式实战</h3>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JAVA并发（三）]]></title>
        <id>https://q456qq520.github.io/post/java-bing-fa-san/</id>
        <link href="https://q456qq520.github.io/post/java-bing-fa-san/">
        </link>
        <updated>2022-08-16T03:20:47.000Z</updated>
        <content type="html"><![CDATA[<h1 id="5-java并发容器和框架">5 Java并发容器和框架、</h1>
<h2 id="51-concurrenthashmap的实现原理与使用">5.1 ConcurrentHashMap的实现原理与使用</h2>
<h3 id="511-为什么要使用concurrenthashmap">5.1.1 为什么要使用ConcurrentHashMap</h3>
<p>在并发编程中使用HashMap可能导致程序死循环。而使用线程安全的HashTable效率又非常低下，基于以上两个原因，便有了ConcurrentHashMap的登场机会。</p>
<h5 id="1线程不安全的hashmap">（1）线程不安全的HashMap</h5>
<p>在多线程环境下，使用HashMap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap。如下所示：</p>
<pre><code class="language-java">final HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(2);
Thread t = new Thread(new Runnable() {
    @Override
    public void run() {
        for (int i = 0; i &lt; 10000; i++) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    map.put(UUID.randomUUID().toString(), &quot;&quot;);
                }
            }, &quot;ftf&quot; + i).start();
        }
    }
}, &quot;ftf&quot;);
t.start();
t.join();
</code></pre>
<p>HashMap在并发执行put操作时会引起死循环，<strong>是因为多线程会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry。</strong></p>
<h5 id="2效率低下的hashtable">（2）效率低下的HashTable</h5>
<p>HashTable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法，其他线程也访问HashTable的同步方法时，会进入阻塞或轮询状态。如线程1使用put进行元素添加，线程2不但不能使用put方法添加元素，也不能使用get方法来获取元素，所以竞争越激烈效率越低。</p>
<h5 id="3concurrenthashmap的锁分段技术可有效提升并发访问率">（3）ConcurrentHashMap的锁分段技术可有效提升并发访问率</h5>
<p>ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段地存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。</p>
<h3 id="512-concurrenthashmap的结构">5.1.2 ConcurrentHashMap的结构</h3>
<p>在JDK1.5~1.7版本，Java使用了分段锁机制实现ConcurrentHashMap.</p>
<p>简而言之，ConcurrentHashMap在对象中保存了一个Segment数组，即将整个Hash表划分为多个分段；而每个Segment元素，即每个分段则类似于一个Hashtable；这样，在执行put操作时首先根据hash算法定位到元素属于哪个Segment，然后对该Segment加锁即可。因此，ConcurrentHashMap在多线程并发编程中可是实现多线程put操作。</p>
<p>在JDK1.7之前，ConcurrentHashMap是通过分段锁机制来实现的，所以其最大并发度受Segment的个数限制。因此，在JDK1.8中，ConcurrentHashMap的实现原理摒弃了这种设计，而是选择了与HashMap类似的数组+链表+红黑树的方式实现，而加锁则采用CAS和synchronized实现。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1660640046350.png" alt="" loading="lazy"></figure>
<h3 id="513-初始化">5.1.3 初始化</h3>
<pre><code class="language-java">// 这构造函数里，什么都不干
public ConcurrentHashMap() {
}
public ConcurrentHashMap(int initialCapacity) {
    if (initialCapacity &lt; 0)
        throw new IllegalArgumentException();
    int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ?
               MAXIMUM_CAPACITY :
               tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1));
    this.sizeCtl = cap;
}
</code></pre>
<p>通过提供初始容量，计算了 sizeCtl，sizeCtl = 【 (1.5 * initialCapacity + 1)，然后向上取最近的 2 的 n 次方】。如 initialCapacity 为 10，那么得到 sizeCtl 为 16，如果 initialCapacity 为 11，得到 sizeCtl 为 32。</p>
<h3 id="514-concurrenthashmap的操作">5.1.4 ConcurrentHashMap的操作</h3>
<h5 id="1put">1.put</h5>
<pre><code class="language-java">public V put(K key, V value) {
    return putVal(key, value, false);
}
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    // 得到 hash 值
    int hash = spread(key.hashCode());
    // 用于记录相应链表的长度
    int binCount = 0;
    for (Node&lt;K,V&gt;[] tab = table;;) {
        Node&lt;K,V&gt; f; int n, i, fh;
        // 如果数组&quot;空&quot;，进行数组初始化
        if (tab == null || (n = tab.length) == 0)
            // 初始化数组，后面会详细介绍
            tab = initTable();

        // 找该 hash 值对应的数组下标，得到第一个节点 f
        else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) {
            // 如果数组该位置为空，
            //    用一次 CAS 操作将这个新值放入其中即可，这个 put 操作差不多就结束了，可以拉到最后面了
            //          如果 CAS 失败，那就是有并发操作，进到下一个循环就好了
            if (casTabAt(tab, i, null,
                         new Node&lt;K,V&gt;(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        // hash 居然可以等于 MOVED，这个需要到后面才能看明白，不过从名字上也能猜到，肯定是因为在扩容
        else if ((fh = f.hash) == MOVED)
            // 帮助数据迁移，这个等到看完数据迁移部分的介绍后，再理解这个就很简单了
            tab = helpTransfer(tab, f);

        else { // 到这里就是说，f 是该位置的头节点，而且不为空

            V oldVal = null;
            // 获取数组该位置的头节点的监视器锁
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    if (fh &gt;= 0) { // 头节点的 hash 值大于 0，说明是链表
                        // 用于累加，记录链表的长度
                        binCount = 1;
                        // 遍历链表
                        for (Node&lt;K,V&gt; e = f;; ++binCount) {
                            K ek;
                            // 如果发现了&quot;相等&quot;的 key，判断是否要进行值覆盖，然后也就可以 break 了
                            if (e.hash == hash &amp;&amp;
                                ((ek = e.key) == key ||
                                 (ek != null &amp;&amp; key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            // 到了链表的最末端，将这个新值放到链表的最后面
                            Node&lt;K,V&gt; pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node&lt;K,V&gt;(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) { // 红黑树
                        Node&lt;K,V&gt; p;
                        binCount = 2;
                        // 调用红黑树的插值方法插入新节点
                        if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }

            if (binCount != 0) {
                // 判断是否要将链表转换为红黑树，临界值和 HashMap 一样，也是 8
                if (binCount &gt;= TREEIFY_THRESHOLD)
                    // 这个方法和 HashMap 中稍微有一点点不同，那就是它不是一定会进行红黑树转换，
                    // 如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树
                    //    具体源码我们就不看了，扩容部分后面说
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    // 
    addCount(1L, binCount);
    return null;
}
</code></pre>
<p>初始化数组: initTable<br>
这个比较简单，主要就是初始化一个合适大小的数组，然后会设置 sizeCtl。</p>
<p>初始化方法中的并发问题是通过对 sizeCtl 进行一个 CAS 操作来控制的</p>
<pre><code class="language-java">private final Node&lt;K,V&gt;[] initTable() {
    Node&lt;K,V&gt;[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        if ((sc = sizeCtl) &lt; 0)
            Thread.yield(); // lost initialization race; just spin
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            try {
                if ((tab = table) == null || tab.length == 0) {
                    int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings(&quot;unchecked&quot;)
                    Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
                    table = tab = nt;
                    sc = n - (n &gt;&gt;&gt; 2);
                }
            } finally {
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
</code></pre>
<p><strong>链表转红黑树: treeifyBin</strong><br>
treeifyBin 不一定就会进行红黑树转换，也可能是仅仅做数组扩容。</p>
<pre><code class="language-java">private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) {
    Node&lt;K,V&gt; b; int n, sc;
    if (tab != null) {
        // MIN_TREEIFY_CAPACITY 为 64
        // 所以，如果数组长度小于 64 的时候，其实也就是 32 或者 16 或者更小的时候，会进行数组扩容
        if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY)
            // 后面我们再详细分析这个方法
            tryPresize(n &lt;&lt; 1);
        // b 是头节点
        else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) {
            // 加锁
            synchronized (b) {

                if (tabAt(tab, index) == b) {
                    // 下面就是遍历链表，建立一颗红黑树
                    TreeNode&lt;K,V&gt; hd = null, tl = null;
                    for (Node&lt;K,V&gt; e = b; e != null; e = e.next) {
                        TreeNode&lt;K,V&gt; p =
                            new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val,
                                              null, null);
                        if ((p.prev = tl) == null)
                            hd = p;
                        else
                            tl.next = p;
                        tl = p;
                    }
                    // 将红黑树设置到数组相应位置中
                    setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd));
                }
            }
        }
    }
}
</code></pre>
<p><strong>扩容: tryPresize</strong></p>
<pre><code class="language-java"> // 首先要说明的是，方法参数 size 传进来的时候就已经翻了倍了
private final void tryPresize(int size) {
    // c: size 的 1.5 倍，再加 1，再往上取最近的 2 的 n 次方。
    int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY :
        tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1);
    int sc;
    while ((sc = sizeCtl) &gt;= 0) {
        Node&lt;K,V&gt;[] tab = table; int n;

        // 这个 if 分支和之前说的初始化数组的代码基本上是一样的，在这里，我们可以不用管这块代码
        if (tab == null || (n = tab.length) == 0) {
            n = (sc &gt; c) ? sc : c;
            if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
                try {
                    if (table == tab) {
                        @SuppressWarnings(&quot;unchecked&quot;)
                        Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
                        table = nt;
                        sc = n - (n &gt;&gt;&gt; 2); // 0.75 * n
                    }
                } finally {
                    sizeCtl = sc;
                }
            }
        }
        else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY)
            break;
        else if (tab == table) {
            // 我没看懂 rs 的真正含义是什么，不过也关系不大
            int rs = resizeStamp(n);

            if (sc &lt; 0) {
                Node&lt;K,V&gt;[] nt;
                if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                    sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||
                    transferIndex &lt;= 0)
                    break;
                // 2. 用 CAS 将 sizeCtl 加 1，然后执行 transfer 方法
                //    此时 nextTab 不为 null
                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))
                    transfer(tab, nt);
            }
            // 1. 将 sizeCtl 设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)
            //     我是没看懂这个值真正的意义是什么? 不过可以计算出来的是，结果是一个比较大的负数
            //  调用 transfer 方法，此时 nextTab 参数为 null
            else if (U.compareAndSwapInt(this, SIZECTL, sc,
                                         (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2))
                transfer(tab, null);
        }
    }
}
</code></pre>
<p>这个方法的核心在于 sizeCtl 值的操作，首先将其设置为一个负数，然后执行 transfer(tab, null)，再下一个循环将 sizeCtl 加 1，并执行 transfer(tab, nt)，之后可能是继续 sizeCtl 加 1，并执行 transfer(tab, nt)。 所以，可能的操作就是执行 1 次 transfer(tab, null) + 多次 transfer(tab, nt)。</p>
<p><strong>数据迁移: transfer</strong></p>
<p>著作权归https://pdai.tech所有。<br>
链接：https://pdai.tech/md/java/thread/java-thread-x-juc-collection-ConcurrentHashMap.html</p>
<p>原数组长度为 n，所以我们有 n 个迁移任务，让每个线程每次负责一个小任务是最简单的，每做完一个任务再检测是否有其他没做完的任务，帮助迁移就可以了，而这里使用了一个 stride，简单理解就是步长，每个线程每次负责迁移其中的一部分，如每次迁移 16 个小任务。所以，我们就需要一个全局的调度者来安排哪个线程执行哪几个任务，这个就是属性 transferIndex 的作用。</p>
<p>第一个发起数据迁移的线程会将 transferIndex 指向原数组最后的位置，然后从后往前的 stride 个任务属于第一个线程，然后将 transferIndex 指向新的位置，再往前的 stride 个任务属于第二个线程，依此类推。当然，这里说的第二个线程不是真的一定指代了第二个线程，也可以是同一个线程，其实就是将一个大的迁移任务分为了一个个任务包。</p>
<pre><code class="language-java">
private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) {
    int n = tab.length, stride;

    // stride 在单核下直接等于 n，多核模式下为 (n&gt;&gt;&gt;3)/NCPU，最小值是 16
    // stride 可以理解为”步长“，有 n 个位置是需要进行迁移的，
    //   将这 n 个任务分为多个任务包，每个任务包有 stride 个任务
    if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)
        stride = MIN_TRANSFER_STRIDE; // subdivide range

    // 如果 nextTab 为 null，先进行一次初始化
    //    前面我们说了，外围会保证第一个发起迁移的线程调用此方法时，参数 nextTab 为 null
    //       之后参与迁移的线程调用此方法时，nextTab 不会为 null
    if (nextTab == null) {
        try {
            // 容量翻倍
            Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1];
            nextTab = nt;
        } catch (Throwable ex) {      // try to cope with OOME
            sizeCtl = Integer.MAX_VALUE;
            return;
        }
        // nextTable 是 ConcurrentHashMap 中的属性
        nextTable = nextTab;
        // transferIndex 也是 ConcurrentHashMap 的属性，用于控制迁移的位置
        transferIndex = n;
    }

    int nextn = nextTab.length;

    // ForwardingNode 翻译过来就是正在被迁移的 Node
    // 这个构造方法会生成一个Node，key、value 和 next 都为 null，关键是 hash 为 MOVED
    // 后面我们会看到，原数组中位置 i 处的节点完成迁移工作后，
    //    就会将位置 i 处设置为这个 ForwardingNode，用来告诉其他线程该位置已经处理过了
    //    所以它其实相当于是一个标志。
    ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab);


    // advance 指的是做完了一个位置的迁移工作，可以准备做下一个位置的了
    boolean advance = true;
    boolean finishing = false; // to ensure sweep before committing nextTab

    /*
     * 下面这个 for 循环，最难理解的在前面，而要看懂它们，应该先看懂后面的，然后再倒回来看
     * 
     */

    // i 是位置索引，bound 是边界，注意是从后往前
    for (int i = 0, bound = 0;;) {
        Node&lt;K,V&gt; f; int fh;

        // 下面这个 while 真的是不好理解
        // advance 为 true 表示可以进行下一个位置的迁移了
        //   简单理解结局: i 指向了 transferIndex，bound 指向了 transferIndex-stride
        while (advance) {
            int nextIndex, nextBound;
            if (--i &gt;= bound || finishing)
                advance = false;

            // 将 transferIndex 值赋给 nextIndex
            // 这里 transferIndex 一旦小于等于 0，说明原数组的所有位置都有相应的线程去处理了
            else if ((nextIndex = transferIndex) &lt;= 0) {
                i = -1;
                advance = false;
            }
            else if (U.compareAndSwapInt
                     (this, TRANSFERINDEX, nextIndex,
                      nextBound = (nextIndex &gt; stride ?
                                   nextIndex - stride : 0))) {
                // 看括号中的代码，nextBound 是这次迁移任务的边界，注意，是从后往前
                bound = nextBound;
                i = nextIndex - 1;
                advance = false;
            }
        }
        if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) {
            int sc;
            if (finishing) {
                // 所有的迁移操作已经完成
                nextTable = null;
                // 将新的 nextTab 赋值给 table 属性，完成迁移
                table = nextTab;
                // 重新计算 sizeCtl: n 是原数组长度，所以 sizeCtl 得出的值将是新数组长度的 0.75 倍
                sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1);
                return;
            }

            // 之前我们说过，sizeCtl 在迁移前会设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2
            // 然后，每有一个线程参与迁移就会将 sizeCtl 加 1，
            // 这里使用 CAS 操作对 sizeCtl 进行减 1，代表做完了属于自己的任务
            if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
                // 任务结束，方法退出
                if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT)
                    return;

                // 到这里，说明 (sc - 2) == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT，
                // 也就是说，所有的迁移任务都做完了，也就会进入到上面的 if(finishing){} 分支了
                finishing = advance = true;
                i = n; // recheck before commit
            }
        }
        // 如果位置 i 处是空的，没有任何节点，那么放入刚刚初始化的 ForwardingNode ”空节点“
        else if ((f = tabAt(tab, i)) == null)
            advance = casTabAt(tab, i, null, fwd);
        // 该位置处是一个 ForwardingNode，代表该位置已经迁移过了
        else if ((fh = f.hash) == MOVED)
            advance = true; // already processed
        else {
            // 对数组该位置处的结点加锁，开始处理数组该位置处的迁移工作
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    Node&lt;K,V&gt; ln, hn;
                    // 头节点的 hash 大于 0，说明是链表的 Node 节点
                    if (fh &gt;= 0) {
                        // 下面这一块和 Java7 中的 ConcurrentHashMap 迁移是差不多的，
                        // 需要将链表一分为二，
                        //   找到原链表中的 lastRun，然后 lastRun 及其之后的节点是一起进行迁移的
                        //   lastRun 之前的节点需要进行克隆，然后分到两个链表中
                        int runBit = fh &amp; n;
                        Node&lt;K,V&gt; lastRun = f;
                        for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) {
                            int b = p.hash &amp; n;
                            if (b != runBit) {
                                runBit = b;
                                lastRun = p;
                            }
                        }
                        if (runBit == 0) {
                            ln = lastRun;
                            hn = null;
                        }
                        else {
                            hn = lastRun;
                            ln = null;
                        }
                        for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) {
                            int ph = p.hash; K pk = p.key; V pv = p.val;
                            if ((ph &amp; n) == 0)
                                ln = new Node&lt;K,V&gt;(ph, pk, pv, ln);
                            else
                                hn = new Node&lt;K,V&gt;(ph, pk, pv, hn);
                        }
                        // 其中的一个链表放在新数组的位置 i
                        setTabAt(nextTab, i, ln);
                        // 另一个链表放在新数组的位置 i+n
                        setTabAt(nextTab, i + n, hn);
                        // 将原数组该位置处设置为 fwd，代表该位置已经处理完毕，
                        //    其他线程一旦看到该位置的 hash 值为 MOVED，就不会进行迁移了
                        setTabAt(tab, i, fwd);
                        // advance 设置为 true，代表该位置已经迁移完毕
                        advance = true;
                    }
                    else if (f instanceof TreeBin) {
                        // 红黑树的迁移
                        TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;
                        TreeNode&lt;K,V&gt; lo = null, loTail = null;
                        TreeNode&lt;K,V&gt; hi = null, hiTail = null;
                        int lc = 0, hc = 0;
                        for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) {
                            int h = e.hash;
                            TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;
                                (h, e.key, e.val, null, null);
                            if ((h &amp; n) == 0) {
                                if ((p.prev = loTail) == null)
                                    lo = p;
                                else
                                    loTail.next = p;
                                loTail = p;
                                ++lc;
                            }
                            else {
                                if ((p.prev = hiTail) == null)
                                    hi = p;
                                else
                                    hiTail.next = p;
                                hiTail = p;
                                ++hc;
                            }
                        }
                        // 如果一分为二后，节点数小于等于6，那么将红黑树转换回链表
                        ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                            (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t;
                        hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                            (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t;

                        // 将 ln 放置在新数组的位置 i
                        setTabAt(nextTab, i, ln);
                        // 将 hn 放置在新数组的位置 i+n
                        setTabAt(nextTab, i + n, hn);
                        // 将原数组该位置处设置为 fwd，代表该位置已经处理完毕，
                        //    其他线程一旦看到该位置的 hash 值为 MOVED，就不会进行迁移了
                        setTabAt(tab, i, fwd);
                        // advance 设置为 true，代表该位置已经迁移完毕
                        advance = true;
                    }
                }
            }
        }
    }
}
</code></pre>
<p><strong>get 过程分析</strong></p>
<ul>
<li>计算 hash 值</li>
<li>根据 hash 值找到数组对应位置: (n - 1) &amp; h</li>
<li>根据该位置处结点性质进行相应查找<br>
如果该位置为 null，那么直接返回 null 就可以了<br>
如果该位置处的节点刚好就是我们需要的，返回该节点的值即可<br>
如果该位置节点的 hash 值小于 0，说明正在扩容，或者是红黑树<br>
如果以上 3 条都不满足，那就是链表，进行遍历比对即可</li>
</ul>
<h2 id="52-concurrentlinkedqueue">5.2 ConcurrentLinkedQueue</h2>
<p>在并发编程中，有时候需要使用线程安全的队列。如果要实现一个线程安全的队列有两种方式：一种是使用阻塞算法，另一种是使用非阻塞算法。使用阻塞算法的队列可以用一个锁（入队和出队用同一把锁）或两个锁（入队和出队用不同的锁）等方式来实现。非阻塞的实现方式则可以使用循环CAS的方式来实现。</p>
<p>ConcurrentLinkedQueue是一个使用非阻塞算法的基于链接节点的无界线程安全队列，它采用先进先出的规<br>
则对节点进行排序，当我们添加一个元素的时候，它会添加到队列的尾部；当我们获取一个元素时，它会返回队列头部的元素。它采用了“wait-free”算法（即CAS算法）来实现。</p>
<pre><code class="language-java">public class ConcurrentLinkedQueue&lt;E&gt; extends AbstractQueue&lt;E&gt;
        implements Queue&lt;E&gt;, java.io.Serializable {}
</code></pre>
<p>ConcurrentLinkedQueue继承了抽象类AbstractQueue，AbstractQueue定义了对队列的基本操作；同时实现了Queue接口，Queue定义了对队列的基本操作，同时，还实现了Serializable接口，表示可以被序列化。</p>
<p>类的属性如下：</p>
<blockquote>
<p>属性中包含了head域和tail域，表示链表的头节点和尾结点，同时，ConcurrentLinkedQueue也使用了反射机制和CAS机制来更新头节点和尾结点，保证原子性。</p>
</blockquote>
<pre><code class="language-java">public class ConcurrentLinkedQueue&lt;E&gt; extends AbstractQueue&lt;E&gt;
        implements Queue&lt;E&gt;, java.io.Serializable {
    // 版本序列号        
    private static final long serialVersionUID = 196745693267521676L;
    // 反射机制
    private static final sun.misc.Unsafe UNSAFE;
    // head域的偏移量
    private static final long headOffset;
    // tail域的偏移量
    private static final long tailOffset;
    static {
        try {
            UNSAFE = sun.misc.Unsafe.getUnsafe();
            Class&lt;?&gt; k = ConcurrentLinkedQueue.class;
            headOffset = UNSAFE.objectFieldOffset
                (k.getDeclaredField(&quot;head&quot;));
            tailOffset = UNSAFE.objectFieldOffset
                (k.getDeclaredField(&quot;tail&quot;));
        } catch (Exception e) {
            throw new Error(e);
        }
    }
    
    // 头节点
    private transient volatile Node&lt;E&gt; head;
    // 尾结点
    private transient volatile Node&lt;E&gt; tail;
}
</code></pre>
<h3 id="521-concurrentlinkedqueue的结构">5.2.1 ConcurrentLinkedQueue的结构</h3>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1660644979695.png" alt="ConcurrentLinkedQueue的类图" loading="lazy"></figure>
<p>ConcurrentLinkedQueue由head节点和tail节点组成，每个节点（Node）由节点元素（item）和指向下一个节点（next）的引用组成，节点与节点之间就是通过这个next关联起来，从而组成一张链表结构的队列。默认情况下head节点存储的元素为空，tail节点等于head节点。</p>
<pre><code class="language-java">private static class Node&lt;E&gt; {
    // 元素
    volatile E item;
    // next域
    volatile Node&lt;E&gt; next;

    /**
        * Constructs a new node.  Uses relaxed write because item can
        * only be seen after publication via casNext.
        */
    // 构造函数
    Node(E item) {
        // 设置item的值
        UNSAFE.putObject(this, itemOffset, item);
    }
    // 比较并替换item值
    boolean casItem(E cmp, E val) {
        return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val);
    }
    
    void lazySetNext(Node&lt;E&gt; val) {
        // 设置next域的值，并不会保证修改对其他线程立即可见
        UNSAFE.putOrderedObject(this, nextOffset, val);
    }
    // 比较并替换next域的值
    boolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) {
        return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val);
    }

    // Unsafe mechanics
    // 反射机制
    private static final sun.misc.Unsafe UNSAFE;
    // item域的偏移量
    private static final long itemOffset;
    // next域的偏移量
    private static final long nextOffset;

    static {
        try {
            UNSAFE = sun.misc.Unsafe.getUnsafe();
            Class&lt;?&gt; k = Node.class;
            itemOffset = UNSAFE.objectFieldOffset
                (k.getDeclaredField(&quot;item&quot;));
            nextOffset = UNSAFE.objectFieldOffset
                (k.getDeclaredField(&quot;next&quot;));
        } catch (Exception e) {
            throw new Error(e);
        }
    }
}
</code></pre>
<h3 id="522-入队列">5.2.2 入队列</h3>
<h5 id="1入队列的过程">1.入队列的过程</h5>
<p>入队列就是将入队节点添加到队列的尾部。</p>
<p>入队主要做两件事情：第一是将入队节点设置成当前队列尾节点的下一个节点；第二是更新tail节点，如果tail节点的next节点不为空，则将入队节点设置成tail节点，<strong>如果tail节点的next节点为空，则将入队节点设置成tail的next节点，所以tail节点不总是尾节点。</strong></p>
<p>多个线程同时进行入队的情况就变得更加复杂了，因为可能会出现其他线程插队的情况。如果有一个线程正在<br>
入队，那么它必须先获取尾节点，然后设置尾节点的下一个节点为入队节点，但这时可能有另外一个线程插队了，那么队列的尾节点就会发生变化，这时当前线程要暂停入队操作，然后重新获取尾节点。</p>
<blockquote>
<p>offer接口</p>
</blockquote>
<pre><code class="language-java">public boolean offer(E e) {
    // 元素不为null
    checkNotNull(e);
    // 新生一个结点
    final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e);

    for (Node&lt;E&gt; t = tail, p = t;;) { // 无限循环
        // q为p结点的下一个结点
        Node&lt;E&gt; q = p.next;
        if (q == null) { // q结点为null
            // p is last node
            if (p.casNext(null, newNode)) { // 比较并进行替换p结点的next域
                // Successful CAS is the linearization point
                // for e to become an element of this queue,
                // and for newNode to become &quot;live&quot;.
                if (p != t) // p不等于t结点，不一致    // hop two nodes at a time
                    // 比较并替换尾结点
                    casTail(t, newNode);  // Failure is OK.
                // 返回
                return true;
            }
            // Lost CAS race to another thread; re-read next
        }
        else if (p == q) // p结点等于q结点
            // We have fallen off list.  If tail is unchanged, it
            // will also be off-list, in which case we need to
            // jump to head, from which all live nodes are always
            // reachable.  Else the new tail is a better bet.
            // 原来的尾结点与现在的尾结点是否相等，若相等，则p赋值为head，否则，赋值为现在的尾结点
            p = (t != (t = tail)) ? t : head;
        else
            // Check for tail updates after two hops.
            // 重新赋值p结点
            p = (p != t &amp;&amp; t != (t = tail)) ? t : q;
    }
}
</code></pre>
<p>整个入队过程主要做两件事情：第一是定位出尾节点；第二是使用CAS算法将入队节点设置成尾节点的next节点，如不成功则重试。</p>
<h3 id="523-出队列">5.2.3 出队列</h3>
<p>出队列的就是从队列里返回一个节点元素，并清空该节点对元素的引用。</p>
<p>并不是每次出队时都更新head节点，当head节点里有元素时，直接弹出head节点里的元素，而不会更新head节点。只有当head节点里没有元素时，出队操作才会更新head节点。这种做法也是通过<strong>hops变量</strong>来减少使用CAS更新head节点的消耗，从而提高出队效率。</p>
<pre><code class="language-java">public E poll() {
    restartFromHead:
    for (;;) { // 无限循环
        for (Node&lt;E&gt; h = head, p = h, q;;) { // 保存头节点
            // item项
            E item = p.item;

            if (item != null &amp;&amp; p.casItem(item, null)) { // item不为null并且比较并替换item成功
                // Successful CAS is the linearization point
                // for item to be removed from this queue.
                if (p != h) // p不等于h    // hop two nodes at a time
                    // 更新头节点
                    updateHead(h, ((q = p.next) != null) ? q : p); 
                // 返回item
                return item;
            }
            else if ((q = p.next) == null) { // q结点为null
                // 更新头节点
                updateHead(h, p);
                return null;
            }
            else if (p == q) // p等于q
                // 继续循环
                continue restartFromHead;
            else
                // p赋值为q
                p = q;
        }
    }
}
</code></pre>
<p>首先获取头节点的元素，然后判断头节点元素是否为空，如果为空，表示另外一个线程已经进行了一次出队操作将该节点的元素取走，如果不为空，则使用CAS的方式将头节点的引用设置成null，如果CAS成功，则直接返回头节点的元素，如果不成功，表示另外一个线程已经进行了一次出队操作更新了head节点，导致元素发生了变化，需要重新获取头节点。</p>
<h3 id="524-remove">5.2.4 remove</h3>
<pre><code class="language-java">public boolean remove(Object o) {
    // 元素为null，返回
    if (o == null) return false;
    Node&lt;E&gt; pred = null;
    for (Node&lt;E&gt; p = first(); p != null; p = succ(p)) { // 获取第一个存活的结点
        // 第一个存活结点的item值
        E item = p.item;
        if (item != null &amp;&amp;
            o.equals(item) &amp;&amp;
            p.casItem(item, null)) { // 找到item相等的结点，并且将该结点的item设置为null
            // p的后继结点
            Node&lt;E&gt; next = succ(p);
            if (pred != null &amp;&amp; next != null) // pred不为null并且next不为null
                // 比较并替换next域
                pred.casNext(p, next);
            return true;
        }
        // pred赋值为p
        pred = p;
    }
    return false;
}
</code></pre>
<h3 id="525-hops延迟更新的策略的设计">5.2.5 HOPS(延迟更新的策略)的设计</h3>
<p>通过上面对offer和poll方法的分析，我们发现tail和head是延迟更新的，两者更新触发时机为：</p>
<p><strong>tail更新触发时机</strong>：当tail指向的节点的下一个节点不为null的时候，会执行定位队列真正的队尾节点的操作，找到队尾节点后完成插入之后才会通过casTail进行tail更新；当tail指向的节点的下一个节点为null的时候，只插入节点不更新tail。</p>
<p><strong>head更新触发时机</strong>：当head指向的节点的item域为null的时候，会执行定位队列真正的队头节点的操作，找到队头节点后完成删除之后才会通过updateHead进行head更新；当head指向的节点的item域不为null的时候，只删除节点不更新head。</p>
<p>如果让tail永远作为队列的队尾节点，实现的代码量会更少，而且逻辑更易懂。但是，这样做有一个缺点，如果大量的入队操作，每次都要执行CAS进行tail的更新，汇总起来对性能也会是大大的损耗。如果能减少CAS更新的操作，无疑可以大大提升入队的操作效率，所以每间隔1次(tail和队尾节点的距离为1)进行才利用CAS更新tail。对head的更新也是同样的道理，虽然，这样设计会多出在循环中定位队尾节点，但总体来说读的操作效率要远远高于写的性能，因此，多出来的在循环中定位尾节点的操作的性能损耗相对而言是很小的。</p>
<h2 id="53-java中的阻塞队列">5.3 Java中的阻塞队列</h2>
<h3 id="531-什么是阻塞队列">5.3.1 什么是阻塞队列</h3>
<p>阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作支持阻塞的插入和移除方法。</p>
<pre><code>1）支持阻塞的插入方法：意思是当队列满时，队列会阻塞插入元素的线程，直到队列不满。
2）支持阻塞的移除方法：意思是在队列为空时，获取元素的线程会等待队列变为非空
</code></pre>
<p>阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器。</p>
<p>在阻塞队列不可用时，这两个附加操作提供了4种处理方式，如下所示：</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1660707761776.png" alt="插入和移除操作的4中处理方式" loading="lazy"></figure>
<ol>
<li>抛出异常：当队列满时，如果再往队列里插入元素，会抛出IllegalStateException（&quot;Queue full&quot;）异常。当队列空时，从队列里获取元素会抛出NoSuchElementException异常。</li>
<li>返回特殊值：当往队列插入元素时，会返回元素是否插入成功，成功返回true。如果是移除方法，则是从队列里取出一个元素，如果没有则返回null。</li>
<li>一直阻塞：当阻塞队列满时，如果生产者线程往队列里put元素，队列会一直阻塞生产者线程，直到队列可用或者响应中断退出。当队列空时，如果消费者线程从队列里take元素，队列会阻塞住消费者线程，直到队列不为空。</li>
<li>超时退出：当阻塞队列满时，如果生产者线程往队列里插入元素，队列会阻塞生产者线程一段时间，如果超过了指定的时间，生产者线程就会退出。</li>
</ol>
<p><em><strong>注意 如果是无界阻塞队列，队列不可能会出现满的情况，所以使用put或offer方法永远不会被阻塞，而且使用offer方法时，该方法永远返回true。</strong></em></p>
<h3 id="532-java里的阻塞队列">5.3.2 Java里的阻塞队列</h3>
<ol>
<li>ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列。</li>
<li>LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列。</li>
<li>PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。</li>
<li>DelayQueue：一个使用优先级队列实现的无界阻塞队列。</li>
<li>SynchronousQueue：一个不存储元素的阻塞队列。</li>
<li>LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。</li>
<li>LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。</li>
</ol>
<h3 id="533-阻塞队列的实现原理">5.3.3 阻塞队列的实现原理</h3>
<p>如果队列是空的，消费者会一直等待，当生产者添加元素时，消费者是如何知道当前队列有元素的呢？</p>
<p>使用通知模式实现。所谓通知模式，就是当生产者往满的队列里添加元素时会阻塞住生产者，当消费者消费了一个队列中的元素后，会通知生产者当前队列可用。</p>
<blockquote>
<p>ArrayBlockingQueue</p>
</blockquote>
<pre><code class="language-java"> public ArrayBlockingQueue(int capacity, boolean fair) {
    if (capacity &lt;= 0)
        throw new IllegalArgumentException();
    this.items = new Object[capacity];
    lock = new ReentrantLock(fair);
    notEmpty = lock.newCondition();
    notFull =  lock.newCondition();
}

public void put(E e) throws InterruptedException {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == items.length)
            notFull.await();
        enqueue(e);
    } finally {
        lock.unlock();
    }
}

public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == 0)
            notEmpty.await();
        return dequeue();
    } finally {
        lock.unlock();
    }
}

private void enqueue(E x) {
    // assert lock.getHoldCount() == 1;
    // assert items[putIndex] == null;
    final Object[] items = this.items;
    items[putIndex] = x;
    if (++putIndex == items.length)
        putIndex = 0;
    count++;
    notEmpty.signal();
}
</code></pre>
<p>当往队列里插入一个元素时，如果队列不可用，那么阻塞生产者主要通过LockSupport.park（this）来实现。</p>
<blockquote>
<p>awiat()</p>
</blockquote>
<pre><code class="language-java"> public final void await() throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    Node node = addConditionWaiter();
    int savedState = fullyRelease(node);
    int interruptMode = 0;
    while (!isOnSyncQueue(node)) {
        LockSupport.park(this);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null) // clean up if cancelled
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
}
</code></pre>
<p>继续进入源码，发现调用setBlocker先保存一下将要阻塞的线程，然后调用unsafe.park阻塞当前线程。</p>
<blockquote>
<p>park</p>
</blockquote>
<pre><code class="language-java"> public static void park(Object blocker) {
    Thread t = Thread.currentThread();
    setBlocker(t, blocker);
    UNSAFE.park(false, 0L);
    setBlocker(t, null);
}
</code></pre>
<p>park这个方法会阻塞当前线程，只有以下4种情况中的一种发生时，该方法才会返回。</p>
<ol>
<li>与park对应的unpark执行或已经执行时。“已经执行”是指unpark先执行，然后再执行park的情况。</li>
<li>线程被中断时。</li>
<li>等待完time参数指定的毫秒数时。</li>
<li>异常现象发生时，这个异常现象没有任何原因。</li>
</ol>
<h2 id="54-forkjoin框架">5.4 Fork/Join框架</h2>
<h3 id="541-什么是forkjoin框架">5.4.1 什么是Fork/Join框架</h3>
<p>Fork/Join框架是Java 7提供的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。</p>
<p>Fork就是把一个大任务切分为若干子任务并行的执行，Join就是合并这些子任务的执行结果，最后得到这个大任务的结果。比如计算1+2+…+10000，可以分割成10个子任务，每个子任务分别对1000个数进行求和，最终汇总这10个子任务的结果。Fork/Join的运行流程如下：</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1660805395353.png" alt="Fork Join的运行流程图" loading="lazy"></figure>
<h3 id="542-工作窃取算法">5.4.2 工作窃取算法</h3>
<p>工作窃取（work-stealing）算法是指某个线程从其他队列里窃取任务来执行。那么，为什么需要使用工作窃取算法呢？</p>
<p>假如我们需要做一个比较大的任务，可以把这个任务分割为若干互不依赖的子任务，为了减少线程间的竞争，把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应。比如A线程负责处理A队列里的任务。但是，有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务等待处理。干完活的线程与其等着，不如去帮其他线程干活，于是它就去其他线程的队列<br>
里窃取一个任务来执行。而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。</p>
<p><strong>工作窃取算法的优点</strong>：充分利用线程进行并行计算，减少了线程间的竞争。<br>
<strong>工作窃取算法的缺点</strong>：在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且该算法会消耗了更多的系统资源，比如创建多个线程和多个双端队列。</p>
<h3 id="543-forkjoin框架的设计">5.4.3 Fork/Join框架的设计</h3>
<p>步骤1 分割任务。首先我们需要有一个fork类来把大任务分割成子任务，有可能子任务还是很大，所以还需要不停地分割，直到分割出的子任务足够小。</p>
<p>步骤2 执行任务并合并结果。分割的子任务分别放在双端队列里，然后几个启动线程分别从双端队列里获取任务执行。子任务执行完的结果都统一放在一个队列里，启动一个线程从队列里拿数据，然后合并这些数据。</p>
<p>Fork/Join使用两个类来完成以上两件事情。<br>
①ForkJoinTask：我们要使用ForkJoin框架，必须首先创建一个ForkJoin任务。它提供在任务中执行fork()和join()操作的机制。通常情况下，我们不需要直接继承ForkJoinTask类，只需要继承它的子类，Fork/Join框架提供了以下两个子类。</p>
<pre><code>RecursiveAction：用于没有返回结果的任务。
RecursiveTask：用于有返回结果的任务。
</code></pre>
<p>②ForkJoinPool：ForkJoinTask需要通过ForkJoinPool来执行。</p>
<p>任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列的头部。当一个工作线程的队列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务。</p>
<h3 id="544-使用forkjoin框架">5.4.4 使用Fork/Join框架</h3>
<p>让我们通过一个简单的需求来使用Fork/Join框架，需求是：计算1+2+3+4的结果。</p>
<p>使用Fork/Join框架首先要考虑到的是如何分割任务，如果希望每个子任务最多执行两个数的相加，那么我们设置分割的阈值是2，由于是4个数字相加，所以Fork/Join框架会把这个任务fork成两个子任务，子任务一负责计算1+2，子任务二负责计算3+4，然后再join两个子任务的结果。因为是有结果的任务，所以必须继承RecursiveTask，实现代码如下。</p>
<blockquote>
<p>计算1+2+3+4</p>
</blockquote>
<pre><code class="language-java">package cm.forkjoin;

import java.util.concurrent.ExecutionException;
import java.util.concurrent.ForkJoinPool;
import java.util.concurrent.Future;
import java.util.concurrent.RecursiveTask;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/18 15:01
 */
public class TestForkJoin extends RecursiveTask&lt;Integer&gt; {
    private static final int THRESHOLD = 2; // 阈值

    private int start;
    private int end;
    public TestForkJoin(int start, int end) {
        this.start = start;
        this.end = end;
    }

    @Override
    protected Integer compute() {
        int sum = 0;
        // 如果任务足够小就计算任务
        boolean canCompute = (end - start) &lt;= THRESHOLD;

        if (canCompute) {
            System.out.println(&quot;计算&quot; + start + &quot;-&quot; + end);
            for (int i = start; i &lt;= end; i++) {
                sum += i;
            }
        }else {
            // 如果任务大于阈值，就分裂成两个子任务计算
            System.out.println(&quot;拆分&quot; + start + &quot;-&quot; + end);
            int middle = (start + end) / 2;
            TestForkJoin leftTask = new TestForkJoin(start, middle);
            TestForkJoin rightTask = new TestForkJoin(middle + 1, end);
            // 执行子任务
            leftTask.fork();
            rightTask.fork();
            // 等待子任务执行完，并得到其结果
            int leftResult = leftTask.join();
            int rightResult = rightTask.join();
            // 合并子任务
            sum = leftResult + rightResult;
        }
        return sum;
    }

    public static void main(String[] args) {
        ForkJoinPool forkJoinPool = new ForkJoinPool();
        // 生成一个计算任务，负责计算1+2+3+4
        TestForkJoin task = new TestForkJoin(1, 4);
        // 执行一个任务
        Future&lt;Integer&gt; result = forkJoinPool.submit(task);
        try {
            System.out.println(result.get());
        } catch (InterruptedException e) {
        } catch (ExecutionException e) {
        }
    }
}
</code></pre>
<p>ForkJoinTask与一般任务的主要区别在于它需要实现compute方法，在这个方法里，首先需要判断任务是否足够小，如果足够小就直接执行任务。如果不足够小，就必须分割成两个子任务，每个子任务在调用fork方法时，又会进入compute方法，看看当前子任务是否需要继续分割成子任务，如果不需要继续分割，则执行当<br>
前子任务并返回结果。使用join方法会等待子任务执行完并得到其结果。</p>
<h3 id="545-forkjoin框架的异常处理">5.4.5 Fork/Join框架的异常处理</h3>
<p>ForkJoinTask在执行的时候可能会抛出异常，但是我们没办法在主线程里直接捕获异常，所以ForkJoinTask提供了isCompletedAbnormally()方法来检查任务是否已经抛出异常或已经被取消了，并且可以通过ForkJoinTask的getException方法获取异常。</p>
<pre><code class="language-java"> if(this.isCompletedAbnormally())
    {
        System.out.println(this.getException());
    }
</code></pre>
<h3 id="546-forkjoin框架的实现原理">5.4.6 Fork/Join框架的实现原理</h3>
<p>ForkJoinPool由ForkJoinTask数组和ForkJoinWorkerThread数组组成，ForkJoinTask数组负责将存放程序提交给ForkJoinPool的任务，而ForkJoinWorkerThread数组负责执行这些任务。</p>
<h5 id="1forkjointask的fork方法实现原理">（1）ForkJoinTask的fork方法实现原理</h5>
<p>当我们调用ForkJoinTask的fork方法时，程序会调用ForkJoinWorkerThread的push方法异步地执行这个任务，然后立即返回结果。代码如下。</p>
<blockquote>
<p>fork()</p>
</blockquote>
<pre><code class="language-java"> public final ForkJoinTask&lt;V&gt; fork() {
    Thread t;
    if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread)
        ((ForkJoinWorkerThread)t).workQueue.push(this);
    else
        ForkJoinPool.common.externalPush(this);
    return this;
}
</code></pre>
<p>push方法把当前任务存放在ForkJoinTask数组队列里。然后再调用ForkJoinPool的signalWork()方法唤醒或创建一个工作线程来执行任务。代码如下。</p>
<blockquote>
<p>push()</p>
</blockquote>
<pre><code class="language-java"> final void push(ForkJoinTask&lt;?&gt; task) {
            ForkJoinTask&lt;?&gt;[] a; ForkJoinPool p;
            int b = base, s = top, n;
            if ((a = array) != null) {    // ignore if queue removed
                int m = a.length - 1;     // fenced write for task visibility
                U.putOrderedObject(a, ((m &amp; s) &lt;&lt; ASHIFT) + ABASE, task);
                U.putOrderedInt(this, QTOP, s + 1);
                if ((n = s - b) &lt;= 1) {
                    if ((p = pool) != null)
                        p.signalWork(p.workQueues, this);
                }
                else if (n &gt;= m)
                    growArray();
            }
        }
</code></pre>
<h5 id="2forkjointask的join方法实现原理">（2）ForkJoinTask的join方法实现原理</h5>
<p>Join方法的主要作用是阻塞当前线程并等待获取结果，代码如下。</p>
<blockquote>
<p>join()</p>
</blockquote>
<pre><code class="language-java">  public final V join() {
    int s;
    if ((s = doJoin() &amp; DONE_MASK) != NORMAL)
        reportException(s);
    return getRawResult();
}
</code></pre>
<p>首先，它调用了doJoin()方法，通过doJoin()方法得到当前任务的状态来判断返回什么结果，任务状态有4种：已完成（NORMAL）、被取消（CANCELLED）、信号（SIGNAL）和出现异常（EXCEPTIONAL）。</p>
<pre><code>- 如果任务状态是已完成，则直接返回任务结果。
- 如果任务状态是被取消，则直接抛出CancellationException。
- 如果任务状态是抛出异常，则直接抛出对应的异常。
</code></pre>
<blockquote>
<p>doJoin()</p>
</blockquote>
<pre><code class="language-java">  private int doJoin() {
    int s; Thread t; ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue w;
    return (s = status) &lt; 0 ? s :
        ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ?
        (w = (wt = (ForkJoinWorkerThread)t).workQueue).
        tryUnpush(this) &amp;&amp; (s = doExec()) &lt; 0 ? s :
        wt.pool.awaitJoin(w, this, 0L) :
        externalAwaitDone();
}
</code></pre>
<p>在doJoin()方法里，首先通过查看任务的状态，看任务是否已经执行完成，如果执行完成，则直接返回任务状态；如果没有执行完，则从任务数组里取出任务并执行。如果任务顺利执行完成，则设置任务状态为NORMAL，如果出现异常，则记录异常，并将任务状态设置为EXCEPTIONAL。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Netty (一)]]></title>
        <id>https://q456qq520.github.io/post/netty-yi/</id>
        <link href="https://q456qq520.github.io/post/netty-yi/">
        </link>
        <updated>2022-08-14T14:29:06.000Z</updated>
        <content type="html"><![CDATA[<h1 id="一-nio-基础">一. NIO 基础</h1>
<p>non-blocking io 非阻塞 IO</p>
<h2 id="1-三大组件">1. 三大组件</h2>
<h3 id="11-channel-buffer">1.1 Channel &amp; Buffer</h3>
<p>channel 有一点类似于 stream，它就是读写数据的<strong>双向通道</strong>，可以从 channel 将数据读入buffer，也可以将 buffer 的数据写入 channel，而之前的 stream 要么是输入，要么是输出，channel 比stream 更为底层</p>
<p>常见的 Channel 有</p>
<ul>
<li>FileChannel</li>
<li>DatagramChannel （udp）</li>
<li>SocketChannel （tcp）</li>
<li>ServerSocketChannel （tcp）</li>
</ul>
<p>buffer 则用来缓冲读写数据，常见的 buffer 有</p>
<ul>
<li>ByteBuffer
<ul>
<li>MappedByteBuffer</li>
<li>DirectByteBuffer</li>
<li>HeapByteBuffer</li>
</ul>
</li>
<li>ShortBuffer</li>
<li>IntBuffer</li>
<li>LongBuffer</li>
<li>FloatBuffer</li>
<li>DoubleBuffer</li>
<li>CharBuffer</li>
</ul>
<h3 id="12-selector">1.2 Selector</h3>
<p>selector 单从字面意思不好理解，需要结合服务器的设计演化来理解它的用途</p>
<h4 id="多线程版设计">多线程版设计</h4>
<p>一个线程对应一个socket，这样设计会有如下缺点</p>
<h4 id="️-多线程版缺点">⚠️ 多线程版缺点</h4>
<ul>
<li>内存占用高</li>
<li>线程上下文切换成本高</li>
<li>只适合连接数少的场景</li>
</ul>
<h4 id="线程池版设计">线程池版设计</h4>
<p>一个线程对应多个socket。</p>
<h4 id="️-线程池版缺点">⚠️ 线程池版缺点</h4>
<ul>
<li>阻塞模式下，线程仅能处理一个 socket 连接</li>
<li>仅适合短连接场景</li>
</ul>
<h4 id="selector-版设计">selector 版设计</h4>
<p>selector 的作用就是配合一个线程来管理多个 channel，获取这些 channel 上发生的事件，这些 channel 工作在非阻塞模式下，不会让线程吊死在一个 channel 上。适合连接数特别多，但流量低的场景（low traffic）</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1660489074106.png" alt="selector 版设计" loading="lazy"></figure>
<p>调用 selector 的 select() 会阻塞直到 channel 发生了读写就绪事件，这些事件发生，select 方法就会返回这些事件交给 thread 来处理</p>
<h2 id="2-bytebuffer">2. ByteBuffer</h2>
<p>有一普通文本文件 data.txt，内容为</p>
<pre><code>1234567890abcd
</code></pre>
<p>使用 FileChannel 来读取文件内容</p>
<pre><code class="language-java">@Slf4j
public class ChannelDemo1 {
    public static void main(String[] args) {
        try (RandomAccessFile file = new RandomAccessFile(&quot;helloword/data.txt&quot;, &quot;rw&quot;)) {
            FileChannel channel = file.getChannel();
            ByteBuffer buffer = ByteBuffer.allocate(10);
            do {
                // 向 buffer 写入
                int len = channel.read(buffer);
                log.debug(&quot;读到字节数：{}&quot;, len);
                if (len == -1) {
                    break;
                }
                // 切换 buffer 读模式
                buffer.flip();
                while(buffer.hasRemaining()) {
                    log.debug(&quot;{}&quot;, (char)buffer.get());
                }
                // 切换 buffer 写模式
                buffer.clear();
            } while (true);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<h3 id="21-bytebuffer-正确使用姿势">2.1  ByteBuffer 正确使用姿势</h3>
<ol>
<li>向 buffer 写入数据，例如调用 channel.read(buffer)</li>
<li>调用 flip() 切换至<strong>读模式</strong></li>
<li>从 buffer 读取数据，例如调用 buffer.get()</li>
<li>调用 clear() 或 compact() 切换至<strong>写模式</strong></li>
<li>重复 1~4 步骤</li>
</ol>
<h3 id="22-bytebuffer-结构">2.2 ByteBuffer 结构</h3>
<p>ByteBuffer 有以下重要属性</p>
<ul>
<li>capacity（容量）</li>
<li>position（位置）</li>
<li>limit</li>
</ul>
<p>一开始</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1660492137807.png" alt="" loading="lazy"></figure>
<p>写模式下，position 是写入位置，limit 等于容量，下图表示写入了 4 个字节后的状态<br>
<img src="https://q456qq520.github.io/post-images/1660492145738.png" alt="" loading="lazy"></p>
<p>flip 动作发生后，position 切换为读取位置，limit 切换为读取限制<br>
<img src="https://q456qq520.github.io/post-images/1660492152484.png" alt="" loading="lazy"></p>
<p>读取 4 个字节后，状态</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1660492162158.png" alt="" loading="lazy"></figure>
<p>clear 动作发生后，<br>
<img src="https://q456qq520.github.io/post-images/1660492170703.png" alt="" loading="lazy"></p>
<p>compact 方法，是把未读完的部分向前压缩，然后切换至写模式<br>
<img src="https://q456qq520.github.io/post-images/1660492179063.png" alt="" loading="lazy"></p>
<h4 id="调试工具类">💡 调试工具类</h4>
<pre><code class="language-java">public class ByteBufferUtil {
    private static final char[] BYTE2CHAR = new char[256];
    private static final char[] HEXDUMP_TABLE = new char[256 * 4];
    private static final String[] HEXPADDING = new String[16];
    private static final String[] HEXDUMP_ROWPREFIXES = new String[65536 &gt;&gt;&gt; 4];
    private static final String[] BYTE2HEX = new String[256];
    private static final String[] BYTEPADDING = new String[16];

    static {
        final char[] DIGITS = &quot;0123456789abcdef&quot;.toCharArray();
        for (int i = 0; i &lt; 256; i++) {
            HEXDUMP_TABLE[i &lt;&lt; 1] = DIGITS[i &gt;&gt;&gt; 4 &amp; 0x0F];
            HEXDUMP_TABLE[(i &lt;&lt; 1) + 1] = DIGITS[i &amp; 0x0F];
        }

        int i;

        // Generate the lookup table for hex dump paddings
        for (i = 0; i &lt; HEXPADDING.length; i++) {
            int padding = HEXPADDING.length - i;
            StringBuilder buf = new StringBuilder(padding * 3);
            for (int j = 0; j &lt; padding; j++) {
                buf.append(&quot;   &quot;);
            }
            HEXPADDING[i] = buf.toString();
        }

        // Generate the lookup table for the start-offset header in each row (up to 64KiB).
        for (i = 0; i &lt; HEXDUMP_ROWPREFIXES.length; i++) {
            StringBuilder buf = new StringBuilder(12);
            buf.append(NEWLINE);
            buf.append(Long.toHexString(i &lt;&lt; 4 &amp; 0xFFFFFFFFL | 0x100000000L));
            buf.setCharAt(buf.length() - 9, '|');
            buf.append('|');
            HEXDUMP_ROWPREFIXES[i] = buf.toString();
        }

        // Generate the lookup table for byte-to-hex-dump conversion
        for (i = 0; i &lt; BYTE2HEX.length; i++) {
            BYTE2HEX[i] = ' ' + StringUtil.byteToHexStringPadded(i);
        }

        // Generate the lookup table for byte dump paddings
        for (i = 0; i &lt; BYTEPADDING.length; i++) {
            int padding = BYTEPADDING.length - i;
            StringBuilder buf = new StringBuilder(padding);
            for (int j = 0; j &lt; padding; j++) {
                buf.append(' ');
            }
            BYTEPADDING[i] = buf.toString();
        }

        // Generate the lookup table for byte-to-char conversion
        for (i = 0; i &lt; BYTE2CHAR.length; i++) {
            if (i &lt;= 0x1f || i &gt;= 0x7f) {
                BYTE2CHAR[i] = '.';
            } else {
                BYTE2CHAR[i] = (char) i;
            }
        }
    }

    /**
     * 打印所有内容
     * @param buffer
     */
    public static void debugAll(ByteBuffer buffer) {
        int oldlimit = buffer.limit();
        buffer.limit(buffer.capacity());
        StringBuilder origin = new StringBuilder(256);
        appendPrettyHexDump(origin, buffer, 0, buffer.capacity());
        System.out.println(&quot;+--------+-------------------- all ------------------------+----------------+&quot;);
        System.out.printf(&quot;position: [%d], limit: [%d]\n&quot;, buffer.position(), oldlimit);
        System.out.println(origin);
        buffer.limit(oldlimit);
    }

    /**
     * 打印可读取内容
     * @param buffer
     */
    public static void debugRead(ByteBuffer buffer) {
        StringBuilder builder = new StringBuilder(256);
        appendPrettyHexDump(builder, buffer, buffer.position(), buffer.limit() - buffer.position());
        System.out.println(&quot;+--------+-------------------- read -----------------------+----------------+&quot;);
        System.out.printf(&quot;position: [%d], limit: [%d]\n&quot;, buffer.position(), buffer.limit());
        System.out.println(builder);
    }

    private static void appendPrettyHexDump(StringBuilder dump, ByteBuffer buf, int offset, int length) {
        if (isOutOfBounds(offset, length, buf.capacity())) {
            throw new IndexOutOfBoundsException(
                    &quot;expected: &quot; + &quot;0 &lt;= offset(&quot; + offset + &quot;) &lt;= offset + length(&quot; + length
                            + &quot;) &lt;= &quot; + &quot;buf.capacity(&quot; + buf.capacity() + ')');
        }
        if (length == 0) {
            return;
        }
        dump.append(
                &quot;         +-------------------------------------------------+&quot; +
                        NEWLINE + &quot;         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |&quot; +
                        NEWLINE + &quot;+--------+-------------------------------------------------+----------------+&quot;);

        final int startIndex = offset;
        final int fullRows = length &gt;&gt;&gt; 4;
        final int remainder = length &amp; 0xF;

        // Dump the rows which have 16 bytes.
        for (int row = 0; row &lt; fullRows; row++) {
            int rowStartIndex = (row &lt;&lt; 4) + startIndex;

            // Per-row prefix.
            appendHexDumpRowPrefix(dump, row, rowStartIndex);

            // Hex dump
            int rowEndIndex = rowStartIndex + 16;
            for (int j = rowStartIndex; j &lt; rowEndIndex; j++) {
                dump.append(BYTE2HEX[getUnsignedByte(buf, j)]);
            }
            dump.append(&quot; |&quot;);

            // ASCII dump
            for (int j = rowStartIndex; j &lt; rowEndIndex; j++) {
                dump.append(BYTE2CHAR[getUnsignedByte(buf, j)]);
            }
            dump.append('|');
        }

        // Dump the last row which has less than 16 bytes.
        if (remainder != 0) {
            int rowStartIndex = (fullRows &lt;&lt; 4) + startIndex;
            appendHexDumpRowPrefix(dump, fullRows, rowStartIndex);

            // Hex dump
            int rowEndIndex = rowStartIndex + remainder;
            for (int j = rowStartIndex; j &lt; rowEndIndex; j++) {
                dump.append(BYTE2HEX[getUnsignedByte(buf, j)]);
            }
            dump.append(HEXPADDING[remainder]);
            dump.append(&quot; |&quot;);

            // Ascii dump
            for (int j = rowStartIndex; j &lt; rowEndIndex; j++) {
                dump.append(BYTE2CHAR[getUnsignedByte(buf, j)]);
            }
            dump.append(BYTEPADDING[remainder]);
            dump.append('|');
        }

        dump.append(NEWLINE +
                &quot;+--------+-------------------------------------------------+----------------+&quot;);
    }

    private static void appendHexDumpRowPrefix(StringBuilder dump, int row, int rowStartIndex) {
        if (row &lt; HEXDUMP_ROWPREFIXES.length) {
            dump.append(HEXDUMP_ROWPREFIXES[row]);
        } else {
            dump.append(NEWLINE);
            dump.append(Long.toHexString(rowStartIndex &amp; 0xFFFFFFFFL | 0x100000000L));
            dump.setCharAt(dump.length() - 9, '|');
            dump.append('|');
        }
    }

    public static short getUnsignedByte(ByteBuffer buffer, int index) {
        return (short) (buffer.get(index) &amp; 0xFF);
    }
}
</code></pre>
<h3 id="23-bytebuffer-常见方法">2.3 ByteBuffer 常见方法</h3>
<h4 id="分配空间">分配空间</h4>
<p>可以使用 allocate 方法为 ByteBuffer 分配空间，其它 buffer 类也有该方法</p>
<pre><code class="language-java"> //HeapByteBuffer 堆内存
//读写效率低，受gc影响
System.out.println(ByteBuffer.allocate(16).getClass());

//DirectByteBuffer 直接内存
//读写效率高，少一次拷贝，分配效率低
System.out.println(ByteBuffer.allocateDirect(16).getClass());
</code></pre>
<h4 id="向-buffer-写入数据">向 buffer 写入数据</h4>
<p>有两种办法</p>
<ul>
<li>调用 channel 的 read 方法</li>
<li>调用 buffer 自己的 put 方法</li>
</ul>
<pre><code class="language-java">int readBytes = channel.read(buf);
</code></pre>
<p>和</p>
<pre><code class="language-java">buf.put((byte)127);
</code></pre>
<h4 id="从-buffer-读取数据">从 buffer 读取数据</h4>
<p>同样有两种办法</p>
<ul>
<li>调用 channel 的 write 方法</li>
<li>调用 buffer 自己的 get 方法</li>
</ul>
<pre><code class="language-java">int writeBytes = channel.write(buf);
</code></pre>
<p>和</p>
<pre><code class="language-java">byte b = buf.get();
</code></pre>
<p>get 方法会让 position 读指针向后走，如果想重复读取数据</p>
<ul>
<li>可以调用 rewind 方法将 position 重新置为 0</li>
<li>或者调用 get(int i) 方法获取索引 i 的内容，它不会移动读指针</li>
</ul>
<h4 id="mark-和-reset">mark 和 reset</h4>
<p>mark 是在读取时，做一个标记，即使 position 改变，只要调用 reset 就能回到 mark 的位置</p>
<blockquote>
<p><strong>注意</strong></p>
<p>rewind 和 flip 都会清除 mark 位置</p>
</blockquote>
<h4 id="字符串与-bytebuffer-互转">字符串与 ByteBuffer 互转</h4>
<pre><code class="language-java">ByteBuffer buffer1 = StandardCharsets.UTF_8.encode(&quot;你好&quot;);
ByteBuffer buffer2 = Charset.forName(&quot;utf-8&quot;).encode(&quot;你好&quot;);

debug(buffer1);
debug(buffer2);

CharBuffer buffer3 = StandardCharsets.UTF_8.decode(buffer1);
System.out.println(buffer3.getClass());
System.out.println(buffer3.toString());
</code></pre>
<p>输出</p>
<pre><code>         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| e4 bd a0 e5 a5 bd                               |......          |
+--------+-------------------------------------------------+----------------+
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| e4 bd a0 e5 a5 bd                               |......          |
+--------+-------------------------------------------------+----------------+
class java.nio.HeapCharBuffer
你好
</code></pre>
<h4 id="️-buffer-的线程安全">⚠️ Buffer 的线程安全</h4>
<blockquote>
<p>Buffer 是<strong>非线程安全的</strong></p>
</blockquote>
<h3 id="24-scattering-reads">2.4 Scattering Reads</h3>
<p>分散读取，有一个文本文件 3parts.txt</p>
<pre><code>onetwothree
</code></pre>
<p>使用如下方式读取，可以将数据填充至多个 buffer</p>
<pre><code class="language-java">try (RandomAccessFile file = new RandomAccessFile(&quot;helloword/3parts.txt&quot;, &quot;rw&quot;)) {
    FileChannel channel = file.getChannel();
    ByteBuffer a = ByteBuffer.allocate(3);
    ByteBuffer b = ByteBuffer.allocate(3);
    ByteBuffer c = ByteBuffer.allocate(5);
    channel.read(new ByteBuffer[]{a, b, c});
    a.flip();
    b.flip();
    c.flip();
    debug(a);
    debug(b);
    debug(c);
} catch (IOException e) {
    e.printStackTrace();
}
</code></pre>
<p>结果</p>
<pre><code>         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 6f 6e 65                                        |one             |
+--------+-------------------------------------------------+----------------+
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 74 77 6f                                        |two             |
+--------+-------------------------------------------------+----------------+
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 74 68 72 65 65                                  |three           |
+--------+-------------------------------------------------+----------------+
</code></pre>
<h3 id="25-gathering-writes">2.5 Gathering Writes</h3>
<p>使用如下方式写入，可以将多个 buffer 的数据填充至 channel</p>
<pre><code class="language-java">try (RandomAccessFile file = new RandomAccessFile(&quot;helloword/3parts.txt&quot;, &quot;rw&quot;)) {
    FileChannel channel = file.getChannel();
    ByteBuffer d = ByteBuffer.allocate(4);
    ByteBuffer e = ByteBuffer.allocate(4);
    channel.position(11);

    d.put(new byte[]{'f', 'o', 'u', 'r'});
    e.put(new byte[]{'f', 'i', 'v', 'e'});
    d.flip();
    e.flip();
    debug(d);
    debug(e);
    channel.write(new ByteBuffer[]{d, e});
} catch (IOException e) {
    e.printStackTrace();
}
</code></pre>
<p>输出</p>
<pre><code>         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 66 6f 75 72                                     |four            |
+--------+-------------------------------------------------+----------------+
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 66 69 76 65                                     |five            |
+--------+-------------------------------------------------+----------------+
</code></pre>
<p>文件内容</p>
<pre><code>onetwothreefourfive
</code></pre>
<h3 id="26-练习">2.6 练习</h3>
<p>网络上有多条数据发送给服务端，数据之间使用 \n 进行分隔<br>
但由于某种原因这些数据在接收时，被进行了重新组合，例如原始数据有3条为</p>
<ul>
<li>Hello,world\n</li>
<li>I'm zhangsan\n</li>
<li>How are you?\n</li>
</ul>
<p>变成了下面的两个 byteBuffer (黏包，半包)</p>
<ul>
<li>Hello,world\nI'm zhangsan\nHo</li>
<li>w are you?\n</li>
</ul>
<p>现在要求你编写程序，将错乱的数据恢复成原始的按 \n 分隔的数据</p>
<pre><code class="language-java">public static void main(String[] args) {
    ByteBuffer source = ByteBuffer.allocate(32);
    //                     11            24
    source.put(&quot;Hello,world\nI'm zhangsan\nHo&quot;.getBytes());
    split(source);

    source.put(&quot;w are you?\nhaha!\n&quot;.getBytes());
    split(source);
}

private static void split(ByteBuffer source) {
    source.flip();
    int oldLimit = source.limit();
    for (int i = 0; i &lt; oldLimit; i++) {
        if (source.get(i) == '\n') {
            System.out.println(i);
            ByteBuffer target = ByteBuffer.allocate(i + 1 - source.position());
            // 0 ~ limit
            source.limit(i + 1);
            target.put(source); // 从source 读，向 target 写
            debugAll(target);
            source.limit(oldLimit);
        }
    }
    source.compact();
}
</code></pre>
<h2 id="3-文件编程">3. 文件编程</h2>
<h3 id="31-filechannel">3.1 FileChannel</h3>
<h4 id="️-filechannel-工作模式">⚠️ FileChannel 工作模式</h4>
<blockquote>
<p>FileChannel 只能工作在阻塞模式下</p>
</blockquote>
<h4 id="获取">获取</h4>
<p>不能直接打开 FileChannel，必须通过 FileInputStream、FileOutputStream 或者 RandomAccessFile 来获取 FileChannel，它们都有 getChannel 方法</p>
<ul>
<li>通过 FileInputStream 获取的 channel 只能读</li>
<li>通过 FileOutputStream 获取的 channel 只能写</li>
<li>通过 RandomAccessFile 是否能读写根据构造 RandomAccessFile 时的读写模式决定</li>
</ul>
<h4 id="读取">读取</h4>
<p>会从 channel 读取数据填充 ByteBuffer，返回值表示读到了多少字节，-1 表示到达了文件的末尾</p>
<pre><code class="language-java">int readBytes = channel.read(buffer);
</code></pre>
<h4 id="写入">写入</h4>
<p>写入的正确姿势如下， SocketChannel</p>
<pre><code class="language-java">ByteBuffer buffer = ...;
buffer.put(...); // 存入数据
buffer.flip();   // 切换读模式

while(buffer.hasRemaining()) {
    channel.write(buffer);
}
</code></pre>
<p>在 while 中调用 channel.write 是因为 write 方法并不能保证一次将 buffer 中的内容全部写入 channel</p>
<h4 id="关闭">关闭</h4>
<p>channel 必须关闭，不过调用了 FileInputStream、FileOutputStream 或者 RandomAccessFile 的 close 方法会间接地调用 channel 的 close 方法</p>
<h4 id="位置">位置</h4>
<p>获取当前位置</p>
<pre><code class="language-java">long pos = channel.position();
</code></pre>
<p>设置当前位置</p>
<pre><code class="language-java">long newPos = ...;
channel.position(newPos);
</code></pre>
<p>设置当前位置时，如果设置为文件的末尾</p>
<ul>
<li>这时读取会返回 -1</li>
<li>这时写入，会追加内容，但要注意如果 position 超过了文件末尾，再写入时在新内容和原末尾之间会有空洞（00）</li>
</ul>
<h4 id="大小">大小</h4>
<p>使用 size 方法获取文件的大小</p>
<h4 id="强制写入">强制写入</h4>
<p>操作系统出于性能的考虑，会将数据缓存，不是立刻写入磁盘。可以调用 force(true)  方法将文件内容和元数据（文件的权限等信息）立刻写入磁盘</p>
<h3 id="32-两个-channel-传输数据">3.2 两个 Channel 传输数据</h3>
<pre><code class="language-java">String FROM = &quot;helloword/data.txt&quot;;
String TO = &quot;helloword/to.txt&quot;;
long start = System.nanoTime();
try (FileChannel from = new FileInputStream(FROM).getChannel();
     FileChannel to = new FileOutputStream(TO).getChannel();
    ) {
    from.transferTo(0, from.size(), to);
} catch (IOException e) {
    e.printStackTrace();
}
long end = System.nanoTime();
System.out.println(&quot;transferTo 用时：&quot; + (end - start) / 1000_000.0);
</code></pre>
<p>输出</p>
<pre><code>transferTo 用时：8.2011
</code></pre>
<p>超过 2g 大小的文件传输</p>
<pre><code class="language-java">public class TestFileChannelTransferTo {
    public static void main(String[] args) {
        try (
                FileChannel from = new FileInputStream(&quot;data.txt&quot;).getChannel();
                FileChannel to = new FileOutputStream(&quot;to.txt&quot;).getChannel();
        ) {
            // 效率高，底层会利用操作系统的零拷贝进行优化
            long size = from.size();
            // left 变量代表还剩余多少字节
            for (long left = size; left &gt; 0; ) {
                System.out.println(&quot;position:&quot; + (size - left) + &quot; left:&quot; + left);
                left -= from.transferTo((size - left), left, to);
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>实际传输一个超大文件</p>
<pre><code>position:0 left:7769948160
position:2147483647 left:5622464513
position:4294967294 left:3474980866
position:6442450941 left:1327497219
</code></pre>
<h3 id="33-path">3.3 Path</h3>
<p>jdk7 引入了 Path 和 Paths 类</p>
<ul>
<li>Path 用来表示文件路径</li>
<li>Paths 是工具类，用来获取 Path 实例</li>
</ul>
<pre><code class="language-java">Path source = Paths.get(&quot;1.txt&quot;); // 相对路径 使用 user.dir 环境变量来定位 1.txt

Path source = Paths.get(&quot;d:\\1.txt&quot;); // 绝对路径 代表了  d:\1.txt

Path source = Paths.get(&quot;d:/1.txt&quot;); // 绝对路径 同样代表了  d:\1.txt

Path projects = Paths.get(&quot;d:\\data&quot;, &quot;projects&quot;); // 代表了  d:\data\projects
</code></pre>
<ul>
<li><code>.</code> 代表了当前路径</li>
<li><code>..</code> 代表了上一级路径</li>
</ul>
<p>例如目录结构如下</p>
<pre><code>d:
	|- data
		|- projects
			|- a
			|- b
</code></pre>
<p>代码</p>
<pre><code class="language-java">Path path = Paths.get(&quot;d:\\data\\projects\\a\\..\\b&quot;);
System.out.println(path);
System.out.println(path.normalize()); // 正常化路径
</code></pre>
<p>会输出</p>
<pre><code>d:\data\projects\a\..\b
d:\data\projects\b
</code></pre>
<h3 id="34-files">3.4 Files</h3>
<p>检查文件是否存在</p>
<pre><code class="language-java">Path path = Paths.get(&quot;helloword/data.txt&quot;);
System.out.println(Files.exists(path));
</code></pre>
<p>创建一级目录</p>
<pre><code class="language-java">Path path = Paths.get(&quot;helloword/d1&quot;);
Files.createDirectory(path);
</code></pre>
<ul>
<li>如果目录已存在，会抛异常 FileAlreadyExistsException</li>
<li>不能一次创建多级目录，否则会抛异常 NoSuchFileException</li>
</ul>
<p>创建多级目录用</p>
<pre><code class="language-java">Path path = Paths.get(&quot;helloword/d1/d2&quot;);
Files.createDirectories(path);
</code></pre>
<p>拷贝文件</p>
<pre><code class="language-java">Path source = Paths.get(&quot;helloword/data.txt&quot;);
Path target = Paths.get(&quot;helloword/target.txt&quot;);

Files.copy(source, target);
</code></pre>
<ul>
<li>如果文件已存在，会抛异常 FileAlreadyExistsException</li>
</ul>
<p>如果希望用 source 覆盖掉 target，需要用 StandardCopyOption 来控制</p>
<pre><code class="language-java">Files.copy(source, target, StandardCopyOption.REPLACE_EXISTING);
</code></pre>
<p>移动文件</p>
<pre><code class="language-java">Path source = Paths.get(&quot;helloword/data.txt&quot;);
Path target = Paths.get(&quot;helloword/data.txt&quot;);

Files.move(source, target, StandardCopyOption.ATOMIC_MOVE);
</code></pre>
<ul>
<li>StandardCopyOption.ATOMIC_MOVE 保证文件移动的原子性</li>
</ul>
<p>删除文件</p>
<pre><code class="language-java">Path target = Paths.get(&quot;helloword/target.txt&quot;);

Files.delete(target);
</code></pre>
<ul>
<li>如果文件不存在，会抛异常 NoSuchFileException</li>
</ul>
<p>删除目录</p>
<pre><code class="language-java">Path target = Paths.get(&quot;helloword/d1&quot;);

Files.delete(target);
</code></pre>
<ul>
<li>如果目录还有内容，会抛异常 DirectoryNotEmptyException</li>
</ul>
<p>遍历目录文件</p>
<pre><code class="language-java">public static void main(String[] args) throws IOException {
    Path path = Paths.get(&quot;C:\\Program Files\\Java\\jdk1.8.0_91&quot;);
    AtomicInteger dirCount = new AtomicInteger();
    AtomicInteger fileCount = new AtomicInteger();
    Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;(){
        @Override
        public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) 
            throws IOException {
            System.out.println(dir);
            dirCount.incrementAndGet();
            return super.preVisitDirectory(dir, attrs);
        }

        @Override
        public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) 
            throws IOException {
            System.out.println(file);
            fileCount.incrementAndGet();
            return super.visitFile(file, attrs);
        }
    });
    System.out.println(dirCount); // 133
    System.out.println(fileCount); // 1479
}
</code></pre>
<p>统计 jar 的数目</p>
<pre><code class="language-java">Path path = Paths.get(&quot;C:\\Program Files\\Java\\jdk1.8.0_91&quot;);
AtomicInteger fileCount = new AtomicInteger();
Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;(){
    @Override
    public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) 
        throws IOException {
        if (file.toFile().getName().endsWith(&quot;.jar&quot;)) {
            fileCount.incrementAndGet();
        }
        return super.visitFile(file, attrs);
    }
});
System.out.println(fileCount); // 724
</code></pre>
<p>删除多级目录</p>
<pre><code class="language-java">Path path = Paths.get(&quot;d:\\a&quot;);
Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;(){
    @Override
    public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) 
        throws IOException {
        Files.delete(file);
        return super.visitFile(file, attrs);
    }

    @Override
    public FileVisitResult postVisitDirectory(Path dir, IOException exc) 
        throws IOException {
        Files.delete(dir);
        return super.postVisitDirectory(dir, exc);
    }
});
</code></pre>
<h4 id="️-删除很危险">⚠️ 删除很危险</h4>
<blockquote>
<p>删除是危险操作，确保要递归删除的文件夹没有重要内容</p>
</blockquote>
<p>拷贝多级目录</p>
<pre><code class="language-java">long start = System.currentTimeMillis();
String source = &quot;D:\\Snipaste-1.16.2-x64&quot;;
String target = &quot;D:\\Snipaste-1.16.2-x64aaa&quot;;

Files.walk(Paths.get(source)).forEach(path -&gt; {
    try {
        String targetName = path.toString().replace(source, target);
        // 是目录
        if (Files.isDirectory(path)) {
            Files.createDirectory(Paths.get(targetName));
        }
        // 是普通文件
        else if (Files.isRegularFile(path)) {
            Files.copy(path, Paths.get(targetName));
        }
    } catch (IOException e) {
        e.printStackTrace();
    }
});
long end = System.currentTimeMillis();
System.out.println(end - start);
</code></pre>
<h2 id="4-网络编程">4. 网络编程</h2>
<h3 id="41-非阻塞-vs-阻塞">4.1 非阻塞 vs 阻塞</h3>
<h4 id="阻塞">阻塞</h4>
<ul>
<li>阻塞模式下，相关方法都会导致线程暂停
<ul>
<li>ServerSocketChannel.accept 会在没有连接建立时让线程暂停</li>
<li>SocketChannel.read 会在没有数据可读时让线程暂停</li>
<li>阻塞的表现其实就是线程暂停了，暂停期间不会占用 cpu，但线程相当于闲置</li>
</ul>
</li>
<li>单线程下，阻塞方法之间相互影响，几乎不能正常工作，需要多线程支持</li>
<li>但多线程下，有新的问题，体现在以下方面
<ul>
<li>32 位 jvm 一个线程 320k，64 位 jvm 一个线程 1024k，如果连接数过多，必然导致 OOM，并且线程太多，反而会因为频繁上下文切换导致性能降低</li>
<li>可以采用线程池技术来减少线程数和线程上下文切换，但治标不治本，如果有很多连接建立，但长时间 inactive，会阻塞线程池中所有线程，因此不适合长连接，只适合短连接</li>
</ul>
</li>
</ul>
<p>服务器端</p>
<pre><code class="language-java">// 使用 nio 来理解阻塞模式, 单线程
// 0. ByteBuffer
ByteBuffer buffer = ByteBuffer.allocate(16);
// 1. 创建了服务器
ServerSocketChannel ssc = ServerSocketChannel.open();

// 2. 绑定监听端口
ssc.bind(new InetSocketAddress(8080));

// 3. 连接集合
List&lt;SocketChannel&gt; channels = new ArrayList&lt;&gt;();
while (true) {
    // 4. accept 建立与客户端连接， SocketChannel 用来与客户端之间通信
    log.debug(&quot;connecting...&quot;);
    SocketChannel sc = ssc.accept(); // 阻塞方法，线程停止运行
    log.debug(&quot;connected... {}&quot;, sc);
    channels.add(sc);
    for (SocketChannel channel : channels) {
        // 5. 接收客户端发送的数据
        log.debug(&quot;before read... {}&quot;, channel);
        channel.read(buffer); // 阻塞方法，线程停止运行
        buffer.flip();
        debugRead(buffer);
        buffer.clear();
        log.debug(&quot;after read...{}&quot;, channel);
    }
}
</code></pre>
<p>客户端</p>
<pre><code class="language-java">SocketChannel sc = SocketChannel.open();
sc.connect(new InetSocketAddress(&quot;localhost&quot;, 8080));
System.out.println(&quot;waiting...&quot;);
</code></pre>
<h4 id="非阻塞">非阻塞</h4>
<ul>
<li>非阻塞模式下，相关方法都会不会让线程暂停
<ul>
<li>在 ServerSocketChannel.accept 在没有连接建立时，会返回 null，继续运行</li>
<li>SocketChannel.read 在没有数据可读时，会返回 0，但线程不必阻塞，可以去执行其它 SocketChannel 的 read 或是去执行 ServerSocketChannel.accept</li>
<li>写数据时，线程只是等待数据写入 Channel 即可，无需等 Channel 通过网络把数据发送出去</li>
</ul>
</li>
<li>但非阻塞模式下，即使没有连接建立，和可读数据，线程仍然在不断运行，白白浪费了 cpu</li>
<li>数据复制过程中，线程实际还是阻塞的（AIO 改进的地方）</li>
</ul>
<p>服务器端，客户端代码不变</p>
<pre><code class="language-java">// 使用 nio 来理解非阻塞模式, 单线程
// 0. ByteBuffer
ByteBuffer buffer = ByteBuffer.allocate(16);
// 1. 创建了服务器
ServerSocketChannel ssc = ServerSocketChannel.open();
ssc.configureBlocking(false); // 非阻塞模式
// 2. 绑定监听端口
ssc.bind(new InetSocketAddress(8080));
// 3. 连接集合
List&lt;SocketChannel&gt; channels = new ArrayList&lt;&gt;();
while (true) {
    // 4. accept 建立与客户端连接， SocketChannel 用来与客户端之间通信
    SocketChannel sc = ssc.accept(); // 非阻塞，线程还会继续运行，如果没有连接建立，但sc是null
    if (sc != null) {
        log.debug(&quot;connected... {}&quot;, sc);
        sc.configureBlocking(false); // 非阻塞模式
        channels.add(sc);
    }
    for (SocketChannel channel : channels) {
        // 5. 接收客户端发送的数据
        int read = channel.read(buffer);// 非阻塞，线程仍然会继续运行，如果没有读到数据，read 返回 0
        if (read &gt; 0) {
            buffer.flip();
            debugRead(buffer);
            buffer.clear();
            log.debug(&quot;after read...{}&quot;, channel);
        }
    }
}
</code></pre>
<h4 id="多路复用">多路复用</h4>
<p>单线程可以配合 Selector 完成对多个 Channel 可读写事件的监控，这称之为<strong>多路复用</strong></p>
<ul>
<li>多路复用仅针对网络 IO、普通文件 IO 没法利用多路复用</li>
<li>如果不用 Selector 的非阻塞模式，线程大部分时间都在做无用功，而 Selector 能够保证
<ul>
<li>有可连接事件时才去连接</li>
<li>有可读事件才去读取</li>
<li>有可写事件才去写入
<ul>
<li>限于网络传输能力，Channel 未必时时可写，一旦 Channel 可写，会触发 Selector 的可写事件</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="42-selector">4.2 Selector</h3>
<pre><code class="language-mermaid">graph TD
subgraph selector 版
thread --&gt; selector
selector --&gt; c1(channel)
selector --&gt; c2(channel)
selector --&gt; c3(channel)
end
</code></pre>
<p>好处</p>
<ul>
<li>一个线程配合 selector 就可以监控多个 channel 的事件，事件发生线程才去处理。避免非阻塞模式下所做无用功</li>
<li>让这个线程能够被充分利用</li>
<li>节约了线程的数量</li>
<li>减少了线程上下文切换</li>
</ul>
<h4 id="创建">创建</h4>
<pre><code class="language-java">Selector selector = Selector.open();
</code></pre>
<h4 id="绑定-channel-事件">绑定 Channel 事件</h4>
<p>也称之为注册事件，绑定的事件 selector 才会关心</p>
<pre><code class="language-java">channel.configureBlocking(false);
SelectionKey key = channel.register(selector, 绑定事件);
</code></pre>
<ul>
<li>channel 必须工作在非阻塞模式</li>
<li>FileChannel 没有非阻塞模式，因此不能配合 selector 一起使用</li>
<li>绑定的事件类型可以有
<ul>
<li>connect - 客户端连接成功时触发</li>
<li>accept - 服务器端成功接受连接时触发</li>
<li>read - 数据可读入时触发，有因为接收能力弱，数据暂不能读入的情况</li>
<li>write - 数据可写出时触发，有因为发送能力弱，数据暂不能写出的情况</li>
</ul>
</li>
</ul>
<h4 id="监听-channel-事件">监听 Channel 事件</h4>
<p>可以通过下面三种方法来监听是否有事件发生，方法的返回值代表有多少 channel 发生了事件</p>
<p>方法1，阻塞直到绑定事件发生</p>
<pre><code class="language-java">int count = selector.select();
</code></pre>
<p>方法2，阻塞直到绑定事件发生，或是超时（时间单位为 ms）</p>
<pre><code class="language-java">int count = selector.select(long timeout);
</code></pre>
<p>方法3，不会阻塞，也就是不管有没有事件，立刻返回，自己根据返回值检查是否有事件</p>
<pre><code class="language-java">int count = selector.selectNow();
</code></pre>
<h4 id="select-何时不阻塞">💡 select 何时不阻塞</h4>
<blockquote>
<ul>
<li>事件发生时
<ul>
<li>客户端发起连接请求，会触发 accept 事件</li>
<li>客户端发送数据过来，客户端正常、异常关闭时，都会触发 read 事件，另外如果发送的数据大于 buffer 缓冲区，会触发多次读取事件</li>
<li>channel 可写，会触发 write 事件</li>
<li>在 linux 下 nio bug 发生时</li>
</ul>
</li>
<li>调用 selector.wakeup()</li>
<li>调用 selector.close()</li>
<li>selector 所在线程 interrupt</li>
</ul>
</blockquote>
<h3 id="43-处理-accept-事件">4.3 处理 accept 事件</h3>
<p>客户端代码为</p>
<pre><code class="language-java">public class Client {
    public static void main(String[] args) {
        try (Socket socket = new Socket(&quot;localhost&quot;, 8080)) {
            System.out.println(socket);
            socket.getOutputStream().write(&quot;world&quot;.getBytes());
            System.in.read();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>服务器端代码为</p>
<pre><code class="language-java">@Slf4j
public class ChannelDemo6 {
    public static void main(String[] args) {
        try (ServerSocketChannel channel = ServerSocketChannel.open()) {
            channel.bind(new InetSocketAddress(8080));
            System.out.println(channel);
            Selector selector = Selector.open();
            channel.configureBlocking(false);
            channel.register(selector, SelectionKey.OP_ACCEPT);

            while (true) {
                int count = selector.select();
//                int count = selector.selectNow();
                log.debug(&quot;select count: {}&quot;, count);
//                if(count &lt;= 0) {
//                    continue;
//                }

                // 获取所有事件
                Set&lt;SelectionKey&gt; keys = selector.selectedKeys();

                // 遍历所有事件，逐一处理
                Iterator&lt;SelectionKey&gt; iter = keys.iterator();
                while (iter.hasNext()) {
                    SelectionKey key = iter.next();
                    // 判断事件类型
                    if (key.isAcceptable()) {
                        ServerSocketChannel c = (ServerSocketChannel) key.channel();
                        // 必须处理
                        SocketChannel sc = c.accept();
                        log.debug(&quot;{}&quot;, sc);
                    }
                    // 处理完毕，必须将事件移除
                    iter.remove();
                }
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<h4 id="事件发生后能否不处理">💡 事件发生后能否不处理</h4>
<blockquote>
<p>事件发生后，要么处理，要么取消（cancel），不能什么都不做，否则下次该事件仍会触发，这是因为 nio 底层使用的是水平触发</p>
</blockquote>
<h3 id="44-处理-read-事件">4.4 处理 read 事件</h3>
<pre><code class="language-java">@Slf4j
public class ChannelDemo6 {
    public static void main(String[] args) {
        try (ServerSocketChannel channel = ServerSocketChannel.open()) {
            channel.bind(new InetSocketAddress(8080));
            System.out.println(channel);
            Selector selector = Selector.open();
            channel.configureBlocking(false);
            channel.register(selector, SelectionKey.OP_ACCEPT);

            while (true) {
                int count = selector.select();
//                int count = selector.selectNow();
                log.debug(&quot;select count: {}&quot;, count);
//                if(count &lt;= 0) {
//                    continue;
//                }

                // 获取所有事件
                Set&lt;SelectionKey&gt; keys = selector.selectedKeys();

                // 遍历所有事件，逐一处理
                Iterator&lt;SelectionKey&gt; iter = keys.iterator();
                while (iter.hasNext()) {
                    SelectionKey key = iter.next();
                    // 判断事件类型
                    if (key.isAcceptable()) {
                        ServerSocketChannel c = (ServerSocketChannel) key.channel();
                        // 必须处理
                        SocketChannel sc = c.accept();
                        sc.configureBlocking(false);
                        sc.register(selector, SelectionKey.OP_READ);
                        log.debug(&quot;连接已建立: {}&quot;, sc);
                    } else if (key.isReadable()) {
                        SocketChannel sc = (SocketChannel) key.channel();
                        ByteBuffer buffer = ByteBuffer.allocate(128);
                        int read = sc.read(buffer);
                        if(read == -1) {
                            key.cancel();
                            sc.close();
                        } else {
                            buffer.flip();
                            debug(buffer);
                        }
                    }
                    // 处理完毕，必须将事件移除
                    iter.remove();
                }
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>开启两个客户端，修改一下发送文字，输出</p>
<pre><code>sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:8080]
21:16:39 [DEBUG] [main] c.i.n.ChannelDemo6 - select count: 1
21:16:39 [DEBUG] [main] c.i.n.ChannelDemo6 - 连接已建立: java.nio.channels.SocketChannel[connected local=/127.0.0.1:8080 remote=/127.0.0.1:60367]
21:16:39 [DEBUG] [main] c.i.n.ChannelDemo6 - select count: 1
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 68 65 6c 6c 6f                                  |hello           |
+--------+-------------------------------------------------+----------------+
21:16:59 [DEBUG] [main] c.i.n.ChannelDemo6 - select count: 1
21:16:59 [DEBUG] [main] c.i.n.ChannelDemo6 - 连接已建立: java.nio.channels.SocketChannel[connected local=/127.0.0.1:8080 remote=/127.0.0.1:60378]
21:16:59 [DEBUG] [main] c.i.n.ChannelDemo6 - select count: 1
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 77 6f 72 6c 64                                  |world           |
+--------+-------------------------------------------------+----------------+
</code></pre>
<h4 id="为何要-iterremove">💡 为何要 iter.remove()</h4>
<blockquote>
<p>因为 select 在事件发生后，就会将相关的 key 放入 selectedKeys 集合，但不会在处理完后从 selectedKeys 集合中移除，需要我们自己编码删除。例如</p>
<ul>
<li>第一次触发了 ssckey 上的 accept 事件，没有移除 ssckey</li>
<li>第二次触发了 sckey 上的 read 事件，但这时 selectedKeys 中还有上次的 ssckey ，在处理时因为没有真正的 serverSocket 连上了，就会导致空指针异常</li>
</ul>
</blockquote>
<h4 id="cancel-的作用">💡 cancel 的作用</h4>
<blockquote>
<p>cancel 会取消注册在 selector 上的 channel，并从 keys 集合中删除 key 后续不会再监听事件</p>
</blockquote>
<h4 id="️-不处理边界的问题">⚠️  不处理边界的问题</h4>
<p>以前有同学写过这样的代码，思考注释中两个问题，以 bio 为例，其实 nio 道理是一样的</p>
<pre><code class="language-java">public class Server {
    public static void main(String[] args) throws IOException {
        ServerSocket ss=new ServerSocket(9000);
        while (true) {
            Socket s = ss.accept();
            InputStream in = s.getInputStream();
            // 这里这么写，有没有问题
            byte[] arr = new byte[4];
            while(true) {
                int read = in.read(arr);
                // 这里这么写，有没有问题
                if(read == -1) {
                    break;
                }
                System.out.println(new String(arr, 0, read));
            }
        }
    }
}
</code></pre>
<p>客户端</p>
<pre><code class="language-java">public class Client {
    public static void main(String[] args) throws IOException {
        Socket max = new Socket(&quot;localhost&quot;, 9000);
        OutputStream out = max.getOutputStream();
        out.write(&quot;hello&quot;.getBytes());
        out.write(&quot;world&quot;.getBytes());
        out.write(&quot;你好&quot;.getBytes());
        max.close();
    }
}
</code></pre>
<p>输出</p>
<pre><code>hell
owor
ld�
�好

</code></pre>
<p>为什么？</p>
<h4 id="处理消息的边界">处理消息的边界</h4>
<figure data-type="image" tabindex="4"><img src="img/0023.png" alt="" loading="lazy"></figure>
<ul>
<li>一种思路是固定消息长度，数据包大小一样，服务器按预定长度读取，缺点是浪费带宽</li>
<li>另一种思路是按分隔符拆分，缺点是效率低</li>
<li>TLV 格式，即 Type 类型、Length 长度、Value 数据，类型和长度已知的情况下，就可以方便获取消息大小，分配合适的 buffer，缺点是 buffer 需要提前分配，如果内容过大，则影响 server 吞吐量
<ul>
<li>Http 1.1 是 TLV 格式</li>
<li>Http 2.0 是 LTV 格式</li>
</ul>
</li>
</ul>
<pre><code class="language-mermaid">sequenceDiagram 
participant c1 as 客户端1
participant s as 服务器
participant b1 as ByteBuffer1
participant b2 as ByteBuffer2
c1 -&gt;&gt; s: 发送 01234567890abcdef3333\r
s -&gt;&gt; b1: 第一次 read 存入 01234567890abcdef
s -&gt;&gt; b2: 扩容
b1 -&gt;&gt; b2: 拷贝 01234567890abcdef
s -&gt;&gt; b2: 第二次 read 存入 3333\r
b2 -&gt;&gt; b2: 01234567890abcdef3333\r
</code></pre>
<p>服务器端</p>
<pre><code class="language-java">private static void split(ByteBuffer source) {
    source.flip();
    for (int i = 0; i &lt; source.limit(); i++) {
        // 找到一条完整消息
        if (source.get(i) == '\n') {
            int length = i + 1 - source.position();
            // 把这条完整消息存入新的 ByteBuffer
            ByteBuffer target = ByteBuffer.allocate(length);
            // 从 source 读，向 target 写
            for (int j = 0; j &lt; length; j++) {
                target.put(source.get());
            }
            debugAll(target);
        }
    }
    source.compact(); // 0123456789abcdef  position 16 limit 16
}

public static void main(String[] args) throws IOException {
    // 1. 创建 selector, 管理多个 channel
    Selector selector = Selector.open();
    ServerSocketChannel ssc = ServerSocketChannel.open();
    ssc.configureBlocking(false);
    // 2. 建立 selector 和 channel 的联系（注册）
    // SelectionKey 就是将来事件发生后，通过它可以知道事件和哪个channel的事件
    SelectionKey sscKey = ssc.register(selector, 0, null);
    // key 只关注 accept 事件
    sscKey.interestOps(SelectionKey.OP_ACCEPT);
    log.debug(&quot;sscKey:{}&quot;, sscKey);
    ssc.bind(new InetSocketAddress(8080));
    while (true) {
        // 3. select 方法, 没有事件发生，线程阻塞，有事件，线程才会恢复运行
        // select 在事件未处理时，它不会阻塞, 事件发生后要么处理，要么取消，不能置之不理
        selector.select();
        // 4. 处理事件, selectedKeys 内部包含了所有发生的事件
        Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator(); // accept, read
        while (iter.hasNext()) {
            SelectionKey key = iter.next();
            // 处理key 时，要从 selectedKeys 集合中删除，否则下次处理就会有问题
            iter.remove();
            log.debug(&quot;key: {}&quot;, key);
            // 5. 区分事件类型
            if (key.isAcceptable()) { // 如果是 accept
                ServerSocketChannel channel = (ServerSocketChannel) key.channel();
                SocketChannel sc = channel.accept();
                sc.configureBlocking(false);
                ByteBuffer buffer = ByteBuffer.allocate(16); // attachment
                // 将一个 byteBuffer 作为附件关联到 selectionKey 上
                SelectionKey scKey = sc.register(selector, 0, buffer);
                scKey.interestOps(SelectionKey.OP_READ);
                log.debug(&quot;{}&quot;, sc);
                log.debug(&quot;scKey:{}&quot;, scKey);
            } else if (key.isReadable()) { // 如果是 read
                try {
                    SocketChannel channel = (SocketChannel) key.channel(); // 拿到触发事件的channel
                    // 获取 selectionKey 上关联的附件
                    ByteBuffer buffer = (ByteBuffer) key.attachment();
                    int read = channel.read(buffer); // 如果是正常断开，read 的方法的返回值是 -1
                    if(read == -1) {
                        key.cancel();
                    } else {
                        split(buffer);
                        // 需要扩容
                        if (buffer.position() == buffer.limit()) {
                            ByteBuffer newBuffer = ByteBuffer.allocate(buffer.capacity() * 2);
                            buffer.flip();
                            newBuffer.put(buffer); // 0123456789abcdef3333\n
                            key.attach(newBuffer);
                        }
                    }

                } catch (IOException e) {
                    e.printStackTrace();
                    key.cancel();  // 因为客户端断开了,因此需要将 key 取消（从 selector 的 keys 集合中真正删除 key）
                }
            }
        }
    }
}
</code></pre>
<p>客户端</p>
<pre><code class="language-java">SocketChannel sc = SocketChannel.open();
sc.connect(new InetSocketAddress(&quot;localhost&quot;, 8080));
SocketAddress address = sc.getLocalAddress();
// sc.write(Charset.defaultCharset().encode(&quot;hello\nworld\n&quot;));
sc.write(Charset.defaultCharset().encode(&quot;0123\n456789abcdef&quot;));
sc.write(Charset.defaultCharset().encode(&quot;0123456789abcdef3333\n&quot;));
System.in.read();
</code></pre>
<h4 id="bytebuffer-大小分配">ByteBuffer 大小分配</h4>
<ul>
<li>每个 channel 都需要记录可能被切分的消息，因为 ByteBuffer 不能被多个 channel 共同使用，因此需要为每个 channel 维护一个独立的 ByteBuffer</li>
<li>ByteBuffer 不能太大，比如一个 ByteBuffer 1Mb 的话，要支持百万连接就要 1Tb 内存，因此需要设计大小可变的 ByteBuffer
<ul>
<li>一种思路是首先分配一个较小的 buffer，例如 4k，如果发现数据不够，再分配 8k 的 buffer，将 4k buffer 内容拷贝至 8k buffer，优点是消息连续容易处理，缺点是数据拷贝耗费性能，参考实现 <a href="http://tutorials.jenkov.com/java-performance/resizable-array.html">http://tutorials.jenkov.com/java-performance/resizable-array.html</a></li>
<li>另一种思路是用多个数组组成 buffer，一个数组不够，把多出来的内容写入新的数组，与前面的区别是消息存储不连续解析复杂，优点是避免了拷贝引起的性能损耗</li>
</ul>
</li>
</ul>
<h3 id="45-处理-write-事件">4.5 处理 write 事件</h3>
<h4 id="一次无法写完例子">一次无法写完例子</h4>
<ul>
<li>非阻塞模式下，无法保证把 buffer 中所有数据都写入 channel，因此需要追踪 write 方法的返回值（代表实际写入字节数）</li>
<li>用 selector 监听所有 channel 的可写事件，每个 channel 都需要一个 key 来跟踪 buffer，但这样又会导致占用内存过多，就有两阶段策略
<ul>
<li>当消息处理器第一次写入消息时，才将 channel 注册到 selector 上</li>
<li>selector 检查 channel 上的可写事件，如果所有的数据写完了，就取消 channel 的注册</li>
<li>如果不取消，会每次可写均会触发 write 事件</li>
</ul>
</li>
</ul>
<pre><code class="language-java">public class WriteServer {

    public static void main(String[] args) throws IOException {
        ServerSocketChannel ssc = ServerSocketChannel.open();
        ssc.configureBlocking(false);
        ssc.bind(new InetSocketAddress(8080));

        Selector selector = Selector.open();
        ssc.register(selector, SelectionKey.OP_ACCEPT);

        while(true) {
            selector.select();

            Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator();
            while (iter.hasNext()) {
                SelectionKey key = iter.next();
                iter.remove();
                if (key.isAcceptable()) {
                    SocketChannel sc = ssc.accept();
                    sc.configureBlocking(false);
                    SelectionKey sckey = sc.register(selector, SelectionKey.OP_READ);
                    // 1. 向客户端发送内容
                    StringBuilder sb = new StringBuilder();
                    for (int i = 0; i &lt; 3000000; i++) {
                        sb.append(&quot;a&quot;);
                    }
                    ByteBuffer buffer = Charset.defaultCharset().encode(sb.toString());
                    int write = sc.write(buffer);
                    // 3. write 表示实际写了多少字节
                    System.out.println(&quot;实际写入字节:&quot; + write);
                    // 4. 如果有剩余未读字节，才需要关注写事件
                    if (buffer.hasRemaining()) {
                        // read 1  write 4
                        // 在原有关注事件的基础上，多关注 写事件
                        sckey.interestOps(sckey.interestOps() + SelectionKey.OP_WRITE);
                        // 把 buffer 作为附件加入 sckey
                        sckey.attach(buffer);
                    }
                } else if (key.isWritable()) {
                    ByteBuffer buffer = (ByteBuffer) key.attachment();
                    SocketChannel sc = (SocketChannel) key.channel();
                    int write = sc.write(buffer);
                    System.out.println(&quot;实际写入字节:&quot; + write);
                    if (!buffer.hasRemaining()) { // 写完了
                        key.interestOps(key.interestOps() - SelectionKey.OP_WRITE);
                        key.attach(null);
                    }
                }
            }
        }
    }
}
</code></pre>
<p>客户端</p>
<pre><code class="language-java">public class WriteClient {
    public static void main(String[] args) throws IOException {
        Selector selector = Selector.open();
        SocketChannel sc = SocketChannel.open();
        sc.configureBlocking(false);
        sc.register(selector, SelectionKey.OP_CONNECT | SelectionKey.OP_READ);
        sc.connect(new InetSocketAddress(&quot;localhost&quot;, 8080));
        int count = 0;
        while (true) {
            selector.select();
            Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator();
            while (iter.hasNext()) {
                SelectionKey key = iter.next();
                iter.remove();
                if (key.isConnectable()) {
                    System.out.println(sc.finishConnect());
                } else if (key.isReadable()) {
                    ByteBuffer buffer = ByteBuffer.allocate(1024 * 1024);
                    count += sc.read(buffer);
                    buffer.clear();
                    System.out.println(count);
                }
            }
        }
    }
}
</code></pre>
<h4 id="write-为何要取消">💡 write 为何要取消</h4>
<p>只要向 channel 发送数据时，socket 缓冲可写，这个事件会频繁触发，因此应当只在 socket 缓冲区写不下时再关注可写事件，数据写完之后再取消关注</p>
<h3 id="46-更进一步">4.6 更进一步</h3>
<h4 id="利用多线程优化">💡 利用多线程优化</h4>
<blockquote>
<p>现在都是多核 cpu，设计时要充分考虑别让 cpu 的力量被白白浪费</p>
</blockquote>
<p>前面的代码只有一个选择器，没有充分利用多核 cpu，如何改进呢？</p>
<p>分两组选择器</p>
<ul>
<li>单线程配一个选择器，专门处理 accept 事件</li>
<li>创建 cpu 核心数的线程，每个线程配一个选择器，轮流处理 read 事件</li>
</ul>
<pre><code class="language-java">public class ChannelDemo7 {
    public static void main(String[] args) throws IOException {
        new BossEventLoop().register();
    }


    @Slf4j
    static class BossEventLoop implements Runnable {
        private Selector boss;
        private WorkerEventLoop[] workers;
        private volatile boolean start = false;
        AtomicInteger index = new AtomicInteger();

        public void register() throws IOException {
            if (!start) {
                ServerSocketChannel ssc = ServerSocketChannel.open();
                ssc.bind(new InetSocketAddress(8080));
                ssc.configureBlocking(false);
                boss = Selector.open();
                SelectionKey ssckey = ssc.register(boss, 0, null);
                ssckey.interestOps(SelectionKey.OP_ACCEPT);
                workers = initEventLoops();
                new Thread(this, &quot;boss&quot;).start();
                log.debug(&quot;boss start...&quot;);
                start = true;
            }
        }

        public WorkerEventLoop[] initEventLoops() {
//        EventLoop[] eventLoops = new EventLoop[Runtime.getRuntime().availableProcessors()];
            WorkerEventLoop[] workerEventLoops = new WorkerEventLoop[2];
            for (int i = 0; i &lt; workerEventLoops.length; i++) {
                workerEventLoops[i] = new WorkerEventLoop(i);
            }
            return workerEventLoops;
        }

        @Override
        public void run() {
            while (true) {
                try {
                    boss.select();
                    Iterator&lt;SelectionKey&gt; iter = boss.selectedKeys().iterator();
                    while (iter.hasNext()) {
                        SelectionKey key = iter.next();
                        iter.remove();
                        if (key.isAcceptable()) {
                            ServerSocketChannel c = (ServerSocketChannel) key.channel();
                            SocketChannel sc = c.accept();
                            sc.configureBlocking(false);
                            log.debug(&quot;{} connected&quot;, sc.getRemoteAddress());
                            workers[index.getAndIncrement() % workers.length].register(sc);
                        }
                    }
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
    }

    @Slf4j
    static class WorkerEventLoop implements Runnable {
        private Selector worker;
        private volatile boolean start = false;
        private int index;

        private final ConcurrentLinkedQueue&lt;Runnable&gt; tasks = new ConcurrentLinkedQueue&lt;&gt;();

        public WorkerEventLoop(int index) {
            this.index = index;
        }

        public void register(SocketChannel sc) throws IOException {
            if (!start) {
                worker = Selector.open();
                new Thread(this, &quot;worker-&quot; + index).start();
                start = true;
            }
            tasks.add(() -&gt; {
                try {
                    SelectionKey sckey = sc.register(worker, 0, null);
                    sckey.interestOps(SelectionKey.OP_READ);
                    worker.selectNow();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            });
            worker.wakeup();
        }

        @Override
        public void run() {
            while (true) {
                try {
                    worker.select();
                    Runnable task = tasks.poll();
                    if (task != null) {
                        task.run();
                    }
                    Set&lt;SelectionKey&gt; keys = worker.selectedKeys();
                    Iterator&lt;SelectionKey&gt; iter = keys.iterator();
                    while (iter.hasNext()) {
                        SelectionKey key = iter.next();
                        if (key.isReadable()) {
                            SocketChannel sc = (SocketChannel) key.channel();
                            ByteBuffer buffer = ByteBuffer.allocate(128);
                            try {
                                int read = sc.read(buffer);
                                if (read == -1) {
                                    key.cancel();
                                    sc.close();
                                } else {
                                    buffer.flip();
                                    log.debug(&quot;{} message:&quot;, sc.getRemoteAddress());
                                    debugAll(buffer);
                                }
                            } catch (IOException e) {
                                e.printStackTrace();
                                key.cancel();
                                sc.close();
                            }
                        }
                        iter.remove();
                    }
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
    }
}
</code></pre>
<h4 id="如何拿到-cpu-个数">💡 如何拿到 cpu 个数</h4>
<blockquote>
<ul>
<li>Runtime.getRuntime().availableProcessors() 如果工作在 docker 容器下，因为容器不是物理隔离的，会拿到物理 cpu 个数，而不是容器申请时的个数</li>
<li>这个问题直到 jdk 10 才修复，使用 jvm 参数 UseContainerSupport 配置， 默认开启</li>
</ul>
</blockquote>
<h3 id="47-udp">4.7 UDP</h3>
<ul>
<li>UDP 是无连接的，client 发送数据不会管 server 是否开启</li>
<li>server 这边的 receive 方法会将接收到的数据存入 byte buffer，但如果数据报文超过 buffer 大小，多出来的数据会被默默抛弃</li>
</ul>
<p>首先启动服务器端</p>
<pre><code class="language-java">public class UdpServer {
    public static void main(String[] args) {
        try (DatagramChannel channel = DatagramChannel.open()) {
            channel.socket().bind(new InetSocketAddress(9999));
            System.out.println(&quot;waiting...&quot;);
            ByteBuffer buffer = ByteBuffer.allocate(32);
            channel.receive(buffer);
            buffer.flip();
            debug(buffer);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>输出</p>
<pre><code>waiting...
</code></pre>
<p>运行客户端</p>
<pre><code class="language-java">public class UdpClient {
    public static void main(String[] args) {
        try (DatagramChannel channel = DatagramChannel.open()) {
            ByteBuffer buffer = StandardCharsets.UTF_8.encode(&quot;hello&quot;);
            InetSocketAddress address = new InetSocketAddress(&quot;localhost&quot;, 9999);
            channel.send(buffer, address);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>接下来服务器端输出</p>
<pre><code>         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 68 65 6c 6c 6f                                  |hello           |
+--------+-------------------------------------------------+----------------+
</code></pre>
<h2 id="5-nio-vs-bio">5. NIO vs BIO</h2>
<h3 id="51-stream-vs-channel">5.1 stream vs channel</h3>
<ul>
<li>stream 不会自动缓冲数据，channel 会利用系统提供的发送缓冲区、接收缓冲区（更为底层）</li>
<li>stream 仅支持阻塞 API，channel 同时支持阻塞、非阻塞 API，网络 channel 可配合 selector 实现多路复用</li>
<li>二者均为全双工，即读写可以同时进行</li>
</ul>
<h3 id="52-io-模型">5.2 IO 模型</h3>
<p>同步阻塞、同步非阻塞、同步多路复用、异步阻塞（没有此情况）、异步非阻塞</p>
<ul>
<li>同步：线程自己去获取结果（一个线程）</li>
<li>异步：线程自己不去获取结果，而是由其它线程送结果（至少两个线程）</li>
</ul>
<p>当调用一次 channel.read 或 stream.read 后，会切换至操作系统内核态来完成真正数据读取，而读取又分为两个阶段，分别为：</p>
<ul>
<li>等待数据阶段</li>
<li>复制数据阶段</li>
</ul>
<figure data-type="image" tabindex="5"><img src="img/0033.png" alt="" loading="lazy"></figure>
<ul>
<li>
<p>阻塞 IO</p>
<figure data-type="image" tabindex="6"><img src="img/0039.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>非阻塞  IO</p>
<figure data-type="image" tabindex="7"><img src="img/0035.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>多路复用</p>
<figure data-type="image" tabindex="8"><img src="img/0038.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>信号驱动</p>
</li>
<li>
<p>异步 IO</p>
<figure data-type="image" tabindex="9"><img src="img/0037.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>阻塞 IO vs 多路复用</p>
<figure data-type="image" tabindex="10"><img src="img/0034.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="11"><img src="img/0036.png" alt="" loading="lazy"></figure>
</li>
</ul>
<h4 id="参考">🔖 参考</h4>
<p>UNIX 网络编程 - 卷 I</p>
<h3 id="53-零拷贝">5.3 零拷贝</h3>
<h4 id="传统-io-问题">传统 IO 问题</h4>
<p>传统的 IO 将一个文件通过 socket 写出</p>
<pre><code class="language-java">File f = new File(&quot;helloword/data.txt&quot;);
RandomAccessFile file = new RandomAccessFile(file, &quot;r&quot;);

byte[] buf = new byte[(int)f.length()];
file.read(buf);

Socket socket = ...;
socket.getOutputStream().write(buf);
</code></pre>
<p>内部工作流程是这样的：</p>
<figure data-type="image" tabindex="12"><img src="img/0024.png" alt="" loading="lazy"></figure>
<ol>
<li>
<p>java 本身并不具备 IO 读写能力，因此 read 方法调用后，要从 java 程序的<strong>用户态</strong>切换至<strong>内核态</strong>，去调用操作系统（Kernel）的读能力，将数据读入<strong>内核缓冲区</strong>。这期间用户线程阻塞，操作系统使用 DMA（Direct Memory Access）来实现文件读，其间也不会使用 cpu</p>
<blockquote>
<p>DMA 也可以理解为硬件单元，用来解放 cpu 完成文件 IO</p>
</blockquote>
</li>
<li>
<p>从<strong>内核态</strong>切换回<strong>用户态</strong>，将数据从<strong>内核缓冲区</strong>读入<strong>用户缓冲区</strong>（即 byte[] buf），这期间 cpu 会参与拷贝，无法利用 DMA</p>
</li>
<li>
<p>调用 write 方法，这时将数据从<strong>用户缓冲区</strong>（byte[] buf）写入 <strong>socket 缓冲区</strong>，cpu 会参与拷贝</p>
</li>
<li>
<p>接下来要向网卡写数据，这项能力 java 又不具备，因此又得从<strong>用户态</strong>切换至<strong>内核态</strong>，调用操作系统的写能力，使用 DMA 将 <strong>socket 缓冲区</strong>的数据写入网卡，不会使用 cpu</p>
</li>
</ol>
<p>可以看到中间环节较多，java 的 IO 实际不是物理设备级别的读写，而是缓存的复制，底层的真正读写是操作系统来完成的</p>
<ul>
<li>用户态与内核态的切换发生了 3 次，这个操作比较重量级</li>
<li>数据拷贝了共 4 次</li>
</ul>
<h4 id="nio-优化">NIO 优化</h4>
<p>通过 DirectByteBuf</p>
<ul>
<li>ByteBuffer.allocate(10)  HeapByteBuffer 使用的还是 java 内存</li>
<li>ByteBuffer.allocateDirect(10)  DirectByteBuffer 使用的是操作系统内存</li>
</ul>
<figure data-type="image" tabindex="13"><img src="img/0025.png" alt="" loading="lazy"></figure>
<p>大部分步骤与优化前相同，不再赘述。唯有一点：java 可以使用 DirectByteBuf 将堆外内存映射到 jvm 内存中来直接访问使用</p>
<ul>
<li>这块内存不受 jvm 垃圾回收的影响，因此内存地址固定，有助于 IO 读写</li>
<li>java 中的 DirectByteBuf 对象仅维护了此内存的虚引用，内存回收分成两步
<ul>
<li>DirectByteBuf 对象被垃圾回收，将虚引用加入引用队列</li>
<li>通过专门线程访问引用队列，根据虚引用释放堆外内存</li>
</ul>
</li>
<li>减少了一次数据拷贝，用户态与内核态的切换次数没有减少</li>
</ul>
<p>进一步优化（底层采用了 linux 2.1 后提供的 sendFile 方法），java 中对应着两个 channel 调用 transferTo/transferFrom 方法拷贝数据</p>
<figure data-type="image" tabindex="14"><img src="img/0026.png" alt="" loading="lazy"></figure>
<ol>
<li>java 调用 transferTo 方法后，要从 java 程序的<strong>用户态</strong>切换至<strong>内核态</strong>，使用 DMA将数据读入<strong>内核缓冲区</strong>，不会使用 cpu</li>
<li>数据从<strong>内核缓冲区</strong>传输到 <strong>socket 缓冲区</strong>，cpu 会参与拷贝</li>
<li>最后使用 DMA 将 <strong>socket 缓冲区</strong>的数据写入网卡，不会使用 cpu</li>
</ol>
<p>可以看到</p>
<ul>
<li>只发生了一次用户态与内核态的切换</li>
<li>数据拷贝了 3 次</li>
</ul>
<p>进一步优化（linux 2.4）</p>
<figure data-type="image" tabindex="15"><img src="img/0027.png" alt="" loading="lazy"></figure>
<ol>
<li>java 调用 transferTo 方法后，要从 java 程序的<strong>用户态</strong>切换至<strong>内核态</strong>，使用 DMA将数据读入<strong>内核缓冲区</strong>，不会使用 cpu</li>
<li>只会将一些 offset 和 length 信息拷入 <strong>socket 缓冲区</strong>，几乎无消耗</li>
<li>使用 DMA 将 <strong>内核缓冲区</strong>的数据写入网卡，不会使用 cpu</li>
</ol>
<p>整个过程仅只发生了一次用户态与内核态的切换，数据拷贝了 2 次。所谓的【零拷贝】，并不是真正无拷贝，而是在不会拷贝重复数据到 jvm 内存中，零拷贝的优点有</p>
<ul>
<li>更少的用户态与内核态的切换</li>
<li>不利用 cpu 计算，减少 cpu 缓存伪共享</li>
<li>零拷贝适合小文件传输</li>
</ul>
<h3 id="53-aio">5.3 AIO</h3>
<p>AIO 用来解决数据复制阶段的阻塞问题</p>
<ul>
<li>同步意味着，在进行读写操作时，线程需要等待结果，还是相当于闲置</li>
<li>异步意味着，在进行读写操作时，线程不必等待结果，而是将来由操作系统来通过回调方式由另外的线程来获得结果</li>
</ul>
<blockquote>
<p>异步模型需要底层操作系统（Kernel）提供支持</p>
<ul>
<li>Windows 系统通过 IOCP 实现了真正的异步 IO</li>
<li>Linux 系统异步 IO 在 2.6 版本引入，但其底层实现还是用多路复用模拟了异步 IO，性能没有优势</li>
</ul>
</blockquote>
<h4 id="文件-aio">文件 AIO</h4>
<p>先来看看 AsynchronousFileChannel</p>
<pre><code class="language-java">@Slf4j
public class AioDemo1 {
    public static void main(String[] args) throws IOException {
        try{
            AsynchronousFileChannel s = 
                AsynchronousFileChannel.open(
                	Paths.get(&quot;1.txt&quot;), StandardOpenOption.READ);
            ByteBuffer buffer = ByteBuffer.allocate(2);
            log.debug(&quot;begin...&quot;);
            s.read(buffer, 0, null, new CompletionHandler&lt;Integer, ByteBuffer&gt;() {
                @Override
                public void completed(Integer result, ByteBuffer attachment) {
                    log.debug(&quot;read completed...{}&quot;, result);
                    buffer.flip();
                    debug(buffer);
                }

                @Override
                public void failed(Throwable exc, ByteBuffer attachment) {
                    log.debug(&quot;read failed...&quot;);
                }
            });

        } catch (IOException e) {
            e.printStackTrace();
        }
        log.debug(&quot;do other things...&quot;);
        System.in.read();
    }
}
</code></pre>
<p>输出</p>
<pre><code>13:44:56 [DEBUG] [main] c.i.aio.AioDemo1 - begin...
13:44:56 [DEBUG] [main] c.i.aio.AioDemo1 - do other things...
13:44:56 [DEBUG] [Thread-5] c.i.aio.AioDemo1 - read completed...2
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 61 0d                                           |a.              |
+--------+-------------------------------------------------+----------------+
</code></pre>
<p>可以看到</p>
<ul>
<li>响应文件读取成功的是另一个线程 Thread-5</li>
<li>主线程并没有 IO 操作阻塞</li>
</ul>
<h4 id="守护线程">💡 守护线程</h4>
<p>默认文件 AIO 使用的线程都是守护线程，所以最后要执行 <code>System.in.read()</code> 以避免守护线程意外结束</p>
<h4 id="网络-aio">网络 AIO</h4>
<pre><code class="language-java">public class AioServer {
    public static void main(String[] args) throws IOException {
        AsynchronousServerSocketChannel ssc = AsynchronousServerSocketChannel.open();
        ssc.bind(new InetSocketAddress(8080));
        ssc.accept(null, new AcceptHandler(ssc));
        System.in.read();
    }

    private static void closeChannel(AsynchronousSocketChannel sc) {
        try {
            System.out.printf(&quot;[%s] %s close\n&quot;, Thread.currentThread().getName(), sc.getRemoteAddress());
            sc.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    private static class ReadHandler implements CompletionHandler&lt;Integer, ByteBuffer&gt; {
        private final AsynchronousSocketChannel sc;

        public ReadHandler(AsynchronousSocketChannel sc) {
            this.sc = sc;
        }

        @Override
        public void completed(Integer result, ByteBuffer attachment) {
            try {
                if (result == -1) {
                    closeChannel(sc);
                    return;
                }
                System.out.printf(&quot;[%s] %s read\n&quot;, Thread.currentThread().getName(), sc.getRemoteAddress());
                attachment.flip();
                System.out.println(Charset.defaultCharset().decode(attachment));
                attachment.clear();
                // 处理完第一个 read 时，需要再次调用 read 方法来处理下一个 read 事件
                sc.read(attachment, attachment, this);
            } catch (IOException e) {
                e.printStackTrace();
            }
        }

        @Override
        public void failed(Throwable exc, ByteBuffer attachment) {
            closeChannel(sc);
            exc.printStackTrace();
        }
    }

    private static class WriteHandler implements CompletionHandler&lt;Integer, ByteBuffer&gt; {
        private final AsynchronousSocketChannel sc;

        private WriteHandler(AsynchronousSocketChannel sc) {
            this.sc = sc;
        }

        @Override
        public void completed(Integer result, ByteBuffer attachment) {
            // 如果作为附件的 buffer 还有内容，需要再次 write 写出剩余内容
            if (attachment.hasRemaining()) {
                sc.write(attachment);
            }
        }

        @Override
        public void failed(Throwable exc, ByteBuffer attachment) {
            exc.printStackTrace();
            closeChannel(sc);
        }
    }

    private static class AcceptHandler implements CompletionHandler&lt;AsynchronousSocketChannel, Object&gt; {
        private final AsynchronousServerSocketChannel ssc;

        public AcceptHandler(AsynchronousServerSocketChannel ssc) {
            this.ssc = ssc;
        }

        @Override
        public void completed(AsynchronousSocketChannel sc, Object attachment) {
            try {
                System.out.printf(&quot;[%s] %s connected\n&quot;, Thread.currentThread().getName(), sc.getRemoteAddress());
            } catch (IOException e) {
                e.printStackTrace();
            }
            ByteBuffer buffer = ByteBuffer.allocate(16);
            // 读事件由 ReadHandler 处理
            sc.read(buffer, buffer, new ReadHandler(sc));
            // 写事件由 WriteHandler 处理
            sc.write(Charset.defaultCharset().encode(&quot;server hello!&quot;), ByteBuffer.allocate(16), new WriteHandler(sc));
            // 处理完第一个 accpet 时，需要再次调用 accept 方法来处理下一个 accept 事件
            ssc.accept(null, this);
        }

        @Override
        public void failed(Throwable exc, Object attachment) {
            exc.printStackTrace();
        }
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JAVA并发（二）]]></title>
        <id>https://q456qq520.github.io/post/java-bing-fa-er/</id>
        <link href="https://q456qq520.github.io/post/java-bing-fa-er/">
        </link>
        <updated>2022-08-10T06:52:00.000Z</updated>
        <content type="html"><![CDATA[<h1 id="4-java中的锁">4、Java中的锁</h1>
<h2 id="41-lock接口">4.1 Lock接口</h2>
<p>锁是用来控制多个线程访问共享资源的方式，一般来说，一个锁能够防止多个线程同时访问共享资源（但是有些锁可以允许多个线程并发的访问共享资源，比如读写锁）。在Lock接口出现之前，Java程序是靠synchronized关键字实现锁功能的，而Java SE 5之后，并发包中新增了<strong>Lock接口</strong>（以及相关实现类）用来实现锁功能，它提供了与<strong>synchronized</strong>关键字类似的同步功能，只是在使用时需要显式地获取和释放锁。虽然它缺少了（通过synchronized块或者方法所提供的）隐式获取释放锁的便捷性，但是却拥有了锁获取与释放的可操作性、可中断的获取锁以及超时获取锁等多种synchronized关键字所不具备的同步特性。</p>
<p>使用synchronized关键字将会隐式地获取锁，但是它将锁的获取和释放固化了，也就是先获取再释放。当然，这种方式简化了同步的管理，可是扩展性没有显示的锁获取和释放来的好。例如，针对一个场景，手把手进行锁获取和释放，先获得锁A，然后再获取锁B，当锁B获得后，释放锁A同时获取锁C，当锁C获得后，再释放B同时获取锁D，以此类推。这种场景下，synchronized关键字就不那么容易实现了，而使用Lock却容易许多。</p>
<p>Lock的使用也很简单，代码清单4-1是Lock的使用的方式。</p>
<blockquote>
<p>代码清单4-1 LockUseCase.java</p>
</blockquote>
<pre><code class="language-java">Lock lock = new ReentrantLock();
lock.lock();
try {
            
} finally {
    lock.unlock();
}
</code></pre>
<p>在finally块中释放锁，目的是保证在获取到锁之后，最终能够被释放。<em>不要将获取锁的过程写在try块中，因为如果在获取锁（自定义锁的实现）时发生了异常，异常抛出的同时，也会导致锁无故释放。</em></p>
<p>Lock接口提供的synchronized关键字所不具备的主要特性如下所示。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1660118700493.png" alt="Lock接口提供的synchronized关键字不具备的主要特性" loading="lazy"></figure>
<p>Lock是一个接口，它定义了锁获取和释放的基本操作，Lock的API如下所示。</p>
<blockquote>
<p>Lock的API</p>
</blockquote>
<pre><code class="language-java">
//获取锁，调用该方法当前线程会获取锁，当锁获得后，返回
void lock();

//可中断获取锁，即在锁的获取中可中断当前线程
void lockInterruptibly() throws InterruptedException;

//尝试非阻塞的获取锁，调用该方法后立即返回，如果能够获取则返回ture，反之false
boolean tryLock();

//超时获取锁，当前线程在以下三种情况会返回
//1、当前线程在超时时间内获得锁
//2、当前线程在超时时间内被中断
//3、超时时间结束,返回false
boolean tryLock(long time, TimeUnit unit) throws InterruptedException;

//释放锁
void unlock();

//获取等待通知组件，该组件和当前锁绑定。当前线程只有获取了锁，才能调用该组件大wait()，而调用后当前线程释放锁
Condition newCondition();
</code></pre>
<p>Lock接口的实现基本都是通过聚合了一个同步器的子类来完成线程访问控制的。</p>
<h2 id="42-队列同步器">4.2 队列同步器</h2>
<p>队列同步器AbstractQueuedSynchronizer（以下简称同步器），是用来构建锁或者其他同步组件的基础框架，它使用了一个<strong>int成员变量</strong>表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。</p>
<p>同步器的主要使用方式是继承，子类通过继承同步器并实现它的抽象方法来管理同步状态，在抽象方法的实现过程中免不了要对同步状态进行更改，这时就需要使用同步器提供的3个方法（getState()、setState(int newState)和compareAndSetState(int expect,int update)）来进行操作，因为它们能够保证状态的改变是安全的。</p>
<p>同步器自身没有实现任何同步接口，它仅仅是定义了若干同步状态获取和释放的方法来供自定义同步组件使用，同步器既可以支持独占式地获取同步状态，也可以支持共享式地获取同步状态，这样就可以方便实现不同类型的同步组件（ReentrantLock、ReentrantReadWriteLock和CountDownLatch等）。</p>
<p>同步器是实现锁（也可以是任意同步组件）的关键，在锁的实现中聚合同步器，利用同步器实现锁的语义。可以这样理解二者之间的关系：<strong>锁是面向使用者的，它定义了使用者与锁交互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。</strong></p>
<h3 id="421-队列同步器的接口与示例">4.2.1 队列同步器的接口与示例</h3>
<p>同步器的设计是基于<strong>模板方法模式</strong>的，也就是说，使用者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。</p>
<p>重写同步器指定的方法时，需要使用同步器提供的如下3个方法来访问或修改同步状态。</p>
<p>getState()：获取当前同步状态。<br>
setState(int newState)：设置当前同步状态。<br>
compareAndSetState(int expect,int update)：使用CAS设置当前状态，该方法能够保证状态设置的原子性。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1660120867568.png" alt="同步器可重写的方法" loading="lazy"></figure>
<p>实现自定义同步组件时，将会调用同步器提供的模板方法。</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1660121528935.png" alt="同步器提供的模板方法" loading="lazy"></figure>
<p>同步器提供的模板方法基本上分为3类：<strong>独占式获取与释放同步状态</strong>、<strong>共享式获取与释放同步状态</strong>和<strong>查询同步队列中的等待线程情况</strong>。自定义同步组件将使用同步器提供的模板方法来实现自己的同步语义。</p>
<p>只有掌握了同步器的工作原理才能更加深入地理解并发包中其他的并发组件，所以下面通过一个独占锁的示例来深入了解一下同步器的工作原理。</p>
<p>顾名思义，<strong>独占锁就是在同一时刻只能有一个线程获取到锁，而其他获取锁的线程只能处于同步队列中等待，只有获取锁的线程释放了锁，后继的线程才能够获取锁</strong>，如代码清单如下：</p>
<pre><code class="language-java">package cm.lock;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.AbstractQueuedSynchronizer;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;

/**
 * 独占锁
 * @author likecat
 * @version 1.0
 * @date 2022/8/10 16:58
 */
public class Mutex implements Lock {
    // 静态内部类，自定义同步器
    private static class Sync extends AbstractQueuedSynchronizer {
        // 是否处于占用状态
        protected boolean isHeldExclusively() {
            return getState() == 1;
        }
        // 当状态为0的时候获取锁
        public boolean tryAcquire(int acquires) {
            if (compareAndSetState(0, 1)) {
                ////设置拥有线程为当前线程
                setExclusiveOwnerThread(Thread.currentThread());
                return true;
            }
            return false;
        }
        // 释放锁，将状态设置为0
        protected boolean tryRelease(int releases) {
            if (getState() == 0) throw new
                    IllegalMonitorStateException();
            setExclusiveOwnerThread(null);
            setState(0);
            return true;
        }
        // 返回一个Condition，每个condition都包含了一个condition队列
        Condition newCondition() { return new ConditionObject(); }
    }
    // 仅需要将操作代理到Sync上即可
    private final Sync sync = new Sync();
    public void lock() { sync.acquire(1); }
    public boolean tryLock() { return sync.tryAcquire(1); }
    public void unlock() { sync.release(1); }
    public Condition newCondition() { return sync.newCondition(); }
    public boolean isLocked() { return sync.isHeldExclusively(); }
    public boolean hasQueuedThreads() { return sync.hasQueuedThreads(); }
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireInterruptibly(1);
    }
    public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
        return sync.tryAcquireNanos(1, unit.toNanos(timeout));
    }
}
</code></pre>
<p>上述示例中，独占锁Mutex是一个自定义同步组件，它在同一时刻只允许一个线程占有锁。Mutex中定义了一个静态内部类，该内部类继承了同步器并实现了独占式获取和释放同步状态。</p>
<p>在tryAcquire(int acquires)方法中，如果经过CAS设置成功（同步状态设置为1），则代表获取了同步状态，而在tryRelease(int releases)方法中只是将同步状态重置为0。用户使用Mutex时并不会直接和内部同步器的实现打交道，而是调用Mutex提供的方法，在Mutex的实现中，以获取锁的lock()方法为例，只需要在方法实现中调用同步器的模板方法acquire(int args)即可，当前线程调用该方法获取同步状态失败后会被加入到同步队列中等待，这样就大大降低了实现一个可靠自定义同步组件的门槛。</p>
<h3 id="422-队列同步器的实现分析">4.2.2 队列同步器的实现分析</h3>
<p>同步器是如何完成线程同步的步骤主要包括：同步队列、独占式同步状态获取与释放、共享式同步状态获取与释放以及超时获取同步状态等同步器的核心数据结构与模板方法</p>
<h5 id="1同步队列">1.同步队列</h5>
<p>同步器依赖内部的同步队列（一个FIFO双向队列）来完成同步状态的管理，当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。</p>
<p>同步队列中的节点（Node）用来保存<strong>获取同步状态失败的线程引用</strong>、<strong>等待状态</strong>以及<strong>前驱</strong>和<br>
<strong>后继节点</strong>，节点的属性类型与名称以及描述如下：</p>
<pre><code class="language-java">static final class Node {
    static final int CANCELLED =  1;
    static final int SIGNAL =       -1;
    static final int CONDITION = -2;
    static final int PROPAGATE = -3;
    //等待状态，包含如下状态
    //CANCELLED,值为1,由于在同步队列中等待的线程等待超时或者被中断，需要从同步队列中取消等待，节点进入该状态将不会变化
    //SIGNAL,值为-1,后继节点的线程处于等待状态，而当前节点的线程如果释放了同步状态或者被取消，将会通知后继节点，使后继节点的线程得以运行
    //CONDITION,值为-2,节点在等待队列中，节点线程等待在Condition上，而当其他线程对Condition调用了 signal。方法后，该节点将会从等待队列中转移到同步队列中，加入到对同步状态的获取中
    //PROPAGATE,值为-3.表示下一次共享式同步状态获取将会无条件地被传播下去
    //INITIAL,值为0,初始状态
    volatile int waitStatus;

    //前驱结点，当前结点加入同步队列时被设置
    volatile Node prev;

    //后继结点
    volatile Node next;

    //等待队列中的后继结点，如果当前结点是共享的，那么这个字段将是一个SHARED常量，也就是说结点类型（独占和共享）和等待队列中的后继结点公用一个字段
    Node nextWaiter;

    //获取同步状态的线程
     volatile Thread thread;
}
</code></pre>
<p>节点是构成同步队列的基础，同步器拥有首节点（head）和尾节点（tail），没有成功获取同步状态的线程将会成为节点加入该队列的尾部，同步队列的基本结构如图下所示。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1660147528285.png" alt="同步队列的基本结构" loading="lazy"></figure>
<p>同步器包含了两个节点类型的引用，一个指向头节点，而另一个指向尾节点。试想一下，当一个线程成功地获取了同步状态（或者锁），其他线程将无法获取到同步状态，转而被构造成为节点并加入到同步队列中，而这个加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect,Nodeupdate)，，它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。</p>
<p>同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点。</p>
<p>设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证，它只需要将首节点设置成为原首节点的后继节点并断开原首节点的next引用即可。</p>
<h5 id="2独占式同步状态获取与释放">2.独占式同步状态获取与释放</h5>
<p>通过调用同步器的acquire(int arg)方法可以获取同步状态，该方法对中断不敏感，也就是由于线程获取同步状态失败后进入同步队列中，后续对线程进行中断操作时，线程不会从同步队列中移出。</p>
<blockquote>
<p>同步器的acquire方法</p>
</blockquote>
<pre><code class="language-java">public final void acquire(int arg) {
        if (!tryAcquire(arg) &amp;&amp;
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }
</code></pre>
<p>上述代码主要完成了同步状态获取、节点构造、加入同步队列以及在同步队列中自旋等待的相关工作，其主要逻辑是：首先调用自定义同步器实现的tryAcquire(int arg)方法，该方法保证线程安全的获取同步状态，如果同步状态获取失败，则构造同步节点（独占式Node.EXCLUSIVE，同一时刻只能有一个线程成功获取同步状态）并通过addWaiter(Node node)方法将该节点加入到同步队列的尾部，最后调用acquireQueued(Node node,int arg)方法，使得该节点以“死循环”的方式获取同步状态。如果获取不到则阻塞节点中的线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现。</p>
<p>下面分析一下相关工作。首先是节点的构造以及加入同步队列，如下：</p>
<blockquote>
<p>同步器的addWaiter和enq方法</p>
</blockquote>
<pre><code class="language-java">private Node addWaiter(Node mode) {
    Node node = new Node(Thread.currentThread(), mode);
    // Try the fast path of enq; backup to full enq on failure
    Node pred = tail;
    if (pred != null) {
        node.prev = pred;
        //通过使用compareAndSetTail(Node expect,Node update)方法来确保节点能够被线程安全添加
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    enq(node);
    return node;
}

    private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}
</code></pre>
<p>在enq(final Node node)方法中，同步器通过“死循环”来保证节点的正确添加，在“死循环”中只有通过CAS将节点设置成为尾节点之后，当前线程才能从该方法返回，否则，当前线程不断地尝试设置。可以看出，enq(final Node node)方法将并发添加节点的请求通过CAS变得“串行化”了。</p>
<blockquote>
<p>同步器的acquireQueued方法</p>
</blockquote>
<pre><code class="language-java">@ReservedStackAccess
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head &amp;&amp; tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
} 
</code></pre>
<p>在acquireQueued(final Node node,int arg)方法中，当前线程在“死循环”中尝试获取同步状态，而只有前驱节点是头节点才能够尝试获取同步状态，这是为什么？原因有两个，如下。</p>
<p>第一，头节点是成功获取到同步状态的节点，而头节点的线程释放了同步状态之后，将会<br>
唤醒其后继节点，后继节点的线程被唤醒后需要检查自己的前驱节点是否是头节点。</p>
<p>第二，维护同步队列的FIFO原则。该方法中，节点自旋获取同步状态的行为如下图所示。</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1660187742025.png" alt="节点自旋获取同步状态" loading="lazy"></figure>
<p>由于非首节点线程前驱节点出队或者被中断而从等待状态返回，随后检查自己的前驱是否是头节点，如果是则尝试获取同步状态。可以看到节点和节点之间在循环检查的过程中基本不相互通信，而是简单地判断自己的前驱是否为头节点，这样就使得节点的释放规则符合FIFO，并且也便于对过早通知的处理（过早通知是指前驱节点不是头节点的线程由于中断而被唤醒）。</p>
<p>独占式同步状态获取流程，也就是acquire(int arg)方法调用流程，如下所示。</p>
<figure data-type="image" tabindex="6"><img src="https://q456qq520.github.io/post-images/1660187831672.png" alt="独占式同步状态获取流程" loading="lazy"></figure>
<p>前驱节点为头节点且能够获取同步状态的判断条件和线程进入等待状态是获取同步状态的自旋过程。当同步状态获取成功之后，当前线程从acquire(int arg)方法返回，如果对于锁这种并发组件而言，代表着当前线程获取了锁。</p>
<p>当前线程获取同步状态并执行了相应逻辑之后，就需要释放同步状态，使得后续节点能够继续获取同步状态。通过调用同步器的**release(int arg)**方法可以释放同步状态，该方法在释放了同步状态之后，会唤醒其后继节点（进而使后继节点重新尝试获取同步状态）。该方法代码如下所示。</p>
<pre><code class="language-java">@ReservedStackAccess
public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;
        if (h != null &amp;&amp; h.waitStatus != 0)
            unparkSuccessor(h);
        return true;
    }
    return false;
}
</code></pre>
<p>该方法执行时，会唤醒头节点的后继节点线程，unparkSuccessor(Node node)方法使用LockSupport来唤醒处于等待状态的线程。</p>
<p>分析了独占式同步状态获取和释放过程后，适当做个总结：在获取同步状态时，同步器维护一个同步队列，获取状态失败的线程都会被加入到队列中并在队列中进行自旋；移出队列（或停止自旋）的条件是前驱节点为头节点且成功获取了同步状态。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态，然后唤醒头节点的后继节点。</p>
<h5 id="3共享式同步状态获取与释放">3.共享式同步状态获取与释放</h5>
<p>共享式获取与独占式获取最主要的区别在于<strong>同一时刻能否有多个线程同时获取到同步状态。</strong></p>
<p>以文件的读写为例，如果一个程序在对文件进行读操作，那么这一时刻对于该文件的写操作均被阻塞，而读操作能够同时进行。写操作要求对资源的独占式访问，而读操作可以是共享式访问，两种不同的访问模式在同一时刻对文件或资源的访问情况。</p>
<p>通过调用同步器的acquireShared(int arg)方法可以共享式地获取同步状态，该方法代码如下所示。</p>
<blockquote>
<p>同步器的acquireShared和doAcquireShared方法</p>
</blockquote>
<pre><code class="language-java">public final void acquireShared(int arg) {
    //返回值大于等于0时，表示能够获取到同步状态
    if (tryAcquireShared(arg) &lt; 0)
        doAcquireShared(arg);
}

private void doAcquireShared(int arg) {
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head) {
                int r = tryAcquireShared(arg);
                //如果返回值大于等于0，表示该次获取同步状态成功并从自旋过程中退出
                if (r &gt;= 0) {
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    if (interrupted)
                        selfInterrupt();
                    failed = false;
                    return;
                }
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
</code></pre>
<p>在acquireShared(int arg)方法中，同步器调用tryAcquireShared(int arg)方法尝试获取同步状态，tryAcquireShared(int arg)方法返回值为int类型，当返回值大于等于0时，表示能够获取到同步状态。因此，在共享式获取的自旋过程中，成功获取到同步状态并退出自旋的条件就是tryAcquireShared(int arg)方法返回值大于等于0。可以看到，在doAcquireShared(int arg)方法的自旋过程中，如果当前节的前驱为头节点时，尝试获取同步状态，如果返回值大于等于0，表示该次获取同步状态成功并从自旋过程中退出。</p>
<p>与独占式一样，共享式获取也需要释放同步状态，通过调用releaseShared(int arg)方法可以释放同步状态，该方法代码如下所示。</p>
<blockquote>
<p>同步器的releaseShared方法</p>
</blockquote>
<pre><code class="language-java">@ReservedStackAccess
public final boolean releaseShared(int arg) {
    if (tryReleaseShared(arg)) {
        doReleaseShared();
        return true;
    }
    return false;
}
</code></pre>
<p>该方法在释放同步状态之后，将会唤醒后续处于等待状态的节点。对于能够支持多个线程同时访问的并发组件（比如Semaphore），它和独占式主要区别在于tryReleaseShared(int arg)方法必须确保同步状态（或者资源数）线程安全释放，一般是通过循环和CAS来保证的，因为释放同步状态的操作会同时来自多个线程。</p>
<blockquote>
<p>同步器的tryReleaseShared方法</p>
</blockquote>
<pre><code class="language-java">protected boolean tryReleaseShared(int releases) {
    // Decrement count; signal when transition to zero
    for (;;) {
        int c = getState();
        if (c == 0)
            return false;
        int nextc = c-1;
        if (compareAndSetState(c, nextc))
            return nextc == 0;
    }
}
</code></pre>
<h5 id="4独占式超时获取同步状态">4.独占式超时获取同步状态</h5>
<p>通过调用同步器的doAcquireNanos(int arg,long nanosTimeout)方法可以超时获取同步状态，**即在指定的时间段内获取同步状态，如果获取到同步状态则返回true，否则，返回false。**该方法提供了传统Java同步操作（比如synchronized关键字）所不具备的特性。</p>
<p>doAcquireNanos(int arg,long nanosTimeout)方法在支持响应中断的基础上，增加了超时获取的特性。针对超时获取，主要需要计算出需要睡眠的时间间隔nanosTimeout，如果nanosTimeout大于0则表示超时时间未到，需要继续睡眠nanosTimeout纳秒，反之，表示已经超时，</p>
<blockquote>
<p>同步器的doAcquireNanos方法</p>
</blockquote>
<pre><code class="language-java">private boolean doAcquireNanos(int arg, long nanosTimeout)
    throws InterruptedException {
if (nanosTimeout &lt;= 0L)
    return false;
final long deadline = System.nanoTime() + nanosTimeout;
final Node node = addWaiter(Node.EXCLUSIVE);
boolean failed = true;
try {
    for (;;) {
        final Node p = node.predecessor();
        if (p == head &amp;&amp; tryAcquire(arg)) {
            setHead(node);
            p.next = null; // help GC
            failed = false;
            return true;
        }
        nanosTimeout = deadline - System.nanoTime();
        if (nanosTimeout &lt;= 0L)
            return false;
        if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
            nanosTimeout &gt; spinForTimeoutThreshold)
            LockSupport.parkNanos(this, nanosTimeout);
        if (Thread.interrupted())
            throw new InterruptedException();
    }
} finally {
    if (failed)
        cancelAcquire(node);
}
}
</code></pre>
<p>该方法在自旋过程中，当节点的前驱节点为头节点时尝试获取同步状态，如果获取成功则从该方法返回，这个过程和独占式同步获取的过程类似，但是在同步状态获取失败的处理上有所不同。如果当前线程获取同步状态失败，则判断是否超时（nanosTimeout小于等于0表示已经超时），如果没有超时，重新计算超时间隔nanosTimeout，然后使当前线程等待nanosTimeout纳秒（当已到设置的超时时间，该线程会从LockSupport.parkNanos(Objectblocker,long nanos)方法返回）。</p>
<p>如果nanosTimeout小于等于spinForTimeoutThreshold（1000纳秒）时，将不会使该线程进行超时等待，而是进入快速的自旋过程。原因在于，非常短的超时等待无法做到十分精确，如果这时再进行超时等待，相反会让nanosTimeout的超时从整体上表现得反而不精确。因此，在超时非常短的场景下，同步器会进入无条件的快速自旋。</p>
<p>独占式超时获取同步状态doAcquireNanos(int arg,long nanosTimeout)和独占式获取同步状态acquire(int args)在流程上非常相似，其主要区别在于未获取到同步状态时的处理逻辑。acquire(int args)在未获取到同步状态时，将会使当前线程一直处于等待状态，而doAcquireNanos(int arg,long nanosTimeout)会使当前线程等待nanosTimeout纳秒，如果当前线程在nanosTimeout纳秒内没有获取到同步状态，将会从等待逻辑中自动返回。</p>
<figure data-type="image" tabindex="7"><img src="https://q456qq520.github.io/post-images/1660200122402.png" alt="独占式超时获取同步状态的流程" loading="lazy"></figure>
<h5 id="5自定义同步组件twinslock">5.自定义同步组件——TwinsLock</h5>
<p>设计一个同步工具：该工具在同一时刻，只允许至多两个线程同时访问，超过两个线程的访问将被阻塞，我们将这个同步工具命名为TwinsLock。</p>
<p>首先，确定访问模式。TwinsLock能够在同一时刻支持多个线程的访问，这显然是共享式访问，因此，需要使用同步器提供的acquireShared(int args)方法等和Shared相关的方法，这就要求TwinsLock必须重写tryAcquireShared(int args)方法和tryReleaseShared(int args)方法，这样才能保证同步器的共享式同步状态的获取与释放方法得以执行。</p>
<p>其次，定义资源数。TwinsLock在同一时刻允许至多两个线程的同时访问，表明同步资源数为2，这样可以设置初始状态status为2，当一个线程进行获取，status减1，该线程释放，则status加1，状态的合法范围为0、1和2，其中0表示当前已经有两个线程获取了同步资源，此时再有其他线程对同步状态进行获取，该线程只能被阻塞。在同步状态变更时，需要使用compareAndSet(int expect,int update)方法做原子性保障。</p>
<p>最后，组合自定义同步器。前面的章节提到，自定义同步组件通过组合自定义同步器来完成同步功能，一般情况下自定义同步器会被定义为自定义同步组件的内部类。</p>
<pre><code class="language-java">package cm.lock;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.AbstractQueuedSynchronizer;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;

/**
 * 自定义同步组件——TwinsLock
 * @author likecat
 * @version 1.0
 * @date 2022/8/11 15:00
 */
public class TwinsLock implements Lock {
    private final Sync sync = new Sync(2);
    private static final class Sync extends AbstractQueuedSynchronizer {
        Sync(int count) {
            if (count &lt;= 0) {
                throw new IllegalArgumentException(&quot;count must large than zero.&quot;);
            }
            setState(count);
        }
        public int tryAcquireShared(int reduceCount) {
            for (;;) {
                int current = getState();
                int newCount = current - reduceCount;
                if (newCount &gt;= 0 || compareAndSetState(current,
                        newCount)) {
                    return newCount;
                }
            }
        }
        public boolean tryReleaseShared(int returnCount) {
            for (;;) {
                int current = getState();
                int newCount = current + returnCount;
                if (compareAndSetState(current, newCount)) {
                    return true;
                }
            }
        }
    }
    public void lock() {
        sync.acquireShared(1);
    }

    @Override
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireInterruptibly(1);
    }

    @Override
    public boolean tryLock() {
        return sync.tryAcquireShared(1) &gt;= 0;
    }

    @Override
    public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {
        return sync.tryAcquireSharedNanos(1,time);
    }

    public void unlock() {
        sync.releaseShared(1);
    }

    @Override
    public Condition newCondition() {
        return null;
    }
}
</code></pre>
<p>TwinsLock实现了Lock接口，提供了面向使用者的接口，使用者调用lock()方法获取锁，随后调用unlock()方法释放锁，而同一时刻只能有两个线程同时获取到锁。TwinsLock同时包含了一个自定义同步器Sync，而该同步器面向线程访问和同步状态控制。以共享式获取同步状态为例：同步器会先计算出获取后的同步状态，然后通过CAS确保状态的正确设置，当tryAcquireShared(int reduceCount)方法返回值大于等于0时，当前线程才获取同步状态，对于上层的TwinsLock而言，则表示当前线程获得了锁。</p>
<p>同步器作为一个桥梁，连接线程访问以及同步状态控制等底层技术与不同并发组件（比如Lock、CountDownLatch等）的接口语义。</p>
<p>下面编写一个测试来验证TwinsLock是否能按照预期工作。在测试用例中，定义了工作者线程Worker，该线程在执行过程中获取锁，当获取锁之后使当前线程睡眠1秒（并不释放锁），随后打印当前线程名称，最后再次睡眠1秒并释放锁，测试用例如下所示。</p>
<pre><code class="language-java">package cm.lock;

import cm.SleepUtils;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/11 15:11
 */
public class TwinsLockTest {

    public static void main(String[] args) throws InterruptedException {
        TwinsLock lock = new TwinsLock();
         class Worker extends Thread {
            public void run() {
                while (true) {
                    lock.lock();
                    try {
                        SleepUtils.second(1);
                        System.out.println(Thread.currentThread().getName());
                        SleepUtils.second(1);
                    } finally {
                        lock.unlock();
                    }
                }
            }
        }
        // 启动10个线程
        for (int i = 0; i &lt; 10; i++) {
            Worker w = new Worker();
            w.setDaemon(true);
            w.start();
        }
//         每隔1秒换行
        for (int i = 0; i &lt; 10; i++) {
            SleepUtils.second(1);
            System.out.println();
        }
    }

}
</code></pre>
<p>运行该测试用例，可以看到线程名称成对输出，也就是在同一时刻只有两个线程能够获取到锁，这表明TwinsLock可以按照预期正确工作。</p>
<h2 id="43-重入锁">4.3 重入锁</h2>
<p>重入锁ReentrantLock，顾名思义，就是支持重进入的锁，<strong>它表示该锁能够支持一个线程对资源的重复加锁。除此之外，该锁的还支持获取锁时的公平和非公平性选择</strong>。</p>
<p>synchronized关键字隐式的支持重进入，比如一个synchronized修饰的递归方法，在方法执行时，执行线程在获取了锁之后仍能连续多次地获得该锁。</p>
<p>ReentrantLock虽然没能像synchronized关键字一样支持隐式的重进入，但是在调用lock()方法时，已经获取到锁的线程，能够再次调用lock()方法获取锁而不被阻塞。</p>
<p>这里提到一个锁获取的公平性问题，<strong>如果在绝对时间上，先对锁进行获取的请求一定先被满足，那么这个锁是公平的，反之，是不公平的</strong>。公平的获取锁，也就是等待时间最长的线程最优先获取锁，也可以说锁获取是顺序的。ReentrantLock提供了一个构造函数，能够控制锁是否是公平的。</p>
<p>事实上，公平的锁机制往往没有非公平的效率高，但是，并不是任何场景都是以TPS作为唯一的指标，公平锁能够减少“饥饿”发生的概率，等待越久的请求越是能够得到优先满足。</p>
<h5 id="1实现重进入">1.实现重进入</h5>
<p>重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞，该特性的实现需要解决以下两个问题。</p>
<blockquote>
<p>1）线程再次获取锁。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。</p>
</blockquote>
<blockquote>
<p>2）锁的最终释放。线程重复n次获取了锁，随后在第n次释放该锁后，其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于0时表示锁已经成功释放。</p>
</blockquote>
<p>ReentrantLock是通过组合自定义同步器来实现锁的获取与释放，以非公平性（默认的）实现为例，获取同步状态的代码如下所示。</p>
<blockquote>
<p>ReentrantLock的nonfairTryAcquire方法</p>
</blockquote>
<pre><code class="language-java">final boolean nonfairTryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            if (compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc &lt; 0) // overflow
                throw new Error(&quot;Maximum lock count exceeded&quot;);
            setState(nextc);
            return true;
        }
        return false;
    }
</code></pre>
<p>该方法增加了再次获取同步状态的处理逻辑：通过判断当前线程是否为获取锁的线程来决定获取操作是否成功，如果是获取锁的线程再次请求，则将同步状态值进行增加并返回true，表示获取同步状态成功。</p>
<p>成功获取锁的线程再次获取锁，只是增加了同步状态值，这也就要求ReentrantLock在释放同步状态时减少同步状态值，该方法的代码如下所示。</p>
<blockquote>
<p>ReentrantLock的tryRelease方法</p>
</blockquote>
<pre><code class="language-java">protected final boolean tryRelease(int releases) {
        int c = getState() - releases;
        if (Thread.currentThread() != getExclusiveOwnerThread())
            throw new IllegalMonitorStateException();
        boolean free = false;
        if (c == 0) {
            free = true;
            setExclusiveOwnerThread(null);
        }
        setState(c);
        return free;
    }
</code></pre>
<p>如果该锁被获取了n次，那么前(n-1)次tryRelease(int releases)方法必须返回false，而只有同步状态完全释放了，才能返回true。可以看到，该方法将同步状态是否为0作为最终释放的条件，当同步状态为0时，将占有线程设置为null，并返回true，表示释放成功。</p>
<h5 id="2公平与非公平获取锁的区别">2.公平与非公平获取锁的区别</h5>
<p>公平性与否是针对获取锁而言的，如果一个锁是公平的，那么锁的获取顺序就应该符合请求的绝对时间顺序，也就是FIFO。</p>
<p>对于非公平锁，只要CAS设置同步状态成功，则表示当前线程获取了锁，而公平锁则不同，代码如下所示。</p>
<blockquote>
<p>ReentrantLock的tryAcquire方法</p>
</blockquote>
<pre><code class="language-java">protected final boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            if (!hasQueuedPredecessors() &amp;&amp;
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc &lt; 0)
                throw new Error(&quot;Maximum lock count exceeded&quot;);
            setState(nextc);
            return true;
        }
        return false;
    }
    ```

该方法与nonfairTryAcquire(int acquires)比较，唯一不同的位置为判断条件多了hasQueuedPredecessors()方法，即加入了同步队列中当前节点是否有前驱节点的判断，如果该方法返回true，则表示有线程比当前线程更早地请求获取锁，因此需要等待前驱线程获取并释放锁之后才能继续获取锁。

下面编写一个测试来观察公平和非公平锁在获取锁时的区别，在测试用例中定义了内部类ReentrantLock2，该类主要公开了getQueuedThreads()方法，该方法返回正在等待获取锁的线程列表，由于列表是逆序输出，为了方便观察结果，将其进行反转，测试用例（部分）如下所示。

```java
package cm.lock;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/11 17:19
 */
public class FairAndUnfairTest {
    private static Lock fairLock = new ReentrantLock2(true);
    private static Lock unfairLock = new ReentrantLock2(false);

public static void main(String[] args) {
    testLock(unfairLock);
    System.out.println(&quot;--------&quot;);
    testLock(fairLock);
}

    private static void testLock(Lock lock) {
        // 启动5个Job
        for (int i = 0; i &lt; 5; i++) {
            Job job = new Job(lock);
            job.start();
        }
    }
    private static class Job extends Thread {
        private Lock lock;
        public Job(Lock lock) {
            this.lock = lock;
        }
        public void run() {
            // 连续2次打印当前的Thread和等待队列中的Thread
            for (int i = 0; i &lt; 2; i++) {
                lock.lock();
                try {
                        Thread.sleep(1000);
                        System.out.println(&quot;获取锁的当前线程[&quot; + Thread.currentThread().getName() + &quot;], 同步队列中的线程&quot; + ((ReentrantLock2)lock).getQueuedThreads() + &quot;&quot;);
                } catch (InterruptedException e) {
                     e.printStackTrace();
                } finally {
                 lock.unlock();
                }
            }
        }
    }
    private static class ReentrantLock2 extends ReentrantLock {
        public ReentrantLock2(boolean fair) {
            super(fair);
        }

        public Collection&lt;Thread&gt; getQueuedThreads() {
            List&lt;Thread&gt; arrayList = new ArrayList&lt;Thread&gt;(super.
                    getQueuedThreads());
            Collections.reverse(arrayList);
            return arrayList;
        }
    }
}
</code></pre>
<p>公平性锁每次都是从同步队列中的第一个节点获取到锁，而非公平性锁出现了一个线程连续获取锁的情况。</p>
<p>为什么会出现线程连续获取锁的情况呢？回顾nonfairTryAcquire(int acquires)方法，当一个线程请求锁时，只要获取了同步状态即成功获取锁。在这个前提下，刚释放锁的线程再次获取同步状态的几率会非常大，使得其他线程只能在同步队列中等待。<strong>非公平性锁可能使线程“饥饿”。</strong></p>
<p><em><strong>公平性锁保证了锁的获取按照FIFO原则，而代价是进行大量的线程切换。非公平性锁虽然可能造成线程“饥饿”，但极少的线程切换，保证了其更大的吞吐量。</strong></em></p>
<h2 id="54-读写锁">5.4 读写锁</h2>
<p>之前提到锁（如Mutex和ReentrantLock）基本都是排他锁，这些锁在同一时刻只允许一个线程进行访问，而读写锁在同一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程和其他写线程均被阻塞。<strong>读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大提升。</strong></p>
<p>一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的。在读多于写的情况下，读写锁能够提供比排它锁更好的并发性和吞吐量。Java并发包提供读写锁的实现是ReentrantReadWriteLock，它提供的特性如下所示。</p>
<figure data-type="image" tabindex="8"><img src="https://q456qq520.github.io/post-images/1660287490202.png" alt="ReentrantReadWriteLock的特性" loading="lazy"></figure>
<h3 id="441-读写锁的接口与示例">4.4.1 读写锁的接口与示例</h3>
<p>ReadWriteLock仅定义了获取读锁和写锁的两个方法，即readLock()方法和writeLock()方法，而其实现——ReentrantReadWriteLock，除了接口方法之外，还提供了一些便于外界监控其内部工作状态的方法，这些方法以及描述如下所示。</p>
<blockquote>
<p>ReentrantReadWriteLock展示内部工作状态的方法</p>
</blockquote>
<pre><code class="language-java">//返回当前度锁被获取的次数，该次数不能与获取读锁的线程数
int getReadLockCount() 

//返回当前线程获取读锁的次数
int getReadHoldCount()

//判断写锁是否被获取
boolean isWriteLocked()

//返回当前写锁被获取的次数
int getWriteHoldCount()
</code></pre>
<p>接下来，通过一个缓存示例说明读写锁的使用方式，示例代码如下所示：</p>
<pre><code class="language-java">package cm.lock;

import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

/**
 * 读写锁缓存示例
 * @author likecat
 * @version 1.0
 * @date 2022/8/12 15:06
 */
public class Cache {
    static Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();
    static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
    static Lock r = rwl.readLock();
    static Lock w = rwl.writeLock();
    // 获取一个key对应的value
    public static final Object get(String key) {
        r.lock();
        try {
            return map.get(key);
        } finally {
            r.unlock();
        }
    }
    // 设置key对应的value，并返回旧的value
    public static final Object put(String key, Object value) {
        w.lock();
        try {
            return map.put(key, value);
        } finally {
            w.unlock();
        }
    }
    
    // 清空所有的内容
    public static final void clear() {
        w.lock();
        try {
            map.clear();
        } finally {
            w.unlock();
        }
    }
}
</code></pre>
<p>上述示例中，Cache组合一个非线程安全的HashMap作为缓存的实现，同时使用读写锁的读锁和写锁来保证Cache是线程安全的。在读操作get(String key)方法中，需要获取读锁，这使得并发访问该方法时不会被阻塞。写操作put(String key,Object value)方法和clear()方法，在更新HashMap时必须提前获取写锁，当获取写锁后，其他线程对于读锁和写锁的获取均被阻塞，而只有写锁被释放之后，其他读写操作才能继续。Cache使用读写锁提升读操作的并发性，也保证每次写操作对所有的读写操作的可见性。</p>
<h3 id="442-读写锁的实现分析">4.4.2 读写锁的实现分析</h3>
<h5 id="1读写状态的设计">1.读写状态的设计</h5>
<p><em>读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。</em></p>
<p>回想ReentrantLock中自定义同步器的实现，同步状态表示锁被一个线程重复获取的次数，而读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状态。</p>
<p>如果在一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量，读写锁将变量切分成了两个部分，<strong>高16位表示读，低16位表示写</strong>，划分方式如下所示。</p>
<figure data-type="image" tabindex="9"><img src="https://q456qq520.github.io/post-images/1660288434069.png" alt="读写锁状态的划分方式" loading="lazy"></figure>
<p>当前同步状态表示一个线程已经获取了写锁，且重进入了两次，同时也连续获取了两次读锁。读写锁是如何迅速确定读和写各自的状态呢？答案是通过位运算。假设当前同步状态值为S，写状态等于S&amp;0x0000FFFF（将高16位全部抹去），读状态等于S&gt;&gt;&gt;16（无符号补0右移16位）。当写状态增加1时，等于S+1，当读状态增加1时，等于S+(1&lt;&lt;16)，也就是S+0x00010000。</p>
<p>根据状态的划分能得出一个推论：<em><strong>S不等于0时，当写状态（S&amp;0x0000FFFF）等于0时，则读状态（S&gt;&gt;&gt;16）大于0，即读锁已被获取。</strong></em></p>
<h5 id="2写锁的获取与释放">2.写锁的获取与释放</h5>
<p>写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态，获取写锁的代码如下所示。</p>
<blockquote>
<p>ReentrantReadWriteLock的tryAcquire方法</p>
</blockquote>
<pre><code class="language-java">protected final boolean tryAcquire(int acquires) {
    Thread current = Thread.currentThread();
    int c = getState();
    int w = exclusiveCount(c);
    if (c != 0) {
        // (Note: if c != 0 and w == 0 then shared count != 0)
        //// 存在读锁或者当前获取线程不是已经获取写锁的线程
        if (w == 0 || current != getExclusiveOwnerThread())
            return false;
        if (w + exclusiveCount(acquires) &gt; MAX_COUNT)
            throw new Error(&quot;Maximum lock count exceeded&quot;);
        // Reentrant acquire
        setState(c + acquires);
        return true;
    }
    if (writerShouldBlock() ||
        !compareAndSetState(c, c + acquires))
        return false;
    setExclusiveOwnerThread(current);
    return true;
}
</code></pre>
<p>该方法除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。</p>
<p>写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，从而等待的读写线程能够继续访问读写锁，同时前次写线程的修改对后续读写线程可见。</p>
<h5 id="3读锁的获取与释放">3.读锁的获取与释放</h5>
<p>读锁是一个支持重进入的共享锁，它能够被多个线程同时获取，在没有其他写线程访问（或者写状态为0）时，读锁总会被成功地获取，而所做的也只是（线程安全的）增加读状态。如果当前线程已经获取了读锁，则增加读状态。如果当前线程在获取读锁时，写锁已被其他线程获取，则进入等待状态。</p>
<blockquote>
<p>ReentrantReadWriteLock的tryAcquireShared方法</p>
</blockquote>
<pre><code class="language-java"> protected final int tryAcquireShared(int unused) {
    Thread current = Thread.currentThread();
    int c = getState();
    if (exclusiveCount(c) != 0 &amp;&amp;
        getExclusiveOwnerThread() != current)
        return -1;
    int r = sharedCount(c);
    if (!readerShouldBlock() &amp;&amp;
        r &lt; MAX_COUNT &amp;&amp;
        compareAndSetState(c, c + SHARED_UNIT)) {
        if (r == 0) {
            firstReader = current;
            firstReaderHoldCount = 1;
        } else if (firstReader == current) {
            firstReaderHoldCount++;
        } else {
            HoldCounter rh = cachedHoldCounter;
            if (rh == null || rh.tid != getThreadId(current))
                cachedHoldCounter = rh = readHolds.get();
            else if (rh.count == 0)
                readHolds.set(rh);
            rh.count++;
        }
        return 1;
    }
    return fullTryAcquireShared(current);
}
</code></pre>
<p>在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。</p>
<p>读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是（1 &lt;&lt; 16）。</p>
<h5 id="4锁降级">4.锁降级</h5>
<p>锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。<strong>锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。</strong></p>
<p>接下来看一个锁降级的示例。因为数据不常变化，所以多个线程可以并发地进行数据处理，当数据变更后，如果当前线程感知到数据变化，则进行数据的准备工作，同时其他处理线程被阻塞，直到当前线程完成数据的准备工作。</p>
<pre><code class="language-java"> public void processData() {
        readLock.lock();
        if (!update) {
            // 必须先释放读锁
            readLock.unlock();
            // 锁降级从写锁获取到开始
            writeLock.lock();
            try {
                if (!update) {
                    // 准备数据的流程（略）
                    update = true;
                }
                readLock.lock();
            } finally {
                writeLock.unlock();
            }
            // 锁降级完成，写锁降级为读锁
        }
        try {
            // 使用数据的流程（略）
        } finally {
            readLock.unlock();
        }
    }
</code></pre>
<p>上述示例中，当数据发生变更后，update变量（布尔类型且volatile修饰）被设置为false，此时所有访问processData()方法的线程都能够感知到变化，但只有一个线程能够获取到写锁，其他线程会被阻塞在读锁和写锁的lock()方法上。当前线程获取写锁完成数据准备之后，再获取读锁，随后释放写锁，完成锁降级。</p>
<p>RentrantReadWriteLock不支持锁升级（把持读锁、获取写锁，最后释放读锁的过程）。目的也是保证数据可见性，如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的。</p>
<h2 id="45-locksupport工具">4.5 LockSupport工具</h2>
<p>当需要阻塞或唤醒一个线程的时候，都会使用LockSupport工具类来完成相应工作。LockSupport定义了一组的公共静态方法，这些方法提供了最基本的线程阻塞和唤醒功能，而LockSupport也成为构建同步组件的基础工具。</p>
<p>LockSupport定义了一组以park开头的方法用来阻塞当前线程，以及unpark(Thread thread)方法来唤醒一个被阻塞的线程。</p>
<figure data-type="image" tabindex="10"><img src="https://q456qq520.github.io/post-images/1660616478713.png" alt="LockSupport提供的阻塞和唤醒方法" loading="lazy"></figure>
<h2 id="46-condition接口">4.6 Condition接口</h2>
<p>任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式。Condition接口也提供了类似Object的监视器方法，与Lock配合可以实现等待/通知模式，但是这两者在使用方式以及功能特性上还是有差别的。</p>
<figure data-type="image" tabindex="11"><img src="https://q456qq520.github.io/post-images/1660616790444.png" alt="Object的监视器方法与Condition接口的对比" loading="lazy"></figure>
<h3 id="461-condition接口与示例">4.6.1 Condition接口与示例</h3>
<p>Condition定义了等待/通知两种类型的方法，当前线程调用这些方法时，需要提前获取到Condition对象关联的锁。Condition对象是由Lock对象（调用Lock对象的newCondition()方法）创建出来的，换句话说，Condition是依赖Lock对象的。</p>
<p>Condition的使用方式比较简单，需要注意在调用方法前获取锁。</p>
<blockquote>
<p>ConditionUseCase</p>
</blockquote>
<pre><code class="language-java">Lock lock = new ReentrantLock();
    Condition condition = lock.newCondition();
    public void conditionWait() throws InterruptedException {
        lock.lock();
        try {
            condition.await();
        } finally {
            lock.unlock();
        }
    }
    public void conditionSignal() throws InterruptedException {
        lock.lock();
        try {
            condition.signal();
        } finally {
            lock.unlock();
        }
    }
</code></pre>
<p>一般都会将Condition对象作为成员变量。当调用await()方法后，当前线程会释放锁并在此等待，而其他线程调用Condition对象的signal()方法，通知当前线程后，当前线程才从await()方法返回，并且在返回前已经获取了锁。</p>
<h3 id="462-condition的实现分析">4.6.2 Condition的实现分析</h3>
<p>ConditionObject是同步器AbstractQueuedSynchronizer的内部类，因为Condition的操作需要获取相关联的锁，所以作为同步器的内部类也较为合理。每个Condition对象都包含着一个队列（以下称为等待队列），该队列是Condition对象实现等待/通知功能的关键。</p>
<h5 id="1等待队列">1.等待队列</h5>
<p>等待队列是一个FIFO的队列，在队列中的每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程，如果一个线程调用了Condition.await()方法，那么该线程将会释放锁、构造成节点加入等待队列并进入等待状态。</p>
<p>一个Condition包含一个等待队列，Condition拥有首节点（firstWaiter）和尾节点（lastWaiter）。当前线程调用Condition.await()方法，将会以当前线程构造节点，并将节点从尾部加入等待队列。</p>
<figure data-type="image" tabindex="12"><img src="https://q456qq520.github.io/post-images/1660617414829.png" alt="等待队列的基本结构" loading="lazy"></figure>
<p>如图所示，Condition拥有首尾节点的引用，而新增节点只需要将原有的尾节点nextWaiter指向它，并且更新尾节点即可。上述节点引用更新的过程并没有使用CAS保证，原因在于调用await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的。</p>
<p>在Object的监视器模型上，一个对象拥有一个同步队列和等待队列，而并发包中的Lock（更确切地说是同步器）拥有一个同步队列和多个等待队列。</p>
<figure data-type="image" tabindex="13"><img src="https://q456qq520.github.io/post-images/1660618808661.png" alt="同步队列与等待队列" loading="lazy"></figure>
<p>Condition的实现是同步器的内部类，因此每个Condition实例都能够访问同步器提供的方法，相当于每个Condition都拥有所属同步器的引用。</p>
<h5 id="2等待">2.等待</h5>
<p>调用Condition的await()方法（或者以await开头的方法），会使当前线程进入等待队列并释放锁，同时线程状态变为等待状态。当从await()方法返回时，当前线程一定获取了Condition相关联的锁。</p>
<p>如果从队列（同步队列和等待队列）的角度看await()方法，当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。</p>
<blockquote>
<p>ConditionObject的await方法</p>
</blockquote>
<pre><code class="language-java">public final void await() throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    // 当前线程加入等待队列
    Node node = addConditionWaiter();
    // 释放同步状态，也就是释放锁
    long savedState = fullyRelease(node);
    int interruptMode = 0;
    while (!isOnSyncQueue(node)) {
        LockSupport.park(this);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null) // clean up if cancelled
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
}
</code></pre>
<p>调用该方法的线程成功获取了锁的线程，也就是同步队列中的首节点，该方法会将当前线程构造成节点并加入等待队列中，然后释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态。</p>
<p>当等待队列中的节点被唤醒，则唤醒节点的线程开始尝试获取同步状态。如果不是通过其他线程调用Condition.signal()方法唤醒，而是对等待线程进行中断，则会抛出InterruptedException。</p>
<p>如果从队列的角度去看，当前线程加入Condition的等待队列，该过程如下图所示。</p>
<figure data-type="image" tabindex="14"><img src="https://q456qq520.github.io/post-images/1660619123259.png" alt="当前线程加入等待队列" loading="lazy"></figure>
<p>同步队列的首节点并不会直接加入等待队列，而是通过addConditionWaiter()方法把当前线程构造成一个新的节点并将其加入等待队列中。</p>
<h5 id="3通知">3.通知</h5>
<p>调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移到同步队列中。</p>
<blockquote>
<p>ConditionObject的signal方法</p>
</blockquote>
<pre><code class="language-java">public final void signal() {
    if (!isHeldExclusively())
        throw new IllegalMonitorStateException();
    Node first = firstWaiter;
    if (first != null)
        doSignal(first);
}
</code></pre>
<p>调用该方法的前置条件是当前线程必须获取了锁，可以看到signal()方法进行了isHeldExclusively()检查，也就是当前线程必须是获取了锁的线程。接着获取等待队列的首节点，将其移动到同步队列并使用LockSupport唤醒节点中的线程。</p>
<p>通过调用同步器的enq(Node node)方法，等待队列中的头节点线程安全地移动到同步队列。当节点移动到同步队列后，当前线程再使用LockSupport唤醒该节点的线程。</p>
<p>被唤醒后的线程，将从await()方法中的while循环中退出（isOnSyncQueue(Node node)方法返回true，节点已经在同步队列中），进而调用同步器的acquireQueued()方法加入到获取同步状态的竞争中。</p>
<p>成功获取同步状态（或者说锁）之后，被唤醒的线程将从先前调用的await()方法返回，此时该线程已经成功地获取了锁。</p>
<p>Condition的signalAll()方法，相当于对等待队列中的每个节点均执行一次signal()方法，效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[数据库连接池示例]]></title>
        <id>https://q456qq520.github.io/post/shu-ju-ku-lian-jie-chi-shi-li/</id>
        <link href="https://q456qq520.github.io/post/shu-ju-ku-lian-jie-chi-shi-li/">
        </link>
        <updated>2022-08-09T10:16:08.000Z</updated>
        <content type="html"><![CDATA[<p>我们使用等待超时模式来构造一个简单的数据库连接池，在示例中模拟从连接池中获取、使用和释放连接的过程，而客户端获取连接的过程被设定为等待超时的模式，也就是在1000毫秒内如果无法获取到可用连接，将会返回给客户端一个null。设定连接池的大小为10个，然后通过调节客户端的线程数来模拟无法获取连接的场景。</p>
<p>首先看一下连接池的定义。它通过构造函数初始化连接的最大上限，通过一个双向队列来维护连接，调用方需要先调用fetchConnection(long)方法来指定在多少毫秒内超时获取连接，当连接使用完成后，需要调用releaseConnection(Connection)方法将连接放回线程池，示例如下所示。</p>
<pre><code class="language-java">package cm.connectpool;

import java.sql.Connection;
import java.util.LinkedList;

/**
 * 连接池
 * @author likecat
 * @version 1.0
 * @date 2022/8/9 18:23
 */
public class ConnectionPool {
    private LinkedList&lt;Connection&gt; pool = new LinkedList&lt;Connection&gt;();
    public ConnectionPool(int initialSize) {
        if (initialSize &gt; 0) {
            for (int i = 0; i &lt; initialSize; i++) {
                pool.addLast(ConnectionDriver.createConnection());
            }
        }
    }
    public void releaseConnection(Connection connection) {
        if (connection != null) {
            synchronized (pool){
            // 连接释放后需要进行通知，这样其他消费者能够感知到连接池中已经归还了一个连接
                pool.addLast(connection);
                pool.notifyAll();
            }
        }
    }
    // 在mills内无法获取到连接，将会返回null
    public Connection fetchConnection(long mills) throws InterruptedException {
        synchronized (pool) {
        // 完全超时
            if (mills &lt;= 0) {
                while (pool.isEmpty()) {
                    pool.wait();
                }
                return pool.removeFirst();
            } else{
                long future = System.currentTimeMillis() + mills;
                long remaining = mills;
                while (pool.isEmpty() &amp;&amp; remaining &gt; 0) {
                    pool.wait(remaining);
                    remaining = future - System.currentTimeMillis();
                }
                Connection result = null;
                if (!pool.isEmpty()) {
                    result = pool.removeFirst();
                }
                return result;
            }
        }
    }
}

</code></pre>
<p>由于java.sql.Connection是一个接口，最终的实现是由数据库驱动提供方来实现的，考虑到只是个示例我们通过动态代理构造了一个Connection，该Connection的代理实现仅仅是在commit()方法调用时休眠100毫秒。</p>
<pre><code class="language-java">package cm.connectpool;

import java.lang.reflect.InvocationHandler;
import java.lang.reflect.Method;
import java.lang.reflect.Proxy;
import java.sql.Connection;
import java.util.concurrent.TimeUnit;

/**
 * 驱动
 * @author likecat
 * @version 1.0
 * @date 2022/8/9 18:24
 */
public class ConnectionDriver {
    static class ConnectionHandler implements InvocationHandler {

        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable{
            if (method.getName().equals(&quot;commit&quot;)) {
                TimeUnit.MILLISECONDS.sleep(100);
            }
            return null;
         }
    }
    // 创建一个Connection的代理，在commit时休眠100毫秒
    public static final Connection createConnection() {
        return (Connection) Proxy.newProxyInstance(ConnectionDriver.class.getClassLoader(), new Class&lt;?&gt;[] { Connection.class }, new ConnectionHandler());
    }
}
</code></pre>
<p>模拟客户端ConnectionRunner获取、使用、最后释放连接的过程，当它使用时连接将会增加获取到连接的数量，反之，将会增加未获取到连接的数量。</p>
<pre><code class="language-java">package cm.connectpool;

import java.sql.Connection;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/9 18:40
 */
public class ConnectionPoolTest {
    static ConnectionPool pool = new ConnectionPool(10);
    // 保证所有ConnectionRunner能够同时开始
    static CountDownLatch start = new CountDownLatch(1);
    // main线程将会等待所有ConnectionRunner结束后才能继续执行
    static CountDownLatch end;
    public static void main(String[] args) throws Exception {
// 线程数量，可以修改线程数量进行观察
        int threadCount = 10;
        end = new CountDownLatch(threadCount);
        int count = 20;
        AtomicInteger got = new AtomicInteger();
        AtomicInteger notGot = new AtomicInteger();
        for (int i = 0; i &lt; threadCount; i++) {
            Thread thread = new Thread(new ConnetionRunner(count, got, notGot),
                    &quot;ConnectionRunnerThread&quot;);
            thread.start();
        }
        start.countDown();
        end.await();
        System.out.println(&quot;total invoke: &quot; + (threadCount * count));
        System.out.println(&quot;got connection: &quot; + got);
        System.out.println(&quot;not got connection &quot; + notGot);
    }
    static class ConnetionRunner implements Runnable {
        int count;
        AtomicInteger got;
        AtomicInteger notGot;
        public ConnetionRunner(int count, AtomicInteger got, AtomicInteger notGot) {
            this.count = count;
            this.got = got;
            this.notGot = notGot;
        }
        public void run() {
            try {
                start.await();
            } catch (Exception ex) {
            }
            while (count &gt; 0) {
                try {
                    // 从线程池中获取连接，如果1000ms内无法获取到，将会返回null
                    // 分别统计连接获取的数量got和未获取到的数量notGot
                    Connection connection = pool.fetchConnection(1000);
                    if (connection != null) {
                        try {
                            connection.createStatement();
                            connection.commit();
                        } finally {
                            pool.releaseConnection(connection);
                            got.incrementAndGet();
                        }
                    } else {
                        notGot.incrementAndGet();
                    }
                } catch (Exception ex) {
                } finally {
                    count--;
                }
            }
            end.countDown();
        }
    }
}

</code></pre>
<p>上述示例中使用了CountDownLatch来确保ConnectionRunnerThread能够同时开始执行，并且在全部结束之后，才使main线程从等待状态中返回。</p>
<p>在资源一定的情况下（连接池中的10个连接），随着客户端线程的逐步增加，客户端出现超时无法获取连接的比率不断升高。虽然客户端线程在这种超时获取的模式下会出现连接无法获取的情况，但是它能够保证客户端线程不会一直挂在连接获取的操作上，而是“按时”返回，并告知客户端连接获取出现问题，是系统的一种自我保护机制。数据库连接池的设计也可以复用到其他的资源获取的场景，针对昂贵资源（比如数据库连接）的获取都应该加以超时限制。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JAVA并发（一）]]></title>
        <id>https://q456qq520.github.io/post/java-bing-fa/</id>
        <link href="https://q456qq520.github.io/post/java-bing-fa/">
        </link>
        <updated>2022-07-07T08:36:25.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-锁机">1、锁机</h1>
<h2 id="11-锁的升级与对比">1.1 锁的升级与对比</h2>
<p>为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，锁一共有4种状态，级别从低到高依次是:无锁状态、偏向锁状态、轻量级锁状 态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏 向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高 获得锁和释放锁的效率</p>
<h3 id="111-偏向锁">1.1.1 偏向锁</h3>
<p>大多数情况下，锁不仅不存在多线程竞争，而且总是由同 一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并 获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出 同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word（存储对象的hashcode和锁信息）里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需 要再测试一下Mark Word中偏向锁的标识是否设置成1(表示当前是偏向锁):如果没有设置，则 使用CAS竞争锁;如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。</p>
<pre><code>(1)偏向锁的撤销

偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时， 持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点(在这个时间点上没有正 在执行的字节码)。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着， 如果线程不处于活动状态，则将对象头设置成无锁状态;如果线程仍然活着，拥有偏向锁的栈 会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他 线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。
</code></pre>
<h3 id="112-轻量级锁">1.1.2 轻量级锁</h3>
<pre><code>(1)轻量级锁加锁

线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用 CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。

(2)轻量级锁解锁

轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成 功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。

因为自旋会消耗CPU，为了避免无用的自旋(比如获得锁的线程被阻塞住了)，一旦锁升级 成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时， 都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮 的夺锁之争。
</code></pre>
<h3 id="113-锁的优缺点对比">1.1.3 锁的优缺点对比</h3>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1657184456814.png" alt="锁的优缺点对比" loading="lazy"></figure>
<h2 id="12-原子操作的实现原理">1.2 原子操作的实现原理</h2>
<p>原子(atomic)本意是“不能被进一步分割的最小粒子”，而原子操作(atomic operation)意 为“不可被中断的一个或一系列操作”。在多处理器上实现原子操作就变得有点复杂。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1657184549916.png" alt="CPU术语定义" loading="lazy"></figure>
<h3 id="121-在java中可以通过锁和循环cas的方式来实现原子操作">1.2.1 在Java中可以通过锁和循环CAS的方式来实现原子操作。</h3>
<p>JVM中的CAS操作正是利用了处理器提供的CMPXCHG指令实现的。自旋CAS实现的基本 思路就是循环进行CAS操作直到成功为止，以下代码实现了一个基于CAS线程安全的计数器 方法safeCount和一个非线程安全的计数器count。</p>
<pre><code class="language-java">package com.curr;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * 并发计数器demo
 * @author likecat
 * @version 1.0
 * @date 2022/7/7 17:08
 */
public class CurrDemo {


    private AtomicInteger atomicI = new AtomicInteger(0);


    private int i = 0;
    public static void main(String[] args) {
        final CurrDemo cas = new CurrDemo();
        List&lt;Thread&gt; ts = new ArrayList&lt;Thread&gt;(600);
        long start = System.currentTimeMillis();
        for (int j = 0; j &lt; 100; j++) {
            Thread t = new Thread(new Runnable() {
                @Override
                public void run() {
                    for (int i = 0; i &lt; 10000; i++) {
                        cas.count();
                        cas.safeCount();
                    }
                }
            });

            ts.add(t);
        }
        for (Thread t : ts) {
            t.start();
        }
        // 等待所有线程执行完成
        for (Thread t : ts) {
            try {
                t.join();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
        System.out.println(cas.i);
        System.out.println(cas.atomicI.get());
        System.out.println(System.currentTimeMillis() - start);
    }

    /**
     * 使用CAS实现线程安全计数器
     *
     */
    private void safeCount() {
        for (;;) {
            int i = atomicI.get();
            boolean suc = atomicI.compareAndSet(i, ++i);
            if (suc) {
                break;
            }
        }
    }

    /**
     * 非线程安全计数器
     */
    private void count() {
        i++;
    }

}
</code></pre>
<p>从Java 1.5开始，JDK的并发包里提供了一些类来支持原子操作，如AtomicBoolean(用原子 方式更新的boolean值)、AtomicInteger(用原子方式更新的int值)和AtomicLong(用原子方式更 新的long值)。这些原子包装类还提供了有用的工具方法，比如以原子的方式将当前值自增1和 自减1。</p>
<h3 id="122-cas实现原子操作的三大问题">1.2.2 CAS实现原子操作的三大问题</h3>
<p>在Java并发包中有一些并发框架也使用了自旋CAS的方式来实现原子操作，比如 LinkedTransferQueue类的Xfer方法。CAS虽然很高效地解决了原子操作，但是CAS仍然存在三 大问题。ABA问题，循环时间长开销大，以及只能保证一个共享变量的原子操作。</p>
<ol>
<li><strong>ABA问题</strong>。因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化 则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它 的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面 追加上版本号，每次变量更新的时候把版本号加1，那么A→B→A就会变成1A→2B→3A。从 Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个 类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是 否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。</li>
<li><strong>循环时间长开销大</strong>。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令，那么效率会有一定的提升。pause指令有两个作用：第一，它可以延迟流水线执行指令（de-pipeline），使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零；第二，它可以避免在退出循环的时候因内存顺序冲突（Memory Order Violation）而引起CPU流水线被清空（CPU Pipeline Flush），从而提高CPU的执行效率。</li>
<li><strong>只能保证一个共享变量的原子操作</strong>。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。。还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。</li>
</ol>
<h3 id="123-使用锁机制实现原子操作">1.2.3 使用锁机制实现原子操作</h3>
<p>锁机制保证了只有获得锁的线程才能够操作锁定的内存区域。JVM内部实现了很多种锁机制，有偏向锁、轻量级锁和互斥锁。有意思的是除了偏向锁，JVM实现锁的方式都用了循环CAS，即当一个线程想进入同步块的时候使用循环CAS的方式来获取锁，当它退出同步块的时候使用循环CAS释放锁。</p>
<h1 id="2-java内存模型">2 Java内存模型</h1>
<h2 id="21-java内存模型的基础">2.1 Java内存模型的基础</h2>
<h3 id="211-并发编程模型的两个关键问题">2.1.1 并发编程模型的两个关键问题</h3>
<p>在并发编程中，需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：<strong>共享内存和消息传递</strong></p>
<p>在共享内存的并发模型里，线程之间共享程序的公共状态，通过写-读内存中的公共状态进行隐式通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过发送消息来显式进行通信。</p>
<p><strong>同步是指程序中用于控制不同线程间操作发生相对顺序的机制</strong>。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。</p>
<p>Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。如果编写多线程程序的Java程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。</p>
<h3 id="212-java内存模型的抽象结构">2.1.2 Java内存模型的抽象结构</h3>
<p>在Java中，所有实例域、静态域和数组元素都存储在堆内存中，堆内存在线程之间共享局部变量（Local Variables），方法定义参数（Java语言规范称之为Formal Method Parameters）和异常处理器参数（ExceptionHandler Parameters）不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。</p>
<p>Java线程之间的通信由Java内存模型（本文简称为JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1658842307969.png" alt="Java内存模型的抽象结构示意图" loading="lazy"></figure>
<p>从上图来看，如果线程A与线程B之间要通信的话，必须要经历下面2个步骤。</p>
<p>1）线程A把本地内存A中更新过的共享变量刷新到主内存中去。<br>
2）线程B到主内存中去读取线程A之前已更新过的共享变量。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1658842388422.png" alt="线程之间的通信图" loading="lazy"></figure>
<p>如上图所示，本地内存A和本地内存B由主内存中共享变量x的副本。假设初始时，这3个内存中的x值都为0。线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。</p>
<p>从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。</p>
<h3 id="213-从源代码到指令序列的重排序">2.1.3 从源代码到指令序列的重排序</h3>
<p>在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型。</p>
<p>1）编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。</p>
<p>2）指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-LevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</p>
<p>3）内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。从Java源代码到最终实际执行的指令序列，会分别经历下面3种重排序，</p>
<pre><code>源代码 -&gt;  1:编译器优化重排序 -&gt; 2:指令级并行重排序 -&gt; 3:内存系统重排序 -&gt; 最终执行的指令序列
</code></pre>
<p>上述的1属于编译器重排序，2和3属于处理器重排序。这些重排序可能会导致多线程程序出现内存可见性问题。对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障（Memory Barriers，Intel称之为Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。</p>
<p>JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。</p>
<h3 id="214-并发编程模型的分类">2.1.4 并发编程模型的分类</h3>
<p>现代的处理器使用写缓冲区临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致！</p>
<h2 id="22-重排序">2..2 重排序</h2>
<p>重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。</p>
<h3 id="221-数据依赖性">2.2.1 数据依赖性</h3>
<p>如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分为下列3种类型</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1658844674668.png" alt="数据依赖类型表" loading="lazy"></figure>
<p>上面3种情况，只要重排序两个操作的执行顺序，程序的执行结果就会被改变。</p>
<p>前面提到过，编译器和处理器可能会对操作做重排序。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。</p>
<p>这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。</p>
<h3 id="222-as-if-serial语义">2.2.2 as-if-serial语义</h3>
<p>as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。</p>
<p>为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。</p>
<p>为了具体说明，请看下面计算圆面积的代码示例。</p>
<pre><code class="language-java">double pi = 3.14; // A
double r = 1.0; // B
double area = pi * r * r; // C
</code></pre>
<p>A和C之间存在数据依赖关系，同时B和C之间也存在数据依赖关系。因此在最终执行的指令序列中，C不能被重排序到A和B的前面（C排到A和B的前面，程序的结果将会被改变）。但A和B之间没有数据依赖关系，编译器和处理器可以重排序A和B之间的执行顺序。</p>
<p>as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器、runtime和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。asif-serial语义使单程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。</p>
<h3 id="223-程序顺序规则">2.2.3 程序顺序规则</h3>
<p>根据happens-before的程序顺序规则，上面计算圆的面积的示例代码存在3个happensbefore关系。</p>
<p>1）A happens-before B。<br>
2）B happens-before C。<br>
3）A happens-before C。</p>
<p>这里的第3个happens-before关系，是根据happens-before的传递性推导出来的。</p>
<p>这里A happens-before B，但实际执行时B却可以排在A之前执行（看上面的重排序后的执行顺序）。如果A happens-before B，JMM并不要求A一定要在B之前执行。JMM仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。这里操作A的执行结果不需要对操作B可见；而且重排序操作A和操作B后的执行结果，与操作A和操作B按happens-before顺序执行的结果一致。在这种情况下，JMM会认为这种重排序并不非法（notillegal），JMM允许这种重排序。</p>
<p><strong>在不改变程序执行结果的前提下，尽可能提高并行度。</strong></p>
<h3 id="224-重排序对多线程的影响">2.2.4 重排序对多线程的影响</h3>
<p>重排序是否会改变多线程程序的执行结果。请看下面的示例代码。</p>
<pre><code class="language-java">class ReorderExample {
    int a = 0;
    boolean flag = false;

    public void writer() {
        a = 1; // 1
        flag = true; // 2
    }

    public void reader() {
        if (flag) { // 3
            int i = a * a; // 4
            ……
        }
    }
}
</code></pre>
<p>flag变量是个标记，用来标识变量a是否已被写入。这里假设有两个线程A和B，A首先执行writer()方法，随后B线程接着执行reader()方法。线程B在执行操作4时，能否看到线程A在操作1对共享变量a的写入呢？</p>
<p>答案是：<strong>不一定能看到</strong>。</p>
<p>由于操作1和操作2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作3和操作4没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。</p>
<p>操作1和操作2做了重排序。程序执行时，线程A首先写标记变量flag，随后线程B读这个变量。由于条件判断为真，线程B将读取变量a。此时，变量a还没有被线程A写入，在这里多线程程序的语义被重排序破坏了！</p>
<p>在程序中，操作3和操作4存在控制依赖关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用<strong>猜测（Speculation）执行</strong>来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算a*a，然后把计算结果临时保存到一个名为重排序缓冲（Reorder Buffer，ROB）的硬件缓存中。当操作3的条件判断为真时，就把该计算结果写入变量i中。</p>
<p>在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。</p>
<h2 id="23-顺序一致性">2.3 顺序一致性</h2>
<p>顺序一致性内存模型是一个理论参考模型，在设计的时候，处理器的内存模型和编程语言的内存模型都会以顺序一致性内存模型作为参照。</p>
<h3 id="231-数据竞争与顺序一致性">2.3.1 数据竞争与顺序一致性</h3>
<p>当程序未正确同步时，就可能会存在数据竞争。Java内存模型规范对数据竞争的定义如<br>
下。</p>
<pre><code>在一个线程中写一个变量，在另一个线程读同一个变量，而且写和读没有通过同步来排序。
</code></pre>
<p>当代码中包含数据竞争时，程序的执行往往产生违反直觉的结果。如果一个多线程程序能正确同步，这个程序将是一个没有数据竞争的程序。JMM对正确同步的多线程程序的内存一致性做了如下保证。</p>
<p>如果程序是正确同步的，程序的执行将具有<strong>顺序一致性（Sequentially Consistent）</strong>——即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。这里的同步是指广义上的同步，包括对常用同步原语（synchronized、volatile和final）的正确使用</p>
<h3 id="232-顺序一致性内存模型">2.3.2 顺序一致性内存模型</h3>
<p>顺序一致性内存模型是一个被计算机科学家理想化了的理论参考模型，它为程序员提供了极强的内存可见性保证。顺序一致性内存模型有两大特性。</p>
<ul>
<li>1)一个线程中的所有操作必须按照程序的顺序来执行。</li>
<li>2)（不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。</li>
</ul>
<p>在概念上，顺序一致性模型有一个单一的全局内存，这个内存通过一个左右摆动的开关可以连接到任意一个线程，同时每一个线程必须按照程序的顺序来执行内存读/写操作。在任意时间点最多只能有一个线程可以连接到内存。当多个线程并发执行时，图中的开关装置能把所有线程的所有内存读/写操作串行化（即在顺序一致性模型中，所有操作之间具有全序关系）。</p>
<figure data-type="image" tabindex="6"><img src="https://q456qq520.github.io/post-images/1658990481932.png" alt="顺序一致性内存模型的视图" loading="lazy"></figure>
<p>为了更好进行理解，假设有两个线程A和B并发执行。其中A线程有3个操作，它们在程序中的顺序是：<br>
A1→A2→A3。B线程也有3个操作，它们在程序中的顺序是：B1→B2→B3。</p>
<p>假设这两个线程使用监视器锁来正确同步：A线程的3个操作执行后释放监视器锁，随后B<br>
线程获取同一个监视器锁。那么程序在顺序一致性模型中的执行效果将会是：</p>
<pre><code>A1→A2→A3→B1→B2→B3
</code></pre>
<p>现在我们再假设这两个线程没有做同步，那这个未同步程序在顺序一致性模型中的执行示意图可能是：</p>
<pre><code>B1→A1→A2→B2→A3→B3
</code></pre>
<p>未同步程序在顺序一致性模型中虽然整体执行顺序是无序的，但所有线程都只能看到一个一致的整体执行顺序。线程A和B看到的执行顺序可能都是：B1→A1→A2→B2→A3→B3。之所以能得到这个保证是因为顺序一致性内存模型中的每个操作必须立即对任意线程可见。</p>
<p>但是，在JMM中就没有这个保证。未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。比如，在当前线程把写过的数据缓存在本地内存中，在没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，会认为这个写操作根本没有被当前线程执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才能对其他线程可见。在这种情况下，当前线程和其他线程看到的操作执行顺序将不一致。</p>
<h3 id="233-同步程序的顺序一致性效果">2.3.3 同步程序的顺序一致性效果</h3>
<p>下面，对前面的示例程序ReorderExample用锁来同步，看看正确同步的程序如何具有顺序<br>
一致性。</p>
<p>请看下面的示例代码。</p>
<pre><code class="language-java">class ReorderExample {
    int a = 0;
    boolean flag = false;

    public synchronized void writer() {  // 获取锁
        a = 1; // 1
        flag = true; // 2
    }                                               // 释放锁

    public synchronized void reader() { // 获取锁
        if (flag) { // 3
            int i = a * a; // 4
            ……
        }
    }                                                // 释放锁
}
</code></pre>
<p>在上面示例代码中，假设A线程执行writer()方法后，B线程执行reader()方法。这是一个正确同步的多线程程序。根据JMM规范，该程序的执行结果将与该程序在顺序一致性模型中的执行结果相同。</p>
<p>顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在JMM中，临界区内的代码可以重排序（但JMM不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。JMM会在退出临界区和进入临界区这两个关键时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性模型相同的内存视图。虽然线程A在临界区内做了重排序，但由于监视器互斥执行的特性，这里的线程B根本无法“观察”到线程A在临<br>
界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。</p>
<figure data-type="image" tabindex="7"><img src="https://q456qq520.github.io/post-images/1658991491289.png" alt="两个内存模型中的执行时序对比图" loading="lazy"></figure>
<p>JMM在具体实现上的基本方针为：<strong>在不改变（正确同步的）程序执行结果的前提下，尽可能地为编译器和处理器的优化打开方便之门。</strong></p>
<h3 id="234-未同步程序的执行特性">2.3.4 未同步程序的执行特性</h3>
<p>对于未同步或未正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，Null，False），JMM保证线程读操作读取到的值不会无中生有（Out Of Thin Air）的冒出来。为了实现最小安全性，JVM在堆上分配对象时，首先会对内存空间进行清零，然后才会在上面分配对象（JVM内部会同步这两个操作）。因此，在已清零的内存空间（Pre-zeroed Memory）分配对象时，域的默认初始化已经完成了。</p>
<p>JMM不保证未同步程序的执行结果与该程序在顺序一致性模型中的执行结果一致。因为如果想要保证执行结果一致，JMM需要禁止大量的处理器和编译器的优化，这对程序的执行性能会产生很大的影响。而且未同步程序在顺序一致性模型中执行时，整体是无序的，其执行结果往往无法预知。而且，保证未同步程序在这两个模型中的执行结果一致没什么意义。</p>
<p>未同步程序在JMM中的执行时，整体上是无序的，其执行结果无法预知。未同步程序在两个模型中的执行特性有如下几个差异。</p>
<pre><code>1）顺序一致性模型保证单线程内的操作会按程序的顺序执行，而JMM不保证单线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）。

2）顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致的操作执行顺序。

3）JMM不保证对64位的long型和double型变量的写操作具有原子性，而顺序一致性模型保证对所有的内存读/写操作都具有原子性。
</code></pre>
<p>第3个差异与处理器总线的工作机制密切相关。在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为<strong>总线事务（Bus Transaction）</strong>。总线事务包括读事务（Read Transaction）和写事务（Write Transaction）。读事务从内存传送数据到处理器，写事务从处理器传送数据到内存，每个事务会读/写内存中一个或多个物理上连续的字。在一个处理器执行总线事务期间，总线会禁止其他的处理器和I/O设备执行内存的读/写。</p>
<p>在一些32位的处理器上，如果要求对64位数据的写操作具有原子性，会有比较大的开销。为了照顾这种处理器，Java语言规范鼓励但不强求JVM对64位的long型变量和double型变量的写操作具有原子性。当JVM在这种处理器上运行时，可能会把一个64位long/double型变量的写操作拆分为两个32位的写操作来执行。这两个32位的写操作可能会被分配到不同的总线事务中执行，此时对这个64位变量的写操作将不具有原子性。</p>
<h2 id="24-volatile的内存语义">2.4 volatile的内存语义</h2>
<p>当声明共享变量为volatile后，对这个变量的读/写将会很特别。</p>
<h3 id="241-volatile的特性">2.4.1 volatile的特性</h3>
<p>理解volatile特性的一个好方法是把对volatile变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步。</p>
<pre><code class="language-java">   class VolatileFeaturesExample {
        volatile long vl = 0L; // 使用volatile声明64位的long型变量
        
        public void set(long l) {
            vl = l; // 单个volatile变量的写
        }
        
        public void getAndIncrement () {
            vl++; // 复合（多个）volatile变量的读/写
        }
        
        public long get() {
            return vl; // 单个volatile变量的读
        }
    }
</code></pre>
<p>锁的happens-before规则保证释放锁和获取锁的两个线程之间的内存可见性，这意味着对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。锁的语义决定了临界区代码的执行具有原子性。这意味着，即使是64位的long型和double型变量，只要它是volatile变量，对该变量的读/写就具有原子性。如果是多个volatile操作或类似于volatile++这种复合操作，这些操作整体上不具有原子性。</p>
<p>简而言之，volatile变量自身具有下列特性。</p>
<ul>
<li>
<p><strong>可见性</strong>。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。</p>
</li>
<li>
<p><strong>原子性</strong>：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。</p>
</li>
</ul>
<h3 id="242-volatile写-读建立的happens-before关系">2.4.2 volatile写-读建立的happens-before关系</h3>
<p>volatile对线程的内存可见性的影响比volatile自身的特性更为重要</p>
<p>从JSR-133开始（即从JDK5开始），volatile变量的写-读可以实现线程之间的通信。</p>
<p>从内存语义的角度来说，volatile的写-读与锁的释放-获取有相同的内存效果：volatile写和锁的释放有相同的内存语义；volatile读与锁的获取有相同的内存语义。</p>
<pre><code class="language-java">   class VolatileExample {
        int a = 0;
        volatile boolean flag = false;
        public void writer() {
            a = 1; // 1
            flag = true; // 2
        }
        public void reader() {
            if (flag) { // 3
                int i = a; // 4
                ……
            }
        }
    }
</code></pre>
<p>假设线程A执行writer()方法之后，线程B执行reader()方法。根据happens-before规则，这个过程建立的happens-before关系可以分为3类：</p>
<pre><code>1）根据程序次序规则，1 happens-before 2;3 happens-before 4。
2）根据volatile规则，2 happens-before 3。
3）根据happens-before的传递性规则，1 happens-before 4。
</code></pre>
<p>这里A线程写一个volatile变量后，B线程读同一个volatile变量。A线程在写volatile变量之前所有可见的共享变量，在B线程读同一个volatile变量后，将立即变得对B线程可见。</p>
<h3 id="243-volatile写-读的内存语义">2.4.3 volatile写-读的内存语义</h3>
<p><strong>当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。</strong></p>
<p>以上面示例程序VolatileExample为例，假设线程A首先执行writer()方法，随后线程B执行reader()方法，初始时两个线程的本地内存中的flag和a都是初始状态。线程A在写flag变量后，本地内存A中被线程A更新过的两个共享变量的值被刷新到主内存中。此时，本地内存A和主内存中的共享变量的值是一致的。</p>
<p><strong>当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。</strong></p>
<p>在读flag变量后，本地内存B包含的值已经被置为无效。此时，线程B必须从主内存中读取共享变量。线程B的读取操作将导致本地内存B与主内存中的共享变量的值变成一致。</p>
<p>下面对volatile写和volatile读的内存语义做个总结。</p>
<ol>
<li>
<p>线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了（其对共享变量所做修改的）消息。</p>
</li>
<li>
<p>线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改的）消息。</p>
</li>
<li>
<p>线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。</p>
</li>
</ol>
<h3 id="244-volatile内存语义的实现">2.4.4 volatile内存语义的实现</h3>
<p>为了实现volatile内存语义，JMM会分别限制编译器重排序和处理器重排序。</p>
<figure data-type="image" tabindex="8"><img src="https://q456qq520.github.io/post-images/1658996497940.png" alt="volatile重排序规则表" loading="lazy"></figure>
<p>举例来说，第三行最后一个单元格的意思是：在程序中，当第一个操作为普通变量的读或写时，如果第二个操作为volatile写，则编译器不能重排序这两个操作。</p>
<p>我们可以从上图看出。</p>
<pre><code>当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。

当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。

当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。
</code></pre>
<p>为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入<strong>内存屏障</strong>来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略。</p>
<pre><code>1、在每个volatile写操作的前面插入一个StoreStore屏障。
2、在每个volatile写操作的后面插入一个StoreLoad屏障。
3、在每个volatile读操作的后面插入一个LoadLoad屏障。
4、在每个volatile读操作的后面插入一个LoadStore屏障。
</code></pre>
<p>上述内存屏障插入策略非常保守，但它可以保证在任意处理器平台，任意的程序中都能得到正确的volatile内存语义。</p>
<p>（StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。StoreLoad屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序。LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。）</p>
<p>X86处理器仅会对写-读操作做重排序。X86不会对读-读、读-写和写-写操作做重排序，因此在X86处理器中会省略掉这3种操作类型对应的内存屏障。在X86中，JMM仅需在volatile写后面插入一个StoreLoad屏障即可正确实现volatile写-读的内存语义。这意味着在X86处理器中，volatile写的开销比volatile读的开销会大很多（因为执行StoreLoad屏障开销会比较大）。</p>
<h3 id="245-jsr-133为什么要增强volatile的内存语义">2.4.5 JSR-133为什么要增强volatile的内存语义</h3>
<h2 id="25-锁的内存语义">2.5 锁的内存语义</h2>
<p><strong>锁可以让临界区互斥执行</strong></p>
<h3 id="251-锁的释放-获取建立的happens-before关系">2.5.1 锁的释放-获取建立的happens-before关系</h3>
<p>锁是Java并发编程中最重要的同步机制。锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。</p>
<pre><code class="language-java"> class MonitorExample {
        int a = 0;
        public synchronized void writer() { // 1
            a++; // 2
        } // 3
        public synchronized void reader() { // 4
            int i = a; // 5
            ……      
        } // 6
    }
</code></pre>
<p>假设线程A执行writer()方法，随后线程B执行reader()方法。根据happens-before规则，这个过程包含的happens-before关系可以分为3类。</p>
<pre><code>1）根据程序次序规则，1 happens-before 2,2 happens-before 3;4 happens-before 5,5 happensbefore 6。

2）根据监视器锁规则，3 happens-before 4。

3）根据happens-before的传递性，2 happens-before 5。
</code></pre>
<p>示在线程A释放了锁之后，随后线程B获取同一个锁。2 happens-before5。因此，线程A在释放锁之前所有可见的共享变量，在线程B获取同一个锁之后，将立刻变得对B线程可见。</p>
<h3 id="252-锁的释放和获取的内存语义">2.5.2 锁的释放和获取的内存语义</h3>
<p><strong>当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。</strong></p>
<p>当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。</p>
<p>对比锁释放-获取的内存语义与volatile写-读的内存语义可以看出：锁释放与volatile写有相同的内存语义；锁获取与volatile读有相同的内存语义。</p>
<p>下面对锁释放和锁获取的内存语义做个总结。</p>
<ol>
<li>
<p>线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了（线程A<br>
对共享变量所做修改的）消息。</p>
</li>
<li>
<p>线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共<br>
享变量所做修改的）消息。</p>
</li>
<li>
<p>线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发<br>
送消息。</p>
</li>
</ol>
<h3 id="253-锁内存语义的实现">2.5.3 锁内存语义的实现</h3>
<p>借助ReentrantLock的源代码，来分析锁内存语义的具体实现机制。</p>
<pre><code class="language-java">  class ReentrantLockExample {
        int a = 0;
        ReentrantLock lock = new ReentrantLock();
        public void writer() {
            lock.lock(); // 获取锁
            try {
                a++;
            } f inally {
                lock.unlock(); // 释放锁
            }
        }
        public void reader () {
            lock.lock(); // 获取锁
            try {
                int i = a;
                ……
            } f inally {
                lock.unlock(); // 释放锁
            }
        }
    }
</code></pre>
<p>在ReentrantLock中，调用lock()方法获取锁；调用unlock()方法释放锁。ReentrantLock的实现依赖于Java同步器框架AbstractQueuedSynchronizer（简称之为AQS）。AQS使用一个整型的volatile变量（命名为state）来维护同步状态。</p>
<figure data-type="image" tabindex="9"><img src="https://q456qq520.github.io/post-images/1659063821657.png" alt="ReentrantLock的类图" loading="lazy"></figure>
<p>ReentrantLock分为<strong>公平锁</strong>和<strong>非公平锁</strong>，我们首先分析公平锁。</p>
<p>使用公平锁时，加锁方法lock()调用轨迹如下。</p>
<p>1）ReentrantLock:lock()。<br>
2）FairSync:lock()。<br>
3）AbstractQueuedSynchronizer:acquire(int arg)。<br>
4）ReentrantLock:tryAcquire(int acquires)。</p>
<p>在第4步真正开始加锁，下面是该方法的源代码。</p>
<pre><code class="language-java">        @ReservedStackAccess
        protected final boolean tryAcquire(int acquires) {
            final Thread current = Thread.currentThread(); //获取当前执行线程
            int c = getState();          // 获取锁的开始，首先读volatile变量state
            if (c == 0) {
                if (!hasQueuedPredecessors() &amp;&amp;
                    compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc &lt; 0)
                    throw new Error(&quot;Maximum lock count exceeded&quot;);
                setState(nextc);
                return true;
            }
            return false;
        }
</code></pre>
<p>从上面源代码中我们可以看出，加锁方法首先读volatile变量state。</p>
<p>在使用公平锁时，解锁方法unlock()调用轨迹如下。</p>
<p>1）ReentrantLock:unlock()。<br>
2）AbstractQueuedSynchronizer:release(int arg)。<br>
3）Sync:tryRelease(int releases)。</p>
<p>在第3步真正开始释放锁，下面是该方法的源代码。</p>
<pre><code class="language-java">@ReservedStackAccess
protected final boolean tryRelease(int releases) {
     int c = getState() - releases;
     if (Thread.currentThread() != getExclusiveOwnerThread())
         throw new IllegalMonitorStateException();
        boolean free = false;
        if (c == 0) {
            free = true;
            setExclusiveOwnerThread(null);
        }
        setState(c);    // 释放锁的最后，写volatile变量state
        return free;
}
</code></pre>
<p>公平锁在释放锁的最后写volatile变量state，在获取锁时首先读这个volatile变量。根据volatile的happens-before规则，释放锁的线程在写volatile变量之前可见的共享变量，在获取锁的线程读取同一个volatile变量后将立即变得对获取锁的线程可见。</p>
<p>现在我们来分析非公平锁的内存语义的实现。非公平锁的释放和公平锁完全一样，所以这里仅仅分析非公平锁的获取。使用非公平锁时，加锁方法lock()调用轨迹如下。</p>
<p>1）ReentrantLock:lock()。<br>
2）NonfairSync:lock()。<br>
3）AbstractQueuedSynchronizer:compareAndSetState(int expect,int update)。</p>
<p>在第3步真正开始加锁，下面是该方法的源代码。</p>
<pre><code class="language-java">protected final boolean compareAndSetState(int expect, int update) {
     // See below for intrinsics setup to support this
     return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
 }
</code></pre>
<p>该方法以原子操作的方式更新state变量，</p>
<p><em>compareAndSet()(CAS)：如果当前状态值等于预期值，则以原子方式将同步状态设置为给定的更新值。此操作具有volatile读和写的内存语义。</em></p>
<p>我们分别从编译器和处理器的角度来分析，CAS如何同时具有volatile读和volatile写的内存语义。</p>
<p>前文我们提到过，编译器不会对volatile读与volatile读后面的任意内存操作重排序；编译器不会对volatile写与volatile写前面的任意内存操作重排序。组合这两个条件，意味着为了同时实现volatile读和volatile写的内存语义，编译器不能对CAS与CAS前面和后面的任意内存操作重排序。</p>
<p><em>sun.misc.Unsafe类的compareAndSwapInt()方法的源代码。</em></p>
<pre><code class="language-java"> public final native boolean compareAndSwapInt(Object o, long offset,
                                                  int expected, int x);
</code></pre>
<p>可以看到，这是一个本地方法调用。程序会根据当前处理器的类型来决定是否为cmpxchg指令添加lock前<br>
缀。如果程序是在多处理器上运行，就为cmpxchg指令加上lock前缀（Lock Cmpxchg）。反之，如<br>
果程序是在单处理器上运行，就省略lock前缀。</p>
<p>对lock前缀的说明如下。</p>
<p>1）确保对内存的读-改-写操作原子执行。在Pentium及Pentium之前的处理器中，带有lock前缀的指令在执行期间会锁住总线，使得其他处理器暂时无法通过总线访问内存。很显然，这会带来昂贵的开销。从Pentium 4、Intel Xeon及P6处理器开始，Intel使用缓存锁定（Cache Locking）来保证指令执行的原子性。缓存锁定将大大降低lock前缀指令的执行开销。</p>
<p>2）禁止该指令，与之前和之后的读和写指令重排序。</p>
<p>3）把写缓冲区中的所有数据刷新到内存中。</p>
<p>上面的第2点和第3点所具有的内存屏障效果，足以同时实现volatile读和volatile写的内存语义。</p>
<p>现在对公平锁和非公平锁的内存语义做个总结。</p>
<ol>
<li>公平锁和非公平锁释放时，最后都要写一个volatile变量state。</li>
<li>公平锁获取时，首先会去读volatile变量。</li>
<li>非公平锁获取时，首先会用CAS更新volatile变量，这个操作同时具有volatile读和volatile<br>
写的内存语义。</li>
</ol>
<p>从本文对ReentrantLock的分析可以看出，锁释放-获取的内存语义的实现至少有下面两种方式。</p>
<p>1）利用volatile变量的写-读所具有的内存语义。<br>
2）利用CAS所附带的volatile读和volatile写的内存语义。</p>
<h3 id="254-concurrent包的实现">2.5.4 concurrent包的实现</h3>
<p>由于Java的CAS同时具有volatile读和volatile写的内存语义，因此Java线程之间的通信现在有了下面4种方式。</p>
<pre><code>1）A线程写volatile变量，随后B线程读这个volatile变量。
2）A线程写volatile变量，随后B线程用CAS更新这个volatile变量。
3）A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。
4）A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。
</code></pre>
<p>仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式。</p>
<p>首先，声明共享变量为volatile。</p>
<p>然后，使用CAS的原子条件更新来实现线程之间的同步。</p>
<p>同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。</p>
<p>AQS，非阻塞数据结构和原子变量类（java.util.concurrent.atomic包中的类），这些concurrent包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。</p>
<figure data-type="image" tabindex="10"><img src="https://q456qq520.github.io/post-images/1659076796126.png" alt="concurrent包的实现示意图" loading="lazy"></figure>
<h2 id="26-final域的内存语义">2.6 final域的内存语义</h2>
<h3 id="361-final域的重排序规则">3.6.1 final域的重排序规则</h3>
<p>对于final域，编译器和处理器要遵守两个重排序规则。</p>
<p>1）在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。</p>
<p>2）初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。</p>
<p><em>示例性代码</em></p>
<pre><code class="language-java"> public class FinalExample {
        int i; // 普通变量
        final int j; // final变量
        static FinalExample obj;
        public FinalExample () { // 构造函数
            i = 1; // 写普通域
            j = 2; // 写final域
        }
        public static void writer () { // 写线程A执行
            obj = new FinalExample ();
        }
        public static void reader () { // 读线程B执行
            FinalExample object = obj; // 读对象引用
            int a = object.i; // 读普通域
            int b = object.j; // 读final域
        }
    }
</code></pre>
<h3 id="262-写final域的重排序规则">2.6.2 写final域的重排序规则</h3>
<p>写final域的重排序规则禁止把final域的写重排序到构造函数之外。这个规则的实现包含下面2个方面。</p>
<p>1）JMM禁止编译器把final域的写重排序到构造函数之外。</p>
<p>2）编译器会在final域的写之后，构造函数return之前，插入一个StoreStore屏障。这个屏障禁止处理器把final域的写重排序到构造函数之外。</p>
<p>现在让我们分析writer()方法。writer()方法只包含一行代码：finalExample=newFinalExample()。这行代码包含两个步骤，如下。</p>
<pre><code>1）构造一个FinalExample类型的对象。
2）把这个对象的引用赋值给引用变量obj。
</code></pre>
<p>假设线程B读对象引用与读对象的成员域之间没有重排序</p>
<figure data-type="image" tabindex="11"><img src="https://q456qq520.github.io/post-images/1659078456654.png" alt="线程执行时序图" loading="lazy"></figure>
<p>写普通域的操作被编译器重排序到了构造函数之外，读线程B错误地读取了普通变量i初始化之前的值。而写final域的操作，被写final域的重排序规则“限定”在了构造函数之内，读线程B正确地读取了final变量初始化之后的值。</p>
<p>写final域的重排序规则可以确保：在对象引用为任意线程可见之前，对象的final域已经被正确初始化过了，而普通域不具有这个保障。</p>
<h3 id="263-读final域的重排序规则">2.6.3 读final域的重排序规则</h3>
<p>读final域的重排序规则是，在一个线程中，初次读对象引用与初次读该对象包含的final域，JMM禁止处理器重排序这两个操作。编译器会在读final域操作的前面插入一个LoadLoad屏障。</p>
<p>reader()方法包含3个操作。</p>
<pre><code>1）初次读引用变量obj。
2）初次读引用变量obj指向对象的普通域j。
3）初次读引用变量obj指向对象的final域i。
</code></pre>
<p>读final域的重排序规则可以确保：在读一个对象的final域之前，一定会先读包含这个final域的对象的引用。在这个示例程序中，如果该引用不为null，那么引用对象的final域一定已经被A线程初始化过了。</p>
<h3 id="264-final域为引用类型">2.6.4 final域为引用类型</h3>
<p>上面我们看到的final域是基础数据类型，如果final域是引用类型，将会有什么效果？</p>
<pre><code class="language-java"> public class FinalReferenceExample {
        final int[] intArray; // final是引用类型
        static FinalReferenceExample obj;
        public FinalReferenceExample () { // 构造函数
            intArray = new int[1]; // 1
            intArray[0] = 1; // 2
        }
        public static void writerOne () { // 写线程A执行
            obj = new FinalReferenceExample (); // 3
        }
        public static void writerTwo () { // 写线程B执行
            obj.intArray[0] = 2; // 4
        }
        public static void reader () { // 读线程C执行
            if (obj != null) { // 5
                int temp1 = obj.intArray[0]; // 6
            }
        }
    }
</code></pre>
<p>本例final域为一个引用类型，它引用一个int型的数组对象。对于引用类型，写final域的重排序规则对编译器和处理器增加了如下约束：<strong>在构造函数内对一个final引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。</strong></p>
<p>1是对final域的写入，2是对这个final域引用的对象的成员域的写入，3是把被构造的对象的引用赋值给某个引用变量。这里除了前面提到的1不能和3重排序外，2和3也不能重排序。</p>
<p>JMM可以确保读线程C至少能看到写线程A在构造函数中对final引用对象的成员域的写入。即C至少能看到数组下标0的值为1。而写线程B对数组元素的写入，读线程C可能看得到，也可能看不到。JMM不保证线程B的写入对读线程C可见，因为写线程B和读线程C之间存在数据竞争，此时的执行结果不可预知。</p>
<h3 id="265-为什么final引用不能从构造函数内溢出">2.6.5 为什么final引用不能从构造函数内“溢出”</h3>
<p><strong>在构造函数内部，不能让这个被构造对象的引用为其他线程所见，也就是对象引用不能在构造函数中“溢出”。</strong></p>
<pre><code class="language-java"> public class FinalReferenceEscapeExample {
        final int i;
        static FinalReferenceEscapeExample obj;
        public FinalReferenceEscapeExample () {
            i = 1; // 1写final域
            obj = this; // 2 this引用在此&quot;逸出&quot;
        }
        public static void writer() {
            new FinalReferenceEscapeExample ();
        }
        public static void reader() {
            if (obj != null) { // 3
                int temp = obj.i; // 4
            }
        }
    }
</code></pre>
<p>在构造函数返回前，被构造对象的引用不能为其他线程所见，因为此时的final域可能还没有被初始化。在构造函数返回后，任意线程都将保证能看到final域正确初始化之后的值，因为1和2操作可能进行重排序，但是2执行完别的线程可见。</p>
<h3 id="266-final语义在处理器中的实现">2.6.6 final语义在处理器中的实现</h3>
<p>写final域的重排序规则会要求编译器在final域的写之后，构造函数return之前插入一个StoreStore障屏。读final域的重排序规则要求编译器在读final域的操作前面插入一个LoadLoad屏障。</p>
<h3 id="267-jsr-133为什么要增强final的语义">2.6.7 JSR-133为什么要增强final的语义</h3>
<h2 id="27-happens-before">2.7 happens-before</h2>
<h3 id="271-jmm的设计">2.7.1 JMM的设计</h3>
<pre><code>double pi = 3.14; // A
double r = 1.0; // B
double area = pi * r * r; // C
</code></pre>
<p>上面计算圆的面积的示例代码存在3个happens-before关系，如下。</p>
<ol>
<li>A happens-before B。</li>
<li>B happens-before C。</li>
<li>A happens-before C。</li>
</ol>
<p>在3个happens-before关系中，2和3是必需的，但1是不必要的。因此，JMM把happens-before要求禁止的重排序分为了下面两类。</p>
<p>1）会改变程序执行结果的重排序，JMM要求编译器和处理器必须禁止这种重排序。。<br>
2）不会改变程序执行结果的重排序，JMM对编译器和处理器不做要求（JMM允许这种重排序）。</p>
<h3 id="272-happens-before的定义">2.7.2 happens-before的定义</h3>
<p>happens-before：分布式系统中事件之间的偏序关系（partial ordering）。JMM可以通过happens-before关系向程序员提供跨线程的内存可见性保证。</p>
<p>happens-before关系的定义如下：</p>
<p>1）如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。</p>
<p>2）两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法。</p>
<h3 id="273-happens-before规则">2.7.3 happens-before规则</h3>
<p>1）程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。</p>
<p>2）监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。</p>
<p>3）volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。</p>
<p>4）传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。</p>
<p>5）start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。</p>
<p>6）join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操happens-before于线程A从ThreadB.join()操作成功返回。</p>
<p>*start()规则：*假设线程A在执行的过程中，通过执行ThreadB.start()来启动线程B；同时，假设线程A在执行ThreadB.start()之前修改了一些共享变量，线程B在开始执行后会读这些共享变量。</p>
<p><em>join()规则：</em>。假设线程A在执行的过程中，通过执行ThreadB.join()来等待线程B终止；同时，假设线程B在终止之前修改了一些共享变量，线程A从ThreadB.join()返回后会读这些共享变量。</p>
<h2 id="28-双重检查锁定与延迟初始化">2.8 双重检查锁定与延迟初始化</h2>
<p>在Java多线程程序中，有时候需要采用延迟初始化来降低初始化类和创建对象的开销。双重检查锁定是常见的延迟初始化技术，但它是一个错误的用法。</p>
<h3 id="281-双重检查锁定的由来">2.8.1 双重检查锁定的由来</h3>
<p>在Java程序中，有时候可能需要推迟一些高开销的对象初始化操作，并且只有在使用这些对象时才进行初始化。</p>
<pre><code class="language-java">非线程安全的延迟初始化对象的示例代码。
public class UnsafeLazyInitialization {
    private static Instance instance;
    public static Instance getInstance() {
        if (instance == null) // 1：A线程执行
            instance = new Instance(); // 2：B线程执行
        return instance;
    }
}
</code></pre>
<p>在UnsafeLazyInitialization类中，假设A线程执行代码1的同时，B线程执行代码2。此时，线程A可能会看到instance引用的对象还没有完成初始化</p>
<pre><code class="language-java">做同步处理来实现线程安全的延迟初始化
public class SafeLazyInitialization {
    private static Instance instance;
    public synchronized static Instance getInstance() {
        if (instance == null)
            instance = new Instance();
        return instance;
    }
}
</code></pre>
<p>由于对getInstance()方法做了同步处理，synchronized将导致性能开销。如果getInstance()方法被多个线程频繁的调用，将会导致程序执行性能的下降。</p>
<pre><code class="language-java">通过双重检查锁定来降低同步的开销
public class DoubleCheckedLocking { // 1
    private static Instance instance; // 2
    public static Instance getInstance() { // 3
        if (instance == null) { // 4:第一次检查
            synchronized (DoubleCheckedLocking.class) { // 5:加锁
                if (instance == null) // 6:第二次检查
                    instance = new Instance(); // 7:问题的根源出在这里
            } // 8
        } // 9
        return instance; // 10
    } // 11
}
</code></pre>
<p>双重检查锁定看起来似乎很完美，但这是一个错误的优化！在线程执行到第4行，代码读取到instance不为null时，instance引用的对象有可能还没有完成初始化。</p>
<h3 id="282-问题的根源">2.8.2 问题的根源</h3>
<p>前面的双重检查锁定示例代码的第7行（instance=new Singleton();）创建了一个对象。这一行代码可以分解为如下的3步。</p>
<pre><code>1：分配对象的内存空间
2：初始化对象
3：设置instance指向刚分配的内存地址
</code></pre>
<p>上面3步中的2和3之间，可能会被重排序。</p>
<p>在知晓了问题发生的根源之后，我们可以想出两个办法来实现线程安全的延迟初始化。</p>
<pre><code>1）不允许2和3重排序。
2）允许2和3重排序，但不允许其他线程“看到”这个重排序。
</code></pre>
<h3 id="283-基于volatile的解决方案">2.8.3 基于volatile的解决方案</h3>
<pre><code class="language-java">public class SafeDoubleCheckedLocking {
    private volatile static Instance instance;

    public static Instance getInstance() {
        if (instance == null) {
            synchronized (SafeDoubleCheckedLocking.class) {
                if (instance == null){
                    instance = new Instance(); // instance为volatile，现在没问题了
                }
            }
            return instance;
        }
    }

}
</code></pre>
<p>当声明对象的引用为volatile后，通过禁止图3-39中的2和3之间的重排序，来保证线程安全的延迟初始<br>
化。</p>
<h3 id="284-基于类初始化的解决方案">2.8.4 基于类初始化的解决方案</h3>
<p>JVM在类的初始化阶段（即在Class被加载后，且被线程使用之前），会执行类的初始化。在执行类的初始化期间，JVM会去获取一个锁。这个锁可以同步多个线程对同一个类的初始化。</p>
<pre><code class="language-java">public class InstanceFactory {
    private static class InstanceHolder {
        public static Instance instance = new Instance();
    }
    public static Instance getInstance() {
        return InstanceHolder.instance ; // 这里将导致InstanceHolder类被初始化
    }
}
</code></pre>
<h1 id="3-java并发编程基础">3 Java并发编程基础</h1>
<h2 id="31-线程简介">3.1 线程简介</h2>
<h3 id="311-什么是线程">3.1.1 什么是线程</h3>
<p>操作系统调度的最小单元是线程，也叫轻量级进程（LightWeight Process），在一个进程里可以创建多个线程，这些线程都拥有各自的计数器、堆栈和局部变量等属性，并且能够访问共享的内存变量。</p>
<h3 id="312-为什么要使用多线程">3.1.2 为什么要使用多线程</h3>
<h3 id="313-线程优先级">3.1.3 线程优先级</h3>
<p>现代操作系统基本采用时分的形式调度运行的线程，操作系统会分出一个个时间片，线程会分配到若干时间片，当线程的时间片用完了就会发生线程调度，并等待着下次分配。线程分配到的时间片多少也就决定了线程使用处理器资源的多少，而<strong>线程优先级就是决定线程需要多或者少分配一些处理器资源的线程属性</strong>。</p>
<p>在Java线程中，通过一个整型成员变量<strong>priority</strong>来控制优先级，优先级的范围从1~10，在线程构建的时候可以通过setPriority(int)方法来修改优先级，默认优先级是5，优先级高的线程分配时间片的数量要多于优先级低的线程。设置线程优先级时，针对频繁阻塞（休眠或者I/O操作）的线程需要设置较高优先级，而偏重计算（需要较多CPU时间或者偏运算）的线程则设置较低的优先级，确保处理器不会被独占。</p>
<p><em>线程优先级不能作为程序正确性的依赖，在不同的JVM以及操作系统上，线程规划会存在差异，有些操作系统甚至会忽略对线程优先级的设定。</em></p>
<h3 id="314-线程的状态">3.1.4 线程的状态</h3>
<p>Java线程在运行的生命周期中可能6种不同的状态，在给定的一个时刻，线程只能处于其中的一个状态。</p>
<figure data-type="image" tabindex="12"><img src="https://q456qq520.github.io/post-images/1659946257434.png" alt="Java线程的状态" loading="lazy"></figure>
<p>线程在自身的生命周期中，并不是固定地处于某个状态，而是随着代码的执行在不同的状态之间进行切换。</p>
<figure data-type="image" tabindex="13"><img src="https://q456qq520.github.io/post-images/1659946809181.png" alt="Java线程状态变迁" loading="lazy"></figure>
<p>线程创建之后，调用start()方法开始运行。当线程执行wait()方法之后，线程进入等待状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而超时等待状态相当于在等待状态的基础上增加了超时限制，也就是超时时间到达时将会返回到运行状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到阻塞状态。线程在执行Runnable的run()方法之后将会进入到终止状态。</p>
<p><em>注意 Java将操作系统中的运行和就绪两个状态合并称为运行状态。阻塞状态是线程阻塞在进入synchronized关键字修饰的方法或代码块（获取锁）时的状态，但是阻塞在java.concurrent包中Lock接口的线程状态却是等待状态，因为java.concurrent包中Lock接口对于阻塞的实现均使用了LockSupport类中的相关方法。</em></p>
<h3 id="315-daemon线程守护线程">3.1.5 Daemon线程（守护线程）</h3>
<p>Daemon线程是一种支持型线程，因为它主要被用作程序中后台调度以及支持性工作。这意味着，当一个Java虚拟机中不存在非Daemon线程的时候，Java虚拟机将会退出。可以通过调用Thread.setDaemon(true)将线程设置为Daemon线程。</p>
<p><strong>Daemon属性需要在启动线程之前设置，不能在启动线程之后设置。</strong></p>
<p>Daemon线程被用作完成支持性工作，但是在Java虚拟机退出时Daemon线程中的finally块并不一定会执行。</p>
<pre><code class="language-java">package cm;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/8 16:32
 */
public class DaemonThread {
    public static void main(String[] args) {
        Thread thread = new Thread(new DaemonRunner(), &quot;DaemonRunner&quot;);
        thread.setDaemon(true);
        thread.start();
    }
    
    static class DaemonRunner implements Runnable {
        @Override
        public void run() {
            try {
                SleepUtils.second(10);
            } finally {
                System.out.println(&quot;DaemonThread finally run.&quot;);
            }
        }
    }
}
</code></pre>
<p>运行Daemon程序，可以看到在终端或者命令提示符上没有任何输出。main线程（非Daemon线程）在启动了线程DaemonRunner之后随着main方法执行完毕而终止，而此时Java虚拟机中已经没有非Daemon线程，虚拟机需要退出。Java虚拟机中的所有Daemon线程都需要立即终止，因此DaemonRunner立即终止，但是DaemonRunner中的finally块并没有执行。</p>
<p><em>注意 在构建Daemon线程时，不能依靠finally块中的内容来确保执行关闭或清理资源的逻辑。</em></p>
<h2 id="32-启动和终止线程">3.2 启动和终止线程</h2>
<h3 id="321-构造线程">3.2.1 构造线程</h3>
<p>在运行线程之前首先要构造一个线程对象，线程对象在构造的时候需要提供线程所需要的属性，如线程所属的线程组、线程优先级、是否是Daemon线程等信息。</p>
<p>下面是java.lang.Thread中对线程进行初始化：</p>
<pre><code class="language-java">private void init(ThreadGroup g, Runnable target, String name,
                      long stackSize, AccessControlContext acc,
                      boolean inheritThreadLocals) {
        if (name == null) {
            throw new NullPointerException(&quot;name cannot be null&quot;);
        }

        this.name = name;
        //当前线程就是该线程的父线程
        Thread parent = currentThread();
        SecurityManager security = System.getSecurityManager();
        if (g == null) {
            /* Determine if it's an applet or not */

            /* If there is a security manager, ask the security manager
               what to do. */
            if (security != null) {
                g = security.getThreadGroup();
            }

            /* If the security doesn't have a strong opinion of the matter
               use the parent thread group. */
            if (g == null) {
                g = parent.getThreadGroup();
            }
        }

        /* checkAccess regardless of whether or not threadgroup is
           explicitly passed in. */
        g.checkAccess();

        /*
         * Do we have the required permissions?
         */
        if (security != null) {
            if (isCCLOverridden(getClass())) {
                security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION);
            }
        }

        g.addUnstarted();

        this.group = g;
        // 将daemon、priority属性设置为父线程的对应属性
        this.daemon = parent.isDaemon();
        this.priority = parent.getPriority();
        if (security == null || isCCLOverridden(parent.getClass()))
            this.contextClassLoader = parent.getContextClassLoader();
        else
            this.contextClassLoader = parent.contextClassLoader;
        this.inheritedAccessControlContext =
                acc != null ? acc : AccessController.getContext();
        this.target = target;
        setPriority(priority);
        // 将父线程的InheritableThreadLocal复制过来
        if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null)
            this.inheritableThreadLocals =
                ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
        /* Stash the specified stack size in case the VM cares */
        this.stackSize = stackSize;

        /* Set thread ID 分配一个线程ID */
        tid = nextThreadID();
    }
</code></pre>
<p>一个新构造的线程对象是由其parent线程来进行空间分配的，而child线程继承了parent是否为Daemon、优先级和加载资源的contextClassLoader以及可继承的ThreadLocal，同时还会分配一个唯一的ID来标识这个child线程。至此，一个能够运行的线程对象就初始化好了，在堆内存中等待着运行。</p>
<h3 id="322-启动线程">3.2.2 启动线程</h3>
<p>线程对象在初始化完成之后，调用start()方法就可以启动这个线程。线程start()方法的含义是：当前线程（即parent线程）同步告知Java虚拟机，只要线程规划器空闲，应立即启动调用start()方法的线程。</p>
<p><em>注意 启动一个线程前，最好为这个线程设置线程名称，因为这样在使用jstack分析程序或者进行问题排查时，就会给开发人员提供一些提示，自定义的线程最好能够起个名字。</em></p>
<h3 id="323-理解中断">3.2.3 理解中断</h3>
<p>中断可以理解为线程的一个标识位属性，它表示一个运行中的线程是否被其他线程进行了中断操作。中断好比其他线程对该线程打了个招呼，其他线程通过调用该线程的**interrupt()**方法对其进行中断操作。</p>
<p>线程通过检查自身是否被中断来进行响应，线程通过方法isInterrupted()来进行判断是否被中断，也可以调用静态方法Thread.interrupted()对当前线程的中断标识位进行复位。如果该线程已经处于终结状态，即使该线程被中断过，在调用该线程对象的isInterrupted()时依旧会返回false。</p>
<p>从Java的API中可以看到，许多声明抛出InterruptedException的方法（例如Thread.sleep(long<br>
millis)方法）这些方法在抛出InterruptedException之前，Java虚拟机会先将该线程的中断标识位清除，然后抛出InterruptedException，此时调用isInterrupted()方法将会返回false。</p>
<p>在下述例子中，首先创建了两个线程，SleepThread和BusyThread，前者不停地睡眠，后者一直运行，然后对这两个线程分别进行中断操作，观察二者的中断标识位。</p>
<pre><code class="language-java">package cm;

import java.util.concurrent.TimeUnit;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/8 18:08
 */
public class Interrupted {
    public static void main(String[] args) throws Exception {
        // sleepThread不停的尝试睡眠
        Thread sleepThread = new Thread(new SleepRunner(), &quot;SleepThread&quot;);
        sleepThread.setDaemon(true);
        // busyThread不停的运行
        Thread busyThread = new Thread(new BusyRunner(), &quot;BusyThread&quot;);
        busyThread.setDaemon(true);
        sleepThread.start();
        busyThread.start();
        // 休眠5秒，让sleepThread和busyThread充分运行
        TimeUnit.SECONDS.sleep(5);
        sleepThread.interrupt();
        busyThread.interrupt();
        System.out.println(&quot;SleepThread interrupted is &quot; + sleepThread.isInterrupted());
        System.out.println(&quot;BusyThread interrupted is &quot; + busyThread.isInterrupted());
        // 防止sleepThread和busyThread立刻退出
        SleepUtils.second(2);
    }
    static class SleepRunner implements Runnable {
        @Override
        public void run() {
            while (true) {
                SleepUtils.second(10);
            }
        }
    }
    static class BusyRunner implements Runnable {
        @Override
        public void run() {
            while (true) {
            }
        }
    }
}
</code></pre>
<pre><code>输出：
SleepThread interrupted is false
BusyThread interrupted is true
</code></pre>
<p>从结果可以看出，抛出InterruptedException的线程SleepThread，其中断标识位被清除了，而一直忙碌运作的线程BusyThread，中断标识位没有被清除。</p>
<h3 id="324-过期的suspend-resume和stop">3.2.4 过期的suspend()、resume()和stop()</h3>
<p>在下面所示的例子中，创建了一个线程PrintThread，它以1秒的频率进行打印，而主线程对其进行暂停、恢复和停止操作。</p>
<pre><code class="language-java">package cm;

import java.text.DateFormat;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.concurrent.TimeUnit;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/9 11:14
 */
public class Deprecated {
    public static void main(String[] args) throws Exception {
        DateFormat format = new SimpleDateFormat(&quot;HH:mm:ss&quot;);
        Thread printThread = new Thread(new Runner(), &quot;PrintThread&quot;);
        printThread.setDaemon(true);
        printThread.start();
        TimeUnit.SECONDS.sleep(3);
        // 将PrintThread进行暂停，输出内容工作停止
        printThread.suspend();
        System.out.println(&quot;main suspend PrintThread at &quot; + format.format(new Date());
        TimeUnit.SECONDS.sleep(3);
        // 将PrintThread进行恢复，输出内容继续
        printThread.resume();
        System.out.println(&quot;main resume PrintThread at &quot; + format.format(new Date()));
        TimeUnit.SECONDS.sleep(3);
        // 将PrintThread进行终止，输出内容停止
        printThread.stop();
        System.out.println(&quot;main stop PrintThread at &quot; + format.format(new Date()));
        TimeUnit.SECONDS.sleep(3);
    }

    static class Runner implements Runnable {
        @Override
        public void run() {
            DateFormat format = new SimpleDateFormat(&quot;HH:mm:ss&quot;);
            while (true) {
                System.out.println(Thread.currentThread().getName() + &quot; Run at &quot; +
                        format.format(new Date()));
                SleepUtils.second(1);
            }
        }
    }
}
</code></pre>
<p>在执行过程中，PrintThread运行了3秒，随后被暂停，3秒后恢复，最后经过3秒被终止。通过示例的输出可以看到，suspend()、resume()和stop()方法完成了线程的暂停、恢复和终止工作，而且非常“人性化”。但是这些API是过期的，也就是不建议使用的。</p>
<p>不建议使用的原因主要有：以suspend()方法为例，在调用后，线程不会释放已经占有的资源（比如锁），而是占有着资源进入睡眠状态，这样容易引发死锁问题。同样，stop()方法在终结一个线程时不会保证线程的资源正常释放，通常是没有给予线程完成资源释放工作的机会，因此会导致程序可能工作在不确定状态下。</p>
<p><em>暂停和恢复操作可以用后面提到的等待/通知机制来替代。</em></p>
<h3 id="325-安全地终止线程">3.2.5 安全地终止线程</h3>
<p>中断状态是线程的一个标识位，而中断操作是一种简便的线程间交互方式，而这种交互方式最适合用来取消或停止任务。除了中断以外，还可以利用一个boolean变量来控制是否需要停止任务并终止该线程。</p>
<p>在下面所示的例子中，创建了一个线程CountThread，它不断地进行变量累加，而主线程尝试对其进行中断操作和停止操作。</p>
<pre><code class="language-java">package cm;

import java.util.concurrent.TimeUnit;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/9 11:21
 */
public class Shutdown {
    public static void main(String[] args) throws Exception {
        Runner one = new Runner();
        Thread countThread = new Thread(one, &quot;CountThread&quot;);
        countThread.start();
        // 睡眠1秒，main线程对CountThread进行中断，使CountThread能够感知中断而结束
        TimeUnit.SECONDS.sleep(1);
        countThread.interrupt();
        Runner two = new Runner();
        countThread = new Thread(two, &quot;CountThread&quot;);
        countThread.start();
        // 睡眠1秒，main线程对Runner two进行取消，使CountThread能够感知on为false而结束
        TimeUnit.SECONDS.sleep(1);
        two.cancel();
    }
    private static class Runner implements Runnable {
        private long i;
        private volatile boolean on = true;
        @Override
        public void run() {
            while (on &amp;&amp; !Thread.currentThread().isInterrupted()){
                i++;
            }
            System.out.println(&quot;Count i = &quot; + i);
        }
        public void cancel() {
            on = false;
        }
    }
}
</code></pre>
<p>main线程通过中断操作和cancel()方法均可使CountThread得以终止。这种通过标识位或者中断操作的方式能够使线程在终止时有机会去清理资源，而不是武断地将线程停止，因此这种终止线程的做法显得更加安全和优雅。</p>
<h2 id="33-线程间通信">3.3 线程间通信</h2>
<h3 id="331-volatile和synchronized关键字">3.3.1 volatile和synchronized关键字</h3>
<p>Java支持多个线程同时访问一个对象或者对象的成员变量，由于每个线程可以拥有这个变量的拷贝（虽然对象以及成员变量分配的内存是在共享内存中的，但是每个执行的线程还是可以拥有一份拷贝，这样做的目的是加速程序的执行），所以程序在执行过程中，一个线程看到的变量并不一定是最新的。</p>
<p>关键字<strong>volatile</strong>可以用来修饰字段（成员变量），就是告知程序任何对该变量的访问均需要从共享内存中获取，而对它的改变必须同步刷新回共享内存，它能保证所有线程对变量访问的可见性。</p>
<p>关键字<strong>synchronized</strong>可以修饰方法或者以同步块的形式来进行使用，它主要确保多个线程在同一个时刻，只能有一个线程处于方法或者同步块中，它保证了线程对变量访问的可见性和排他性。</p>
<p>任意一个对象都拥有自己的<strong>监视器</strong>，当这个对象由同步块或者这个对象的同步方法调用时，执行方法的线程必须先获取到该对象的监视器才能进入同步块或者同步方法，而没有获取到监视器（执行该方法）的线程将会被阻塞在同步块和同步方法的入口处，进入BLOCKED状态。无论采用哪种方式，其本质是对一个对象的监视器（monitor）进行获取，而这个获取过程是排他的，也就是同一时刻只能有一个线程获取到由synchronized所保护对象的监视器。</p>
<figure data-type="image" tabindex="14"><img src="https://q456qq520.github.io/post-images/1660025976820.png" alt="对象、监视器、同步队列和执行线程之间的关系" loading="lazy"></figure>
<p>从图中可以看到，任意线程对Object（Object由synchronized保护）的访问，首先要获得Object的监视器。如果获取失败，线程进入同步队列，线程状态变为BLOCKED。当访问Object的前驱（获得了锁的线程）释放了锁，则该释放操作唤醒阻塞在同步队列中的线程，使其重新尝试对监视器的获取。</p>
<h3 id="332-等待通知机制">3.3.2 等待/通知机制</h3>
<p>等待/通知的相关方法是任意Java对象都具备的，因为这些方法被定义在所有对象的超类java.lang.Object上。</p>
<figure data-type="image" tabindex="15"><img src="https://q456qq520.github.io/post-images/1660026163692.png" alt="等待/通知的相关方法" loading="lazy"></figure>
<p>等待/通知机制，是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B调用了对象O的notify()或者notifyAll()方法，线程A收到通知后从对象O的wait()方法返回，进而执行后续操作。上述两个线程通过对象O来完成交互，而对象上的wait()和notify/notifyAll()的关系就如同开关信号一样，用来完成等待方和通知方之间的交互工作。</p>
<p>调用wait()、notify()以及notifyAll()时需要注意的细节，如下。</p>
<pre><code>1）使用wait()、notify()和notifyAll()时需要先对调用对象加锁。
2）调用wait()方法后，线程状态由RUNNING变为WAITING，并将当前线程放置到对象的等待队列。
3）notify()或notifyAll()方法调用后，等待线程依旧不会从wait()返回，需要调用notify()或notifAll()的线程释放锁之后，等待线程才有机会从wait()返回。
4）notify()方法将等待队列中的一个等待线程从等待队列中移到同步队列中，而notifyAll()方法则是将等待队列中所有的线程全部移到同步队列，被移动的线程状态由WAITING变为BLOCKED。
5）从wait()方法返回的前提是获得了调用对象的锁。
</code></pre>
<p>等待/通知机制依托于同步机制，其目的就是确保等待线程从wait()方法返回时能够感知到通知线程对变量做出的修改。</p>
<h3 id="333-等待通知的经典范式">3.3.3 等待/通知的经典范式</h3>
<p>该范式分为两部分，分别针对<strong>等待方</strong>（消费者）和<strong>通知方</strong>（生产者）。</p>
<p>等待方遵循如下原则。</p>
<pre><code>1）获取对象的锁。
2）如果条件不满足，那么调用对象的wait()方法，被通知后仍要检查条件。
3）条件满足则执行对应的逻辑。
</code></pre>
<pre><code class="language-java">synchronized(对象) {
        while(条件不满足) {
        对象.wait();
        }
        对应的处理逻辑
}
</code></pre>
<p>通知方遵循如下原则。</p>
<pre><code>1）获得对象的锁。
2）改变条件。
3）通知所有等待在对象上的线程。
</code></pre>
<pre><code class="language-java">synchronized(对象) {
    改变条件
    对象.notifyAll();
}
</code></pre>
<h3 id="334-管道输入输出流">3.3.4 管道输入/输出流</h3>
<p>管道输入/输出流和普通的文件输入/输出流或者网络输入/输出流不同之处在于，它主要用于线程之间的数据传输，而传输的媒介为内存。</p>
<p>管道输入/输出流主要包括了如下4种具体实现：PipedOutputStream、PipedInputStream、PipedReader和PipedWriter，前两种面向字节，而后两种面向字符。</p>
<p>示例代码如下,创建了printThread，它用来接受main线程的输入，任何main线程的输入均通过PipedWriter写入，而printThread在另一端通过PipedReader将内容读出并打印。</p>
<pre><code class="language-java">package cm;

import java.io.IOException;
import java.io.PipedReader;
import java.io.PipedWriter;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/9 15:25
 */
public class Piped {
    public static void main(String[] args) throws Exception {
        PipedWriter out = new PipedWriter();
        PipedReader in = new PipedReader();
        // 将输出流和输入流进行连接，否则在使用时会抛出IOException
        out.connect(in);
        Thread printThread = new Thread(new Print(in), &quot;PrintThread&quot;);
        printThread.start();
        int receive = 0;
        try {
            while ((receive = System.in.read()) != -1) {
                out.write(receive);
            }
        } finally {
            out.close();
        }
    }
    static class Print implements Runnable {
        private PipedReader in;
        public Print(PipedReader in) {
            this.in = in;
        }
        public void run() {
            int receive = 0;
            try {
                while ((receive = in.read()) != -1) {
                    System.out.print((char) receive);
                }
            } catch (IOException ex) {
            }
        }
    }
}

</code></pre>
<p>对于Piped类型的流，必须先要进行绑定，也就是调用connect()方法，如果没有将输入/输出流绑定起来，对于该流的访问将会抛出异常。</p>
<h3 id="335-threadjoin的使用">3.3.5 Thread.join()的使用</h3>
<p>如果一个线程A执行了thread.join()语句，其含义是：当前线程A等待thread线程终止之后才从thread.join()返回。线程Thread除了提供join()方法之外，还提供了join(long millis)和join(long millis,int nanos)两个具备超时特性的方法。这两个超时方法表示，如果线程thread在给定的超时时间没有终止，那么将会从该超时方法中返回。</p>
<p>在下面所示的例子中，创建了10个线程，编号0~9，每个线程调用前一个线程的join()方法，也就是线程0结束了，线程1才能从join()方法中返回，而线程0需要等待main线程结束。</p>
<pre><code class="language-java">package cm;

import java.util.concurrent.TimeUnit;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/9 15:37
 */
public class Join {
    public static void main(String[] args) throws Exception {
        Thread previous = Thread.currentThread();
        for (int i = 0; i &lt; 10; i++) {
        // 每个线程拥有前一个线程的引用，需要等待前一个线程终止，才能从等待中返回
            Thread thread = new Thread(new Domino(previous), String.valueOf(i));
            thread.start();
            previous = thread;
        }
        TimeUnit.SECONDS.sleep(5);
        System.out.println(Thread.currentThread().getName() + &quot; terminate.&quot;);
    }

    static class Domino implements Runnable {
        private Thread thread;
        public Domino(Thread thread) {
            this.thread = thread;
        }
        public void run() {
            try {
                thread.join();
            } catch (InterruptedException e) {
            }
            System.out.println(Thread.currentThread().getName() + &quot; terminate.&quot;);
        }
    }
}
</code></pre>
<p>每个线程终止的前提是前驱线程的终止，每个线程等待前驱线程终止后，才从join()方法返回，这里涉及了等待/通知机制（等待前驱线程结束，接收前驱线程结束通知）。</p>
<p>当线程终止时，会调用线程自身的notifyAll()方法，会通知所有等待在该线程对象上的线程。可以看到join()方法的逻辑结构，即加锁、循环和处理逻辑3个步骤。</p>
<h3 id="336-threadlocal的使用">3.3.6 ThreadLocal的使用</h3>
<p>ThreadLocal，即线程变量，是一个以ThreadLocal对象为键、任意对象为值的存储结构。这个结构被附带在线程上，也就是说一个线程可以根据一个ThreadLocal对象查询到绑定在这个线程上的一个值。</p>
<p>可以通过set(T)方法来设置一个值，在当前线程下再通过get()方法获取到原先设置的值。</p>
<p>在下面所示的例子中，构建了一个常用的Profiler类，它具有begin()和end()两个方法，而end()方法返回从begin()方法调用开始到end()方法被调用时的时间差，单位是毫秒。</p>
<pre><code class="language-java">package cm;

import java.util.concurrent.TimeUnit;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/9 16:56
 */
public class Profiler {
    // 第一次get()方法调用时会进行初始化（如果set方法没有调用），每个线程会调用一次
    private static final ThreadLocal&lt;Long&gt; TIME_THREADLOCAL = new ThreadLocal&lt;Long&gt;() {
        protected Long initialValue() {
            return System.currentTimeMillis();
        }
    };
    public static final void begin() {
        TIME_THREADLOCAL.set(System.currentTimeMillis());
    }
    public static final long end() {
        return System.currentTimeMillis() - TIME_THREADLOCAL.get();
    }
    public static void main(String[] args) throws Exception {
        Profiler.begin();
        TimeUnit.SECONDS.sleep(1);
        System.out.println(&quot;Cost: &quot; + Profiler.end() + &quot; mills&quot;);
    }
}
</code></pre>
<h2 id="34-线程应用实例">3.4 线程应用实例</h2>
<h3 id="341-等待超时模式">3.4.1 等待超时模式</h3>
<p>等待超时模式的伪代码如下。</p>
<pre><code class="language-java">    // 对当前对象加锁
    public synchronized Object get(long mills) throws InterruptedException {
        long future = System.currentTimeMillis() + mills;
        long remaining = mills;
// 当超时大于0并且result返回值不满足要求
        while ((result == null) &amp;&amp; remaining &gt; 0) {
            wait(remaining);
            remaining = future - System.currentTimeMillis();
        }
        return result;
    }
</code></pre>
<h3 id="342-一个简单的数据库连接池示例">3.4.2 一个简单的数据库连接池示例</h3>
<p>链接:<a href="/post/shu-ju-ku-lian-jie-chi-shi-li">数据库连接池示例</a></p>
<h3 id="343-线程池技术及其示例">3.4.3 线程池技术及其示例</h3>
<p>面对成千上万的任务递交进服务器时，如果还是采用一个任务一个线程的方式，那么将会创建数以万记的线程，这不是一个好的选择。因为这会使操作系统频繁的进行线程上下文切换，无故增加系统的负载，而线程的创建和消亡都是需要耗费系统资源的，也无疑浪费了系统资源。</p>
<p>线程池技术能够很好地解决这个问题，它预先创建了若干数量的线程，并且不能由用户直接对线程的创建进行控制，在这个前提下重复使用固定或较为固定数目的线程来完成任务的执行。这样做的好处是，一方面，消除了频繁创建和消亡线程的系统资源开销，另一方面，面对过量任务的提交能够平缓的劣化。</p>
<p>下面先看一个简单的线程池接口定义，示例如下：</p>
<pre><code class="language-java">package cm;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/10 11:35
 */
public interface ThreadPool&lt;Job extends Runnable&gt; {
    // 执行一个Job，这个Job需要实现Runnable
    void execute(Job job);
    // 关闭线程池
    void shutdown();
    // 增加工作者线程
    void addWorkers(int num);
    // 减少工作者线程
    void removeWorker(int num);
    // 得到正在等待执行的任务数量
    int getJobSize();
}
</code></pre>
<p>客户端可以通过execute(Job)方法将Job提交入线程池执行，而客户端自身不用等待Job的执行完成。除了execute(Job)方法以外，线程池接口提供了增大/减少工作者线程以及关闭线程池的方法。这里工作者线程代表着一个重复执行Job的线程，而每个由客户端提交的Job都将进入到一个工作队列中等待工作者线程的处理。</p>
<pre><code class="language-java">package cm;

import java.util.ArrayList;
import java.util.Collections;
import java.util.LinkedList;
import java.util.List;
import java.util.concurrent.atomic.AtomicLong;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/10 11:38
 */
public class DefaultThreadPool&lt;Job extends Runnable&gt; implements ThreadPool&lt;Job&gt; {
    // 线程池最大限制数
    private static final int MAX_WORKER_NUMBERS = 10;
    // 线程池默认的数量
    private static final int DEFAULT_WORKER_NUMBERS = 5;
    // 线程池最小的数量
    private static final int MIN_WORKER_NUMBERS = 1;
    // 这是一个工作列表，将会向里面插入工作
    private final LinkedList&lt;Job&gt; jobs = new LinkedList&lt;Job&gt;();
    // 工作者列表
    private final List&lt;Worker&gt; workers = Collections.synchronizedList(new ArrayList&lt;Worker&gt;());
    // 工作者线程的数量
    private int workerNum = DEFAULT_WORKER_NUMBERS;
    // 线程编号生成
    private AtomicLong threadNum = new AtomicLong();
    public DefaultThreadPool() {
        initializeWokers(DEFAULT_WORKER_NUMBERS);
    }
    public DefaultThreadPool(int num) {
        workerNum = num &gt; MAX_WORKER_NUMBERS ? MAX_WORKER_NUMBERS : num &lt; MIN_WORKER_NUMBERS ? MIN_WORKER_NUMBERS : num;
        initializeWokers(workerNum);
    }
    public void execute(Job job) {
        if (job != null) {
        // 添加一个工作，然后进行通知
            synchronized (jobs) {
                jobs.addLast(job);
                jobs.notify();
            }
        }
    }
    public void shutdown() {
        for (Worker worker : workers) {
            worker.shutdown();
        }
    }
    public void addWorkers(int num) {
        synchronized (jobs) {
            // 限制新增的Worker数量不能超过最大值
            if (num + this.workerNum &gt; MAX_WORKER_NUMBERS) {
                num = MAX_WORKER_NUMBERS - this.workerNum;
            }
            initializeWokers(num);
            this.workerNum += num;
        }
    }
    public void removeWorker(int num) {
        synchronized (jobs) {
            if (num &gt;= this.workerNum) {
                throw new IllegalArgumentException(&quot;beyond workNum&quot;);
            }
            // 按照给定的数量停止Worker
            int count = 0;
            while (count &lt; num) {
                Worker worker = workers.get(count);
                if (workers.remove(worker)) {
                    worker.shutdown();
                    count++;
                }
            }
            this.workerNum -= count;
        }
    }
    public int getJobSize() {
        return jobs.size();
    }
    // 初始化线程工作者
    private void initializeWokers(int num) {
        for (int i = 0; i &lt; num; i++) {
            Worker worker = new Worker();
            workers.add(worker);
            Thread thread = new Thread(worker, &quot;ThreadPool-Worker-&quot; + threadNum.incrementAndGet());
            thread.start();
        }
    }
    // 工作者，负责消费任务
    class Worker implements Runnable {
        // 是否工作
        private volatile boolean running = true;
        public void run() {
            while (running) {
                Job job = null;
                synchronized (jobs) {
             // 如果工作者列表是空的，那么就wait
                    while (jobs.isEmpty()) {
                        try {
                            jobs.wait();
                        } catch (InterruptedException ex) {
                            // 感知到外部对WorkerThread的中断操作，返回
                            Thread.currentThread().interrupt();
                            return;
                        }
                    }
                    // 取出一个Job
                    job = jobs.removeFirst();
                }
                if (job != null) {
                    try {
                        job.run();
                    } catch (Exception ex) {
                    // 忽略Job执行中的Exception
                    }
                }
            }
        }
        public void shutdown() {
            running = false;
        }
    }
}
</code></pre>
<p>从线程池的实现可以看到，当客户端调用execute(Job)方法时，会不断地向任务列表jobs中添加Job，而每个工作者线程会不断地从jobs上取出一个Job进行执行，当jobs为空时，工作者线程进入等待状态。</p>
<p>添加一个Job后，对工作队列jobs调用了其notify()方法，而不是notifyAll()方法，因为能够确定有工作者线程被唤醒，这时使用notify()方法将会比notifyAll()方法获得更小的开销（避免将等待队列中的线程全部移动到阻塞队列中）。</p>
<p>可以看到，线程池的本质就是使用了一个线程安全的工作队列连接工作者线程和客户端线程，客户端线程将任务放入工作队列后便返回，而工作者线程则不断地从工作队列上取出工作并执行。当工作队列为空时，所有的工作者线程均等待在工作队列上，当有客户端提交了一个任务之后会通知任意一个工作者线程，随着大量的任务被提交，更多的工作者线程会被唤醒。</p>
<h3 id="344-一个基于线程池技术的简单web服务器">3.4.4 一个基于线程池技术的简单Web服务器</h3>
]]></content>
    </entry>
</feed>