<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://q456qq520.github.io</id>
    <title>LIKECAT</title>
    <updated>2022-09-19T06:42:18.984Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://q456qq520.github.io"/>
    <link rel="self" href="https://q456qq520.github.io/atom.xml"/>
    <subtitle>一条小咸鱼</subtitle>
    <logo>https://q456qq520.github.io/images/avatar.png</logo>
    <icon>https://q456qq520.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, LIKECAT</rights>
    <entry>
        <title type="html"><![CDATA[RocketMq技术内幕笔记（三）]]></title>
        <id>https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-san/</id>
        <link href="https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-san/">
        </link>
        <updated>2022-09-15T03:54:22.000Z</updated>
        <summary type="html"><![CDATA[<h1 id="4-消息存储">4 消息存储</h1>
<h2 id="41-存储概要设计">4.1 存储概要设计</h2>
<p>RocketMQ主要存储的文件包括Comitlog文件、ConsumeQueue文件、IndexFile文<br>
件。</p>
]]></summary>
        <content type="html"><![CDATA[<h1 id="4-消息存储">4 消息存储</h1>
<h2 id="41-存储概要设计">4.1 存储概要设计</h2>
<p>RocketMQ主要存储的文件包括Comitlog文件、ConsumeQueue文件、IndexFile文<br>
件。</p>
<!-- more -->
<p>RocketMQ将所有主题的消息存储在同一个文件中，确保消息发送时顺序写文件。为了提高消息消费的效率， RocketMQ 引入了 ConsumeQueue 消息队列 文件，每个消息主题包含多个消息消费队列，每一个消息队列有一个消息文件 - IndexFile索引文件，其主要设计理念就是为了加速消息的检索性能，根据消息的属性快速从 Commitlog 文件中检索消息。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1663233972923.png" alt="RocketMQ 消息存储设计原理图" loading="lazy"></figure>
<p>1 ) CommitLog:消息存储文件，所有消息主题的消息都存储在 CommitLog 文件中 。<br>
2 ) ConsumeQueue :消息消费队列，消息到达CommitLog文件后，将异步转发到消息消费队列，供消息消费者消费 。<br>
3 ) IndexFile:消息索引文件，主要存储消息 Key 与 Offset 的对应关系 。<br>
4 )事务状态服务 : 存储每条消息的事务状态 。<br>
5 )定时消息服务:每一个延迟级别对应一个消息消费队列，存储延迟队列的消息拉取<br>
进度。</p>
<h2 id="42-初识消息存储">4.2 初识消息存储</h2>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1663311285978.png" alt="CommitLog" loading="lazy"></figure>
<ol>
<li>CommitLog 主要由几部分组成：</li>
</ol>
<p>MappedFileQueue： 主要用来操作相关数据存储文件。将一系列的MappedFile抽象成一个队列。<br>
FlushManager： 数据落地磁盘的管理，主要分为两类：实时数据刷盘(FlushRealTimeService),以及异步刷盘(GroupCommitService)<br>
FlushDiskWatcher： 刷盘观察者，处理队列中的刷盘请求，对于规定时间内没有刷盘成功的进行处理。</p>
<ol start="2">
<li>MappedFileQueue</li>
</ol>
<p>MappedFileQueue 是对数据存储文件的一个抽象，将多个数据文件抽象成为一个文件队列。通过这个文件队列对文件进行操作操作。同时保存一些 CommitLog 的属性。</p>
<ol start="3">
<li>MappedFile<br>
MappedFile 是对文件的抽象，包含了对RocketMQ数据文件的整个操作。例如获取文件名称、文件大小、判断文件是否可用、是否已经满了等等的操作。</li>
</ol>
<p>单个数据文件默认是 1G 。由于只用了一个字节保存Topic的长度所以Topic的最大长度是127字符。</p>
<p>消息存储实现类: org.apache.rocketmq.store.DefaultMessageStore。</p>
<blockquote>
<p>DefaultMessageStore的核心属性</p>
</blockquote>
<pre><code class="language-java">//消息存储配置属性
private final MessageStoreConfig messageStoreConfig;
//CommitLog 文件的存储实现类
private final CommitLog commitLog;
//消息队列存储
private final ConsumeQueueStore consumeQueueStore;
//消息队列文件 ConsumeQueue刷盘线程。
private final FlushConsumeQueueService flushConsumeQueueService;
//清除 CommitLog 文件服务
private final CleanCommitLogService cleanCommitLogService;
//清除 ConsumeQueue 文件服务
private final CleanConsumeQueueService cleanConsumeQueueService;

private final CorrectLogicOffsetService correctLogicOffsetService;

//索引文件实现类
private final IndexService indexService;
//MappedFile 分配服务
private final AllocateMappedFileService allocateMappedFileService;
//CommitLog消息分发，根据 CommitLog文件构建 ConsumeQueue、 IndexFile 文件 。
private ReputMessageService reputMessageService;
//存储 HA 机制
private HAService haService;
//消息堆内存缓存
private final StoreStatsService storeStatsService;
private final TransientStorePool transientStorePool;

private final RunningFlags runningFlags = new RunningFlags();
private final SystemClock systemClock = new SystemClock();

private final ScheduledExecutorService scheduledExecutorService;
private final BrokerStatsManager brokerStatsManager;
//消息拉取长轮询模式消息达到监听器
private final MessageArrivingListener messageArrivingListener;
//Broker配置属性
private final BrokerConfig brokerConfig;

private volatile boolean shutdown = true;
//文件刷盘检测点
private StoreCheckpoint storeCheckpoint;
private TimerMessageStore timerMessageStore;

private AtomicLong printTimes = new AtomicLong(0);
//CommitLog 文件转发请求
private final LinkedList&lt;CommitLogDispatcher&gt; dispatcherList;
</code></pre>
<h2 id="43-消息发送存储流程">4.3 消息发送存储流程</h2>
<p><img src="https://q456qq520.github.io/post-images/1663315678088.png" alt="消息存储时序图" loading="lazy"><br>
消息存储入口: org.apache.rocketmq.store.DefaultMessageStore#putMessage。</p>
<p><strong>Step 1</strong>:如果当前Broker停止工作或 Broker为SLAVE角色或当前Rocket不支持写入则拒绝消息写入;如果消息主题长度超过256个字符、消息属性长度超过65536个字符将拒绝该消息写人。</p>
<p><strong>Step 2</strong>:如果消息的延迟级别大于0，将消息的原主题名称与原消息队列 ID 存入消息属性中，用延迟消息主题SCHEDULE_TOPIC、消息队列 ID 更新原先消息的主题与队列。</p>
<p><strong>Step 3</strong>:获取当前可以写入的 Commitlog文件</p>
<pre><code class="language-java">MappedFile unlockMappedFile = null;
MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile();
</code></pre>
<p>Commitlog文件存储目录为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi>R</mi><mi>O</mi><mi>C</mi><mi>K</mi><mi>E</mi><msub><mi>T</mi><mi>H</mi></msub><mi>O</mi><mi>M</mi><mi>E</mi></mrow><mi mathvariant="normal">/</mi><mi>s</mi><mi>t</mi><mi>o</mi><mi>r</mi><mi>e</mi><mi mathvariant="normal">/</mi><mi>c</mi><mi>o</mi><mi>m</mi><mi>m</mi><mi>i</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi mathvariant="normal">目</mi><mi mathvariant="normal">录</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">每</mi><mi mathvariant="normal">一</mi><mi mathvariant="normal">个</mi><mi mathvariant="normal">文</mi><mi mathvariant="normal">件</mi><mi mathvariant="normal">默</mi><mi mathvariant="normal">认</mi><mn>1</mn><mi>G</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">一</mi><mi mathvariant="normal">个</mi><mi mathvariant="normal">文</mi><mi mathvariant="normal">件</mi><mi mathvariant="normal">写</mi><mi mathvariant="normal">满</mi><mi mathvariant="normal">后</mi><mi mathvariant="normal">再</mi><mi mathvariant="normal">创</mi><mi mathvariant="normal">建</mi><mi mathvariant="normal">另</mi><mi mathvariant="normal">外</mi><mi mathvariant="normal">一</mi><mi mathvariant="normal">个</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">以</mi><mi mathvariant="normal">该</mi><mi mathvariant="normal">文</mi><mi mathvariant="normal">件</mi><mi mathvariant="normal">中</mi><mi mathvariant="normal">第</mi><mi mathvariant="normal">一</mi><mi mathvariant="normal">个</mi><mi mathvariant="normal">偏</mi><mi mathvariant="normal">移</mi><mi mathvariant="normal">量</mi><mi mathvariant="normal">为</mi><mi mathvariant="normal">文</mi><mi mathvariant="normal">件</mi><mi mathvariant="normal">名</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">偏</mi><mi mathvariant="normal">移</mi><mi mathvariant="normal">量</mi><mi mathvariant="normal">小</mi><mi mathvariant="normal">于</mi><mn>20</mn><mi mathvariant="normal">位</mi><mi mathvariant="normal">用</mi><mn>0</mn><mi mathvariant="normal">补</mi><mi mathvariant="normal">齐</mi><mi mathvariant="normal">。</mi><mi>M</mi><mi>a</mi><mi>p</mi><mi>p</mi><mi>e</mi><mi>d</mi><mi>F</mi><mi>i</mi><mi>l</mi><mi>e</mi><mi>Q</mi><mi>u</mi><mi>e</mi><mi>u</mi><mi>e</mi><mi mathvariant="normal">可</mi><mi mathvariant="normal">以</mi><mi mathvariant="normal">看</mi><mi mathvariant="normal">作</mi><mi mathvariant="normal">是</mi></mrow><annotation encoding="application/x-tex">{ROCKET_HOME}/store/commitlog 目录，每一个文件默认1G，一个文件写满后再创建另外一个，以该文件中第一个偏移量为文件名，偏移量小于20位用0补齐。MappedFileQueue 可以看作是</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.08125em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span><span class="mord">/</span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord">/</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">m</span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord cjk_fallback">目</span><span class="mord cjk_fallback">录</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">每</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">件</span><span class="mord cjk_fallback">默</span><span class="mord cjk_fallback">认</span><span class="mord">1</span><span class="mord mathdefault">G</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">件</span><span class="mord cjk_fallback">写</span><span class="mord cjk_fallback">满</span><span class="mord cjk_fallback">后</span><span class="mord cjk_fallback">再</span><span class="mord cjk_fallback">创</span><span class="mord cjk_fallback">建</span><span class="mord cjk_fallback">另</span><span class="mord cjk_fallback">外</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">以</span><span class="mord cjk_fallback">该</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">件</span><span class="mord cjk_fallback">中</span><span class="mord cjk_fallback">第</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">偏</span><span class="mord cjk_fallback">移</span><span class="mord cjk_fallback">量</span><span class="mord cjk_fallback">为</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">件</span><span class="mord cjk_fallback">名</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">偏</span><span class="mord cjk_fallback">移</span><span class="mord cjk_fallback">量</span><span class="mord cjk_fallback">小</span><span class="mord cjk_fallback">于</span><span class="mord">2</span><span class="mord">0</span><span class="mord cjk_fallback">位</span><span class="mord cjk_fallback">用</span><span class="mord">0</span><span class="mord cjk_fallback">补</span><span class="mord cjk_fallback">齐</span><span class="mord cjk_fallback">。</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault">a</span><span class="mord mathdefault">p</span><span class="mord mathdefault">p</span><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">e</span><span class="mord mathdefault">Q</span><span class="mord mathdefault">u</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault">e</span><span class="mord cjk_fallback">可</span><span class="mord cjk_fallback">以</span><span class="mord cjk_fallback">看</span><span class="mord cjk_fallback">作</span><span class="mord cjk_fallback">是</span></span></span></span>  {ROCKET_HOME}/store/commitlog文件夹，而MappedFile则对应该文件夹下一个个的文件。</p>
<p><strong>Step 4</strong>:在写入Commitlog之前，先申请putMessageLock,也就是将消息存储到Commitlog文件中是串行的 。</p>
<pre><code class="language-java">putMessageLock.lock(); //spin or ReentrantLock ,depending on store config
</code></pre>
<p>**Step 5 **:设置消息的存储时间，如果mappedFile为空，表明$  {ROCKET_HOME}/store/Commitlog目录下不存在任何文件，说明本次消息是第一次消息发送，用偏移量0创建第一个commit文件，文件为 00000000000000000000，如果文件创建失败，抛出 CREATE MAPEDFILE FAILED，很有可能是磁盘空间不足或权限不够。</p>
<pre><code class="language-java">if (null == mappedFile || mappedFile.isFull()) {
    mappedFile = this.mappedFileQueue.getLastMappedFile(0); // Mark: NewFile may be cause noise
}
if (null == mappedFile) {
    log.error(&quot;create mapped file1 error, topic: &quot; + msg.getTopic() + &quot; clientAddr: &quot; + msg.getBornHostString());
    beginTimeInLock = 0;
    return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.CREATE_MAPPED_FILE_FAILED, null));
}
</code></pre>
<p><strong>Step 6</strong> :将消息追加到 MappedFile 中。 首先先获取 MappedFile 当前写指针，如果currentPos大于或等于文件大小则表明文件已写满，抛出 AppendMessageStatus.UNKNOWN_ ERROR。 如果 currentPos小于文件大小，通过 slice()方法创建一个与 MappedFile 的共享内存区，并设置position 为当前指针。</p>
<pre><code class="language-java">public AppendMessageResult appendMessagesInner(final MessageExt messageExt, final AppendMessageCallback cb,
                                                PutMessageContext putMessageContext) {
    assert messageExt != null;
    assert cb != null;

    int currentPos = WROTE_POSITION_UPDATER.get(this);

    if (currentPos &lt; this.fileSize) {
        ByteBuffer byteBuffer = appendMessageBuffer().slice();
        byteBuffer.position(currentPos);
        AppendMessageResult result;
        if (messageExt instanceof MessageExtBatch &amp;&amp; !((MessageExtBatch) messageExt).isInnerBatch()) {
            // traditional batch message
            result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos,
                    (MessageExtBatch) messageExt, putMessageContext);
        } else if (messageExt instanceof MessageExtBrokerInner) {
            // traditional single message or newly introduced inner-batch message
            result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos,
                    (MessageExtBrokerInner) messageExt, putMessageContext);
        } else {
            return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR);
        }
        WROTE_POSITION_UPDATER.addAndGet(this, result.getWroteBytes());
        this.storeTimestamp = result.getStoreTimestamp();
        return result;
    }
    log.error(&quot;MappedFile.appendMessage return null, wrotePosition: {} fileSize: {}&quot;, currentPos, this.fileSize);
    return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR);
}
</code></pre>
<p><strong>Step 7</strong>:创建全局唯一消息 ID，消息ID有16字节。前4字节为IP，中间4字节为端口号，最后8字节为消息偏移量。</p>
<pre><code class="language-java">long wroteOffset = fileFromOffset + byteBuffer.position();

Supplier&lt;String&gt; msgIdSupplier = () -&gt; {
    int sysflag = msgInner.getSysFlag();
    int msgIdLen = (sysflag &amp; MessageSysFlag.STOREHOSTADDRESS_V6_FLAG) == 0 ? 4 + 4 + 8 : 16 + 4 + 8;
    ByteBuffer msgIdBuffer = ByteBuffer.allocate(msgIdLen);
    MessageExt.socketAddress2ByteBuffer(msgInner.getStoreHost(), msgIdBuffer);
    msgIdBuffer.clear();//because socketAddress2ByteBuffer flip the buffer
    msgIdBuffer.putLong(msgIdLen - 8, wroteOffset);
    return UtilAll.bytes2string(msgIdBuffer.array());
};
</code></pre>
<p>可以通过 UtilAll.bytes2string方法将 msgld 字节数组转换成字符串，通过 Uti1All.string2bytes 方法将msgld字符串还原成16个字节的字节数组，从而根据提取消息偏移量，可以快速通过msgld找到消息内容。</p>
<p><strong>Step 8</strong> : 获取该消息在消息队列的偏移量。CommitLog中保存了当前所有消息队列的当前待写入偏移量。</p>
<p><strong>Step 9</strong>:根据消息、体的长度、主题的长度、属性的长度结合消息存储格式计算消息的总长度。</p>
<p><strong>Step l0</strong> :如果消息长度+END_FILE_MIN_BLANK_LENGTH大于CommitLog文件的空闲空间，则返回 AppendMessageStatus.END_OF_FILE, Broker会重新创建一个新的 CommitLog文件来存储该消息。 从这里可以看出，每个CommitLog文件最少会空闲 8个字 节，高4字节存储当前文件剩余空间，低4字节存储魔数 : CommitLog.BLANK MAGIC CODE 。</p>
<pre><code class="language-java">if ((msgLen + END_FILE_MIN_BLANK_LENGTH) &gt; maxBlank) {
    this.msgStoreItemMemory.clear();
    // 1 TOTALSIZE
    this.msgStoreItemMemory.putInt(maxBlank);
    // 2 MAGICCODE
    this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE);
    // 3 The remaining space may be any value
    // Here the length of the specially set maxBlank
    final long beginTimeMills = CommitLog.this.defaultMessageStore.now();
    byteBuffer.put(this.msgStoreItemMemory.array(), 0, 8);
    return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, wroteOffset,
        maxBlank, /* only wrote 8 bytes, but declare wrote maxBlank for compute write position */
        msgIdSupplier, msgInner.getStoreTimestamp(),
        queueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills);
}
</code></pre>
<p><strong>Step 11</strong> :将消息内容存储到ByteBuffer中，然后创建AppendMessageResult。 这里只是将消息存储在 MappedFile对应的内存映射Buffer中，并没有刷写到磁盘。</p>
<pre><code class="language-java">final long beginTimeMills = CommitLog.this.defaultMessageStore.now();
CommitLog.this.getMessageStore().getPerfCounter().startTick(&quot;WRITE_MEMORY_TIME_MS&quot;);
// Write messages to the queue buffer
byteBuffer.put(preEncodeBuffer);
CommitLog.this.getMessageStore().getPerfCounter().endTick(&quot;WRITE_MEMORY_TIME_MS&quot;);
msgInner.setEncodedBuff(null);
return new AppendMessageResult(AppendMessageStatus.PUT_OK, wroteOffset, msgLen, msgIdSupplier,msgInner.getStoreTimestamp(), queueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills, messageNum);
</code></pre>
<blockquote>
<p>AppendMessageResult核心属性</p>
</blockquote>
<pre><code class="language-java">public class AppendMessageResult {
    //消息追加结果  PUT_OK :追加成功;END_OF_FILE :超过文件大小;MESSAGE SIZE EXCEEDED :消息长度超过最大允许长度: PROPERTIES_SIZE_EXCEEDED :消息、属性超过最大允许长度; UNKNOWN ERROR :未知异常 。
    private AppendMessageStatus status;
    // 消息的物理偏移量
    private long wroteOffset;
    // 消息的大小
    private int wroteBytes;
    // 消息 ID
    private String msgId;
    private Supplier&lt;String&gt; msgIdSupplier;
    // 消息存储时间戳
    private long storeTimestamp;
    // 消息消费队列逻辑偏移量，类似于数组下标
    private long logicsOffset;
    private long pagecacheRT = 0;
    //消息条数，批量消息发送时消息条数
    private int msgNum = 1;
}
</code></pre>
<p><strong>Step 12</strong>:更新消息队列逻辑偏移量 。</p>
<p><strong>Step 13</strong>:处理完消息追加逻辑后将释放 putMessageLock锁。</p>
<p><strong>Step 14</strong> : DefaultAppendMessageCallback#doAppend 只是将消息追加在内存中， 需要根据是同步刷盘还是异步刷盘方式，将内存中的数据持久化到磁盘，然后执行 HA 主从同步复制。</p>
<h2 id="44-存储文件组织与内存映射">4.4 存储文件组织与内存映射</h2>
<p>RocketMQ通过使用内存映射文件来提高IO访问性能，无论是CommitLog、 ConsumeQueue还是 IndexFile，单个文件都被设计为固定长度，如果一个文件写满以后再创建一个新文件，文件名就为该文件第 一条消息对应的全局物理偏移量。</p>
<h3 id="441-mappedfilequeue-映射文件队列">4.4.1 MappedFileQueue 映射文件队列</h3>
<p>MappedFileQueu巳是 MappedFile 的管理容器， Mapp巳dFileQueue是对存储目录的封装，例如 CommitLog文件的存储路径${ROCKET_HOME}/store/commitlog/，该目录下会存在多个内存映射文件(MappedFile)。</p>
<pre><code class="language-java">public class MappedFileQueue implements Swappable {
    //存储目录
    protected final String storePath;
    //单个文件的存储大小
    protected final int mappedFileSize;
    //MappedFile 文件集合
    protected final CopyOnWriteArrayList&lt;MappedFile&gt; mappedFiles = new CopyOnWriteArrayList&lt;MappedFile&gt;();
    //创建 MappedFile服务类
    protected final AllocateMappedFileService allocateMappedFileService;
    //当前刷盘指针，表示该指针之前的所有数据全部持久化到磁盘
    protected long flushedWhere = 0;
    //当前数据提交指针，内存中ByteBuffer当前的写指针，该值大于等于flushedWhere
    protected long committedWhere = 0;

    protected volatile long storeTimestamp = 0;
}
</code></pre>
<blockquote>
<p>查找 MappedFile</p>
</blockquote>
<pre><code class="language-java">/**
    * 查找 MappedFile
    * @param timestamp
    * @return
    */
public MappedFile getMappedFileByTime(final long timestamp) {
    Object[] mfs = this.copyMappedFiles(0);

    if (null == mfs)
        return null;

    for (int i = 0; i &lt; mfs.length; i++) {
        MappedFile mappedFile = (MappedFile) mfs[i];
        if (mappedFile.getLastModifiedTimestamp() &gt;= timestamp) {
            return mappedFile;
        }
    }

    return (MappedFile) mfs[mfs.length - 1];
}
</code></pre>
<p>根据消息存储时间戳来查找 MappdFile。从MappedFile 列表中第一个文件开始查找，找到第一个最后一次更新时间大于待查找时间戳的文件，如果不存在，则返回最后一个MappedFile文件。</p>
<p>RocketMQ 采取定时删除存储文件的策略，也就是说在存储文件中， 第一个文件不一定是 00000000000000000000，因为该文件在某一时刻会被删除，故根据offset定位MappedFile的算法为</p>
<pre><code class="language-java">(int) ((offset / this.mappedFileSize) - (firstMappedFile.getFileFromOffset() / this.mappedFileSize));
</code></pre>
<blockquote>
<p>MappedFileQueue#findMappedFileByOffset</p>
</blockquote>
<pre><code class="language-java">public MappedFile findMappedFileByOffset(final long offset, final boolean returnFirstOnNotFound) {
    try {
        MappedFile firstMappedFile = this.getFirstMappedFile();
        MappedFile lastMappedFile = this.getLastMappedFile();
        if (firstMappedFile != null &amp;&amp; lastMappedFile != null) {
            if (offset &lt; firstMappedFile.getFileFromOffset() || offset &gt;= lastMappedFile.getFileFromOffset() + this.mappedFileSize) {
                LOG_ERROR.warn(&quot;Offset not matched. Request offset: {}, firstOffset: {}, lastOffset: {}, mappedFileSize: {}, mappedFiles count: {}&quot;,
                    offset,
                    firstMappedFile.getFileFromOffset(),
                    lastMappedFile.getFileFromOffset() + this.mappedFileSize,
                    this.mappedFileSize,
                    this.mappedFiles.size());
            } else {
                int index = (int) ((offset / this.mappedFileSize) - (firstMappedFile.getFileFromOffset() / this.mappedFileSize));
                MappedFile targetFile = null;
                try {
                    targetFile = this.mappedFiles.get(index);
                } catch (Exception ignored) {
                }

                if (targetFile != null &amp;&amp; offset &gt;= targetFile.getFileFromOffset()
                    &amp;&amp; offset &lt; targetFile.getFileFromOffset() + this.mappedFileSize) {
                    return targetFile;
                }

                for (MappedFile tmpMappedFile : this.mappedFiles) {
                    if (offset &gt;= tmpMappedFile.getFileFromOffset()
                        &amp;&amp; offset &lt; tmpMappedFile.getFileFromOffset() + this.mappedFileSize) {
                        return tmpMappedFile;
                    }
                }
            }

            if (returnFirstOnNotFound) {
                return firstMappedFile;
            }
        }
    } catch (Exception e) {
        log.error(&quot;findMappedFileByOffset Exception&quot;, e);
    }

    return null;
}
</code></pre>
<p>获取存储文件最小偏移量，从这里也可以看出，并不是直接返回0，而是返回Mapped­File的 getFileFormOffset()。</p>
<pre><code class="language-java">public long getMinOffset() {
    if (!this.mappedFiles.isEmpty()) {
        try {
            return this.mappedFiles.get(0).getFileFromOffset();
        } catch (IndexOutOfBoundsException e) {
            //continue;
        } catch (Exception e) {
            log.error(&quot;getMinOffset has exception.&quot;, e);
        }
    }
    return -1;
}
</code></pre>
<p>获取存储文件的最大偏移量。 返回最后一个Mapp巳dFile文件的fileFromOffset加上MappedFile 文件当前的读指针。</p>
<pre><code class="language-java">public long getMaxOffset() {
    MappedFile mappedFile = getLastMappedFile();
    if (mappedFile != null) {
        return mappedFile.getFileFromOffset() + mappedFile.getReadPosition();
    }
    return 0;
}
</code></pre>
<p>返回存储文件当前的写指针。 返回最后一个文件的 fileFromOffset加上当前写指针位置。</p>
<pre><code class="language-java">public long getMaxWrotePosition() {
    MappedFile mappedFile = getLastMappedFile();
    if (mappedFile != null) {
        return mappedFile.getFileFromOffset() + mappedFile.getWrotePosition();
    }
    return 0;
}
</code></pre>
<h3 id="442-mappedfile-内存映射文件">4.4.2 MappedFile 内存映射文件</h3>
<p>MappedFile 是RocketMQ内存映射文件的具体实现。</p>
<pre><code class="language-java">public class DefaultMappedFile extends AbstractMappedFile {
    //操作系统每页大小，默认4k
    public static final int OS_PAGE_SIZE = 1024 * 4;
    protected static final InternalLogger log = InternalLoggerFactory.getLogger(LoggerName.STORE_LOGGER_NAME);

    //当前JVM实例中Mapped File虚拟内存
    protected static final AtomicLong TOTAL_MAPPED_VIRTUAL_MEMORY = new AtomicLong(0);
    //当前JVM实例中MappedFile对象个数
    protected static final AtomicInteger TOTAL_MAPPED_FILES = new AtomicInteger(0);

    protected static final AtomicIntegerFieldUpdater&lt;DefaultMappedFile&gt; WROTE_POSITION_UPDATER;
    protected static final AtomicIntegerFieldUpdater&lt;DefaultMappedFile&gt; COMMITTED_POSITION_UPDATER;
    protected static final AtomicIntegerFieldUpdater&lt;DefaultMappedFile&gt; FLUSHED_POSITION_UPDATER;

    //当前该文件的写指针，从0开始
    protected volatile int wrotePosition;
    //当前文件的提交指针，如果开启transientStorePoolEnable 则数据会存储在TransientStorePool中，然后提交到内存映射ByteBuffer中，再刷写到磁盘。
    protected volatile int committedPosition;
    //刷写到磁盘指针，该指针之前的数据持久化到磁盘中
    protected volatile int flushedPosition;
    //文件大小
    protected int fileSize;
    //文件通道
    protected FileChannel fileChannel;
    /**
     * Message will put to here first, and then reput to FileChannel if writeBuffer is not null.
     */
    //堆内存ByteBuffer，如果不为空，数据首先将存储在该Buffer中，然后提交到MappedFile对应的内存映射文件Buffer。transientStorePoolEnable为true时不为空。
    protected ByteBuffer writeBuffer = null;
    //堆内存池， transientStorePoolEnable为true时启用。
    protected TransientStorePool transientStorePool = null;
    //文件名称
    protected String fileName;
    //该文件的初始偏移量
    protected long fileFromOffset;
    //物理文件
    protected File file;
    //物理文件对应的内存映射 Buffer
    protected MappedByteBuffer mappedByteBuffer;
    //文件最后一次 内容写入时间
    protected volatile long storeTimestamp = 0;
    //是否是MappedFileQueue队列中第一个文件
    protected boolean firstCreateInQueue = false;
    private long lastFlushTime = -1L;

    protected MappedByteBuffer mappedByteBufferWaitToClean = null;
    protected long swapMapTime = 0L;
    protected long mappedByteBufferAccessCountSinceLastSwap = 0L;
}
</code></pre>
<h4 id="1-mappedfile初始化">1. MappedFile初始化</h4>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMq技术内幕笔记（二）]]></title>
        <id>https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-er/</id>
        <link href="https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-er/">
        </link>
        <updated>2022-09-13T11:18:59.000Z</updated>
        <summary type="html"><![CDATA[<h1 id="3-消息发送">3 消息发送</h1>
<p>RocketMQ 发送普通消息有 三 种实现方式:可靠同步发送 、 可靠异步发送 、 单向 (Oneway)发送。</p>
]]></summary>
        <content type="html"><![CDATA[<h1 id="3-消息发送">3 消息发送</h1>
<p>RocketMQ 发送普通消息有 三 种实现方式:可靠同步发送 、 可靠异步发送 、 单向 (Oneway)发送。</p>
<!-- more -->
<h2 id="31-rocketmq-消息发送">3.1 RocketMQ 消息发送</h2>
<p>RocketMQ 支持 3 种消息发送方式 :同步(sync)、 异步(async)、单向(oneway)。<br>
同步 : 发送者向 MQ 执行发送消息 API 时，同步等待， 直到消息服务器返回发送结果 。<br>
异步 : 发送者向 MQ 执行发送消息 API 时，调用消息发送Api后，立即返回，消息发送者线程不阻塞，直到运行结束，消息发送成功或失败的回调任务在一个新的线程中执行。<br>
单向:消息发送者向 MQ 执行发送消息 API时，直接返回，不等待消息服务器的结果，也不注册回调函数，简单地说，就是只管发，不在乎消息是否成功存储在消息服务器上 。</p>
<h2 id="32-认识rocketmq消息">3.2 认识RocketMQ消息</h2>
<p>RocketMQ 消息封装类是 org.apache.rocketmq.common.message.Message。</p>
<pre><code class="language-java">public class Message implements Serializable {
    private static final long serialVersionUID = 8445773977080406428L;

    private String topic;
    private int flag;
    private Map&lt;String, String&gt; properties;
    private byte[] body;
    private String transactionId;
}
</code></pre>
<p>Message 扩展属性主要包含下面几个 。<br>
tag:消息TAG，用于消息过滤 。<br>
keys: Message索引键，多个用空格隔开，RocketMQ可以根据这些 key快速检索到消息 。 waitStoreMsgOK:消息发送时是否等消息存储完成后再返回 。<br>
delayTimeLevel: 消息延迟级别，用于定时消息或消息重试 。</p>
<h2 id="33-生产者启动流程">3.3 生产者启动流程</h2>
<h3 id="331-初识-defaultmqproducer-消息发送者">3.3.1 初识 DefaultMQProducer 消息发送者</h3>
<p>DefaultMQProducer是默认的消息生产者实现类，它实现 MQAdmin 的接口。其主要接口有：</p>
<pre><code class="language-java">/**
    * @param key accesskey
    * @param newTopic 主题名称
    * @param queueNum 队列数量
    * @param topicSysFlag 主题系统标签，默认为0
    * @param attributes
    * @throws MQClientException if there is any client error.
    */
@Deprecated
@Override
public void createTopic(String key, String newTopic, int queueNum, int topicSysFlag, Map&lt;String, String&gt; attributes) throws MQClientException {
    this.defaultMQProducerImpl.createTopic(key, withNamespace(newTopic), queueNum, topicSysFlag);
}

/**
    * 根据 时间 戳从队列中查找其偏移量
    */
@Override
public long searchOffset(MessageQueue mq, long timestamp) throws MQClientException {
    return this.defaultMQProducerImpl.searchOffset(queueWithNamespace(mq), timestamp);
}

/**
    * 查找该消息 队列中 最大的物理偏移量
    */
@Deprecated
@Override
public long maxOffset(MessageQueue mq) throws MQClientException {
    return this.defaultMQProducerImpl.maxOffset(queueWithNamespace(mq));
}

/**
    * 查找该消息队列中最小物理偏移量
    */
@Deprecated
@Override
public long minOffset(MessageQueue mq) throws MQClientException {
    return this.defaultMQProducerImpl.minOffset(queueWithNamespace(mq));
}


/**
    * 根据消息偏移量查找消息
    */
@Deprecated
@Override
public MessageExt viewMessage(
    String offsetMsgId) throws RemotingException, MQBrokerException, InterruptedException, MQClientException {
    return this.defaultMQProducerImpl.viewMessage(offsetMsgId);
}

/**
    * 根据条件查询消息
    * @param topic message topic
    * @param key message key index word  消息索引字段
    * @param maxNum max message number 本次最多取出消息条数。
    * @param begin from when 开始时间
    * @param end to when 结束时间
    */
@Deprecated
@Override
public QueryResult queryMessage(String topic, String key, int maxNum, long begin, long end)
    throws MQClientException, InterruptedException {
    return this.defaultMQProducerImpl.queryMessage(withNamespace(topic), key, maxNum, begin, end);
}

    /**
    * 根据主题与消息 ID 查找消息
    * @throws InterruptedException if the sending thread is interrupted.
    */
@Deprecated
@Override
public MessageExt viewMessage(String topic,
    String msgId) throws RemotingException, MQBrokerException, InterruptedException, MQClientException {
    try {
        return this.viewMessage(msgId);
    } catch (Exception ignored) {
    }
    return this.defaultMQProducerImpl.queryMessageByUniqKey(withNamespace(topic), msgId);
}

/**
    * 查找该主题下所有的消息队列
    */
@Override
public List&lt;MessageQueue&gt; fetchPublishMessageQueues(String topic) throws MQClientException {
    return this.defaultMQProducerImpl.fetchPublishMessageQueues(withNamespace(topic));
}

    /**
    * 同步发送消息，具体发送到主题中的哪个消息队列由负载算法决定
    */
@Override
public SendResult send(
    Message msg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    return this.defaultMQProducerImpl.send(msg);
}

/**
    * 同步发送消息，如果发送超过 timeout 则抛出超时异常
    */
@Override
public SendResult send(Message msg,
    long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    return this.defaultMQProducerImpl.send(msg, timeout);
}

/**
    * 异步发送消息， sendCallback参数是消息发送成功后的回调方法 
    */
@Override
public void send(Message msg,
    SendCallback sendCallback) throws MQClientException, RemotingException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    this.defaultMQProducerImpl.send(msg, sendCallback);
}

/**
    * 异步发送消息 ，如果发送超过 timeout指定的值，则抛出超时异常
    */
@Override
public void send(Message msg, SendCallback sendCallback, long timeout)
    throws MQClientException, RemotingException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    this.defaultMQProducerImpl.send(msg, sendCallback, timeout);
}

    /**
    * 单向消息发送，就是不在乎发送结果，消息发送出去后该方法立即返回
    */
@Override
public void sendOneway(Message msg) throws MQClientException, RemotingException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    this.defaultMQProducerImpl.sendOneway(msg);
}

/**
    * 同步方式发送消息，发送到指定消息队列
    */
@Override
public SendResult send(Message msg, MessageQueue mq)
    throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    return this.defaultMQProducerImpl.send(msg, queueWithNamespace(mq));
}

/**
    * 同步方式发送消息，发送到指定消息队列 超时异常
    */
@Override
public SendResult send(Message msg, MessageQueue mq, long timeout)
    throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    return this.defaultMQProducerImpl.send(msg, queueWithNamespace(mq), timeout);
}

/**
    * 异步方式发送消息，发送到指定消息 队列 
    */
@Override
public void send(Message msg, MessageQueue mq, SendCallback sendCallback)
    throws MQClientException, RemotingException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    this.defaultMQProducerImpl.send(msg, queueWithNamespace(mq), sendCallback);
}

/**
    * 异步方式发送消息，发送到指定消息队列 超时异常
    */
@Override
public void send(Message msg, MessageQueue mq, SendCallback sendCallback, long timeout)
    throws MQClientException, RemotingException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    this.defaultMQProducerImpl.send(msg, queueWithNamespace(mq), sendCallback, timeout);
}

/**
    * 单向方式发送消息，发送到指定的消息队列
    */
@Override
public void sendOneway(Message msg,
    MessageQueue mq) throws MQClientException, RemotingException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    this.defaultMQProducerImpl.sendOneway(msg, queueWithNamespace(mq));
}

/**
    * 消息发送，指定消息选择算法，覆盖消息生产者默认的消息队列负载
    */
@Override
public SendResult send(Message msg, MessageQueueSelector selector, Object arg)
    throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    return this.defaultMQProducerImpl.send(msg, selector, arg);
}

/**
    * 同步批量消息发送
    */
@Override
public SendResult send(Collection&lt;Message&gt; msgs, MessageQueue messageQueue,
    long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    return this.defaultMQProducerImpl.send(batch(msgs), messageQueue, timeout);
}
</code></pre>
<blockquote>
<p>DefaultMQProducer核心属性</p>
</blockquote>
<pre><code class="language-java"> /**
    * 生产者所属组，消息服务器在回查事务状态时会随机选择该组中任何一个生产者发起事务回查请求 
    */
private String producerGroup;

/**
    * 默认 topicKey。
    */
private String createTopicKey = TopicValidator.AUTO_CREATE_TOPIC_KEY_TOPIC;

/**
    * 默认主题在每一个 Broker 队列数量。
    */
private volatile int defaultTopicQueueNums = 4;

/**
    * 发送消息默认超时时间， 默认 3s。
    */
private int sendMsgTimeout = 3000;

/**
    * 消息体超过该值则启用压缩，默认 4K。
    */
private int compressMsgBodyOverHowmuch = 1024 * 4;

/**
    *
    * 同 步方式发送消息重试次数，默认为 2，总共执行 3 次 。
    */
private int retryTimesWhenSendFailed = 2;

/**
    * 异步方式发送消息重试次数，默认为 2。
    */
private int retryTimesWhenSendAsyncFailed = 2;

/**
    * 消息重试时选择另外一个 Broker时是否不等 待存储结果就返回 ， 默认为 false。
    */
private boolean retryAnotherBrokerWhenNotStoreOK = false;

/**
    * 允许发送的最大消息长度，默认为 4M，眩值最大值为 2&quot;32-1
    */
private int maxMessageSize = 1024 * 1024 * 4; // 4M
</code></pre>
<h3 id="332-消息生产者启动流程">3.3.2 消息生产者启动流程</h3>
<p>消息生产者启动主要从DefaultMQProducerlmpl的start方法开始。</p>
<pre><code class="language-java">public void start(final boolean startFactory) throws MQClientException {
    switch (this.serviceState) {
        case CREATE_JUST:
            this.serviceState = ServiceState.START_FAILED;

//Step1:检查productGroup是否符合要求;并改变生产者的 instanceName为进程 ID。
            this.checkConfig();
            if (!this.defaultMQProducer.getProducerGroup().equals(MixAll.CLIENT_INNER_PRODUCER_GROUP)) {
                this.defaultMQProducer.changeInstanceNameToPID();
            }

 // /Step2 :创建 MQClientInstance实例。 整个JVM 实例中只存在一个 MQClientManager实例，维护一个MQClientInstance缓存表 ConcurrentMap&lt;String/*clientId灯，MQClientInstance&gt; factoryTable =new ConcurrentHashMap&lt;String， MQClientInstance&gt;()，也就是 同一个 clientId只 会创建一个 MQClientInstance。
            this.mQClientFactory = MQClientManager.getInstance().getOrCreateMQClientInstance(this.defaultMQProducer, rpcHook);


//Step3 :向 MQClientlnstance注册，将当前生产者加入到 MQClientlnstance管理中，方 便后续调用网络请求、进行心跳检测等。
//Step4 : 启动 MQClientlnstance，如果 MQC!ientlnstance 已经启动 ，则本次启 动不会真 正执行。
            boolean registerOK = mQClientFactory.registerProducer(this.defaultMQProducer.getProducerGroup(), this);
            if (!registerOK) {
                this.serviceState = ServiceState.CREATE_JUST;
                throw new MQClientException(&quot;The producer group[&quot; + this.defaultMQProducer.getProducerGroup()
                    + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL),
                    null);
            }

            this.topicPublishInfoTable.put(this.defaultMQProducer.getCreateTopicKey(), new TopicPublishInfo());

            if (startFactory) {
                mQClientFactory.start();
            }

            log.info(&quot;the producer [{}] start OK. sendMessageWithVIPChannel={}&quot;, this.defaultMQProducer.getProducerGroup(),
                this.defaultMQProducer.isSendMessageWithVIPChannel());
            this.serviceState = ServiceState.RUNNING;
            break;
        case RUNNING:
        case START_FAILED:
        case SHUTDOWN_ALREADY:
            throw new MQClientException(&quot;The producer service state not OK, maybe started once, &quot;
                + this.serviceState
                + FAQUrl.suggestTodo(FAQUrl.CLIENT_SERVICE_NOT_OK),
                null);
        default:
            break;
    }

    this.mQClientFactory.sendHeartbeatToAllBrokerWithLock();

    RequestFutureHolder.getInstance().startScheduledTask(this);

}
</code></pre>
<blockquote>
<p>MQClientManager</p>
</blockquote>
<pre><code class="language-java">public MQClientInstance getOrCreateMQClientInstance(final ClientConfig clientConfig, RPCHook rpcHook) {
    String clientId = clientConfig.buildMQClientId();
    MQClientInstance instance = this.factoryTable.get(clientId);
    if (null == instance) {
        instance =
            new MQClientInstance(clientConfig.cloneClientConfig(),
                this.factoryIndexGenerator.getAndIncrement(), clientId, rpcHook);
        MQClientInstance prev = this.factoryTable.putIfAbsent(clientId, instance);
        if (prev != null) {
            instance = prev;
            log.warn(&quot;Returned Previous MQClientInstance for clientId:[{}]&quot;, clientId);
        } else {
            log.info(&quot;Created new MQClientInstance for clientId:[{}]&quot;, clientId);
        }
    }

    return instance;
}
</code></pre>
<h2 id="34-消息发送基本流程">3.4 消息发送基本流程</h2>
<p>消息发送流程主要的步骤:验证消息、查找路由 、 消息发送 (包含异常处理机制) 。</p>
<blockquote>
<p>同步消息发送入口</p>
</blockquote>
<pre><code class="language-java">//DefaultMQProducer
public SendResult send(
    Message msg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    return this.defaultMQProducerImpl.send(msg);
}

//DefaultMQProducerImpl
public SendResult send(Message msg,
    long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    return this.sendDefaultImpl(msg, CommunicationMode.SYNC, null, timeout);
}
</code></pre>
<h3 id="341-消息长度验证">3.4.1 消息长度验证</h3>
<p>消息发送之前，首先确保生产者处于运行状态，然后验证消息是否符合相应的规范，具体的规范要求是主题名称、消息体不能为空、消息长度不能等于 0且默认不能超过允许 发送消息的最大长度 4M (maxMessageSize=1024 *1024 *4)。</p>
<pre><code class="language-java">public static void checkMessage(Message msg, DefaultMQProducer defaultMQProducer) throws MQClientException {
    if (null == msg) {
        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message is null&quot;);
    }
    // topic
    Validators.checkTopic(msg.getTopic());
    Validators.isNotAllowedSendTopic(msg.getTopic());

    // body
    if (null == msg.getBody()) {
        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message body is null&quot;);
    }

    if (0 == msg.getBody().length) {
        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message body length is zero&quot;);
    }

    if (msg.getBody().length &gt; defaultMQProducer.getMaxMessageSize()) {
        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL,
            &quot;the message body size over max value, MAX: &quot; + defaultMQProducer.getMaxMessageSize());
    }
}
</code></pre>
<h3 id="342-查找主题路由信息">3.4.2 查找主题路由信息</h3>
<p>消息发送之前，首先需要获取主题的路由信息，确认发送到具体的 Broker节点。。</p>
<pre><code class="language-java">private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) {
    TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic);
    if (null == topicPublishInfo || !topicPublishInfo.ok()) {
        this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo());
        this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic);
        topicPublishInfo = this.topicPublishInfoTable.get(topic);
    }

    if (topicPublishInfo.isHaveTopicRouterInfo() || topicPublishInfo.ok()) {
        return topicPublishInfo;
    } else {
        this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic, true, this.defaultMQProducer);
        topicPublishInfo = this.topicPublishInfoTable.get(topic);
        return topicPublishInfo;
    }
}
</code></pre>
<p>tryToFindTopicPublishlnfo是查找主题的路由信息的方法。如果生产者中缓存了 topic 的路由信息，如果该路由信息中包含了消息队列，则直接返回该路由信息，如果没有缓存或没有包含消息队列， 则向 NameServer查询该topic的路由信息。如果最终未找到路由信息，则抛出异常 : 无法找到主题相关路由信息异常。</p>
<blockquote>
<p>TopicPublishInfo</p>
</blockquote>
<pre><code class="language-java">public class TopicPublishInfo {
    private boolean orderTopic = false; //是否是顺序消息
    private boolean haveTopicRouterInfo = false; 
    private List&lt;MessageQueue&gt; messageQueueList = new ArrayList&lt;MessageQueue&gt;();  //该主题队列的消息队列
    private volatile ThreadLocalIndex sendWhichQueue = new ThreadLocalIndex(); // 每选择一次消息 队列， 该值会自增 l，如果 Integer.MAX_VALUE,则重置为 0，用于选择消息队列。
    private TopicRouteData topicRouteData;
}

public class TopicRouteData extends RemotingSerializable {
    private String orderTopicConf;
    private List&lt;QueueData&gt; queueDatas; //topic 队列元数据 。
    private List&lt;BrokerData&gt; brokerDatas; //topic 分布的 broker元数据 
    private HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable; //broker 上过滤服务器地址列表。
    //It could be null or empty
    private Map&lt;String/*brokerName*/, TopicQueueMappingInfo&gt; topicQueueMappingByBroker;
}
</code></pre>
<p>第一次发送消息时，本地没有缓存 topic 的路由信息，查询NameServer尝试获取，如果路由信息未找到，再次尝试用默认主题 DefaultMQProducerlmpl#createTopicKey去查询，如果 BrokerConfig#autoCreateTopicEnable为true时，NameServer将返回路由信息，如果 autoCreateTopicEnable为false将抛出无法找到topic路由异常。</p>
<blockquote>
<p>updateTopicRouteInfoFromNameServer</p>
</blockquote>
<pre><code class="language-java">public boolean updateTopicRouteInfoFromNameServer(final String topic, boolean isDefault,
    DefaultMQProducer defaultMQProducer) {
    try {
        //获取锁
        if (this.lockNamesrv.tryLock(LOCK_TIMEOUT_MILLIS, TimeUnit.MILLISECONDS)) {
            try {
//Step 1 :如果isDefault为true，则使用默认主题去查询，如果查询到路由信息，
// 则替换路由信息中读写队列个数为消息生产者默认的队列个数(defaultTopicQueueNums);如果
// isDefault为false，则使用参数 topic去查询;如果未查询到路由信息，则返回false，表示路由信息未变化
                TopicRouteData topicRouteData;
                if (isDefault &amp;&amp; defaultMQProducer != null) {
                    topicRouteData = this.mQClientAPIImpl.getDefaultTopicRouteInfoFromNameServer(defaultMQProducer.getCreateTopicKey(),
                        clientConfig.getMqClientApiTimeout());
                    if (topicRouteData != null) {
                        for (QueueData data : topicRouteData.getQueueDatas()) {
                            int queueNums = Math.min(defaultMQProducer.getDefaultTopicQueueNums(), data.getReadQueueNums());
                            data.setReadQueueNums(queueNums);
                            data.setWriteQueueNums(queueNums);
                        }
                    }
                } else {
                    topicRouteData = this.mQClientAPIImpl.getTopicRouteInfoFromNameServer(topic, clientConfig.getMqClientApiTimeout());
                }
                if (topicRouteData != null) {
                    TopicRouteData old = this.topicRouteTable.get(topic);
                      //Step2:如果路由信息找到，与本地缓存中的路由信息进行对比，判断路由信息是否发生了改变，如果未发生变化，则直接返回false。
                    boolean changed = topicRouteData.topicRouteDataChanged(old);
                    if (!changed) {
                        changed = this.isNeedUpdateTopicRouteInfo(topic);
                    } else {
                        log.info(&quot;the topic[{}] route info changed, old[{}] ,new[{}]&quot;, topic, old, topicRouteData);
                    }

      //Step3:更新 MQClientInstanceBroker地址缓存表。
                    if (changed) {
                        for (BrokerData bd : topicRouteData.getBrokerDatas()) {
                            this.brokerAddrTable.put(bd.getBrokerName(), bd.getBrokerAddrs());
                        }

                        // Update endpoint map
                        {
                            ConcurrentMap&lt;MessageQueue, String&gt; mqEndPoints = topicRouteData2EndpointsForStaticTopic(topic, topicRouteData);
                            if (!mqEndPoints.isEmpty()) {
                                topicEndPointsTable.put(topic, mqEndPoints);
                            }
                        }

                        // Update Pub info
                        {
                            TopicPublishInfo publishInfo = topicRouteData2TopicPublishInfo(topic, topicRouteData);
                            publishInfo.setHaveTopicRouterInfo(true);
                            for (Entry&lt;String, MQProducerInner&gt; entry : this.producerTable.entrySet()) {
                                MQProducerInner impl = entry.getValue();
                                if (impl != null) {
                                    impl.updateTopicPublishInfo(topic, publishInfo);
                                }
                            }
                        }

// step 4:根据 topicRouteData中的 List&lt;QueueData&gt;转换成topicPublishInfo的 List&lt;MessageQueue&gt;
//列表。其具体实现在topicRouteData2TopicPublishInfo， 然后会更新该 MQClientInstance所管辖的所有消息发送关于topic的路由信息
                        if (!consumerTable.isEmpty()) {
                            Set&lt;MessageQueue&gt; subscribeInfo = topicRouteData2TopicSubscribeInfo(topic, topicRouteData);
                            for (Entry&lt;String, MQConsumerInner&gt; entry : this.consumerTable.entrySet()) {
                                MQConsumerInner impl = entry.getValue();
                                if (impl != null) {
                                    impl.updateTopicSubscribeInfo(topic, subscribeInfo);
                                }
                            }
                        }
                        TopicRouteData cloneTopicRouteData = new TopicRouteData(topicRouteData);
                        log.info(&quot;topicRouteTable.put. Topic = {}, TopicRouteData[{}]&quot;, topic, cloneTopicRouteData);
                        this.topicRouteTable.put(topic, cloneTopicRouteData);
                        return true;
                    }
                } else {
                    log.warn(&quot;updateTopicRouteInfoFromNameServer, getTopicRouteInfoFromNameServer return null, Topic: {}. [{}]&quot;, topic, this.clientId);
                }
            } catch (MQClientException e) {
                if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX) &amp;&amp; !topic.equals(TopicValidator.AUTO_CREATE_TOPIC_KEY_TOPIC)) {
                    log.warn(&quot;updateTopicRouteInfoFromNameServer Exception&quot;, e);
                }
            } catch (RemotingException e) {
                log.error(&quot;updateTopicRouteInfoFromNameServer Exception&quot;, e);
                throw new IllegalStateException(e);
            } finally {
                this.lockNamesrv.unlock();
            }
        } else {
            log.warn(&quot;updateTopicRouteInfoFromNameServer tryLock timeout {}ms. [{}]&quot;, LOCK_TIMEOUT_MILLIS, this.clientId);
        }
    } catch (InterruptedException e) {
        log.warn(&quot;updateTopicRouteInfoFromNameServer Exception&quot;, e);
    }

    return false;
}
</code></pre>
<p>循环遍历路由信息的QueueData 信息，如果队列没有写权限，则继续遍历下一个QueueData ，根据 topic+序号创建 MessageQueue，填充 topicPublishlnfo的List<QuueMessage>。 完成消息发送的路由查找 。</p>
<blockquote>
<p>topicRouteData2TopicSubscribeInfo</p>
</blockquote>
<pre><code class="language-java">public static Set&lt;MessageQueue&gt; topicRouteData2TopicSubscribeInfo(final String topic, final TopicRouteData route) {
    Set&lt;MessageQueue&gt; mqList = new HashSet&lt;&gt;();
    if (route.getTopicQueueMappingByBroker() != null
            &amp;&amp; !route.getTopicQueueMappingByBroker().isEmpty()) {
        ConcurrentMap&lt;MessageQueue, String&gt; mqEndPoints = topicRouteData2EndpointsForStaticTopic(topic, route);
        return mqEndPoints.keySet();
    }
    List&lt;QueueData&gt; qds = route.getQueueDatas();
    for (QueueData qd : qds) {
        if (PermName.isReadable(qd.getPerm())) {
            for (int i = 0; i &lt; qd.getReadQueueNums(); i++) {
                MessageQueue mq = new MessageQueue(topic, qd.getBrokerName(), i);
                mqList.add(mq);
            }
        }
    }

    return mqList;
}
</code></pre>
<h3 id="343-选择消息队列">3.4.3 选择消息队列</h3>
<p>首先消息发送端采用重试机制 ，由retryTimesWhenSendFailed指定同步方式重试次数，异步重试机制在收到消息发送结构后执行回调之前进行重试。由retryTimesWhenSend-AsyncFailed指定，接下来就是循环执行，选择消息队列、发送消息，发送成功则返回，收到异常则重试。选择消息队列有两种方式。</p>
<p>1 ) sendLatencyFaultEnable=false，默认不启用Broker故障延迟机制。<br>
2 ) sendLatencyFaultEnable=true，启用Broker故障延迟机制。</p>
<h4 id="1-默认机制">1. 默认机制</h4>
<pre><code class="language-java">public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) {
    //判断启用不启用Broker故障延迟机制
    if (this.sendLatencyFaultEnable) {
        try {
            int index = tpInfo.getSendWhichQueue().incrementAndGet();
            for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) {
                int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size();
                if (pos &lt; 0)
                    pos = 0;
                MessageQueue mq = tpInfo.getMessageQueueList().get(pos);
                //验证该消息队列是否可用
                if (latencyFaultTolerance.isAvailable(mq.getBrokerName()))
                    return mq;
            }

            final String notBestBroker = latencyFaultTolerance.pickOneAtLeast();
            int writeQueueNums = tpInfo.getQueueIdByBroker(notBestBroker);
            if (writeQueueNums &gt; 0) {
                final MessageQueue mq = tpInfo.selectOneMessageQueue();
                if (notBestBroker != null) {
                    mq.setBrokerName(notBestBroker);
                    mq.setQueueId(tpInfo.getSendWhichQueue().incrementAndGet() % writeQueueNums);
                }
                return mq;
            } else {
                latencyFaultTolerance.remove(notBestBroker);
            }
        } catch (Exception e) {
            log.error(&quot;Error occurred when selecting message queue&quot;, e);
        }

        return tpInfo.selectOneMessageQueue();
    }
    //不启用Broker故障延迟机制
    return tpInfo.selectOneMessageQueue(lastBrokerName);
}
</code></pre>
<blockquote>
<p>TopicPublishInfo 启用Broker故障延迟机制</p>
</blockquote>
<pre><code class="language-java">public MessageQueue selectOneMessageQueue(final String lastBrokerName) {
    if (lastBrokerName == null) {
        return selectOneMessageQueue();
    } else {
        for (int i = 0; i &lt; this.messageQueueList.size(); i++) {
            int index = this.sendWhichQueue.incrementAndGet();
            int pos = Math.abs(index) % this.messageQueueList.size();
            if (pos &lt; 0)
                pos = 0;
            MessageQueue mq = this.messageQueueList.get(pos);
            if (!mq.getBrokerName().equals(lastBrokerName)) {
                return mq;
            }
        }
        return selectOneMessageQueue();
    }
}

public MessageQueue selectOneMessageQueue() {
    int index = this.sendWhichQueue.incrementAndGet();
    int pos = Math.abs(index) % this.messageQueueList.size();
    if (pos &lt; 0)
        pos = 0;
    return this.messageQueueList.get(pos);
}
</code></pre>
<p>首先在一次消息发送过程中，可能会多次执行选择消息队列这个方法，lastBrokerName就是上一次选择的执行发送消息失败的Broker。第一次执行消息队列选择时，lastBrokerName为null，此时直接用 sendWhichQueue自增再获取值，与当前路由表中消息队列个数取模，返回该位置的MessageQueue(selectOneMessageQueue()方法)，如果消息发送再失败的话，下次进行消息队列选择时规避上次 MesageQueue所在的Broker，否则还是很有可能再次失败。</p>
<p>该算法在一次消息发送过程中能成功规避故障的Broker，但如果 Broker若机，由于路 由算法中的消息队列是按 Broker排序的，如果上一次根据路由算法选择的是若机的Broker的第一个队列，那么随后的下次选择的是若机Broker的第二个队列，消息发送很有可能会失败，再次引发重试，带来不必要的性能损耗。</p>
<p>Broker不可用后，路由信息中为什么还会包含该 Broker的路由信息呢?其实这不难解释:首先， NameServer 检测Broker是否可用是有延迟的，最短为一次心跳检测间隔(10s); 其次，NameServer不会 检测到 Broker岩机后马上推送消息给消息生产者，而是消息生产者每隔 30s更新一次路由信息，所以消息生产者最快感知Broker最新的路由信息也需要30s。如果能引人一种机制，在 Broker若机期间，如果一次消息发送失败后，可以将该 Broker暂时排除在消息队列的选择范围中。</p>
<h4 id="2-broker故障延迟机制">2. Broker故障延迟机制</h4>
<p>代码如上</p>
<p>1 )根据对消息队列进行轮询获取一个消息队列 。<br>
2)验证该消息队列是否可用，latencyFaultTolerance.isAvailable(mq.getBrokerName())<br>
3)如果返回的 MessageQueue可用， 移除latencyFaultTolerance关于该topic条目， 表<br>
明该Broker故障已经恢复。</p>
<p><strong>Broker故障延迟机制核心类-LatencyFaultTolerance</strong></p>
<pre><code class="language-java">public interface LatencyFaultTolerance&lt;T&gt; {
    /**
     * 更新失败条目
     * @param name brokerName
     * @param currentLatency 消息发送故障延迟时间
     * @param notAvailableDuration 不可用持续时辰，在这个时间内Broker将被规避
     */
    void updateFaultItem(final T name, final long currentLatency, final long notAvailableDuration);

    /**
     * 判断 Broker是否可用
     * @param name
     * @return
     */
    boolean isAvailable(final T name);

    /**
     * 移除Fault条目，意味着Broker重新参与路由计算
     * @param name
     */
    void remove(final T name);

    /**
     * 尝试从规避的Broker中选择一个可用的Broker，如果没有找到，将返回null
     * @return
     */
    T pickOneAtLeast();
}
</code></pre>
<p><strong>Faultltem: 失败条目(规避规则条目)</strong></p>
<pre><code class="language-java">class FaultItem implements Comparable&lt;FaultItem&gt; {
    //条目唯一键，这里为brokerName
    private final String name;
    //本次消息发送延迟
    private volatile long currentLatency;
    //故障规避开始时间
    private volatile long startTimestamp;
}
</code></pre>
<p><strong>MQFaultStrategy:消息失败策略，延迟实现的门面类</strong></p>
<pre><code class="language-java">private long[] latencyMax = {50L, 100L, 550L, 1000L, 2000L, 3000L, 15000L};
private long[] notAvailableDuration = {0L, 0L, 30000L, 60000L, 120000L, 180000L, 600000L};
</code></pre>
<p>latencyMax根据currentLatency本次消息发送延迟，从latencyMax尾部向前找到<br>
第一个比currentLatency小的索引index，如果没有找到，返回0。然后根据这个索引从 notAvailableDuration数组中取出对应的时间，在这个时长内，Broker将设置为不可用。</p>
<blockquote>
<p><em>MQFaultStrategy#updateFaultltem</em></p>
</blockquote>
<pre><code class="language-java">/**
    * 更新失败条目
    * @param brokerName
    * @param currentLatency 本次消息发送延迟时间
    * @param isolation isolation，是否隔离，该参数的含义如果为 true，则使用默认时长30s来
    * 计算Broker故障规避时长，如果为false，则使用本次消息发送延迟时间来计算Broker故障规避时长。
    */
public void updateFaultItem(final String brokerName, final long currentLatency, boolean isolation) {
    if (this.sendLatencyFaultEnable) {
        long duration = computeNotAvailableDuration(isolation ? 30000 : currentLatency);
        this.latencyFaultTolerance.updateFaultItem(brokerName, currentLatency, duration);
    }
}

private long computeNotAvailableDuration(final long currentLatency) {
    for (int i = latencyMax.length - 1; i &gt;= 0; i--) {
        if (currentLatency &gt;= latencyMax[i])
            return this.notAvailableDuration[i];
    }

    return 0;
}
</code></pre>
<p>computeNotAvailableDuration的作用是计算因本次消息发送故障需要将 Broker 规避的时长，也就是接下来多久的时间内该 Broker将不参与消息发送队列负载。具体算法:从 latencyMax数组尾部开始寻找，找到第一个比currentLatency小的下标， 然后从notAvailableDuration数组中获取需要规避的时长，该方法最终调用LatencyFaultTolerance的updateFaultltem。</p>
<pre><code class="language-java">@Override
public void updateFaultItem(final String name, final long currentLatency, final long notAvailableDuration) {
    FaultItem old = this.faultItemTable.get(name);
    if (null == old) {
        final FaultItem faultItem = new FaultItem(name);
        faultItem.setCurrentLatency(currentLatency);
        faultItem.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);

        old = this.faultItemTable.putIfAbsent(name, faultItem);
        if (old != null) {
            old.setCurrentLatency(currentLatency);
            old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);
        }
    } else {
        old.setCurrentLatency(currentLatency);
        old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);
    }
}
</code></pre>
<p>根据 broker名称从缓存表中获取Faultitem，如果找到则更新Faultltem，否则创建Faultltem。这里有两个关键点。<br>
1)currentLatency、startTimeStamp被volatile修饰。<br>
2)startTimeStamp为当前系统时间加上需要规避的时长。startTimeStamp是判断broker当前是否可用的直接一句，请看 Faultltem#isAvailable方法。</p>
<pre><code class="language-java">public boolean isAvailable() {
    return (System.currentTimeMillis() - startTimestamp) &gt;= 0;
}
</code></pre>
<h3 id="344-消息发送">3.4.4 消息发送</h3>
<pre><code class="language-java">/**
    * 发送消息
    * @param msg 待发送消息
    * @param mq  消息将发送到该消息队列上
    * @param communicationMode 消息发送模式
    * @param sendCallback 异步消息回调函数
    * @param topicPublishInfo 主题路由信息
    * @param timeout 消息发送超时时间
    */
private SendResult sendKernelImpl(final Message msg,
    final MessageQueue mq,
    final CommunicationMode communicationMode,
    final SendCallback sendCallback,
    final TopicPublishInfo topicPublishInfo,
    final long timeout)
</code></pre>
<p>Step 1:根据MessageQueue获取Broker的网络地址。如果MQClientlnstance的brokerAddrTable禾缓存该Broker的信息，则从NameServer主动更新一下topic的路由信息。如果路由更新后还是找不到 Broker信息，则抛出MQClientException，提示Broker不存在。</p>
<blockquote>
<p>DefaultMQProducelmpl#sendKernellmpl</p>
</blockquote>
<pre><code class="language-java">String brokerName = this.mQClientFactory.getBrokerNameFromMessageQueue(mq);
String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(brokerName);
if (null == brokerAddr) {
    tryToFindTopicPublishInfo(mq.getTopic());
    brokerName = this.mQClientFactory.getBrokerNameFromMessageQueue(mq);
    brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(brokerName);
}
</code></pre>
<p>Step2:为消息分配全局唯一ID ，如果消息体默认超过 4K(compressMsgBodyOverHowmuch), 会对消息体采用 zip压缩，并设置消息的系统标记为 MessageSysFlag.COMPRESSED_FLAG。 如果是事务 Prepared消息，则设消息的系统标记为MessageSysFlag.TRANSACTION_ PREPARED_TYPE。</p>
<blockquote>
<p>DefaultMQProducelmpl#sendKernellmpl</p>
</blockquote>
<pre><code class="language-java">if (!(msg instanceof MessageBatch)) {
    MessageClientIDSetter.setUniqID(msg);
}

boolean topicWithNamespace = false;
if (null != this.mQClientFactory.getClientConfig().getNamespace()) {
    msg.setInstanceId(this.mQClientFactory.getClientConfig().getNamespace());
    topicWithNamespace = true;
}

int sysFlag = 0;
boolean msgBodyCompressed = false;
if (this.tryToCompressMessage(msg)) {//压缩消息
    sysFlag |= MessageSysFlag.COMPRESSED_FLAG;
    sysFlag |= compressType.getCompressionFlag();
    msgBodyCompressed = true;
}

final String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);
if (Boolean.parseBoolean(tranMsg)) {
    sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE;
}
</code></pre>
<p>Step3 :如果注册了消息发送钩子函数，则执行消息发送之前的增强逻辑。通过DefaultMQProducerlmpl#registerSendMessageHook注册钩子处理类，并且可以注册多个。</p>
<pre><code class="language-java">if (hasCheckForbiddenHook()) {
    CheckForbiddenContext checkForbiddenContext = new CheckForbiddenContext();
    checkForbiddenContext.setNameSrvAddr(this.defaultMQProducer.getNamesrvAddr());
    checkForbiddenContext.setGroup(this.defaultMQProducer.getProducerGroup());
    checkForbiddenContext.setCommunicationMode(communicationMode);
    checkForbiddenContext.setBrokerAddr(brokerAddr);
    checkForbiddenContext.setMessage(msg);
    checkForbiddenContext.setMq(mq);
    checkForbiddenContext.setUnitMode(this.isUnitMode());
    this.executeCheckForbiddenHook(checkForbiddenContext);
}

if (this.hasSendMessageHook()) {
    context = new SendMessageContext();
    context.setProducer(this);
    context.setProducerGroup(this.defaultMQProducer.getProducerGroup());
    context.setCommunicationMode(communicationMode);
    context.setBornHost(this.defaultMQProducer.getClientIP());
    context.setBrokerAddr(brokerAddr);
    context.setMessage(msg);
    context.setMq(mq);
    context.setNamespace(this.defaultMQProducer.getNamespace());
    String isTrans = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);
    if (isTrans != null &amp;&amp; isTrans.equals(&quot;true&quot;)) {
        context.setMsgType(MessageType.Trans_Msg_Half);
    }

    if (msg.getProperty(&quot;__STARTDELIVERTIME&quot;) != null || msg.getProperty(MessageConst.PROPERTY_DELAY_TIME_LEVEL) != null) {
        context.setMsgType(MessageType.Delay_Msg);
    }
    this.executeSendMessageHookBefore(context);
}
</code></pre>
<p>Step4 :构建消息发送请求包。 主要包含如下重要信息:生产者组、主题名称、默认创建主题 Key、该主题在单个Broker默认队列数 、队列ID (队列序号)、消息系统标记( MessageSysFlag)、消息发送时间、消息标记(RocketMQ对消息中的 flag不做任何处理，供应用程序使用)、消息扩展属性、消息重试次数、是否是批量消息等。</p>
<pre><code class="language-java">SendMessageRequestHeader requestHeader = new SendMessageRequestHeader();
requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup());
requestHeader.setTopic(msg.getTopic());
requestHeader.setDefaultTopic(this.defaultMQProducer.getCreateTopicKey());
requestHeader.setDefaultTopicQueueNums(this.defaultMQProducer.getDefaultTopicQueueNums());
requestHeader.setQueueId(mq.getQueueId());
requestHeader.setSysFlag(sysFlag);
requestHeader.setBornTimestamp(System.currentTimeMillis());
requestHeader.setFlag(msg.getFlag());
requestHeader.setProperties(MessageDecoder.messageProperties2String(msg.getProperties()));
requestHeader.setReconsumeTimes(0);
requestHeader.setUnitMode(this.isUnitMode());
requestHeader.setBatch(msg instanceof MessageBatch);
if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
    String reconsumeTimes = MessageAccessor.getReconsumeTime(msg);
    if (reconsumeTimes != null) {
        requestHeader.setReconsumeTimes(Integer.valueOf(reconsumeTimes));
        MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_RECONSUME_TIME);
    }

    String maxReconsumeTimes = MessageAccessor.getMaxReconsumeTimes(msg);
    if (maxReconsumeTimes != null) {
        requestHeader.setMaxReconsumeTimes(Integer.valueOf(maxReconsumeTimes));
        MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_MAX_RECONSUME_TIMES);
    }
}
</code></pre>
<p>Step5:根据消息发送方式，同步、异步、单向方式进行网络传输。</p>
<blockquote>
<p>MQClientAPIImpl#sendMessage</p>
</blockquote>
<pre><code class="language-java"> public SendResult sendMessage(
        final String addr,
        final String brokerName,
        final Message msg,
        final SendMessageRequestHeader requestHeader,
        final long timeoutMillis,
        final CommunicationMode communicationMode,
        final SendCallback sendCallback,
        final TopicPublishInfo topicPublishInfo,
        final MQClientInstance instance,
        final int retryTimesWhenSendFailed,
        final SendMessageContext context,
        final DefaultMQProducerImpl producer
    ) throws RemotingException, MQBrokerException, InterruptedException {
        long beginStartTime = System.currentTimeMillis();
        RemotingCommand request = null;
        String msgType = msg.getProperty(MessageConst.PROPERTY_MESSAGE_TYPE);
        boolean isReply = msgType != null &amp;&amp; msgType.equals(MixAll.REPLY_MESSAGE_FLAG);
        if (isReply) {
            if (sendSmartMsg) {
                SendMessageRequestHeaderV2 requestHeaderV2 = SendMessageRequestHeaderV2.createSendMessageRequestHeaderV2(requestHeader);
                request = RemotingCommand.createRequestCommand(RequestCode.SEND_REPLY_MESSAGE_V2, requestHeaderV2);
            } else {
                request = RemotingCommand.createRequestCommand(RequestCode.SEND_REPLY_MESSAGE, requestHeader);
            }
        } else {
            if (sendSmartMsg || msg instanceof MessageBatch) {
                SendMessageRequestHeaderV2 requestHeaderV2 = SendMessageRequestHeaderV2.createSendMessageRequestHeaderV2(requestHeader);
                request = RemotingCommand.createRequestCommand(msg instanceof MessageBatch ? RequestCode.SEND_BATCH_MESSAGE : RequestCode.SEND_MESSAGE_V2, requestHeaderV2);
            } else {
                request = RemotingCommand.createRequestCommand(RequestCode.SEND_MESSAGE, requestHeader);
            }
        }
        request.setBody(msg.getBody());

        switch (communicationMode) {
            case ONEWAY:
                this.remotingClient.invokeOneway(addr, request, timeoutMillis);
                return null;
            case ASYNC:
                final AtomicInteger times = new AtomicInteger();
                long costTimeAsync = System.currentTimeMillis() - beginStartTime;
                if (timeoutMillis &lt; costTimeAsync) {
                    throw new RemotingTooMuchRequestException(&quot;sendMessage call timeout&quot;);
                }
                this.sendMessageAsync(addr, brokerName, msg, timeoutMillis - costTimeAsync, request, sendCallback, topicPublishInfo, instance,
                    retryTimesWhenSendFailed, times, context, producer);
                return null;
            case SYNC:
                long costTimeSync = System.currentTimeMillis() - beginStartTime;
                if (timeoutMillis &lt; costTimeSync) {
                    throw new RemotingTooMuchRequestException(&quot;sendMessage call timeout&quot;);
                }
                return this.sendMessageSync(addr, brokerName, msg, timeoutMillis - costTimeSync, request);
            default:
                assert false;
                break;
        }

        return null;
    }
</code></pre>
<p>Step6:如果注册了消息发送钩子函数，执行 after逻辑。 注意，就算消息发送过程中发<br>
生 RemotingException、 MQBrokerException、 InterruptedException时该方法也会执行。</p>
<pre><code class="language-java">if (this.hasSendMessageHook()) {
    context.setSendResult(sendResult);
    this.executeSendMessageHookAfter(context);
}
</code></pre>
<h4 id="1-同步发送">1. 同步发送</h4>
<p>MQ客户端发送消息的入口是MQClientAPIImpl#sendMessage。请求命令是Request­<br>
Code.SEND_MESSAGE，我们可以找到该命令的处理类: org.apache.rocketmq.broker.processor. SendMessageProcessor。入口方法在 SendMessageProcessor#sendMessage。</p>
<pre><code class="language-java">public RemotingCommand sendMessage(final ChannelHandlerContext ctx,
    final RemotingCommand request,
    final SendMessageContext sendMessageContext,
    final SendMessageRequestHeader requestHeader,
    final TopicQueueMappingContext mappingContext,
    final SendMessageCallback sendMessageCallback) throws RemotingCommandException {
    //发送消息并且进行消息审查
    final RemotingCommand response = preSend(ctx, request, requestHeader);
    if (response.getCode() != -1) {
        return response;
    }

    final SendMessageResponseHeader responseHeader = (SendMessageResponseHeader) response.readCustomHeader();

    final byte[] body = request.getBody();

    int queueIdInt = requestHeader.getQueueId();
    TopicConfig topicConfig = this.brokerController.getTopicConfigManager().selectTopicConfig(requestHeader.getTopic());

    if (queueIdInt &lt; 0) {
        queueIdInt = randomQueueId(topicConfig.getWriteQueueNums());
    }

    MessageExtBrokerInner msgInner = new MessageExtBrokerInner();
    msgInner.setTopic(requestHeader.getTopic());
    msgInner.setQueueId(queueIdInt);

    Map&lt;String, String&gt; oriProps = MessageDecoder.string2messageProperties(requestHeader.getProperties());

    // Step2:如果消息重试次数超过允许的最大重试次数，消息将进入到 DLD 延迟队列 
    if (!handleRetryAndDLQ(requestHeader, response, request, msgInner, topicConfig, oriProps)) {
        return response;
    }

    msgInner.setBody(body);
    msgInner.setFlag(requestHeader.getFlag());

    String uniqKey = oriProps.get(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX);
    if (uniqKey == null || uniqKey.length() &lt;= 0) {
        uniqKey = MessageClientIDSetter.createUniqID();
        oriProps.put(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX, uniqKey);
    }

    MessageAccessor.setProperties(msgInner, oriProps);
    msgInner.setTagsCode(MessageExtBrokerInner.tagsString2tagsCode(topicConfig.getTopicFilterType(), msgInner.getTags()));
    msgInner.setBornTimestamp(requestHeader.getBornTimestamp());
    msgInner.setBornHost(ctx.channel().remoteAddress());
    msgInner.setStoreHost(this.getStoreHost());
    msgInner.setReconsumeTimes(requestHeader.getReconsumeTimes() == null ? 0 : requestHeader.getReconsumeTimes());
    String clusterName = this.brokerController.getBrokerConfig().getBrokerClusterName();
    MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_CLUSTER, clusterName);

    msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties()));

    // Map&lt;String, String&gt; oriProps = MessageDecoder.string2messageProperties(requestHeader.getProperties());
    String traFlag = oriProps.get(MessageConst.PROPERTY_TRANSACTION_PREPARED);
    boolean sendTransactionPrepareMessage = false;
    if (Boolean.parseBoolean(traFlag)
        &amp;&amp; !(msgInner.getReconsumeTimes() &gt; 0 &amp;&amp; msgInner.getDelayTimeLevel() &gt; 0)) { //For client under version 4.6.1
        if (this.brokerController.getBrokerConfig().isRejectTransactionMessage()) {
            response.setCode(ResponseCode.NO_PERMISSION);
            response.setRemark(
                &quot;the broker[&quot; + this.brokerController.getBrokerConfig().getBrokerIP1()
                    + &quot;] sending transaction message is forbidden&quot;);
            return response;
        }
        sendTransactionPrepareMessage = true;
    }

    long beginTimeMillis = this.brokerController.getMessageStore().now();

    if (brokerController.getBrokerConfig().isAsyncSendEnable()) {
        CompletableFuture&lt;PutMessageResult&gt; asyncPutMessageFuture;
        if (sendTransactionPrepareMessage) {
            asyncPutMessageFuture = this.brokerController.getTransactionalMessageService().asyncPrepareMessage(msgInner);
        } else {
            asyncPutMessageFuture = this.brokerController.getMessageStore().asyncPutMessage(msgInner);
        }

        final int finalQueueIdInt = queueIdInt;
        final MessageExtBrokerInner finalMsgInner = msgInner;
        asyncPutMessageFuture.thenAcceptAsync(putMessageResult -&gt; {
            RemotingCommand responseFuture =
                handlePutMessageResult(putMessageResult, response, request, finalMsgInner, responseHeader, sendMessageContext,
                    ctx, finalQueueIdInt, beginTimeMillis, mappingContext);
            if (responseFuture != null) {
                doResponse(ctx, request, responseFuture);
            }
            sendMessageCallback.onComplete(sendMessageContext, response);
        }, this.brokerController.getPutMessageFutureExecutor());
        // Returns null to release the send message thread
        return null;
    } else {
        PutMessageResult putMessageResult = null;
        if (sendTransactionPrepareMessage) {
            putMessageResult = this.brokerController.getTransactionalMessageService().prepareMessage(msgInner);
        } else {
            //调用 DefaultMessageStore#putMessage 进行消息 存储
            putMessageResult = this.brokerController.getMessageStore().putMessage(msgInner);
        }
        handlePutMessageResult(putMessageResult, response, request, msgInner, responseHeader, sendMessageContext, ctx, queueIdInt, beginTimeMillis, mappingContext);
        sendMessageCallback.onComplete(sendMessageContext, response);
        return response;
    }
}
</code></pre>
<blockquote>
<p>msgCheck</p>
</blockquote>
<pre><code class="language-java">protected RemotingCommand msgCheck(final ChannelHandlerContext ctx,
    final SendMessageRequestHeader requestHeader, final RemotingCommand request,
    final RemotingCommand response) {

    //1 )检查该Broker是否有写权限
    if (!PermName.isWriteable(this.brokerController.getBrokerConfig().getBrokerPermission())
        &amp;&amp; this.brokerController.getTopicConfigManager().isOrderTopic(requestHeader.getTopic())) {
        response.setCode(ResponseCode.NO_PERMISSION);
        response.setRemark(&quot;the broker[&quot; + this.brokerController.getBrokerConfig().getBrokerIP1()
            + &quot;] sending message is forbidden&quot;);
        return response;
    }

    //检查该Topic是否可以进行消息发送。主要针对默认主题，默认主题不能发送消息，仅仅供路由查找
    if (!TopicValidator.validateTopic(requestHeader.getTopic(), response)) {
        return response;
    }
    if (TopicValidator.isNotAllowedSendTopic(requestHeader.getTopic(), response)) {
        return response;
    }

    TopicConfig topicConfig =
        this.brokerController.getTopicConfigManager().selectTopicConfig(requestHeader.getTopic());
    if (null == topicConfig) {
        int topicSysFlag = 0;
        if (requestHeader.isUnitMode()) {
            if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
                topicSysFlag = TopicSysFlag.buildSysFlag(false, true);
            } else {
                topicSysFlag = TopicSysFlag.buildSysFlag(true, false);
            }
        }

        LOGGER.warn(&quot;the topic {} not exist, producer: {}&quot;, requestHeader.getTopic(), ctx.channel().remoteAddress());
        //在 NameServer端存储主题的配置信息，
        topicConfig = this.brokerController.getTopicConfigManager().createTopicInSendMessageMethod(
            requestHeader.getTopic(),
            requestHeader.getDefaultTopic(),
            RemotingHelper.parseChannelRemoteAddr(ctx.channel()),
            requestHeader.getDefaultTopicQueueNums(), topicSysFlag);

        if (null == topicConfig) {
            if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
                topicConfig =
                    this.brokerController.getTopicConfigManager().createTopicInSendMessageBackMethod(
                        requestHeader.getTopic(), 1, PermName.PERM_WRITE | PermName.PERM_READ,
                        topicSysFlag);
            }
        }

        if (null == topicConfig) {
            response.setCode(ResponseCode.TOPIC_NOT_EXIST);
            response.setRemark(&quot;topic[&quot; + requestHeader.getTopic() + &quot;] not exist, apply first please!&quot;
                + FAQUrl.suggestTodo(FAQUrl.APPLY_TOPIC_URL));
            return response;
        }
    }
    //4)检查队列，如果队列不合法，返回错误码 。
    int queueIdInt = requestHeader.getQueueId();
    int idValid = Math.max(topicConfig.getWriteQueueNums(), topicConfig.getReadQueueNums());
    if (queueIdInt &gt;= idValid) {
        String errorInfo = String.format(&quot;request queueId[%d] is illegal, %s Producer: %s&quot;,
            queueIdInt,
            topicConfig,
            RemotingHelper.parseChannelRemoteAddr(ctx.channel()));

        LOGGER.warn(errorInfo);
        response.setCode(ResponseCode.SYSTEM_ERROR);
        response.setRemark(errorInfo);

        return response;
    }
    return response;
}
</code></pre>
<blockquote>
<p>handleRetryAndDLQ</p>
</blockquote>
<pre><code class="language-java">private boolean handleRetryAndDLQ(SendMessageRequestHeader requestHeader, RemotingCommand response,
    RemotingCommand request,
    MessageExt msg, TopicConfig topicConfig, Map&lt;String, String&gt; properties) {
    String newTopic = requestHeader.getTopic();
    if (null != newTopic &amp;&amp; newTopic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
        String groupName = newTopic.substring(MixAll.RETRY_GROUP_TOPIC_PREFIX.length());
        SubscriptionGroupConfig subscriptionGroupConfig =
            this.brokerController.getSubscriptionGroupManager().findSubscriptionGroupConfig(groupName);
        if (null == subscriptionGroupConfig) {
            response.setCode(ResponseCode.SUBSCRIPTION_GROUP_NOT_EXIST);
            response.setRemark(
                &quot;subscription group not exist, &quot; + groupName + &quot; &quot; + FAQUrl.suggestTodo(FAQUrl.SUBSCRIPTION_GROUP_NOT_EXIST));
            return false;
        }

        int maxReconsumeTimes = subscriptionGroupConfig.getRetryMaxTimes();
        if (request.getVersion() &gt;= MQVersion.Version.V3_4_9.ordinal() &amp;&amp; requestHeader.getMaxReconsumeTimes() != null) {
            maxReconsumeTimes = requestHeader.getMaxReconsumeTimes();
        }
        int reconsumeTimes = requestHeader.getReconsumeTimes() == null ? 0 : requestHeader.getReconsumeTimes();
        // Using '&gt;' instead of '&gt;=' to compatible with the case that reconsumeTimes here are increased by client.

        // Step2:如果消息重试次数超过允许的最大重试次数，消息将进入到 DLD 延迟队列。延迟队列主题: %DLQ%+消费组名
        if (reconsumeTimes &gt; maxReconsumeTimes) {
            properties.put(MessageConst.PROPERTY_DELAY_TIME_LEVEL, &quot;-1&quot;);
            newTopic = MixAll.getDLQTopic(groupName);
            int queueIdInt = randomQueueId(DLQ_NUMS_PER_GROUP);
            topicConfig = this.brokerController.getTopicConfigManager().createTopicInSendMessageBackMethod(newTopic,
                DLQ_NUMS_PER_GROUP,
                PermName.PERM_WRITE | PermName.PERM_READ, 0
            );
            msg.setTopic(newTopic);
            msg.setQueueId(queueIdInt);
            msg.setDelayTimeLevel(0);
            if (null == topicConfig) {
                response.setCode(ResponseCode.SYSTEM_ERROR);
                response.setRemark(&quot;topic[&quot; + newTopic + &quot;] not exist&quot;);
                return false;
            }
        }
    }
    int sysFlag = requestHeader.getSysFlag();
    if (TopicFilterType.MULTI_TAG == topicConfig.getTopicFilterType()) {
        sysFlag |= MessageSysFlag.MULTI_TAGS_FLAG;
    }
    msg.setSysFlag(sysFlag);
    return true;
}
</code></pre>
<h4 id="2异步发送">2.异步发送</h4>
<p>消息异步发送是指消息生产者调用发送的 API后，无须阻塞等待消息服务器返回本次消息发送结果，只需要提供一个回调函数，供消息发送客户端在收到响应结果回调。 异步方 式相比同步方式，消息发送端的发送性能会显著提高，但为了保护消息服务器的负载压力， RocketMQ 对消息 发送的异步消息进行了井发控制，通过参数clientAsyncSemaphoreValue来控制，默认为65535。异步消息发送虽然也可以通过 DefaultMQProducer#retryTimes­WhenSendAsyncFailed 属性来控制消息重试次数，但是重试的调用人 口是在收到服务端响应包时进行的，如果出现网络异常、网络超时等将不会重试。</p>
<h4 id="3-单向发送">3. 单向发送</h4>
<p>单向发送是指消息生产者调用消息发送的API后，无须等待消息服务器返回本次消息发送结果，并且无须提供回调函数，表示消息发送压根就不关心本次消息发送是否成功，其实现原理与异步消息发送相同，只是消息发送客户端在收到响应结果后什么都不做而已，并且没有重试机制。</p>
<h2 id="35-批量消息发送">3.5 批量消息发送</h2>
<p>批量消息发送是将同一主题的多条消息一起打包发送到消息服务端，减少网络调用次数，提高网络传输效率 。</p>
<p>当然，并不是在同一批次中发送的消息数量越多性能就越好，其判断依据是单条消息的长度，如果单条消息内容比较长，则打包多条消息发送会影响其他线程发送消息的响应时间，并且单批次消息发送总长度不能超过 DefaultMQProducer#maxMessageSize。</p>
<blockquote>
<p>RemotingCommand</p>
</blockquote>
<pre><code class="language-java">//请求命令编码，请求命令类型
private int code;
private LanguageCode language = LanguageCode.JAVA;

//版本号
private int version = 0;

//客户端请求序号
private int opaque = requestId.getAndIncrement();

//标记。倒数第一位表示请求类型，O:请求; 1:返回。倒数第二位，1:表示oneway
private int flag = 0;

//描述
private String remark;
//扩展属性
private HashMap&lt;String, String&gt; extFields;
//每个请求对应 的请求头信息
private transient CommandCustomHeader customHeader;

private SerializeType serializeTypeCurrentRPC = serializeTypeConfigInThisServer;
//请求体
private transient byte[] body;
</code></pre>
<p>单条消息发送时，消息体的内容将保存在body中。 批量消息发送 ，需要将多条消息体的内容存储在body中。</p>
<p>RocketMQ采取的方式是，对单条消息内容使用固定格式进行存储。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1663150413082.png" alt="消息封装格式" loading="lazy"></figure>
<blockquote>
<p>DefaultMQProducer#send 消息批量发迭</p>
</blockquote>
<pre><code class="language-java">@Override
public SendResult send(
    Collection&lt;Message&gt; msgs) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    return this.defaultMQProducerImpl.send(batch(msgs));
}
</code></pre>
<p>首先在消息发送端，调用batch方法，将一批消息封装成MessageBatch对象。Message­Batch继承自Message对象，MessageBatch内部持有List<Message> messages。这样的话，批量消息发送与单条消息发送的处理流程完全一样。MessageBatch只需要将该集合中的每条消息的消息体 body聚合成一个 byte数组，在消息服务端能够从该 byte[] 数值中正确解析出消息即可。</p>
<p>在创建RemotingCommand对象时将调用messageBatch#encode()方法填充到Remoting-Command的body域中。</p>
<pre><code class="language-java">public static byte[] encodeMessages(List&lt;Message&gt; messages) {
    //TO DO refactor, accumulate in one buffer, avoid copies
    List&lt;byte[]&gt; encodedMessages = new ArrayList&lt;byte[]&gt;(messages.size());
    int allSize = 0;
    for (Message message : messages) {
        byte[] tmp = encodeMessage(message);
        encodedMessages.add(tmp);
        allSize += tmp.length;
    }
    byte[] allBytes = new byte[allSize];
    int pos = 0;
    for (byte[] bytes : encodedMessages) {
        System.arraycopy(bytes, 0, allBytes, pos, bytes.length);
        pos += bytes.length;
    }
    return allBytes;
}

public static byte[] encodeMessage(Message message) {
    //only need flag, body, properties
    byte[] body = message.getBody();
    int bodyLen = body.length;
    String properties = messageProperties2String(message.getProperties());
    byte[] propertiesBytes = properties.getBytes(CHARSET_UTF8);
    //note properties length must not more than Short.MAX
    short propertiesLength = (short) propertiesBytes.length;
    int sysFlag = message.getFlag();
    int storeSize = 4 // 1 TOTALSIZE
        + 4 // 2 MAGICCOD
        + 4 // 3 BODYCRC
        + 4 // 4 FLAG
        + 4 + bodyLen // 4 BODY
        + 2 + propertiesLength;
    ByteBuffer byteBuffer = ByteBuffer.allocate(storeSize);
    // 1 TOTALSIZE
    byteBuffer.putInt(storeSize);

    // 2 MAGICCODE
    byteBuffer.putInt(0);

    // 3 BODYCRC
    byteBuffer.putInt(0);

    // 4 FLAG
    int flag = message.getFlag();
    byteBuffer.putInt(flag);

    // 5 BODY
    byteBuffer.putInt(bodyLen);
    byteBuffer.put(body);

    // 6 properties
    byteBuffer.putShort(propertiesLength);
    byteBuffer.put(propertiesBytes);

    return byteBuffer.array();
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMq技术内幕笔记（一）]]></title>
        <id>https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-yi/</id>
        <link href="https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-yi/">
        </link>
        <updated>2022-09-07T09:47:04.000Z</updated>
        <summary type="html"><![CDATA[<h1 id="1-大纲">1 大纲</h1>
<h2 id="11-rocketmq-原代码的目录结构">1.1 RocketMQ 原代码的目录结构</h2>
<p>RocketMQ 核心目 录说明如下 。</p>
<ol>
<li>broker: broker模块(broker启动进程) 。</li>
<li>client:消息客户端，包含消息生产者、消息消费者相关类。</li>
<li>common:公共包。</li>
<li>dev:开发者信息(非源代码)。</li>
<li>distribution:部署实例文件夹(非源代码)。</li>
<li>example: RocketMQ 示例代码 。</li>
<li>filter:消息过滤相关基础类。</li>
<li>filtersrv: 消息过滤服务器实现相关类(Filter启动进程)。</li>
<li>logappender:日志实现相关类。</li>
<li>namesrv : NameServer 实现相关类(Names巳rver启动进程) 。</li>
<li>openmessaging: 消息开放标准，正在制定中 。</li>
<li>remoting: 远程通信模块，基于 Netty。</li>
<li>srvutil:服务器工具类。</li>
<li>store:消息存储实现相关类 。</li>
<li>style: checkstyle相关实现。</li>
<li>test: 测试相关类。</li>
<li>tools: 工具类，监控命令相关实现类。</li>
</ol>
]]></summary>
        <content type="html"><![CDATA[<h1 id="1-大纲">1 大纲</h1>
<h2 id="11-rocketmq-原代码的目录结构">1.1 RocketMQ 原代码的目录结构</h2>
<p>RocketMQ 核心目 录说明如下 。</p>
<ol>
<li>broker: broker模块(broker启动进程) 。</li>
<li>client:消息客户端，包含消息生产者、消息消费者相关类。</li>
<li>common:公共包。</li>
<li>dev:开发者信息(非源代码)。</li>
<li>distribution:部署实例文件夹(非源代码)。</li>
<li>example: RocketMQ 示例代码 。</li>
<li>filter:消息过滤相关基础类。</li>
<li>filtersrv: 消息过滤服务器实现相关类(Filter启动进程)。</li>
<li>logappender:日志实现相关类。</li>
<li>namesrv : NameServer 实现相关类(Names巳rver启动进程) 。</li>
<li>openmessaging: 消息开放标准，正在制定中 。</li>
<li>remoting: 远程通信模块，基于 Netty。</li>
<li>srvutil:服务器工具类。</li>
<li>store:消息存储实现相关类 。</li>
<li>style: checkstyle相关实现。</li>
<li>test: 测试相关类。</li>
<li>tools: 工具类，监控命令相关实现类。</li>
</ol>
<!-- more -->
<h2 id="12-rocketmq-的设计理念和目标">1.2 RocketMQ 的设计理念和目标</h2>
<h3 id="121-设计理念">1.2.1 设计理念</h3>
<p>RocketMQ 设计基于主题的发布与 订阅 模式 ， (Broker)、消息消费。</p>
<p>NameServer：实现元数据的管理(Topic路由信息等)，因为 Topic 路由信息无须在集群之 间保持强一致，追求最终一致性，并且能容 忍分钟级的 不一致 。</p>
<p>高效的IO存储机制：RocketMQ追求消息发送的高吞吐量， RocketMQ 的消息存储文件设计成文件组的概念，组内单个文件大小固定，方便引人内存 l映射机制，所 有主 题的消息存储基于顺序写，极大地提高了消息写性能， 同时为了兼顾消息消费与消息查找，引入了消息消费队列文件与索引文件。</p>
<h3 id="122-设计能力">1.2.2 设计能力</h3>
<ol>
<li>
<p>架构模式<br>
RocketMQ 与大部分消息中间件一样，采用发布订阅模式，基本的参与组件主要包括 :<br>
消息发送者、消息服务器(消息存储)、消息消费、路由发现 。</p>
</li>
<li>
<p>顺序消息<br>
所谓顺序消息，就是消息消费者按照消息达到消息存储服务器的顺序消费 。 RocketMQ 可以严格保证消息有序 。</p>
</li>
<li>
<p>消息过滤<br>
RocketMQ 消息过滤支持在服务端与消费端的消息过滤机制 。<br>
1 )消息在 Broker 端过滤。Broker只将消息消费者感兴趣的消息发送给消息消费者 。<br>
2 )消息在消息消费端过滤，消息过滤方式完全由消息消费者自定义，但缺点是有很多无用的消息会从 Broker传输到消费端。</p>
</li>
<li>
<p>消息存储<br>
RocketMQ 追求消息存储的高性能，引人内存映射机制，所有主题的消息顺序存储在同一个文件中 。 同时为了避免消息无限在消息存储服务器中累积，引入了消息文件过期机制与文件存储空间报警机制。</p>
</li>
<li>
<p>消息高可用性<br>
通常影响消息可靠性的有以下几种情况 。</p>
</li>
</ol>
<ol>
<li>Broker正常关机。</li>
<li>Broker异常 Crash。</li>
<li>OS Crash。</li>
<li>机器断电，但 是 能立即恢复供电情况 。</li>
<li>机器无法开机(可能是 CPU、主板、 内存等关键设备损 坏)。</li>
<li>磁盘设备损坏。<br>
情况 1~4 的 RocketMQ 在同步刷盘机制下可以确保不丢失消息，在异步刷盘模式下，会丢失少量消息 。 情况 5-6 属于单点故障，一旦发生，该节点上的消息全 部丢失，如果开启了异步复制机制， RoketMQ 能保证只丢失少量消息。</li>
</ol>
<ol start="6">
<li>
<p>消息到达 (消费)低延迟<br>
RocketMQ在消息不发生消息堆积时，以长轮询模式实现准实时的消息推送模式。</p>
</li>
<li>
<p>确保消息必须被消费一次<br>
RocketMQ 通过消息消费确认机制(ACK)来确保消息至少被消费一次，但由于ACK消息有可能丢失等其他原因，RocketMQ无法做到消息只被消费一次，有重复消费的可能。</p>
</li>
<li>
<p>回溯消息<br>
回溯消息是指消息消费端已经消费成功的消息，由于业务要求需要重新消费消息。 RocketMQ 支持按时间回溯消息，时间维度可精确到毫秒，可以向前或向后回溯。</p>
</li>
<li>
<p>消息堆积<br>
RocketMQ 消息存储使用磁盘文件 (内存映射机制)，并且在物理布局上为多个大小相等的文件组成逻辑文件组，可以无限循环使用。 RocketMQ消息存储文件并不是永久存储在消息服务器端，而是提供了过期机制，默认保留3天。</p>
</li>
<li>
<p>定时消息<br>
定 时消息 是指消息发送到 Broker 后， 不能被消息消费端立即消费，要到特定的时间点或者等待特定的时间后才能被消费。 如果要支持任意精度的定时消息消费，必须在消息服务端对消息进行排序，势必带来很大的性能损耗，故RocketMQ不支持任意精度的定时消息，而只支持特定延迟级别。</p>
</li>
<li>
<p>消息重试机制<br>
消息重试是指消息在消费时，如果发送异常，消息中间件需要支持消息重新投递，RocketMQ支持消息重试机制。</p>
</li>
</ol>
<h1 id="2-rocketmq路由中心nameserver">2 RocketMQ路由中心NameServer</h1>
<h2 id="21-nameserver-架构设计">2.1 NameServer 架构设计</h2>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1663034308783.png" alt="RocketMQ 物理部署图" loading="lazy"></figure>
<p>Broker消息服务器在启动时向所有 NameServer注册，消息生产者(Producer)在发送消 息之前先从 NameServer获取Broker 服务器地址列表，然后根据负载算法从列表中选择一 台消息服务器进行消息发送。NameServer与每台 Broker 服务器保持长连接，并间隔30s检测Broker是否存活，如果检测到 Broker右机，则从路由注册表中将其移除。但是路由变化不会马上通知消息生产者。</p>
<p>NameServer本身的高可用可通过部 署多台 NameServer服务器来实现，但彼此之间互不通信，也就是 NameServer服务器之间在某一时刻的数据并不会完全相同，但这对消 息发送不会造成任何影响。</p>
<h2 id="22-nameserver-启动流程">2.2 NameServer 启动流程</h2>
<p>NameServer启动类 : org.apache.rocketmq.namesrv.NamesrvStartup。</p>
<ol>
<li>Step 1: 首先来解析配置文件，需要填充 NameServerConfig、NettyServerConfig属性值。</li>
</ol>
<pre><code class="language-java">  public static void parseCommandlineAndConfigFile(String[] args) throws Exception {
        System.setProperty(RemotingCommand.REMOTING_VERSION_KEY, Integer.toString(MQVersion.CURRENT_VERSION));
        //PackageConflictDetect.detectFastjson();

        Options options = ServerUtil.buildCommandlineOptions(new Options());
        CommandLine commandLine = ServerUtil.parseCmdLine(&quot;mqnamesrv&quot;, args, buildCommandlineOptions(options), new PosixParser());
        if (null == commandLine) {
            System.exit(-1);
            return;
        }

        namesrvConfig = new NamesrvConfig();
        nettyServerConfig = new NettyServerConfig();
        nettyClientConfig = new NettyClientConfig();
        nettyServerConfig.setListenPort(9876);
        controllerConfig = new ControllerConfig();
        if (commandLine.hasOption('c')) {
            String file = commandLine.getOptionValue('c');
            if (file != null) {
                InputStream in = new BufferedInputStream(Files.newInputStream(Paths.get(file)));
                properties = new Properties();
                properties.load(in);
                MixAll.properties2Object(properties, namesrvConfig);
                MixAll.properties2Object(properties, nettyServerConfig);
                MixAll.properties2Object(properties, nettyClientConfig);
                MixAll.properties2Object(properties, controllerConfig);

                namesrvConfig.setConfigStorePath(file);

                System.out.printf(&quot;load config properties file OK, %s%n&quot;, file);
                in.close();
            }
        }

        if (commandLine.hasOption('p')) {
            MixAll.printObjectProperties(null, namesrvConfig);
            MixAll.printObjectProperties(null, nettyServerConfig);
            MixAll.printObjectProperties(null, nettyClientConfig);
            MixAll.printObjectProperties(null, controllerConfig);
            System.exit(0);
        }

        MixAll.properties2Object(ServerUtil.commandLine2Properties(commandLine), namesrvConfig);

        if (null == namesrvConfig.getRocketmqHome()) {
            System.out.printf(&quot;Please set the %s variable in your environment to match the location of the RocketMQ installation%n&quot;, MixAll.ROCKETMQ_HOME_ENV);
            System.exit(-2);
        }

        LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory();
        JoranConfigurator configurator = new JoranConfigurator();
        configurator.setContext(lc);
        lc.reset();
        configurator.doConfigure(namesrvConfig.getRocketmqHome() + &quot;/conf/logback_namesrv.xml&quot;);

        log = InternalLoggerFactory.getLogger(LoggerName.NAMESRV_LOGGER_NAME);

        MixAll.printObjectProperties(log, namesrvConfig);
        MixAll.printObjectProperties(log, nettyServerConfig);
    }
</code></pre>
<p>创建 NameServerConfig ( NameServer业务参数)、NettyServer-Config ( NameServer网络参数)，然后在解析启动时把指定的配置文件或启动命令中的选项 值，填充到 nameServerConfig,nettyServerConfig对象。</p>
<pre><code class="language-java">public class NamesrvConfig {
    //rocketmq 主目录，可以通过 -Drocketmq.home.dir=path或通过设置环境变量 ROCKETMQ_HOME 来配置 RocketMQ 的主目录 。
    private String rocketmqHome = System.getProperty(MixAll.ROCKETMQ_HOME_PROPERTY, System.getenv(MixAll.ROCKETMQ_HOME_ENV));

    //NameServer存储 KV 配置属性 的持久化路径 
    private String kvConfigPath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;kvConfig.json&quot;;

    //NameServer 默认配置文件路径
    private String configStorePath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;namesrv.properties&quot;;
    private String productEnvName = &quot;center&quot;;
    private boolean clusterTest = false;

    //是否支持顺序消息，默认是不支持
    private boolean orderMessageEnable = false;
    private boolean returnOrderTopicConfigToBroker = true;
}
</code></pre>
<pre><code class="language-java">public class NettyServerConfig implements Cloneable {

    //NameServer监昕端口，该值默认会被初始化为 9876
    private int listenPort = 0;

    //Netty业务线程池线程个数。
    private int serverWorkerThreads = 8;

    //Netty public任务线程池线程个数，Netty网络设计，
    //根据业务类型会创建不同的线程池，比如处理消息发送、消息消费、心跳检测等 。
    //如果该业务类型(RequestCode)未注册线程池， 则由 public线程池执行。
    private int serverCallbackExecutorThreads = 0;

    //IO线程池线程个数，主要是 NameServer、Broker端解析请求、返回相应的线程个数，这类线程主要是处理网络请求的解析请求包，然后转发到
    //各个业务线程池完成具体的业务操作，然后将结果再返回调用方 。
    private int serverSelectorThreads = 3;

    //send oneway 消息请求井发度
    private int serverOnewaySemaphoreValue = 256;

    //异步消息发送最大并发度
    private int serverAsyncSemaphoreValue = 64;

    //网络连接最大空闲时间，默认120s。 如果连接空闲时间超过该参数设置的值，连接将被关闭。
    private int serverChannelMaxIdleTimeSeconds = 120;

    //网络 socket发送缓存区大小， 默认 64k
    private int serverSocketSndBufSize = NettySystemConfig.socketSndbufSize;
    //网络 socket接收缓存区大小 ，默认 64k
    private int serverSocketRcvBufSize = NettySystemConfig.socketRcvbufSize;
    private int writeBufferHighWaterMark = NettySystemConfig.writeBufferHighWaterMark;
    private int writeBufferLowWaterMark = NettySystemConfig.writeBufferLowWaterMark;
    private int serverSocketBacklog = NettySystemConfig.socketBacklog;
    //ByteBuffer是否开启缓存 ， 建议开启
    private boolean serverPooledByteBufAllocatorEnable = true;

    /**
     * make install
     * ../glibc-2.10.1/configure \ --prefix=/usr \ --with-headers=/usr/include \
     * --host=x86_64-linux-gnu \ --build=x86_64-pc-linux-gnu \ --without-gd
     */
    //是否启用EpollIO模型， Linux环境建议开启。
    private boolean useEpollNativeSelector = false;
}
</code></pre>
<blockquote>
<p>️启动 NameServer时，可以先使用/mqnameserver-c configFile -p 打印当前加载的配置属性</p>
</blockquote>
<ol start="2">
<li>Step2:根据启动属性创建 NamesrvController实例，并初始化该实例，实例为NameServer核心控制器。</li>
</ol>
<pre><code class="language-java">  public boolean initialize() {
        //加载kvConfigPath下kvConfig.json配置文件里的KV配置，然后将这些配置放到KVConfigManager#configTable属性中
        loadConfig();
        //根据nettyServerConfig初始化一个netty服务器。
        initiateNetworkComponents();
        //初始化负责处理Netty网络交互数据的线程池，默认线程数是16个
        initiateThreadExecutors();
        ////注册Netty服务端业务处理逻辑，如果开启了clusterTest，那么注册的请求处理类是ClusterTestRequestProcessor，否则请求处理类是DefaultRequestProcessor
        registerProcessor();
        //注册心跳机制线程池，延迟5毫秒启动，每隔5秒遍历RouteInfoManager#brokerLiveTable这个属性，用来扫描不存活的broker
        //注册打印KV配置线程池，延迟1分钟启动、每10分钟打印出kvConfig配置
        startScheduleService();
        initiateSslContext();
        initiateRpcHooks();
        return true;
    }
</code></pre>
<ol start="3">
<li>Step3 :注册JVM钩子函数并启动服务器，以便监昕 Broker、消息生产者的网络请求 。</li>
</ol>
<pre><code class="language-java">//在 JVM 进程关闭之前，先将线程池关闭，及时释放资源 。
        Runtime.getRuntime().addShutdownHook(new ShutdownHookThread(log, (Callable&lt;Void&gt;) () -&gt; {
            controller.shutdown();
            return null;
        }));

        controller.start();
</code></pre>
<h2 id="23-nameserver-路由注册-故障剔除">2.3 NameServer 路由注册、故障剔除</h2>
<p>NameServer主要作用是为消息生产者和消息消费者提供关于主题Topic的路由信息，那么NameServer需要存储路由的基础信息，还要能够管理Broker节点，包括路由注册、 路由删除等功能。</p>
<h3 id="231-路由元信息">2.3.1 路由元信息</h3>
<p>NameServer路由实现类: org.apache.rocketmq.namesrv.routeinfo.RoutelnfoManager</p>
<blockquote>
<p>RoutelnfoManage 路由元数据</p>
</blockquote>
<pre><code class="language-java">public class RouteInfoManager {
    private static final InternalLogger log = InternalLoggerFactory.getLogger(LoggerName.NAMESRV_LOGGER_NAME);
    private final static long DEFAULT_BROKER_CHANNEL_EXPIRED_TIME = 1000 * 60 * 2;
    private final ReadWriteLock lock = new ReentrantReadWriteLock();

    //Topic 消息队列路由信息，消息发送时根据路由表进行负 载均衡 。
    private final Map&lt;String/* topic */, Map&lt;String, QueueData&gt;&gt; topicQueueTable;

    //Broker 基础信息， 包含 brokerName、 所属集群名称 、 主备 Broker地址。
    private final Map&lt;String/* brokerName */, BrokerData&gt; brokerAddrTable;

    //Broker 集群信息，存储集群中所有 Broker 名称 。
    private final Map&lt;String/* clusterName */, Set&lt;String/* brokerName */&gt;&gt; clusterAddrTable;
    //Broker 状态信息 。 NameServer 每次 收到心跳包时会 替换该信 息
    private final Map&lt;BrokerAddrInfo/* brokerAddr */, BrokerLiveInfo&gt; brokerLiveTable;
    // Broker上的 FilterServer列表，用于类模式消息过滤
    private final Map&lt;BrokerAddrInfo/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable;
    private final Map&lt;String/* topic */, Map&lt;String/*brokerName*/, TopicQueueMappingInfo&gt;&gt; topicQueueMappingInfoTable;

    private final BatchUnregistrationService unRegisterService;

    private final NamesrvController namesrvController;
    private final NamesrvConfig namesrvConfig;
}
</code></pre>
<p>RocketMQ基于订阅发布机制，一个Topic拥有多个消息队列 ，一个Broker为每一主题默认创建4个读队列4个写队列。多个Broker组成一个集群，BrokerName由相同的多台Broker组成Master-Slave架构 ， brokerId为0代表 Master，大于0表示Slave。 BrokerLivelnfo中的lastUpdateTimestamp 存储上次收到Broker心跳包的时间。</p>
<h3 id="232-路由注册">2.3.2 路由注册</h3>
<p>RocketMQ路由注册是通过 Broker与NameServer的心跳功能实现的。Broker启动时 向 集群中 所有的 NameServer发送心跳语句，每隔30s向 集群 中所 有 NameServer发送心跳包，NameServer收到Broker心跳包时会更新brokerLiveTable缓存中BrokerLivelnfo的lastUpdateTimestamp，然后NameServer每隔10s扫描 brokerLiveTable，如果连续120s没有收到心跳包， NameServer将移除该 Broker的路由信息同时关闭Socket连接。</p>
<ol>
<li>Broker发送心跳包</li>
</ol>
<blockquote>
<p>Broker端心跳包发送</p>
</blockquote>
<pre><code class="language-java">  scheduledFutures.add(this.scheduledExecutorService.scheduleAtFixedRate(new AbstractBrokerRunnable(this.getBrokerIdentity()) {
            @Override
            public void run2() {
                try {
                    if (System.currentTimeMillis() &lt; shouldStartTime) {
                        BrokerController.LOG.info(&quot;Register to namesrv after {}&quot;, shouldStartTime);
                        return;
                    }
                    if (isIsolated) {
                        BrokerController.LOG.info(&quot;Skip register for broker is isolated&quot;);
                        return;
                    }
                    BrokerController.this.registerBrokerAll(true, false, brokerConfig.isForceRegister());
                } catch (Throwable e) {
                    BrokerController.LOG.error(&quot;registerBrokerAll Exception&quot;, e);
                }
            }
        }, 1000 * 10, Math.max(10000, Math.min(brokerConfig.getRegisterNameServerPeriod(), 60000)), TimeUnit.MILLISECONDS));
</code></pre>
<blockquote>
<p>registerBrokerAll</p>
</blockquote>
<pre><code class="language-java">   final List&lt;RegisterBrokerResult&gt; registerBrokerResultList = new CopyOnWriteArrayList&lt;&gt;();

final CountDownLatch countDownLatch = new CountDownLatch(nameServerAddressList.size());
    for (final String namesrvAddr : nameServerAddressList) {
        brokerOuterExecutor.execute(new AbstractBrokerRunnable(brokerIdentity) {
            @Override
            public void run2() {
                try {
                    RegisterBrokerResult result = registerBroker(namesrvAddr, oneway, timeoutMills, requestHeader, body);
                    if (result != null) {
                        registerBrokerResultList.add(result);
                    }

                    LOGGER.info(&quot;Registering current broker to name server completed. TargetHost={}&quot;, namesrvAddr);
                } catch (Exception e) {
                    LOGGER.error(&quot;Failed to register current broker to name server. TargetHost={}&quot;, namesrvAddr, e);
                } finally {
                    countDownLatch.countDown();
                }
            }
        });
    }

        try {
        if (!countDownLatch.await(timeoutMills, TimeUnit.MILLISECONDS)) {
            LOGGER.warn(&quot;Registration to one or more name servers does NOT complete within deadline. Timeout threshold: {}ms&quot;, timeoutMills);
        }
    } catch (InterruptedException ignore) {
    }
</code></pre>
<p>该方法主要是遍历 NameServer列表，Broker消息服务器依次向 NameServer发送心跳包。</p>
<pre><code class="language-java">  private RegisterBrokerResult registerBroker(
            final String namesrvAddr,
            final boolean oneway,
            final int timeoutMills,
            final RegisterBrokerRequestHeader requestHeader,
            final byte[] body
    ) throws RemotingCommandException, MQBrokerException, RemotingConnectException, RemotingSendRequestException, RemotingTimeoutException,
            InterruptedException {
        RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.REGISTER_BROKER, requestHeader);
        request.setBody(body);

        if (oneway) {
            try {
                this.remotingClient.invokeOneway(namesrvAddr, request, timeoutMills);
            } catch (RemotingTooMuchRequestException e) {
                // Ignore
            }
            return null;
        }
        //....
    }
</code></pre>
<p>发送心跳包具体逻辑，首先封装请求包头( Header)。</p>
<p>brokerAddr: broker 地址 。<br>
brokerId: brokerld,0:Master;大 0: Slave。<br>
brokerName:broker名称。<br>
clusterName: 集群名称。<br>
haServerAddr: master 地址，初次请求时该值为空，slave 向Nameserver注册后返回。<br>
requestBody:<br>
filterServerList：消息过滤服务器列表。<br>
topicConfigWrapper：主题配置。</p>
<pre><code class="language-java">    final RegisterBrokerRequestHeader requestHeader = new RegisterBrokerRequestHeader();
    requestHeader.setBrokerAddr(brokerAddr);
    requestHeader.setBrokerId(brokerId);
    requestHeader.setBrokerName(brokerName);
    requestHeader.setClusterName(clusterName);
    requestHeader.setHaServerAddr(haServerAddr);
    requestHeader.setEnableActingMaster(enableActingMaster);
    requestHeader.setCompressed(false);

    RegisterBrokerBody requestBody = new RegisterBrokerBody();
    requestBody.setTopicConfigSerializeWrapper(TopicConfigAndMappingSerializeWrapper.from(topicConfigWrapper));
    requestBody.setFilterServerList(filterServerList);
</code></pre>
<blockquote>
<p>RocketMQ网络传输基于 Netty,每一个请求，RocketMQ都会定义一个RequestCode，然后在服务端会对应相应的网络处理器 (processor包中)。</p>
</blockquote>
<ol start="2">
<li>NameServer处理心跳包</li>
</ol>
<p>org.apache.rocketmq.namesrv.processor.DefaultRequestProcessor 网络处理器解析请求类型， 如果请求类型为RequestCode.REGISTER_BROKER，则请求最终转发到RoutelnfoMan ager#registerBroker。</p>
<pre><code class="language-java">this.lock.writeLock().lockInterruptibly();

//init or update the cluster info
Set&lt;String&gt; brokerNames = this.clusterAddrTable.computeIfAbsent(clusterName, k -&gt; new HashSet&lt;&gt;());
brokerNames.add(brokerName);
</code></pre>
<ul>
<li>Step1:路由注册需要加写锁，防止并发修改RoutelnfoManager中的路由表。</li>
</ul>
<pre><code class="language-java">// 是否第一个注册
boolean registerFirst = false; 
BrokerData brokerData = this.brokerAddrTable.get(brokerName);
if (null == brokerData) {
    registerFirst = true;
    brokerData = new BrokerData(clusterName, brokerName, new HashMap&lt;&gt;());
    this.brokerAddrTable.put(brokerName, brokerData);
}

boolean isOldVersionBroker = enableActingMaster == null;
brokerData.setEnableActingMaster(!isOldVersionBroker &amp;&amp; enableActingMaster);
brokerData.setZoneName(zoneName);

//省略

String oldAddr = brokerAddrsMap.put(brokerId, brokerAddr);
registerFirst = registerFirst || (StringUtils.isEmpty(oldAddr));
</code></pre>
<p>Step2 :维护BrokerData信息，首先从brokerAddrTable根据 BrokerName尝试获取 Broker信息，如果不存在，则新建BrokerData并放入到brokerAddrTable, registerFirst设置为 true;如果存在，直接替换原先的，registerFirst设置为false，表示非第一次注册。</p>
<pre><code class="language-java">boolean isMaster = MixAll.MASTER_ID == brokerId;
boolean isPrimeSlave = !isOldVersionBroker &amp;&amp; !isMaster
        &amp;&amp; brokerId == Collections.min(brokerAddrsMap.keySet());
if (null != topicConfigWrapper &amp;&amp; (isMaster || isPrimeSlave)) {

        ConcurrentMap&lt;String, TopicConfig&gt; tcTable =
                topicConfigWrapper.getTopicConfigTable();
        if (tcTable != null) {
            for (Map.Entry&lt;String, TopicConfig&gt; entry : tcTable.entrySet()) {
                if (registerFirst || this.isTopicConfigChanged(clusterName, brokerAddr,
                        topicConfigWrapper.getDataVersion(), brokerName,
                        entry.getValue().getTopicName())) {
                    final TopicConfig topicConfig = entry.getValue();
                    if (isPrimeSlave) {
                        // Wipe write perm for prime slave
                        topicConfig.setPerm(topicConfig.getPerm() &amp; (~PermName.PERM_WRITE));
                    }
                    this.createAndUpdateQueueData(brokerName, topicConfig);
                }
            }
        }
}
</code></pre>
<ul>
<li>Step3 :如果Broker为Master，并且BrokerTopic配置信息发生变化或者是初次注册，则需要创建或更新 Topic路由元数据，填充topicQueueTable，其实就是为默认主题自动注 册路由信息其中包含 MixAII.DEFAULT_TOPIC的路由信息。当消息生产者发送主题时，如果该主题未创建并且BrokerConfig的autoCreateTopicEnable为true时，将返回MixAII. DEFAULT_TOPIC的路由信息。</li>
</ul>
<pre><code class="language-java">private void createAndUpdateQueueData(final String brokerName, final TopicConfig topicConfig) {
    QueueData queueData = new QueueData();
    queueData.setBrokerName(brokerName);
    queueData.setWriteQueueNums(topicConfig.getWriteQueueNums());
    queueData.setReadQueueNums(topicConfig.getReadQueueNums());
    queueData.setPerm(topicConfig.getPerm());
    queueData.setTopicSysFlag(topicConfig.getTopicSysFlag());

    Map&lt;String, QueueData&gt; queueDataMap = this.topicQueueTable.get(topicConfig.getTopicName());
    if (null == queueDataMap) {
        queueDataMap = new HashMap&lt;&gt;();
        queueDataMap.put(brokerName, queueData);
        this.topicQueueTable.put(topicConfig.getTopicName(), queueDataMap);
        log.info(&quot;new topic registered, {} {}&quot;, topicConfig.getTopicName(), queueData);
    } else {
        final QueueData existedQD = queueDataMap.get(brokerName);
        if (existedQD == null) {
            queueDataMap.put(brokerName, queueData);
        } else if (!existedQD.equals(queueData)) {
            log.info(&quot;topic changed, {} OLD: {} NEW: {}&quot;, topicConfig.getTopicName(), existedQD,
                queueData);
            queueDataMap.put(brokerName, queueData);
        }
    }
}
</code></pre>
<p>根据 TopicConfig创建 QueueData数据结构 ，然后更新 topicQueueTable。</p>
<pre><code class="language-java">BrokerAddrInfo brokerAddrInfo = new BrokerAddrInfo(clusterName, brokerAddr);
BrokerLiveInfo prevBrokerLiveInfo = this.brokerLiveTable.put(brokerAddrInfo,
        new BrokerLiveInfo(
                System.currentTimeMillis(),
                timeoutMillis == null ? DEFAULT_BROKER_CHANNEL_EXPIRED_TIME : timeoutMillis,
                topicConfigWrapper == null ? new DataVersion() : topicConfigWrapper.getDataVersion(),
                channel,
                haServerAddr));
if (null == prevBrokerLiveInfo) {
    log.info(&quot;new broker registered, {} HAService: {}&quot;, brokerAddrInfo, haServerAddr);
}
</code></pre>
<ul>
<li>Step4: 更新BrokerLivelnfo，存活Broker信息表， BrokeLivelnfo是执行路由删除的重要依据。</li>
</ul>
<pre><code class="language-java">if (filterServerList != null) {
    if (filterServerList.isEmpty()) {
        this.filterServerTable.remove(brokerAddrInfo);
    } else {
        this.filterServerTable.put(brokerAddrInfo, filterServerList);
    }
}

if (MixAll.MASTER_ID != brokerId) {
    String masterAddr = brokerData.getBrokerAddrs().get(MixAll.MASTER_ID);
    if (masterAddr != null) {
        BrokerAddrInfo masterAddrInfo = new BrokerAddrInfo(clusterName, masterAddr);
        BrokerLiveInfo masterLiveInfo = this.brokerLiveTable.get(masterAddrInfo);
        if (masterLiveInfo != null) {
            result.setHaServerAddr(masterLiveInfo.getHaServerAddr());
            result.setMasterAddr(masterAddr);
        }
    }
}
</code></pre>
<ul>
<li>Step5 : 注册Broker的过滤器Server地址列表，一个Broker上会关联多个FilterServer消息过滤服务器;如果此Broker为从节点，则需要查找该Broker的Master 的节点信息，并更新对应的masterAddr属性 。</li>
</ul>
<blockquote>
<p>NameServe与Broker保持长连接， Broker状态存储在 brokerLiveTable中，NameServer每收到一个心跳包，将更新 brokerLiveTable中关于Broker的状态信息以及路 由表( topicQueueTable、 brokerAddrTable、brokerLiveTable、filterServerTable)。 更新上述 路由表( HashTable)使用了锁粒度较少的<strong>读写锁</strong>，允许多个消息发送者( Producer)并发读，保证消息发送时的高并发。但同一时刻NameServer只处理一个Broker心跳包，多个心跳包请求串行执行。</p>
</blockquote>
<h3 id="233-路由删除">2.3.3 路由删除</h3>
<p>NameServer会每隔10s扫描brokerLiveTable状态表，如果BrokerLive的lastUpdateTimestamp的时间戳距当前时间超过 120s，则认为Broker失效，移除该 Broker, 关闭与Broker连接，并同时更新topicQueueTable、brokerAddrTable、brokerLiveTable、filterServerTable。</p>
<p>RocktMQ有两个触发点来触发路由删除。</p>
<ol>
<li>NameServer定时扫描 brokerLiveTable检测上次心跳包与当前系统时间的时间差，如果时间戳大于 120s则需要移除该 Broker信息 。<br>
2 ) Broker在正常被关闭的情况下会执行unregisterBroker指令。</li>
</ol>
<pre><code class="language-java">public void scanNotActiveBroker() {
    try {
        log.info(&quot;start scanNotActiveBroker&quot;);
        for (Entry&lt;BrokerAddrInfo, BrokerLiveInfo&gt; next : this.brokerLiveTable.entrySet()) {
            long last = next.getValue().getLastUpdateTimestamp();
            long timeoutMillis = next.getValue().getHeartbeatTimeoutMillis();
            if ((last + timeoutMillis) &lt; System.currentTimeMillis()) {
                RemotingUtil.closeChannel(next.getValue().getChannel());
                log.warn(&quot;The broker channel expired, {} {}ms&quot;, next.getKey(), timeoutMillis);
                this.onChannelDestroy(next.getKey());
            }
        }
    } catch (Exception e) {
        log.error(&quot;scanNotActiveBroker exception&quot;, e);
    }
}
</code></pre>
<pre><code class="language-java">public void onChannelDestroy(BrokerAddrInfo brokerAddrInfo) {
    UnRegisterBrokerRequestHeader unRegisterRequest = new UnRegisterBrokerRequestHeader();
    boolean needUnRegister = false;
    if (brokerAddrInfo != null) {
        try {
            try {
                this.lock.readLock().lockInterruptibly();
                needUnRegister = setupUnRegisterRequest(unRegisterRequest, brokerAddrInfo);
            } finally {
                this.lock.readLock().unlock();
            }
        } catch (Exception e) {
            log.error(&quot;onChannelDestroy Exception&quot;, e);
        }
    }

    if (needUnRegister) {
        boolean result = this.submitUnRegisterBrokerRequest(unRegisterRequest);
        log.info(&quot;the broker's channel destroyed, submit the unregister request at once, &quot; +
            &quot;broker info: {}, submit result: {}&quot;, unRegisterRequest, result);
    }
}
</code></pre>
<p>Step1 :申请写锁，把需要移除的broker添加到阻塞队列。</p>
<pre><code class="language-java">public void unRegisterBroker(Set&lt;UnRegisterBrokerRequestHeader&gt; unRegisterRequests) {
        try {
            try {
                Set&lt;String&gt; removedBroker = new HashSet&lt;&gt;();
                Set&lt;String&gt; reducedBroker = new HashSet&lt;&gt;();
                Map&lt;String, BrokerStatusChangeInfo&gt; needNotifyBrokerMap = new HashMap&lt;&gt;();

                this.lock.writeLock().lockInterruptibly();
                for (final UnRegisterBrokerRequestHeader unRegisterRequest : unRegisterRequests) {
                    final String brokerName = unRegisterRequest.getBrokerName();
                    final String clusterName = unRegisterRequest.getClusterName();

                    BrokerAddrInfo brokerAddrInfo = new BrokerAddrInfo(clusterName, unRegisterRequest.getBrokerAddr());

                    BrokerLiveInfo brokerLiveInfo = this.brokerLiveTable.remove(brokerAddrInfo);
                    log.info(&quot;unregisterBroker, remove from brokerLiveTable {}, {}&quot;,
                        brokerLiveInfo != null ? &quot;OK&quot; : &quot;Failed&quot;,
                        brokerAddrInfo
                    );

                    this.filterServerTable.remove(brokerAddrInfo);

                    boolean removeBrokerName = false;
                    boolean isMinBrokerIdChanged = false;
                    BrokerData brokerData = this.brokerAddrTable.get(brokerName);
                    if (null != brokerData) {
                        if (!brokerData.getBrokerAddrs().isEmpty() &amp;&amp;
                            unRegisterRequest.getBrokerId().equals(Collections.min(brokerData.getBrokerAddrs().keySet()))) {
                            isMinBrokerIdChanged = true;
                        }
                        String addr = brokerData.getBrokerAddrs().remove(unRegisterRequest.getBrokerId());
                        log.info(&quot;unregisterBroker, remove addr from brokerAddrTable {}, {}&quot;,
                            addr != null ? &quot;OK&quot; : &quot;Failed&quot;,
                            brokerAddrInfo
                        );
                        if (brokerData.getBrokerAddrs().isEmpty()) {
                            this.brokerAddrTable.remove(brokerName);
                            log.info(&quot;unregisterBroker, remove name from brokerAddrTable OK, {}&quot;,
                                brokerName
                            );

                            removeBrokerName = true;
                        } else if (isMinBrokerIdChanged) {
                            needNotifyBrokerMap.put(brokerName, new BrokerStatusChangeInfo(
                                brokerData.getBrokerAddrs(), addr, null));
                        }
                    }

                    if (removeBrokerName) {
                        Set&lt;String&gt; nameSet = this.clusterAddrTable.get(clusterName);
                        if (nameSet != null) {
                            boolean removed = nameSet.remove(brokerName);
                            log.info(&quot;unregisterBroker, remove name from clusterAddrTable {}, {}&quot;,
                                removed ? &quot;OK&quot; : &quot;Failed&quot;,
                                brokerName);

                            if (nameSet.isEmpty()) {
                                this.clusterAddrTable.remove(clusterName);
                                log.info(&quot;unregisterBroker, remove cluster from clusterAddrTable {}&quot;,
                                    clusterName
                                );
                            }
                        }
                        removedBroker.add(brokerName);
                    } else {
                        reducedBroker.add(brokerName);
                    }
                }

                cleanTopicByUnRegisterRequests(removedBroker, reducedBroker);

                if (!needNotifyBrokerMap.isEmpty() &amp;&amp; namesrvConfig.isNotifyMinBrokerIdChanged()) {
                    notifyMinBrokerIdChanged(needNotifyBrokerMap);
                }
            } finally {
                this.lock.writeLock().unlock();
            }
        } catch (Exception e) {
            log.error(&quot;unregisterBroker Exception&quot;, e);
        }
    }
</code></pre>
<p>Step2 :统一删除每个map中元数据。</p>
<pre><code class="language-java">private void cleanTopicByUnRegisterRequests(Set&lt;String&gt; removedBroker, Set&lt;String&gt; reducedBroker) {
    Iterator&lt;Entry&lt;String, Map&lt;String, QueueData&gt;&gt;&gt; itMap = this.topicQueueTable.entrySet().iterator();
    while (itMap.hasNext()) {
        Entry&lt;String, Map&lt;String, QueueData&gt;&gt; entry = itMap.next();

        String topic = entry.getKey();
        Map&lt;String, QueueData&gt; queueDataMap = entry.getValue();

        for (final String brokerName : removedBroker) {
            final QueueData removedQD = queueDataMap.remove(brokerName);
            if (removedQD != null) {
                log.debug(&quot;removeTopicByBrokerName, remove one broker's topic {} {}&quot;, topic, removedQD);
            }
        }

        if (queueDataMap.isEmpty()) {
            log.debug(&quot;removeTopicByBrokerName, remove the topic all queue {}&quot;, topic);
            itMap.remove();
        }

        for (final String brokerName : reducedBroker) {
            final QueueData queueData = queueDataMap.get(brokerName);

            if (queueData != null) {
                if (this.brokerAddrTable.get(brokerName).isEnableActingMaster()) {
                    // Master has been unregistered, wipe the write perm
                    if (isNoMasterExists(brokerName)) {
                        queueData.setPerm(queueData.getPerm() &amp; (~PermName.PERM_WRITE));
                    }
                }
            }
        }
    }
}
</code></pre>
<p>Step3 :删除Topic队列中元数据。</p>
<h3 id="234-路由发现">2.3.4 路由发现</h3>
<p>RocketMQ路由发现是非实时的，当Topic路由出现变化后，NameServer不主动推送给客户端，而是由客户端定时拉取主题最新的路由。根据主题名称拉取路由信息的命令编码为: GET_ROUTEINTO_BY_TOPIC。</p>
<pre><code class="language-java">public class TopicRouteData extends RemotingSerializable {

    //顺序消息配置内容，来自于 kvConfig。
    private String orderTopicConf;
    //topic 队列元数据 
    private List&lt;QueueData&gt; queueDatas;
    //topic分布的 broker元数据
    private List&lt;BrokerData&gt; brokerDatas;
    //broker上过滤服务器地址列表。
    private HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable;
    //It could be null or empty
    private Map&lt;String/*brokerName*/, TopicQueueMappingInfo&gt; topicQueueMappingByBroker;
}
</code></pre>
<pre><code class="language-java">public RemotingCommand getRouteInfoByTopic(ChannelHandlerContext ctx,
        RemotingCommand request) throws RemotingCommandException {
        final RemotingCommand response = RemotingCommand.createResponseCommand(null);
        final GetRouteInfoRequestHeader requestHeader =
            (GetRouteInfoRequestHeader) request.decodeCommandCustomHeader(GetRouteInfoRequestHeader.class);

        TopicRouteData topicRouteData = this.namesrvController.getRouteInfoManager().pickupTopicRouteData(requestHeader.getTopic());

        if (topicRouteData != null) {
            if (this.namesrvController.getNamesrvConfig().isOrderMessageEnable()) {
                String orderTopicConf =
                    this.namesrvController.getKvConfigManager().getKVConfig(NamesrvUtil.NAMESPACE_ORDER_TOPIC_CONFIG,
                        requestHeader.getTopic());
                topicRouteData.setOrderTopicConf(orderTopicConf);
            }

            byte[] content;
            Boolean standardJsonOnly = requestHeader.getAcceptStandardJsonOnly();
            if (request.getVersion() &gt;= MQVersion.Version.V4_9_4.ordinal() || (null != standardJsonOnly &amp;&amp; standardJsonOnly)) {
                content = topicRouteData.encode(SerializerFeature.BrowserCompatible,
                    SerializerFeature.QuoteFieldNames, SerializerFeature.SkipTransientField,
                    SerializerFeature.MapSortField);
            } else {
                content = topicRouteData.encode();
            }

            response.setBody(content);
            response.setCode(ResponseCode.SUCCESS);
            response.setRemark(null);
            return response;
        }

        response.setCode(ResponseCode.TOPIC_NOT_EXIST);
        response.setRemark(&quot;No topic route info in name server for the topic: &quot; + requestHeader.getTopic()
            + FAQUrl.suggestTodo(FAQUrl.APPLY_TOPIC_URL));
        return response;
    }
</code></pre>
<p>Step1:调用 RouterlnfoManager 的方法，从路由 表 topicQueueTable、 brokerAddrTable、 filterServerTable中分别填充TopicRouteData中的List<QueueData>、List<BrokerData>和 filterServer 地址表 。<br>
Step2 : 如果找到主题对应的路由信息并且该主题为顺序消息，则从 NameServer KVconfig 中获取关于顺序消息相关 的配置填充路由信息 。</p>
<p>如果找不到路由信息CODE则使用 TOPIC_NOT_EXISTS ，表示没有找到对应的路由 。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1663067880142.png" alt="NameServer 路由 注册、删除机制" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis6.0的新特性]]></title>
        <id>https://q456qq520.github.io/post/redis60-de-xin-te-xing/</id>
        <link href="https://q456qq520.github.io/post/redis60-de-xin-te-xing/">
        </link>
        <updated>2022-09-07T07:26:39.000Z</updated>
        <summary type="html"><![CDATA[<p>Redis 6.0版本中新出的多线程特性。</p>
]]></summary>
        <content type="html"><![CDATA[<p>Redis 6.0版本中新出的多线程特性。</p>
<!-- more -->
<h1 id="1-从单线程处理网络请求到多线程处理">1 从单线程处理网络请求到多线程处理</h1>
<p>在Redis 6.0中，非常受关注的第一个新特性就是多线程。这是因为，Redis一直被大家熟知的就是它的单线程架构，虽然有些命令操作可以用后台线程或子进程执行（比如数据删除、快照生成、AOF重写），但是，从网络IO处理到实际的读写命令处理，都是由单个线程完成的。</p>
<p>**Redis的多IO线程只是用来处理网络请求的，对于读写命令，Redis仍然使用单线程来处理。**这是因为，Redis处理请求时，网络处理经常是瓶颈，通过多个IO线程并行处理网络操作，可以提升实例的整体处理性能。而继续使用单线程执行命令操作，就不用为了保证Lua脚本、事务的原子性，额外开发多线程互斥机制了。</p>
<h2 id="11-主线程和io线程具体是怎么协作完成请求处理的">1.1 主线程和IO线程具体是怎么协作完成请求处理的?</h2>
<p>可以把主线程和多IO线程的协作分成四个阶段。</p>
<h3 id="111-阶段一服务端和客户端建立socket连接并分配处理线程">1.1.1 阶段一：服务端和客户端建立Socket连接，并分配处理线程</h3>
<p>首先，主线程负责接收建立连接请求。当有客户端请求和实例建立Socket连接时，主线程会创建和客户端的连接，并把 Socket 放入全局等待队列中。紧接着，主线程通过轮询方法把Socket连接分配给IO线程。</p>
<h3 id="112-阶段二io线程读取并解析请求">1.1.2 阶段二：IO线程读取并解析请求</h3>
<p>主线程一旦把Socket分配给IO线程，就会进入阻塞状态，等待IO线程完成客户端请求读取和解析。因为有多个IO线程在并行处理。</p>
<h3 id="113-阶段三主线程执行请求操作">1.1.3 阶段三：主线程执行请求操作</h3>
<p>等到IO线程解析完请求，主线程还是会以单线程的方式执行这些命令操作。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662536175466.png" alt="主线程执行请求操作" loading="lazy"></figure>
<h3 id="114-阶段四io线程回写socket和主线程清空全局队列">1.1.4 阶段四：IO线程回写Socket和主线程清空全局队列</h3>
<p>当主线程执行完请求操作后，会把需要返回的结果写入缓冲区，然后，主线程会阻塞等待IO线程把这些结果回写到Socket中，并返回给客户端。</p>
<p>和IO线程读取和解析请求一样，IO线程回写Socket时，也是有多个线程在并发执行，所以回写Socket的速度也很快。等到IO线程回写Socket完毕，主线程会清空全局队列，等待客户端的后续请求。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662536234785.png" alt="IO线程回写Socket和主线程清空全局队列" loading="lazy"></figure>
<h2 id="12-开启多线程">1.2 开启多线程</h2>
<p>在Redis 6.0中，多线程机制默认是关闭的，如果需要使用多线程功能，需要在redis.conf中完成两个设置。</p>
<ol>
<li><strong>设置io-thread-do-reads配置项为yes，表示启用多线程。</strong></li>
</ol>
<blockquote>
<p>io-threads-do-reads yes</p>
</blockquote>
<ol start="2">
<li><strong>设置线程个数</strong></li>
</ol>
<p>一般来说，线程个数要小于Redis实例所在机器的CPU核个数，例如，对于一个8核的机器来说，Redis官方建议配置6个IO线程。</p>
<blockquote>
<p>io-threads  6</p>
</blockquote>
<h1 id="2-实现服务端协助的客户端缓存">2 实现服务端协助的客户端缓存</h1>
<p>和之前的版本相比，Redis 6.0新增了一个重要的特性，就是实现了服务端协助的客户端缓存功能，也称为跟踪（Tracking）功能。有了这个功能，业务应用中的Redis客户端就可以把读取的数据缓存在业务应用本地了，应用就可以直接在本地快速读取数据了。</p>
<p>不过，当把数据缓存在客户端本地时，我们会面临一个问题：如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理？</p>
<p>6.0实现的Tracking功能实现了两种模式，来解决这个问题。</p>
<h2 id="21-普通模式">2.1 普通模式</h2>
<p>在这个模式下，实例会在服务端记录客户端读取过的key，并监测key是否有修改。一旦key的值发生变化，服务端会给客户端发送<strong>invalidate</strong>消息，通知客户端缓存失效了。</p>
<p>在使用普通模式时，服务端对于记录的key只会报告一次invalidate消息，也就是说，服务端在给客户端发送过一次invalidate消息后，如果key再被修改，此时，服务端就不会再次给客户端发送invalidate消息。</p>
<p>只有当客户端再次执行读命令时，服务端才会再次监测被读取的key，并在key修改时发送invalidate消息。这样设计的考虑是节省有限的内存空间。毕竟，如果客户端不再访问这个key了，而服务端仍然记录key的修改情况，就会浪费内存资源。</p>
<p>通过执行下面的命令，打开或关闭普通模式下的Tracking功能。</p>
<blockquote>
<p>CLIENT TRACKING ON|OFF</p>
</blockquote>
<h2 id="22-广播模式">2.2 广播模式</h2>
<p>在这个模式下，服务端会给客户端广播所有key的失效情况，不过，这样做了之后，如果key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。</p>
<p>所以，在实际应用时，我们会让客户端注册希望跟踪的key的前缀，当带有注册前缀的key被修改时，服务端会把失效消息广播给所有注册的客户端。</p>
<p><strong>和普通模式不同，在广播模式下，即使客户端还没有读取过key，但只要它注册了要跟踪的key，服务端都会把key失效消息通知给这个客户端。</strong></p>
<p>注册命令如下：</p>
<blockquote>
<p>CLIENT TRACKING ON BCAST PREFIX user</p>
</blockquote>
<p>普通模式和广播模式，需要客户端使用RESP 3协议，RESP 3协议是6.0新启用的通信协议。</p>
<h2 id="23-resp-2协议">2.3 RESP 2协议</h2>
<p>对于使用RESP 2协议的客户端来说，就需要使用另一种模式，也就是<strong>重定向模式（redirect）</strong>。在重定向模式下，想要获得失效消息通知的客户端，就需要执行订阅命令<strong>SUBSCRIBE</strong>，专门订阅用于发送失效消息的频道_redis_:invalidate。同时，再使用另外一个客户端，执行CLIENT TRACKING命令，设置服务端将失效消息转发给使用RESP 2协议的客户端。</p>
<p>假设客户端B想要获取失效消息，但是客户端B只支持RESP 2协议，客户端A支持RESP 3协议。我们可以分别在客户端B和A上执行SUBSCRIBE和CLIENT TRACKING，如下所示：</p>
<pre><code class="language-redis">//客户端B执行，客户端B的ID号是303
SUBSCRIBE _redis_:invalidate

//客户端A执行
CLIENT TRACKING ON BCAST REDIRECT 303
</code></pre>
<p>这样设置以后，如果有键值对被修改了，客户端B就可以通过_redis_:invalidate频道，获得失效消息了。</p>
<h1 id="3-实例的访问权限控制列表功能access-control-listacl">3 实例的访问权限控制列表功能（Access Control List，ACL）</h1>
<h2 id="31-从简单的基于密码访问到细粒度的权限控制">3.1 从简单的基于密码访问到细粒度的权限控制</h2>
<p>在Redis 6.0 版本之前，要想实现实例的安全访问，只能通过设置密码来控制，例如，客户端连接实例前需要输入密码。</p>
<p>此外，对于一些高风险的命令（例如KEYS、FLUSHDB、FLUSHALL等），在Redis 6.0 之前，我们也只能通过rename-command来重新命名这些命令，避免客户端直接调用。</p>
<p>Redis 6.0 提供了更加细粒度的访问权限控制，这主要有两方面的体现。</p>
<p>首先，6.0版本支持创建不同用户来使用Redis。在6.0版本前，所有客户端可以使用同一个密码进行登录使用，但是没有用户的概念，而在6.0中，我们可以使用ACL SETUSER命令创建用户。例如，我们可以执行下面的命令，创建并启用一个用户normaluser，把它的密码设置为“abc”：</p>
<blockquote>
<p>ACL SETUSER normaluser on &gt; abc</p>
</blockquote>
<p>另外，6.0版本还支持以用户为粒度设置命令操作的访问权限。加号（+）和减号（-）就分别表示给用户赋予或撤销命令的调用权限。</p>
<p>假设我们要设置用户normaluser只能调用Hash类型的命令操作，而不能调用String类型的命令操作，我们可以执行如下命令：</p>
<blockquote>
<p>ACL SETUSER normaluser +@hash -@string</p>
</blockquote>
<p>除了设置某个命令或某类命令的访问控制权限，6.0版本还支持以key为粒度设置访问权限。</p>
<p>具体的做法是使用波浪号“~”和key的前缀来表示控制访问的key。例如，我们执行下面命令，就可以设置用户normaluser只能对以“user:”为前缀的key进行命令操作：</p>
<blockquote>
<p>ACL SETUSER normaluser ~user:* +@all</p>
</blockquote>
<h1 id="4-启用resp-3协议">4 启用RESP 3协议</h1>
<p>Redis 6.0实现了RESP 3通信协议，而之前都是使用的RESP 2。在RESP 2中，客户端和服务器端的通信内容都是以字节数组形式进行编码的，客户端需要根据操作的命令或是数据类型自行对传输的数据进行解码，增加了客户端开发复杂度。</p>
<p>而RESP 3直接支持多种数据类型的区分编码，包括空值、浮点数、布尔值、有序的字典集合、无序的集合等。</p>
<p>所谓区分编码，就是指直接通过不同的开头字符，区分不同的数据类型，这样一来，客户端就可以直接通过判断传递消息的开头字符，来实现数据转换操作了，提升了客户端的效率。除此之外，RESP 3协议还可以支持客户端以普通模式和广播模式实现客户端缓存。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java并发 - 锁]]></title>
        <id>https://q456qq520.github.io/post/java-bing-fa-suo/</id>
        <link href="https://q456qq520.github.io/post/java-bing-fa-suo/">
        </link>
        <updated>2022-09-06T07:57:36.000Z</updated>
        <summary type="html"><![CDATA[<p>Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。</p>
]]></summary>
        <content type="html"><![CDATA[<p>Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。</p>
<!-- more -->
<h1 id="1-乐观锁-vs-悲观锁">1. 乐观锁 VS 悲观锁</h1>
<blockquote>
<p>乐观锁与悲观锁是一种广义上的概念，体现了看待线程同步的不同角度。在Java和数据库中都有此概念对应的实际应用。</p>
</blockquote>
<p>对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，<strong>synchronized关键字</strong>和<strong>Lock</strong>的实现类都是悲观锁。</p>
<p>而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。</p>
<p>乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。</p>
<p>根据从上面的概念描述我们可以发现：</p>
<ul>
<li>悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。</li>
<li>乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。</li>
</ul>
<pre><code class="language-java">// ------------------------- 悲观锁的调用方式 -------------------------
// synchronized
public synchronized void testMethod() {
	// 操作同步资源
}
// ReentrantLock
private ReentrantLock lock = new ReentrantLock(); // 需要保证多个线程使用的是同一个锁
public void modifyPublicResources() {
	lock.lock();
	// 操作同步资源
	lock.unlock();
}

// ------------------------- 乐观锁的调用方式 -------------------------
private AtomicInteger atomicInteger = new AtomicInteger();  // 需要保证多个线程使用的是同一个AtomicInteger
atomicInteger.incrementAndGet(); //执行自增1
</code></pre>
<h1 id="2-自旋锁-vs-适应性自旋锁">2. 自旋锁 VS 适应性自旋锁</h1>
<p>阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。</p>
<p>在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。</p>
<p>而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。</p>
<p>自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。</p>
<p>自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。</p>
<h1 id="3-无锁-vs-偏向锁-vs-轻量级锁-vs-重量级锁">3. 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁</h1>
<p>这四种锁是指锁的状。</p>
<p>偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。</p>
<p>锁膨胀方向： 无锁 → 偏向锁 → 轻量级锁 → 重量级锁 (此过程是不可逆的)</p>
<p>参考链接:<a href="/post/java-bing-fa">Java并发(一)</a></p>
<h1 id="4-公平锁-vs-非公平锁">4. 公平锁 VS 非公平锁</h1>
<p>公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。</p>
<p>非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。</p>
<h1 id="5-可重入锁-vs-非可重入锁">5. 可重入锁 VS 非可重入锁</h1>
<p>可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。下面用示例代码来进行分析：</p>
<pre><code class="language-java">public class Widget {
    public synchronized void doSomething() {
        System.out.println(&quot;方法1执行...&quot;);
        doOthers();
    }

    public synchronized void doOthers() {
        System.out.println(&quot;方法2执行...&quot;);
    }
}
</code></pre>
<p>在上面的代码中，类中的两个方法都是被内置锁synchronized修饰的，doSomething()方法中调用doOthers()方法。因为内置锁是可重入的，所以同一个线程在调用doOthers()时可以直接获得当前对象的锁，进入doOthers()进行操作。</p>
<p>如果是一个不可重入锁，那么当前线程在调用doOthers()之前需要将执行doSomething()时获取当前对象的锁释放掉，实际上该对象锁已被当前线程所持有，且无法释放。所以此时会出现死锁。</p>
<p>ReentrantLock和synchronized都是重入锁。</p>
<p>首先ReentrantLock和NonReentrantLock都继承父类AQS，其父类AQS中维护了一个同步状态status来计数重入次数，status初始值为0。</p>
<p>当线程尝试获取锁时，可重入锁先尝试获取并更新status值，如果status == 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。而非可重入锁是直接去获取并尝试更新当前status的值，如果status != 0的话会导致其获取锁失败，当前线程阻塞。</p>
<p>释放锁时，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放。</p>
<h1 id="6-独享锁排他锁-vs-共享锁">6. 独享锁(排他锁) VS 共享锁</h1>
<p>独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。</p>
<p>共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。</p>
<p>独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。</p>
<p>ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。</p>
<p>在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java基础 - LinkedHashSet&Map]]></title>
        <id>https://q456qq520.github.io/post/java-ji-chu-linkedhashsetandmap/</id>
        <link href="https://q456qq520.github.io/post/java-ji-chu-linkedhashsetandmap/">
        </link>
        <updated>2022-09-06T07:19:31.000Z</updated>
        <content type="html"><![CDATA[<h1 id="总体介绍">总体介绍</h1>
<p>LinkedHashSet和LinkedHashMap在Java里也有着相同的实现，前者仅仅是对后者做了一层包装，也就是说LinkedHashSet里面有一个LinkedHashMap(适配器模式)。</p>
<p>LinkedHashMap实现了Map接口，即允许放入key为null的元素，也允许插入value为null的元素。从名字上可以看出该容器是linked list和HashMap的混合体，也就是说它同时满足HashMap和linked list的某些特性。可将LinkedHashMap看作采用linked list增强的HashMap。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662449233623.png" alt="base" loading="lazy"></figure>
<p>事实上LinkedHashMap是HashMap的直接子类，<strong>二者唯一的区别是LinkedHashMap在HashMap的基础上，采用双向链表(doubly-linked list)的形式将所有entry连接起来，这样是为保证元素的迭代顺序跟插入顺序相同</strong>。上图给出了LinkedHashMap的结构图，主体部分跟HashMap完全一样，多了header指向双向链表的头部(是一个哑元)，该双向链表的迭代顺序就是entry的插入顺序。</p>
<p>除了可以保迭代历顺序，这种结构还有一个好处 :  <strong>迭代LinkedHashMap时不需要像HashMap那样遍历整个table，而只需要直接遍历header指向的双向链表即可</strong>，也就是说LinkedHashMap的迭代时间就只跟entry的个数相关，而跟table的大小无关。</p>
<p>有两个参数可以影响LinkedHashMap的性能: 初始容量(inital capacity)和负载系数(load factor)。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。</p>
<p>将对象放入到LinkedHashMap或LinkedHashSet中时，有两个方法需要特别关心: hashCode()和equals()。hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到LinkedHashMap或LinkedHashSet中，需要@Override hashCode()和equals()方法。</p>
<p>出于性能原因，LinkedHashMap是非同步的(not synchronized)，如果需要在多线程环境使用，需要程序员手动同步；或者通过如下方式将LinkedHashMap包装成(wrapped)同步的:</p>
<pre><code class="language-java">Map m = Collections.synchronizedMap(new LinkedHashMap(...));
</code></pre>
<h1 id="方法剖析">方法剖析</h1>
<h2 id="get">get()</h2>
<p>get(Object key)方法根据指定的key值返回对应的value。该方法跟HashMap.get()方法的流程几乎完全一样，参考链接:<a href="/post/java-ji-chu-hashmap">Java基础-HashMap</a></p>
<h2 id="put">put()</h2>
<p>put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于get()方法；如果没有找到，则会通过addEntry(int hash, K key, V value, int bucketIndex)方法插入新的entry。</p>
<p>注意，这里的插入有两重含义:</p>
<blockquote>
<p>从table的角度看，新的entry需要插入到对应的bucket里，当有哈希冲突时，采用头插法将新的entry插入到冲突链表的头部。<br>
从header的角度看，新的entry需要插入到双向链表的尾部。</p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662449865619.png" alt="addEntry" loading="lazy"></figure>
<pre><code class="language-java">// LinkedHashMap.addEntry()
void addEntry(int hash, K key, V value, int bucketIndex) {
    if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) {
        resize(2 * table.length);// 自动扩容，并重新哈希
        hash = (null != key) ? hash(key) : 0;
        bucketIndex = hash &amp; (table.length-1);// hash%table.length
    }
    // 1.在冲突链表头部插入新的entry
    HashMap.Entry&lt;K,V&gt; old = table[bucketIndex];
    Entry&lt;K,V&gt; e = new Entry&lt;&gt;(hash, key, value, old);
    table[bucketIndex] = e;
    // 2.在双向链表的尾部插入新的entry
    e.addBefore(header);
    size++;
}
</code></pre>
<p>上述代码中用到了addBefore()方法将新entry e插入到双向链表头引用header的前面，这样e就成为双向链表中的最后一个元素。addBefore()的代码如下:</p>
<pre><code class="language-java">// LinkedHashMap.Entry.addBefor()，将this插入到existingEntry的前面
private void addBefore(Entry&lt;K,V&gt; existingEntry) {
    after  = existingEntry;
    before = existingEntry.before;
    before.after = this;
    after.before = this;
}
</code></pre>
<p>上述代码只是简单修改相关entry的引用而已。</p>
<h2 id="remove">remove()</h2>
<p>remove(Object key)的作用是删除key值对应的entry，该方法的具体逻辑是在removeEntryForKey(Object key)里实现的。removeEntryForKey()方法会首先找到key值对应的entry，然后删除该entry(修改链表的相应引用)。查找过程跟get()方法类似。</p>
<p>注意，这里的删除也有两重含义:</p>
<blockquote>
<p>从table的角度看，需要将该entry从对应的bucket里删除，如果对应的冲突链表不空，需要修改冲突链表的相应引用。<br>
从header的角度来看，需要将该entry从双向链表中删除，同时修改链表中前面以及后面元素的相应引用。</p>
</blockquote>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1662450018650.png" alt="remove" loading="lazy"></figure>
<pre><code class="language-java">// LinkedHashMap.removeEntryForKey()，删除key值对应的entry
final Entry&lt;K,V&gt; removeEntryForKey(Object key) {
	......
	int hash = (key == null) ? 0 : hash(key);
    int i = indexFor(hash, table.length);// hash&amp;(table.length-1)
    Entry&lt;K,V&gt; prev = table[i];// 得到冲突链表
    Entry&lt;K,V&gt; e = prev;
    while (e != null) {// 遍历冲突链表
        Entry&lt;K,V&gt; next = e.next;
        Object k;
        if (e.hash == hash &amp;&amp;
            ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) {// 找到要删除的entry
            modCount++; size--;
            // 1. 将e从对应bucket的冲突链表中删除
            if (prev == e) table[i] = next;
            else prev.next = next;
            // 2. 将e从双向链表中删除
            e.before.after = e.after;
            e.after.before = e.before;
            return e;
        }
        prev = e; e = next;
    }
    return e;
}
</code></pre>
<h1 id="linkedhashset">LinkedHashSet</h1>
<pre><code class="language-java">public class LinkedHashSet&lt;E&gt;
    extends HashSet&lt;E&gt;
    implements Set&lt;E&gt;, Cloneable, java.io.Serializable {
    ......
    // LinkedHashSet里面有一个LinkedHashMap
    public LinkedHashSet(int initialCapacity, float loadFactor) {
        map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);
    }
	......
    public boolean add(E e) {//简单的方法转换
        return map.put(e, PRESENT)==null;
    }
    ......
}
</code></pre>
<h1 id="linkedhashmap经典用法">LinkedHashMap经典用法</h1>
<p>LinkedHashMap除了可以保证迭代顺序外，还有一个非常有用的用法: 可以轻松实现一个采用了FIFO替换策略的缓存。具体说来，LinkedHashMap有一个子类方法protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest)，该方法的作用是告诉Map是否要删除“最老”的Entry，所谓最老就是当前Map中最早插入的Entry，如果该方法返回true，最老的那个元素就会被删除。在每次插入新元素的之后LinkedHashMap会自动询问removeEldestEntry()是否要删除最老的元素。这样只需要在子类中重载该方法，当元素个数超过一定数量时让removeEldestEntry()返回true，就能够实现一个固定大小的FIFO策略的缓存。示例代码如下:</p>
<pre><code class="language-java">/** 一个固定大小的FIFO替换策略的缓存 */
class FIFOCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt;{
    private final int cacheSize;
    public FIFOCache(int cacheSize){
        this.cacheSize = cacheSize;
    }

    // 当Entry个数超过cacheSize时，删除最老的Entry
    @Override
    protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) {
       return size() &gt; cacheSize;
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java基础 - TreeMap]]></title>
        <id>https://q456qq520.github.io/post/java-ji-chu-treemap/</id>
        <link href="https://q456qq520.github.io/post/java-ji-chu-treemap/">
        </link>
        <updated>2022-09-06T06:30:51.000Z</updated>
        <content type="html"><![CDATA[<h1 id="总体介绍">总体介绍</h1>
<p>TreeSet和TreeMap，前者仅仅是对后者做了一层包装，也就是说TreeSet里面有一个TreeMap**(适配器模式)**。</p>
<p>Java TreeMap实现了<strong>SortedMap</strong>接口，也就是说会按照key的大小顺序对Map中的元素进行排序，key大小的评判可以通过其本身的自然顺序(natural ordering)，也可以通过构造时传入的比较器(Comparator)。</p>
<p>TreeMap底层通过红黑树(Red-Black tree)实现，也就意味着containsKey(), get(), put(), remove()都有着log(n)的时间复杂度。</p>
<p>![红黑树(https://q456qq520.github.io/post-images/1662446050114.png)</p>
<p>出于性能原因，TreeMap是非同步的(not synchronized)，如果需要在多线程环境使用，需要程序员手动同步；或者通过如下方式将TreeMap包装成(wrapped)同步的:</p>
<pre><code class="language-java"> SortedMap m = Collections.synchronizedSortedMap(new TreeMap(...));
</code></pre>
<p>红黑树是一种近似平衡的二叉查找树，它能够确保任何一个节点的左右子树的高度差不会超过二者中较低那个的一倍。具体来说，红黑树是满足如下条件的二叉查找树(binary search tree):</p>
<ol>
<li>每个节点要么是红色，要么是黑色。</li>
<li>根节点必须是黑色</li>
<li>红色节点不能连续(也即是，红色节点的孩子和父亲都不能是红色)。</li>
<li>对于每个节点，从该点至null(树尾端)的任何路径，都含有相同个数的黑色节点。</li>
</ol>
<p>在树的结构发生改变时(插入或者删除操作)，往往会破坏上述条件3或条件4，需要通过调整使得查找树重新满足红黑树的约束条件。</p>
<h1 id="预备知识">预备知识</h1>
<p>当查找树的结构发生改变时，红黑树的约束条件可能被破坏，需要通过调整使得查找树重新满足红黑树的约束条件。调整可以分为两类: 一类是颜色调整，即改变某个节点的颜色；另一类是结构调整，集改变检索树的结构关系。结构调整过程包含两个基本操作:<strong>左旋(Rotate Left)，右旋(RotateRight)</strong>。</p>
<h2 id="左旋">左旋</h2>
<p>左旋的过程是将x的右子树绕x逆时针旋转，使得x的右子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的属性仍然满足。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662447037690.png" alt="左旋" loading="lazy"></figure>
<pre><code class="language-java">//Rotate Left
private void rotateLeft(Entry&lt;K,V&gt; p) {
    if (p != null) {
        Entry&lt;K,V&gt; r = p.right;
        p.right = r.left;
        if (r.left != null)
            r.left.parent = p;
        r.parent = p.parent;
        if (p.parent == null)
            root = r;
        else if (p.parent.left == p)
            p.parent.left = r;
        else
            p.parent.right = r;
        r.left = p;
        p.parent = r;
    }
}
</code></pre>
<h2 id="右旋">右旋</h2>
<p>右旋的过程是将x的左子树绕x顺时针旋转，使得x的左子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的属性仍然满足。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662447192164.png" alt="右旋" loading="lazy"></figure>
<pre><code class="language-java">//Rotate Right
private void rotateRight(Entry&lt;K,V&gt; p) {
    if (p != null) {
        Entry&lt;K,V&gt; l = p.left;
        p.left = l.right;
        if (l.right != null) l.right.parent = p;
        l.parent = p.parent;
        if (p.parent == null)
            root = l;
        else if (p.parent.right == p)
            p.parent.right = l;
        else p.parent.left = l;
        l.right = p;
        p.parent = l;
    }
}
</code></pre>
<h2 id="寻找节点后继">寻找节点后继</h2>
<p>对于一棵二叉查找树，给定节点t，其后继(树中比大于t的最小的那个元素)可以通过如下方式找到:</p>
<blockquote>
<p>t的右子树不空，则t的后继是其右子树中最小的那个元素。<br>
t的右孩子为空，则t的后继是其第一个向左走的祖先。</p>
</blockquote>
<p>后继节点在红黑树的删除操作中将会用到。</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1662447570182.png" alt="后继" loading="lazy"></figure>
<p>TreeMap中寻找节点后继的代码如下:</p>
<pre><code class="language-java">// 寻找节点后继函数successor()
static &lt;K,V&gt; TreeMap.Entry&lt;K,V&gt; successor(Entry&lt;K,V&gt; t) {
    if (t == null)
        return null;
    else if (t.right != null) {// 1. t的右子树不空，则t的后继是其右子树中最小的那个元素
        Entry&lt;K,V&gt; p = t.right;
        while (p.left != null)
            p = p.left;
        return p;
    } else {// 2. t的右孩子为空，则t的后继是其第一个向左走的祖先
        Entry&lt;K,V&gt; p = t.parent;
        Entry&lt;K,V&gt; ch = t;
        while (p != null &amp;&amp; ch == p.right) {
            ch = p;
            p = p.parent;
        }
        return p;
    }
}
</code></pre>
<h1 id="方法剖析">方法剖析</h1>
<h2 id="get">get()</h2>
<p>get(Object key)方法根据指定的key值返回对应的value，该方法调用了getEntry(Object key)得到相应的entry，然后返回entry.value。因此getEntry()是算法的核心。算法思想是根据key的自然顺序(或者比较器顺序)对二叉查找树进行查找，直到找到满足k.compareTo(p.key) == 0的entry。</p>
<p>![get(https://q456qq520.github.io/post-images/1662447909864.png)</p>
<pre><code class="language-java">//getEntry()方法
final Entry&lt;K,V&gt; getEntry(Object key) {
    ......
    if (key == null)//不允许key值为null
        throw new NullPointerException();
    Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key;//使用元素的自然顺序
    Entry&lt;K,V&gt; p = root;
    while (p != null) {
        int cmp = k.compareTo(p.key);
        if (cmp &lt; 0)//向左找
            p = p.left;
        else if (cmp &gt; 0)//向右找
            p = p.right;
        else
            return p;
    }
    return null;
}
</code></pre>
<h2 id="put">put()</h2>
<p>put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于getEntry()方法；如果没有找到则会在红黑树中插入新的entry，如果插入之后破坏了红黑树的约束条件，还需要进行调整(旋转，改变某些节点的颜色)。</p>
<pre><code class="language-java">public V put(K key, V value) {
	......
    int cmp;
    Entry&lt;K,V&gt; parent;
    if (key == null)
        throw new NullPointerException();
    Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key;//使用元素的自然顺序
    do {
        parent = t;
        cmp = k.compareTo(t.key);
        if (cmp &lt; 0) t = t.left;//向左找
        else if (cmp &gt; 0) t = t.right;//向右找
        else return t.setValue(value);
    } while (t != null);
    Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent);//创建并插入新的entry
    if (cmp &lt; 0) parent.left = e;
    else parent.right = e;
    fixAfterInsertion(e);//调整
    size++;
    return null;
}
</code></pre>
<p>首先在红黑树上找到合适的位置，然后创建新的entry并插入(当然，新插入的节点一定是树的叶子)。难点是调整函数fixAfterInsertion()，前面已经说过，调整往往需要1.改变某些节点的颜色，2.对某些节点进行旋转。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1662448057289.png" alt="put" loading="lazy"></figure>
<p>调整函数fixAfterInsertion()的具体代码如下，其中用到了上文中提到的rotateLeft()和rotateRight()函数。通过代码我们能够看到，情况2其实是落在情况3内的。情况4～情况6跟前三种情况是对称的，因此图解中并没有画出后三种情况，读者可以参考代码自行理解。</p>
<pre><code class="language-java">//红黑树调整函数fixAfterInsertion()
private void fixAfterInsertion(Entry&lt;K,V&gt; x) {
    x.color = RED;
    while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) {
        if (parentOf(x) == leftOf(parentOf(parentOf(x)))) {
            Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x)));
            if (colorOf(y) == RED) {
                setColor(parentOf(x), BLACK);              // 情况1
                setColor(y, BLACK);                        // 情况1
                setColor(parentOf(parentOf(x)), RED);      // 情况1
                x = parentOf(parentOf(x));                 // 情况1
            } else {
                if (x == rightOf(parentOf(x))) {
                    x = parentOf(x);                       // 情况2
                    rotateLeft(x);                         // 情况2
                }
                setColor(parentOf(x), BLACK);              // 情况3
                setColor(parentOf(parentOf(x)), RED);      // 情况3
                rotateRight(parentOf(parentOf(x)));        // 情况3
            }
        } else {
            Entry&lt;K,V&gt; y = leftOf(parentOf(parentOf(x)));
            if (colorOf(y) == RED) {
                setColor(parentOf(x), BLACK);              // 情况4
                setColor(y, BLACK);                        // 情况4
                setColor(parentOf(parentOf(x)), RED);      // 情况4
                x = parentOf(parentOf(x));                 // 情况4
            } else {
                if (x == leftOf(parentOf(x))) {
                    x = parentOf(x);                       // 情况5
                    rotateRight(x);                        // 情况5
                }
                setColor(parentOf(x), BLACK);              // 情况6
                setColor(parentOf(parentOf(x)), RED);      // 情况6
                rotateLeft(parentOf(parentOf(x)));         // 情况6
            }
        }
    }
    root.color = BLACK;
}
</code></pre>
<p>##remove()<br>
remove(Object key)的作用是删除key值对应的entry，该方法首先通过上文中提到的getEntry(Object key)方法找到key值对应的entry，然后调用deleteEntry(Entry&lt;K,V&gt; entry)删除对应的entry。由于删除操作会改变红黑树的结构，有可能破坏红黑树的约束条件，因此有可能要进行调整。</p>
<p>getEntry()函数前面已经讲解过，这里重点放deleteEntry()上，该函数删除指定的entry并在红黑树的约束被破坏时进行调用fixAfterDeletion(Entry&lt;K,V&gt; x)进行调整。 由于红黑树是一棵增强版的二叉查找树，红黑树的删除操作跟普通二叉查找树的删除操作也就非常相似，唯一的区别是红黑树在节点删除之后可能需要进行调整。现在考虑一棵普通二叉查找树的删除过程，可以简单分为两种情况:</p>
<blockquote>
<p>删除点p的左右子树都为空，或者只有一棵子树非空。<br>
删除点p的左右子树都非空。</p>
</blockquote>
<p>对于上述情况1，处理起来比较简单，直接将p删除(左右子树都为空时)，或者用非空子树替代p(只有一棵子树非空时)；对于情况2，可以用p的后继s(树中大于x的最小的那个元素)代替p，然后使用情况1删除。 基于以上逻辑，红黑树的节点删除函数deleteEntry()代码如下:</p>
<pre><code class="language-java">// 红黑树entry删除函数deleteEntry()
private void deleteEntry(Entry&lt;K,V&gt; p) {
    modCount++;
    size--;
    if (p.left != null &amp;&amp; p.right != null) {// 2. 删除点p的左右子树都非空。
        Entry&lt;K,V&gt; s = successor(p);// 后继
        p.key = s.key;
        p.value = s.value;
        p = s;
    }
    Entry&lt;K,V&gt; replacement = (p.left != null ? p.left : p.right);
    if (replacement != null) {// 1. 删除点p只有一棵子树非空。
        replacement.parent = p.parent;
        if (p.parent == null)
            root = replacement;
        else if (p == p.parent.left)
            p.parent.left  = replacement;
        else
            p.parent.right = replacement;
        p.left = p.right = p.parent = null;
        if (p.color == BLACK)
            fixAfterDeletion(replacement);// 调整
    } else if (p.parent == null) {
        root = null;
    } else { // 1. 删除点p的左右子树都为空
        if (p.color == BLACK)
            fixAfterDeletion(p);// 调整
        if (p.parent != null) {
            if (p == p.parent.left)
                p.parent.left = null;
            else if (p == p.parent.right)
                p.parent.right = null;
            p.parent = null;
        }
    }
}
</code></pre>
<p>上述代码中占据大量代码行的，是用来修改父子节点间引用关系的代码，其逻辑并不难理解。下面着重讲解删除后调整函数fixAfterDeletion()。首先请思考一下，删除了哪些点才会导致调整？只有删除点是BLACK的时候，才会触发调整函数，因为删除RED节点不会破坏红黑树的任何约束，而删除BLACK节点会破坏规则4。</p>
<p>跟fixAfterInsertion()函数一样，这里也要分成若干种情况。记住，无论有多少情况，具体的调整操作只有两种: ** 1.改变某些节点的颜色，2.对某些节点进行旋转。**</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1662448600339.png" alt="remove" loading="lazy"></figure>
<p>上述图解的总体思想是: 将情况1首先转换成情况2，或者转换成情况3和情况4。当然，该图解并不意味着调整过程一定是从情况1开始。通过后续代码我们还会发现几个有趣的规则: a).如果是由情况1之后紧接着进入的情况2，那么情况2之后一定会退出循环(因为x为红色)；b).一旦进入情况3和情况4，一定会退出循环(因为x为root)。</p>
<p>删除后调整函数fixAfterDeletion()的具体代码如下，其中用到了上文中提到的rotateLeft()和rotateRight()函数。通过代码我们能够看到，情况3其实是落在情况4内的。情况5～情况8跟前四种情况是对称的。</p>
<pre><code class="language-java">private void fixAfterDeletion(Entry&lt;K,V&gt; x) {
    while (x != root &amp;&amp; colorOf(x) == BLACK) {
        if (x == leftOf(parentOf(x))) {
            Entry&lt;K,V&gt; sib = rightOf(parentOf(x));
            if (colorOf(sib) == RED) {
                setColor(sib, BLACK);                   // 情况1
                setColor(parentOf(x), RED);             // 情况1
                rotateLeft(parentOf(x));                // 情况1
                sib = rightOf(parentOf(x));             // 情况1
            }
            if (colorOf(leftOf(sib))  == BLACK &amp;&amp;
                colorOf(rightOf(sib)) == BLACK) {
                setColor(sib, RED);                     // 情况2
                x = parentOf(x);                        // 情况2
            } else {
                if (colorOf(rightOf(sib)) == BLACK) {
                    setColor(leftOf(sib), BLACK);       // 情况3
                    setColor(sib, RED);                 // 情况3
                    rotateRight(sib);                   // 情况3
                    sib = rightOf(parentOf(x));         // 情况3
                }
                setColor(sib, colorOf(parentOf(x)));    // 情况4
                setColor(parentOf(x), BLACK);           // 情况4
                setColor(rightOf(sib), BLACK);          // 情况4
                rotateLeft(parentOf(x));                // 情况4
                x = root;                               // 情况4
            }
        } else { // 跟前四种情况对称
            Entry&lt;K,V&gt; sib = leftOf(parentOf(x));
            if (colorOf(sib) == RED) {
                setColor(sib, BLACK);                   // 情况5
                setColor(parentOf(x), RED);             // 情况5
                rotateRight(parentOf(x));               // 情况5
                sib = leftOf(parentOf(x));              // 情况5
            }
            if (colorOf(rightOf(sib)) == BLACK &amp;&amp;
                colorOf(leftOf(sib)) == BLACK) {
                setColor(sib, RED);                     // 情况6
                x = parentOf(x);                        // 情况6
            } else {
                if (colorOf(leftOf(sib)) == BLACK) {
                    setColor(rightOf(sib), BLACK);      // 情况7
                    setColor(sib, RED);                 // 情况7
                    rotateLeft(sib);                    // 情况7
                    sib = leftOf(parentOf(x));          // 情况7
                }
                setColor(sib, colorOf(parentOf(x)));    // 情况8
                setColor(parentOf(x), BLACK);           // 情况8
                setColor(leftOf(sib), BLACK);           // 情况8
                rotateRight(parentOf(x));               // 情况8
                x = root;                               // 情况8
            }
        }
    }
    setColor(x, BLACK);
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java 基础 - HashMap]]></title>
        <id>https://q456qq520.github.io/post/java-ji-chu-hashmap/</id>
        <link href="https://q456qq520.github.io/post/java-ji-chu-hashmap/">
        </link>
        <updated>2022-09-06T06:17:44.000Z</updated>
        <content type="html"><![CDATA[<h1 id="java7-hashmap">Java7 HashMap</h1>
<h2 id="概述">概述</h2>
<p>HashMap实现了Map接口，即允许放入key为null的元素，也允许插入value为null的元素；除该类未实现同步外，其余跟Hashtable大致相同；跟TreeMap不同，该容器不保证元素顺序，根据需要该容器可能会对元素重新哈希，元素的顺序也会被重新打散，因此不同时间迭代同一个HashMap的顺序可能会不同。<br>
根据对冲突的处理方式不同，哈希表有两种实现方式，一种<strong>开放地址方式(Open addressing)</strong>，另一种是<strong>冲突链表方式(Separate chaining with linked lists)</strong>。Java7 HashMap采用的是冲突链表方式。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662445311067.png" alt="HaspMap" loading="lazy"></figure>
<p>从上图容易看出，如果选择合适的哈希函数，put()和get()方法可以在常数时间内完成。但在对HashMap进行迭代时，需要遍历整个table以及后面跟的冲突链表。因此对于迭代比较频繁的场景，不宜将HashMap的初始大小设的过大。</p>
<p>有两个参数可以影响HashMap的性能: 初始容量(inital capacity)和负载系数(load factor)。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。</p>
<p>将对象放入到HashMap或HashSet中时，有两个方法需要特别关心: hashCode()和equals()。hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到HashMap或HashSet中，需要**@Override** hashCode()和equals()方法。</p>
<h1 id="java8-hashmap">Java8 HashMap</h1>
<p>Java8利用了红黑树，由 数组+链表+红黑树 组成。</p>
<p>查找的时候，根据 hash 值我们能够快速定位到数组的具体下标，但是之后的话，需要顺着链表一个个比较下去才能找到我们需要的，时间复杂度取决于链表的长度，为 O(n)。 为了降低这部分的开销，在 Java8 中，当链表中的元素达到了 8 个时，会将链表转换为红黑树，在这些位置进行查找的时候可以降低时间复杂度为 O(logN)。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662445189410.png" alt="hashmap结构" loading="lazy"></figure>
<p>著作权归https://pdai.tech所有。<br>
链接：https://pdai.tech/md/java/collection/java-map-HashMap&amp;HashSet.html</p>
<p>Java7 中使用 Entry 来代表每个 HashMap 中的数据节点，Java8 中使用 Node，基本没有区别，都是 key，value，hash 和 next 这四个属性，不过，Node 只能用于链表的情况，红黑树的情况需要使用 TreeNode。</p>
<p>根据数组元素中，第一个节点数据类型是 Node 还是 TreeNode 来判断该位置下是链表还是红黑树的。</p>
<h2 id="put过程">put过程</h2>
<pre><code class="language-java">public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}

// 第四个参数 onlyIfAbsent 如果是 true，那么只有在不存在该 key 时才会进行 put 操作
// 第五个参数 evict 我们这里不关心
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;
    // 第一次 put 值的时候，会触发下面的 resize()，类似 java7 的第一次 put 也要初始化数组长度
    // 第一次 resize 和后续的扩容有些不一样，因为这次是数组从 null 初始化到默认的 16 或自定义的初始容量
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    // 找到具体的数组下标，如果此位置没有值，那么直接初始化一下 Node 并放置在这个位置就可以了
    if ((p = tab[i = (n - 1) &amp; hash]) == null)
        tab[i] = newNode(hash, key, value, null);

    else {// 数组该位置有数据
        Node&lt;K,V&gt; e; K k;
        // 首先，判断该位置的第一个数据和我们要插入的数据，key 是不是&quot;相等&quot;，如果是，取出这个节点
        if (p.hash == hash &amp;&amp;
            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))
            e = p;
        // 如果该节点是代表红黑树的节点，调用红黑树的插值方法，本文不展开说红黑树
        else if (p instanceof TreeNode)
            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);
        else {
            // 到这里，说明数组该位置上是一个链表
            for (int binCount = 0; ; ++binCount) {
                // 插入到链表的最后面(Java7 是插入到链表的最前面)
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    // TREEIFY_THRESHOLD 为 8，所以，如果新插入的值是链表中的第 8 个
                    // 会触发下面的 treeifyBin，也就是将链表转换为红黑树
                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                // 如果在该链表中找到了&quot;相等&quot;的 key(== 或 equals)
                if (e.hash == hash &amp;&amp;
                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                    // 此时 break，那么 e 为链表中[与要插入的新值的 key &quot;相等&quot;]的 node
                    break;
                p = e;
            }
        }
        // e!=null 说明存在旧值的key与要插入的key&quot;相等&quot;
        // 对于我们分析的put操作，下面这个 if 其实就是进行 &quot;值覆盖&quot;，然后返回旧值
        if (e != null) {
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    // 如果 HashMap 由于新插入这个值导致 size 已经超过了阈值，需要进行扩容
    if (++size &gt; threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
</code></pre>
<h2 id="数组扩容">数组扩容</h2>
<p>resize() 方法用于初始化数组或数组扩容，每次扩容后，容量为原来的 2 倍，并进行数据迁移。</p>
<pre><code class="language-java">final Node&lt;K,V&gt;[] resize() {
    Node&lt;K,V&gt;[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap &gt; 0) { // 对应数组扩容
        if (oldCap &gt;= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        // 将数组大小扩大一倍
        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;
                 oldCap &gt;= DEFAULT_INITIAL_CAPACITY)
            // 将阈值扩大一倍
            newThr = oldThr &lt;&lt; 1; // double threshold
    }
    else if (oldThr &gt; 0) // 对应使用 new HashMap(int initialCapacity) 初始化后，第一次 put 的时候
        newCap = oldThr;
    else {// 对应使用 new HashMap() 初始化后，第一次 put 的时候
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }

    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;

    // 用新的数组大小初始化新的数组
    Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];
    table = newTab; // 如果是初始化数组，到这里就结束了，返回 newTab 即可

    if (oldTab != null) {
        // 开始遍历原数组，进行数据迁移。
        for (int j = 0; j &lt; oldCap; ++j) {
            Node&lt;K,V&gt; e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                // 如果该数组位置上只有单个元素，那就简单了，简单迁移这个元素就可以了
                if (e.next == null)
                    newTab[e.hash &amp; (newCap - 1)] = e;
                // 如果是红黑树，具体我们就不展开了
                else if (e instanceof TreeNode)
                    ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);
                else { 
                    // 这块是处理链表的情况，
                    // 需要将此链表拆成两个链表，放到新的数组中，并且保留原来的先后顺序
                    // loHead、loTail 对应一条链表，hiHead、hiTail 对应另一条链表，代码还是比较简单的
                    Node&lt;K,V&gt; loHead = null, loTail = null;
                    Node&lt;K,V&gt; hiHead = null, hiTail = null;
                    Node&lt;K,V&gt; next;
                    do {
                        next = e.next;
                        if ((e.hash &amp; oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        // 第一条链表
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        // 第二条链表的新的位置是 j + oldCap，这个很好理解
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
</code></pre>
<h2 id="get-过程">get 过程</h2>
<ol>
<li>计算 key 的 hash 值，根据 hash 值找到对应数组下标: hash &amp; (length-1)</li>
<li>判断数组该位置处的元素是否刚好就是我们要找的，如果不是，走第三步</li>
<li>判断该元素类型是否是 TreeNode，如果是，用红黑树的方法取数据，如果不是，走第四步</li>
<li>遍历链表，直到找到相等(==或equals)的 key</li>
</ol>
<pre><code class="language-java">public V get(Object key) {
    Node&lt;K,V&gt; e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}
final Node&lt;K,V&gt; getNode(int hash, Object key) {
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;
    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;
        (first = tab[(n - 1) &amp; hash]) != null) {
        // 判断第一个节点是不是就是需要的
        if (first.hash == hash &amp;&amp; // always check first node
            ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))
            return first;
        if ((e = first.next) != null) {
            // 判断是否是红黑树
            if (first instanceof TreeNode)
                return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);

            // 链表遍历
            do {
                if (e.hash == hash &amp;&amp;
                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java 基础 - 泛型机制详解]]></title>
        <id>https://q456qq520.github.io/post/java-ji-chu-fan-xing-ji-zhi-xiang-jie/</id>
        <link href="https://q456qq520.github.io/post/java-ji-chu-fan-xing-ji-zhi-xiang-jie/">
        </link>
        <updated>2022-09-05T07:45:31.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>Java泛型这个特性是从JDK 1.5才开始加入的，因此为了兼容之前的版本，Java泛型的实现采取了“伪泛型”的策略，即Java在语法上支持泛型，但是在编译阶段会进行所谓的“类型擦除”（Type Erasure），将所有的泛型表示（尖括号中的内容）都替换为具体的类型（其对应的原生态类型），就像完全没有泛型一样。</p>
</blockquote>
<h1 id="1为什么会引入泛型">1.为什么会引入泛型</h1>
<blockquote>
<p>泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。</p>
</blockquote>
<p>引入泛型的意义在于：</p>
<p><strong>适用于多种数据类型执行相同的代码（代码复用）</strong></p>
<p>我们通过一个例子来阐述，先看下下面的代码：</p>
<pre><code class="language-java">private static int add(int a, int b) {
    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b));
    return a + b;
}

private static float add(float a, float b) {
    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b));
    return a + b;
}

private static double add(double a, double b) {
    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b));
    return a + b;
}
</code></pre>
<p>如果没有泛型，要实现不同类型的加法，每种类型都需要重载一个add方法；通过泛型，我们可以复用为一个方法：</p>
<pre><code class="language-java">private static &lt;T extends Number&gt; double add(T a, T b) {
    System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a.doubleValue() + b.doubleValue()));
    return a.doubleValue() + b.doubleValue();
}
</code></pre>
<p>泛型中的类型在使用时指定，不需要强制类型转换（类型安全，编译器会检查类型）</p>
<h1 id="2泛型的基本使用">2.泛型的基本使用</h1>
<p>泛型有三种使用方式，分别为：泛型类、泛型接口、泛型方法。</p>
<h2 id="21-泛型类">2.1 泛型类</h2>
<p>从一个简单的泛型类看起：</p>
<pre><code class="language-java">class Point&lt;T&gt;{         // 此处可以随便写标识符号，T是type的简称  
    private T var ;     // var的类型由T指定，即：由外部指定  
    public T getVar(){  // 返回值的类型由外部决定  
        return var ;  
    }  
    public void setVar(T var){  // 设置的类型也由外部决定  
        this.var = var ;  
    }  
}  
public class GenericsDemo06{  
    public static void main(String args[]){  
        Point&lt;String&gt; p = new Point&lt;String&gt;() ;     // 里面的var类型为String类型  
        p.setVar(&quot;it&quot;) ;                            // 设置字符串  
        System.out.println(p.getVar().length()) ;   // 取得字符串的长度  
    }  
}
</code></pre>
<p>多元泛型</p>
<pre><code class="language-java">class Notepad&lt;K,V&gt;{       // 此处指定了两个泛型类型  
    private K key ;     // 此变量的类型由外部决定  
    private V value ;   // 此变量的类型由外部决定  
    public K getKey(){  
        return this.key ;  
    }  
    public V getValue(){  
        return this.value ;  
    }  
    public void setKey(K key){  
        this.key = key ;  
    }  
    public void setValue(V value){  
        this.value = value ;  
    }  
} 
public class GenericsDemo09{  
    public static void main(String args[]){  
        Notepad&lt;String,Integer&gt; t = null ;        // 定义两个泛型类型的对象  
        t = new Notepad&lt;String,Integer&gt;() ;       // 里面的key为String，value为Integer  
        t.setKey(&quot;汤姆&quot;) ;        // 设置第一个内容  
        t.setValue(20) ;            // 设置第二个内容  
        System.out.print(&quot;姓名；&quot; + t.getKey()) ;      // 取得信息  
        System.out.print(&quot;，年龄；&quot; + t.getValue()) ;       // 取得信息  
  
    }  
}
</code></pre>
<h2 id="22-泛型接口">2.2 泛型接口</h2>
<pre><code class="language-java">interface Info&lt;T&gt;{        // 在接口上定义泛型  
    public T getVar() ; // 定义抽象方法，抽象方法的返回值就是泛型类型  
}  
class InfoImpl&lt;T&gt; implements Info&lt;T&gt;{   // 定义泛型接口的子类  
    private T var ;             // 定义属性  
    public InfoImpl(T var){     // 通过构造方法设置属性内容  
        this.setVar(var) ;    
    }  
    public void setVar(T var){  
        this.var = var ;  
    }  
    public T getVar(){  
        return this.var ;  
    }  
} 
public class GenericsDemo24{  
    public static void main(String arsg[]){  
        Info&lt;String&gt; i = null;        // 声明接口对象  
        i = new InfoImpl&lt;String&gt;(&quot;汤姆&quot;) ;  // 通过子类实例化对象  
        System.out.println(&quot;内容：&quot; + i.getVar()) ;  
    }  
}  
</code></pre>
<h2 id="23-泛型方法">2.3 泛型方法</h2>
<p>泛型方法，是在调用方法的时候指明泛型的具体类型。</p>
<p>定义泛型方法语法格式</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662364711146.png" alt="定义泛型方法语法格式" loading="lazy"></figure>
<p>调用泛型方法语法格式<br>
<img src="https://q456qq520.github.io/post-images/1662364736330.png" alt="调用泛型方法语法格式" loading="lazy"></p>
<p>说明一下，定义泛型方法时，必须在返回值前边加一个<T>，来声明这是一个泛型方法，持有一个泛型T，然后才可以用泛型T作为方法的返回值。 Class<T>的作用就是指明泛型的具体类型，而Class<T>类型的变量c，可以用来创建泛型类的对象。</p>
<p>为什么要用变量c来创建对象呢？既然是泛型方法，就代表着我们不知道具体的类型是什么，也不知道构造方法如何，因此没有办法去new一个对象，但可以利用变量c的newInstance方法去创建对象，也就是利用反射创建对象。</p>
<p>泛型方法要求的参数是Class<T>类型，而Class.forName()方法的返回值也是Class<T>，因此可以用Class.forName()作为参数。其中，forName()方法中的参数是何种类型，返回的Class<T>就是何种类型。在本例中，forName()方法中传入的是User类的完整路径，因此返回的是Class<User>类型的对象，因此调用泛型方法时，变量c的类型就是Class<User>，因此泛型方法中的泛型T就被指明为User，因此变量obj的类型为User。 当然，泛型方法不是仅仅可以有一个参数Class<T>，可以根据需要添加其他参数。</p>
<p>为什么要使用泛型方法呢？因为泛型类要在实例化的时候就指明类型，如果想换一种类型，不得不重新new一次，可能不够灵活；而泛型方法可以在调用的时候指明类型，更加灵活。</p>
<h2 id="24-泛型的上下限">2.4 泛型的上下限</h2>
<pre><code class="language-java">class A{}
class B extends A {}

// 如下两个方法不会报错
public static void funA(A a) {
    // ...          
}
public static void funB(B b) {
    funA(b);
    // ...             
}

// 如下funD方法会报错
public static void funC(List&lt;A&gt; listA) {
    // ...          
}
public static void funD(List&lt;B&gt; listB) {
    funC(listB); // Unresolved compilation problem: The method doPrint(List&lt;A&gt;) in the type test is not applicable for the arguments (List&lt;B&gt;)
    // ...             
}

那么如何解决呢？ 为了解决泛型中隐含的转换问题，Java泛型加入了类型参数的上下边界机制。&lt;? extends A&gt;表示该类型参数可以是A(上边界)或者A的子类类型。编译时擦除到类型A，即用A类型代替类型参数。这种方法可以解决开始遇到的问题，编译器知道类型参数的范围，如果传入的实例类型B是在这个范围内的话允许转换，这时只要一次类型转换就可以了，运行时会把对象当做A的实例看待。

```java
public static void funC(List&lt;? extends A&gt; listA) {
    // ...          
}
public static void funD(List&lt;B&gt; listB) {
    funC(listB); // OK
    // ...             
}
</code></pre>
<p><strong>泛型上下限的引入</strong><br>
在使用泛型的时候，我们可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。</p>
<ol>
<li>上限</li>
</ol>
<pre><code class="language-java">class Info&lt;T extends Number&gt;{    // 此处泛型只能是数字类型
    private T var ;        // 定义泛型变量
    public void setVar(T var){
        this.var = var ;
    }
    public T getVar(){
        return this.var ;
    }
    public String toString(){    // 直接打印
        return this.var.toString() ;
    }
}
public class demo1{
    public static void main(String args[]){
        Info&lt;Integer&gt; i1 = new Info&lt;Integer&gt;() ;        // 声明Integer的泛型对象
    }
}
</code></pre>
<ol start="2">
<li>下限</li>
</ol>
<pre><code class="language-java">class Info&lt;T&gt;{
    private T var ;        // 定义泛型变量
    public void setVar(T var){
        this.var = var ;
    }
    public T getVar(){
        return this.var ;
    }
    public String toString(){    // 直接打印
        return this.var.toString() ;
    }
}
public class GenericsDemo21{
    public static void main(String args[]){
        Info&lt;String&gt; i1 = new Info&lt;String&gt;() ;        // 声明String的泛型对象
        Info&lt;Object&gt; i2 = new Info&lt;Object&gt;() ;        // 声明Object的泛型对象
        i1.setVar(&quot;hello&quot;) ;
        i2.setVar(new Object()) ;
        fun(i1) ;
        fun(i2) ;
    }
    public static void fun(Info&lt;? super String&gt; temp){    // 只能接收String或Object类型的泛型，String类的父类只有Object类
        System.out.print(temp + &quot;, &quot;) ;
    }
}
</code></pre>
<p><strong>小结</strong></p>
<blockquote>
<?> 无限制通配符
<? extends E> extends 关键字声明了类型的上界，表示参数化的类型可能是所指定的类型，或者是此类型的子类
<? super E> super 关键字声明了类型的下界，表示参数化的类型可能是指定的类型，或者是此类型的父类
1. 如果参数化类型表示一个 T 的生产者，使用 < ? extends T>;
2. 如果它表示一个 T 的消费者，就使用 < ? super T>；
3. 如果既是生产又是消费，那使用通配符就没什么意义了，因为你需要的是精确的参数类型。
</blockquote>
<h2 id="25泛型数组">2.5.泛型数组</h2>
<pre><code class="language-java">List&lt;String&gt;[] list11 = new ArrayList&lt;String&gt;[10]; //编译错误，非法创建 
List&lt;String&gt;[] list12 = new ArrayList&lt;?&gt;[10]; //编译错误，需要强转类型 
List&lt;String&gt;[] list13 = (List&lt;String&gt;[]) new ArrayList&lt;?&gt;[10]; //OK，但是会有警告 
List&lt;?&gt;[] list14 = new ArrayList&lt;String&gt;[10]; //编译错误，非法创建 
List&lt;?&gt;[] list15 = new ArrayList&lt;?&gt;[10]; //OK 
List&lt;String&gt;[] list6 = new ArrayList[10]; //OK，但是会有警告
</code></pre>
<h1 id="3深入理解泛型">3.深入理解泛型</h1>
<h2 id="31-如何理解java中的泛型是伪泛型泛型中类型擦除">3.1 如何理解Java中的泛型是伪泛型？泛型中类型擦除</h2>
<blockquote>
<p>java泛型这个特性是从JDK 1.5才开始加入的，因此为了兼容之前的版本，Java泛型的实现采取了“伪泛型”的策略，即Java在语法上支持泛型，但是在编译阶段会进行所谓的“类型擦除”（Type Erasure），将所有的泛型表示（尖括号中的内容）都替换为具体的类型（其对应的原生态类型），就像完全没有泛型一样。理解类型擦除对于用好泛型是很有帮助的，尤其是一些看起来“疑难杂症”的问题，弄明白了类型擦除也就迎刃而解了。</p>
</blockquote>
<p>泛型的类型擦除原则是：<br>
- 消除类型参数声明，即删除&lt;&gt;及其包围的部分。<br>
- 根据类型参数的上下界推断并替换所有的类型参数为原生态类型：如果类型参数是无限制通配符或没有上下界限定则替换为Object，如果存在上下界限定则根据子类替换原则取类型参数的最左边限定类型（即父类）。<br>
- 为了保证类型安全，必要时插入强制类型转换代码。<br>
- 自动产生“桥接方法”以保证擦除类型后的代码仍然具有泛型的“多态性”。</p>
<h2 id="32-那么如何进行擦除的呢">3.2 那么如何进行擦除的呢？</h2>
<ul>
<li>擦除类定义中的类型参数 - 无限制类型擦除</li>
</ul>
<p>当类定义中的类型参数没有任何限制时，在类型擦除中直接被替换为Object，即形如<T>和&lt;?&gt;的类型参数都被替换为Object。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662369716778.png" alt="无限制类型擦除" loading="lazy"></figure>
<ul>
<li>擦除类定义中的类型参数 - 有限制类型擦除</li>
</ul>
<p>当类定义中的类型参数存在限制（上下界）时，在类型擦除中替换为类型参数的上界或者下界，比如形如<T extends Number>和&lt;? extends Number&gt;的类型参数被替换为Number，&lt;? super Number&gt;被替换为Object。</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1662369723517.png" alt="有限制类型擦除" loading="lazy"></figure>
<ul>
<li>擦除方法定义中的类型参数</li>
</ul>
<p>擦除方法定义中的类型参数原则和擦除类定义中的类型参数是一样的，这里仅以擦除方法定义中的有限制类型参数为例。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1662369746834.png" alt="擦除方法定义中的类型参数" loading="lazy"></figure>
<p>如何证明类型的擦除呢？</p>
<ol>
<li>原始类型相等</li>
</ol>
<pre><code class="language-java">public class Test {

    public static void main(String[] args) {

        ArrayList&lt;String&gt; list1 = new ArrayList&lt;String&gt;();
        list1.add(&quot;abc&quot;);

        ArrayList&lt;Integer&gt; list2 = new ArrayList&lt;Integer&gt;();
        list2.add(123);

        System.out.println(list1.getClass() == list2.getClass()); // true
    }
}
</code></pre>
<ol start="2">
<li>通过反射添加其它类型元素</li>
</ol>
<pre><code class="language-java">public class Test {

    public static void main(String[] args) throws Exception {

        ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();

        list.add(1);  //这样调用 add 方法只能存储整形，因为泛型类型的实例为 Integer

        list.getClass().getMethod(&quot;add&quot;, Object.class).invoke(list, &quot;asd&quot;);

        for (int i = 0; i &lt; list.size(); i++) {
            System.out.println(list.get(i));
        }
    }

}
</code></pre>
<h2 id="33-如何理解类型擦除后保留的原始类型">3.3 如何理解类型擦除后保留的原始类型?</h2>
<p>原始类型 就是擦除去了泛型信息，最后在字节码中的类型变量的真正类型，无论何时定义一个泛型，相应的原始类型都会被自动提供，类型变量擦除，并使用其限定类型（无限定的变量用Object）替换。</p>
<h2 id="34-如何理解泛型的编译期检查">3.4 如何理解泛型的编译期检查？</h2>
<blockquote>
<p>既然说类型变量会在编译的时候擦除掉，那为什么我们往 ArrayList 创建的对象中添加整数会报错呢？不是说泛型变量String会在编译的时候变为Object类型吗？为什么不能存别的类型呢？既然类型擦除了，如何保证我们只能使用泛型变量限定的类型呢？</p>
</blockquote>
<p><strong>Java编译器是通过先检查代码中泛型的类型，然后在进行类型擦除，再进行编译。</strong></p>
<pre><code class="language-java">public class Test {  

    public static void main(String[] args) {  

        ArrayList&lt;String&gt; list1 = new ArrayList();  
        list1.add(&quot;1&quot;); //编译通过  
        list1.add(1); //编译错误  
        String str1 = list1.get(0); //返回类型就是String  

        ArrayList list2 = new ArrayList&lt;String&gt;();  
        list2.add(&quot;1&quot;); //编译通过  
        list2.add(1); //编译通过  
        Object object = list2.get(0); //返回类型就是Object  

        new ArrayList&lt;String&gt;().add(&quot;11&quot;); //编译通过  
        new ArrayList&lt;String&gt;().add(22); //编译错误  

        String str2 = new ArrayList&lt;String&gt;().get(0); //返回类型就是String  
    }  
} 
</code></pre>
<p>通过上面的例子，我们可以明白，<strong>类型检查就是针对引用的，谁是一个引用，用这个引用调用泛型方法，就会对这个引用调用的方法进行类型检测，而无关它真正引用的对象。</strong></p>
<p>泛型中参数话类型为什么不考虑继承关系？</p>
<h2 id="35-如何理解泛型的多态泛型的桥接方法">3.5 如何理解泛型的多态？泛型的桥接方法</h2>
<blockquote>
<p>类型擦除会造成多态的冲突，而JVM解决方法就是桥接方法。</p>
</blockquote>
<h2 id="36-如何理解基本类型不能作为泛型类型">3.6 如何理解基本类型不能作为泛型类型？</h2>
<blockquote>
<p>比如，我们没有ArrayList<int>，只有ArrayList<Integer>, 为何？</p>
</blockquote>
<p>因为当类型擦除后，ArrayList的原始类型变为Object，但是Object类型不能存储int值，只能引用Integer的值。</p>
<p>另外需要注意，我们能够使用list.add(1)是因为Java基础类型的自动装箱拆箱操作。</p>
<h2 id="37-如何理解泛型类型不能实例化">3.7 如何理解泛型类型不能实例化？</h2>
<blockquote>
<p>不能实例化泛型类型, 这本质上是由于类型擦除决定的：</p>
</blockquote>
<p>T test = new T(); // ERROR</p>
<p>因为在 Java 编译期没法确定泛型参数化类型，也就找不到对应的类字节码文件，所以自然就不行了，此外由于T 被擦除为 Object，如果可以 new T() 则就变成了 new Object()，失去了本意。<br>
   <br>
如果我们确实需要实例化一个泛型，应该如何做呢？可以通过反射实现</p>
<pre><code class="language-java">static &lt;T&gt; T newTclass (Class &lt; T &gt; clazz) throws InstantiationException, IllegalAccessException {
    T obj = clazz.newInstance();
    return obj;
}
</code></pre>
<h2 id="38-泛型数组能不能采用具体的泛型类型进行初始化">3.8 泛型数组：能不能采用具体的泛型类型进行初始化？</h2>
<h2 id="39-泛型数组如何正确的初始化泛型数组实例">3.9 泛型数组：如何正确的初始化泛型数组实例</h2>
<pre><code class="language-java">public class ArrayWithTypeToken&lt;T&gt; {
    private T[] array;

    public ArrayWithTypeToken(Class&lt;T&gt; type, int size) {
        array = (T[]) Array.newInstance(type, size);
    }

    public void put(int index, T item) {
        array[index] = item;
    }

    public T get(int index) {
        return array[index];
    }

    public T[] create() {
        return array;
    }
}
//...

ArrayWithTypeToken&lt;Integer&gt; arrayToken = new ArrayWithTypeToken&lt;Integer&gt;(Integer.class, 100);
Integer[] array = arrayToken.create();
</code></pre>
<p>所以使用反射来初始化泛型数组算是优雅实现，因为泛型类型 T在运行时才能被确定下来，我们能创建泛型数组也必然是在 Java 运行时想办法，而运行时能起作用的技术最好的就是反射了。</p>
<p>参考链接：https://pdai.tech/md/java/basic/java-basic-x-generic.html</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JAVA并发（四）]]></title>
        <id>https://q456qq520.github.io/post/java-bing-fa-si/</id>
        <link href="https://q456qq520.github.io/post/java-bing-fa-si/">
        </link>
        <updated>2022-08-18T10:13:51.000Z</updated>
        <content type="html"><![CDATA[<h1 id="6-java中的13个原子操作类">6 Java中的13个原子操作类</h1>
<p>Atomic包里一共提供了13个类，属于4种类型的原子更新方式，分别是原子更新基本类型、原子更新数组、原子更新引用和原子更新属性（字段）。Atomic包里的类基本都是使用Unsafe实现的包装类。</p>
<h2 id="61-原子更新基本类型类">6.1 原子更新基本类型类</h2>
<p>使用原子的方式更新基本类型，Atomic包提供了以下3个类。</p>
<pre><code>AtomicBoolean：原子更新布尔类型。
AtomicInteger：原子更新整型。
AtomicLong：原子更新长整型。
</code></pre>
<p>以上3个类提供的方法几乎一模一样，下面以AtomicInteger为例，AtomicInteger的常用方法如下。</p>
<ol>
<li>int addAndGet（int delta）：以原子方式将输入的数值与实例中的值（AtomicInteger里的value）相加，并返回结果。</li>
<li>boolean compareAndSet（int expect，int update）：如果输入的数值等于预期值，则以原子方式将该值设置为输入的值。</li>
<li>int getAndIncrement()：以原子方式将当前值加1，注意，这里返回的是自增前的值。</li>
<li>void lazySet（int newValue）：最终会设置成newValue，使用lazySet设置值后，可能导致其他<br>
线程在之后的一小段时间内还是可以读到旧的值。</li>
<li>int getAndSet（int newValue）：以原子方式设置为newValue的值，并返回旧值。</li>
</ol>
<p>那么getAndIncrement是如何实现原子操作的呢？</p>
<blockquote>
<p>AtomicInteger</p>
</blockquote>
<pre><code class="language-java">  public final int getAndIncrement() {
        return unsafe.getAndAddInt(this, valueOffset, 1);
    }
</code></pre>
<p>Atomic包里的类基本都是使用Unsafe实现的，Unsafe只提供了3种CAS方法：compareAndSwapObject、compareAndSwapInt和compareAndSwapLong，都是native方法。</p>
<h2 id="62-原子更新数组">6.2 原子更新数组</h2>
<p>通过原子的方式更新数组里的某个元素，Atomic包提供了以下3个类。</p>
<pre><code>AtomicIntegerArray：原子更新整型数组里的元素。
AtomicLongArray：原子更新长整型数组里的元素。
AtomicReferenceArray：原子更新引用类型数组里的元素。
</code></pre>
<p>AtomicIntegerArray类主要是提供原子的方式更新数组里的整型，其常用方法如下。</p>
<pre><code>int addAndGet（int i，int delta）：以原子方式将输入值与数组中索引i的元素相加。
boolean compareAndSet（int i，int expect，int update）：如果当前值等于预期值，则以原子方式将数组位置i的元素设置成update值。
</code></pre>
<p>以上几个类提供的方法几乎一样</p>
<h2 id="63-原子更新引用类型">6.3 原子更新引用类型</h2>
<p>原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下3个类。</p>
<pre><code>AtomicReference：原子更新引用类型。
AtomicReferenceFieldUpdater：原子更新引用类型里的字段。
AtomicMarkableReference：原子更新带有标记位的引用类型。可以原子更新一个布尔类型的标记位和引用类型。
</code></pre>
<h2 id="64-原子更新字段类">6.4 原子更新字段类</h2>
<p>如果需原子地更新某个类里的某个字段时，就需要使用原子更新字段类，Atomic包提供了以下3个类进行原子字段更新。</p>
<pre><code>AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。
AtomicLongFieldUpdater：原子更新长整型字段的更新器。
AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于原子的更新数据和数据的版本号，可以解决使用CAS进行原子更新时可能出现的ABA问题。
</code></pre>
<p>要想原子地更新字段类需要两步。第一步，因为原子更新字段类都是抽象类，每次使用的时候必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新类的字段（属性）必须使用public volatile修饰符。</p>
<h1 id="7-java中的并发工具类">7 Java中的并发工具类</h1>
<p>在JDK的并发包里提供了几个非常有用的并发工具类。CountDownLatch、CyclicBarrier和Semaphore工具类提供了一种并发流程控制的手段，Exchanger工具类则提供了在线程间交换数据的一种手段。</p>
<h2 id="71-等待多线程完成的countdownlatch">7.1 等待多线程完成的CountDownLatch</h2>
<p>CountDownLatch允许一个或多个线程等待其他线程完成操作</p>
<p>当我们调用CountDownLatch的countDown方法时，N就会减1，CountDownLatch的await方法会阻塞当前线程，直到N变成零。由于countDown方法可以用在任何地方，所以这里说的N个点，可以是N个线程，也可以是1个线程里的N个执行步骤。用在多个线程时，只需要把这个CountDownLatch的引用传递到线程里即可。</p>
<p>计数器必须大于等于0，只是等于0时候，计数器就是零，调用await方法时不会阻塞当前线程。CountDownLatch不可能重新初始化或者修改CountDownLatch对象的内部计数器的值。一个线程调用countDown方法happen-before，另外一个线程调用await方法。</p>
<h2 id="72-同步屏障cyclicbarrier">7.2 同步屏障CyclicBarrier</h2>
<p>CyclicBarrier的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。</p>
<h3 id="721-cyclicbarrier简介">7.2.1 CyclicBarrier简介</h3>
<p>CyclicBarrier默认的构造方法是CyclicBarrier（int parties），其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。示例代码如下所示。</p>
<blockquote>
<p>CyclicBarrier示例</p>
</blockquote>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.CyclicBarrier;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/19 17:00
 */
public class CyclicBarrierTest {
    static CyclicBarrier c = new CyclicBarrier(2);
    public static void main(String[] args) {
        new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    c.await();
                } catch (Exception e) {
                }
                System.out.println(1);
            }
        }).start();
        try {
            c.await();
        } catch (Exception e) {
        }
        System.out.println(2);
    }
}
</code></pre>
<p>因为主线程和子线程的调度是由CPU决定的，两个线程都有可能先执行，所以会产生两种输出。</p>
<p>如果把new CyclicBarrier(2)修改成new CyclicBarrier(3)，则主线程和子线程会永远等待，因为没有第三个线程执行await方法，即没有第三个线程到达屏障，所以之前到达屏障的两个线程都不会继续执行。</p>
<p>CyclicBarrier还提供一个更高级的构造函数CyclicBarrier（int parties，Runnable barrierAction），用于在线程到达屏障时，优先执行barrierAction，方便处理更复杂的业务场景，如下所示：</p>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.CyclicBarrier;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/19 17:03
 */
public class CyclicBarrierTest2 {
        static CyclicBarrier c = new CyclicBarrier(2, new A());
        public static void main(String[] args) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    try {
                        c.await();
                    } catch (Exception e) {
                    }
                    System.out.println(1);
                }
            }).start();
            try {
                c.await();
            } catch (Exception e) {
            }
            System.out.println(2);
        }
        static class A implements Runnable {
            @Override
            public void run() {
                System.out.println(3);
            }
        }
}
</code></pre>
<p>因为CyclicBarrier设置了拦截线程的数量是2，所以必须等代码中的第一个线程和线程A<br>
都执行完之后，才会继续执行主线程。</p>
<h3 id="722-cyclicbarrier的应用场景">7.2.2 CyclicBarrier的应用场景</h3>
<h3 id="723-cyclicbarrier和countdownlatch的区别">7.2.3 CyclicBarrier和CountDownLatch的区别</h3>
<p>CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置。所以CyclicBarrier能处理更为复杂的业务场景。例如，如果计算发生错误，可以重置计数器，并让线程重新执行一次。</p>
<p>CyclicBarrier还提供其他有用的方法，比如getNumberWaiting方法可以获得Cyclic-Barrier阻塞的线程数量。isBroken()方法用来了解阻塞的线程是否被中断。</p>
<h2 id="73-控制并发线程数的semaphore">7.3 控制并发线程数的Semaphore</h2>
<p>Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。</p>
<h5 id="1应用场景">1.应用场景</h5>
<p>Semaphore可以用于做流量控制，特别是公用资源有限的应用场景，比如数据库连接。假如有一个需求，要读取几万个文件的数据，因为都是IO密集型任务，我们可以启动几十个线程并发地读取，但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只有10个，这时我们必须控制只有10个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。这个时候，就可以使用Semaphore来做流量控制，示例如下：</p>
<blockquote>
<p>SemaphoreTest</p>
</blockquote>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Semaphore;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/22 15:33
 */
public class SemaphoreTest {
    private static final int THREAD_COUNT = 30;
    private static ExecutorService threadPool = Executors.newFixedThreadPool(THREAD_COUNT);
    private static Semaphore s = new Semaphore(10);
    public static void main(String[] args) {
        for (int i = 0; i&lt; THREAD_COUNT; i++) {
            threadPool.execute(new Runnable() {
                @Override
                public void run() {
                    try {
                        s.acquire();
                        System.out.println(&quot;save data&quot;);
                        s.release();
                    } catch (InterruptedException e) {
                    }
                }
            });
        }
        threadPool.shutdown();
    }
}
</code></pre>
<p>在代码中，虽然有30个线程在执行，但是只允许10个并发执行。Semaphore的构造方法Semaphore（int permits）接受一个整型的数字，表示可用的许可证数量。Semaphore（10）表示允许10个线程获取许可证，也就是最大并发数是10。Semaphore的用法也很简单，首先线程使用Semaphore的acquire()方法获取一个许可证，使用完之后调用release()方法归还许可证。还可以用tryAcquire()方法尝试获取许可证。</p>
<h5 id="2其他方法">2.其他方法</h5>
<p>Semaphore还提供一些其他方法，具体如下。</p>
<ol>
<li>intavailablePermits()：返回此信号量中当前可用的许可证数。</li>
<li>intgetQueueLength()：返回正在等待获取许可证的线程数。</li>
<li>booleanhasQueuedThreads()：是否有线程正在等待获取许可证。</li>
<li>void reducePermits（int reduction）：减少reduction个许可证，是个protected方法。</li>
<li>Collection getQueuedThreads()：返回所有等待获取许可证的线程集合，是个protected方<br>
法。</li>
</ol>
<h2 id="74-线程间交换数据的exchanger">7.4 线程间交换数据的Exchanger</h2>
<p>Exchanger（交换者）是一个用于线程间协作的工具类。Exchanger用于进行线程间的数据交换。</p>
<p>它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行exchange方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。</p>
<h3 id="71">7.1</h3>
<p>Exchanger可以用于遗传算法，遗传算法里需要选出两个人作为交配对象，这时候会交换两人的数据，并使用交叉规则得出2个交配结果。</p>
<p>Exchanger也可以用于校对工作，比如我们需要将纸制银行流水通过人工的方式录入成电子银行流水，为了避免错误，采用AB岗两人进行录入，录入到Excel之后，系统需要加载这两个Excel，并对两个Excel数据进行校对，看看是否录入一致。</p>
<blockquote>
<p>11</p>
</blockquote>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.Exchanger;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/22 15:55
 */
public class ExchangerTest {
    private static final Exchanger&lt;String&gt; exgr = new Exchanger&lt;String&gt;();
    private static ExecutorService threadPool = Executors.newFixedThreadPool(2);
    public static void main(String[] args) {
        threadPool.execute(new Runnable() {
            @Override
            public void run() {
                try {
                    String A = &quot;银行流水A&quot;; // A录入银行流水数据
                    exgr.exchange(A);

                    System.out.println(&quot;比较完成&quot;);
                } catch (InterruptedException e) {
                }
            }
        });
        threadPool.execute(new Runnable() {
            @Override
            public void run() {
                try {
                    String B = &quot;银行流水B&quot;; // B录入银行流水数据
                    String A = exgr.exchange(&quot;B&quot;);
                    System.out.println(&quot;A和B数据是否一致：&quot; + A.equals(B) + &quot;，A录入的是：&quot;
                            + A + &quot;，B录入是：&quot; + B);
                } catch (InterruptedException e) {
                }
            }
        });
        threadPool.shutdown();
    }
}
</code></pre>
<p>如果两个线程有一个没有执行exchange()方法，则会一直等待，如果担心有特殊情况发生，避免一直等待，可以使用exchange（V x，longtimeout，TimeUnit unit）设置最大等待时长。</p>
<h1 id="8-java中的线程池">8 Java中的线程池</h1>
<h2 id="81-线程池的实现原理">8.1 线程池的实现原理</h2>
<p>在开发过程中，合理地使用线程池能够带来3个好处。<br>
第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。<br>
第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。<br>
第三：提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。</p>
<p>ThreadPoolExecutor执行execute方法分下面4种情况。<br>
1）如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。<br>
2）如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。<br>
3）如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。<br>
4）如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用<br>
RejectedExecutionHandler.rejectedExecution()方法。</p>
<p>线程池执行任务的方法如下。</p>
<blockquote>
<p>execute()</p>
</blockquote>
<pre><code class="language-java">  public void execute(Runnable command) {
        if (command == null)
            throw new NullPointerException();
        int c = ctl.get();
        if (workerCountOf(c) &lt; corePoolSize) {
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
        if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
            int recheck = ctl.get();
            if (! isRunning(recheck) &amp;&amp; remove(command))
                reject(command);
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
        else if (!addWorker(command, false))
            reject(command);
    }
</code></pre>
<p>线程池中的线程执行任务分两种情况，如下。<br>
1）在execute()方法中创建一个线程时，会让这个线程执行当前任务。<br>
2）这个线程执行完上图中1的任务后，会反复从BlockingQueue获取任务来执行。</p>
<h2 id="82-线程池的使用">8.2 线程池的使用</h2>
<h3 id="821-线程池的创建">8.2.1 线程池的创建</h3>
<p>我们可以通过ThreadPoolExecutor来创建一个线程池</p>
<pre><code class="language-java">new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime,
milliseconds,runnableTaskQueue, handler);
</code></pre>
<p>1）corePoolSize（线程池的基本大小）：当提交一个任务到线程池时，线程池会创建一个线<br>
程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任<br>
务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads()方法，<br>
线程池会提前创建并启动所有基本线程。</p>
<p>2）runnableTaskQueue（任务队列）：用于保存等待执行的任务的阻塞队列。可以选择以下几<br>
个阻塞队列。<br>
ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按FIFO（先进先出）原则对元素进行排序。<br>
LinkedBlockingQueue：一个基于链表结构的阻塞队列，此队列按FIFO排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列。<br>
SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于Linked-BlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。<br>
PriorityBlockingQueue：一个具有优先级的无限阻塞队列。</p>
<p>3）maximumPoolSize（线程池最大数量）：线程池允许创建的最大线程数。如果队列满了，并<br>
且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是，如<br>
果使用了无界的任务队列这个参数就没什么效果。</p>
<p>4）ThreadFactory：用于设置创建线程的工厂。</p>
<p>5）RejectedExecutionHandler（拒绝策略）：当队列和线程池都满了，说明线程池处于饱和状<br>
态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法<br>
处理新任务时抛出异常。</p>
<pre><code>AbortPolicy：直接抛出异常。
CallerRunsPolicy：只用调用者所在线程来运行任务。
DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。
DiscardPolicy：不处理，丢弃掉。
</code></pre>
<h3 id="822-向线程池提交任务">8.2.2 向线程池提交任务</h3>
<p>可以使用两个方法向线程池提交任务，分别为execute()和submit()方法。</p>
<p>**execute()**方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功。通过以下代码可知execute()方法输入的任务是一个Runnable类的实例。</p>
<pre><code class="language-java">threadsPool.execute(new Runnable() {
    @Override
    public void run() {
    // TODO Auto-generated method stub
    }
});
</code></pre>
<p>submit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。</p>
<pre><code class="language-java">Future&lt;Object&gt; future = executor.submit(harReturnValuetask);
    try {
        Object s = future.get();
    } catch (InterruptedException e) {
    // 处理中断异常
    } catch (ExecutionException e) {
    // 处理无法执行任务异常
    } finally {
    // 关闭线程池
    executor.shutdown();
}
</code></pre>
<h3 id="823-关闭线程池">8.2.3 关闭线程池</h3>
<p>可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池。它们的原理是遍历线程池中的工作线程，然后逐个调用线程的interrupt方法来中断线程，所以无法响应中断的任务可能永远无法终止。</p>
<p>但是它们存在一定的区别，shutdownNow首先将线程池的状态设置成STOP，然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表，而shutdown只是将线程池的状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。</p>
<p>只要调用了这两个关闭方法中的任意一个，isShutdown方法就会返回true。当所有的任务都已关闭后，才表示线程池关闭成功，这时调用isTerminaed方法会返回true。至于应该调用哪一种方法来关闭线程池，应该由提交到线程池的任务特性决定，通常调用shutdown方法来关闭线程池，如果任务不一定要执行完，则可以调用shutdownNow方法。</p>
<h3 id="824-合理地配置线程池">8.2.4 合理地配置线程池</h3>
<h3 id="825-线程池的监控">8.2.5 线程池的监控</h3>
<p>果在系统中大量使用线程池，则有必要对线程池进行监控，方便在出现问题时，可以根<br>
据线程池的使用状况快速定位问题。可以通过线程池提供的参数进行监控，在监控线程池的<br>
时候可以使用以下属性。</p>
<p>taskCount：线程池需要执行的任务数量。<br>
completedTaskCount：线程池在运行过程中已完成的任务数量，小于或等于taskCount。<br>
largestPoolSize：线程池里曾经创建过的最大线程数量。通过这个数据可以知道线程池是<br>
否曾经满过。如该数值等于线程池的最大大小，则表示线程池曾经满过。<br>
getPoolSize：线程池的线程数量。如果线程池不销毁的话，线程池里的线程不会自动销<br>
毁，所以这个大小只增不减。<br>
getActiveCount：获取活动的线程数。</p>
<p>通过扩展线程池进行监控。可以通过继承线程池来自定义线程池，重写线程池的beforeExecute、afterExecute和terminated方法，也可以在任务执行前、执行后和线程池关闭前执行一些代码来进行监控。例如，监控任务的平均执行时间、最大执行时间和最小执行时间等。这几个方法在线程池里是空方法。</p>
<h1 id="9-executor框架">9 Executor框架</h1>
<p>Java的线程既是工作单元，也是执行机制。从JDK 5开始，把工作单元与执行机制分离开来。工作单元包括Runnable和Callable，而执行机制由Executor框架提供。</p>
<h2 id="91-executor框架简介">9..1 Executor框架简介</h2>
<h3 id="911-executor框架的两级调度模型">9.1.1 Executor框架的两级调度模型</h3>
<p>在HotSpot VM的线程模型中，Java线程（java.lang.Thread）被一对一映射为本地操作系统线程。Java线程启动时会创建一个本地操作系统线程；当该Java线程终止时，这个操作系统线程也会被回收。操作系统会调度所有线程并将它们分配给可用的CPU。</p>
<p>在上层，Java多线程程序通常把应用分解为若干个任务，然后使用用户级的调度器（Executor框架）将这些任务映射为固定数量的线程；在底层，操作系统内核将这些线程映射到硬件处理器上。</p>
<p>应用程序通过Executor框架控制上层的调度；而下层的调度由操作系统内核控制，下层的调度不受应用程序的控制。</p>
<h3 id="912-executor框架的结构与成员">9.1.2 Executor框架的结构与成员</h3>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1661163229274.png" alt="任务的两级调度模型" loading="lazy"></figure>
<h5 id="1executor框架的结构">1.Executor框架的结构</h5>
<p>Executor框架主要由3大部分组成如下。<br>
任务。包括被执行任务需要实现的接口：Runnable接口或Callable接口。<br>
任务的执行。包括任务执行机制的核心接口Executor，以及继承自Executor的ExecutorService接口。Executor框架有两个关键类实现了ExecutorService接口（ThreadPoolExecutor和ScheduledThreadPoolExecutor）。<br>
异步计算的结果。包括接口Future和实现Future接口的FutureTask类</p>
<p>下面是这些类和接口的简介。</p>
<ol>
<li>Executor是一个接口，它是Executor框架的基础，它将任务的提交与任务的执行分离开来。</li>
<li>ThreadPoolExecutor是线程池的核心实现类，用来执行被提交的任务</li>
<li>·ScheduledThreadPoolExecutor是一个实现类，可以在给定的延迟后运行命令，或者定期执行命令。ScheduledThreadPoolExecutor比Timer更灵活，功能更强大。</li>
<li>Future接口和实现Future接口的FutureTask类，代表异步计算的结果。</li>
<li>Runnable接口和Callable接口的实现类，都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行。</li>
</ol>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1661163737003.png" alt="Executor框架的使用示意图" loading="lazy"></figure>
<p>主线程首先要创建实现Runnable或者Callable接口的任务对象。工具类Executors可以把一个Runnable对象封装为一个Callable对象（Executors.callable（Runnable task）或Executors.callable（Runnable task，Object resule））。</p>
<p>然后可以把Runnable对象直接交给ExecutorService执行（ExecutorService.execute（Runnablecommand））；或者也可以把Runnable对象或Callable对象提交给ExecutorService执行（ExecutorService.submit（Runnable task）或ExecutorService.submit（Callable<T>task）。</p>
<p>如果执行ExecutorService.submit（…），ExecutorService将返回一个实现Future接口的对象（到目前为止的JDK中，返回的是FutureTask对象）。由于FutureTask实现了Runnable，程序员也可以创建FutureTask，然后直接交给ExecutorService执行。</p>
<p>最后，主线程可以执行FutureTask.get()方法来等待任务执行完成。主线程也可以执FutureTask.cancel（boolean mayInterruptIfRunning）来取消此任务的执行。</p>
<h5 id="2executor框架的成员">2.Executor框架的成员</h5>
<p>Executor框架的主要成员：ThreadPoolExecutor、ScheduledThreadPoolExecutor、Future接口、Runnable接口、Callable接口和Executors。</p>
<p>（1）ThreadPoolExecutor</p>
<p>ThreadPoolExecutor通常使用工厂类Executors来创建。Executors可以创建3种类型的ThreadPoolExecutor：SingleThreadExecutor、FixedThreadPool和CachedThreadPool。</p>
<ol>
<li>FixedThreadPool。下面是Executors提供的，创建使用固定线程数的FixedThreadPool的API。</li>
</ol>
<pre><code class="language-java"> public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue&lt;Runnable&gt;());
    }

    public static ExecutorService newWorkStealingPool(int parallelism) {
        return new ForkJoinPool
            (parallelism,
             ForkJoinPool.defaultForkJoinWorkerThreadFactory,
             null, true);
    }
</code></pre>
<p>FixedThreadPool适用于为了满足资源管理的需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。</p>
<ol start="2">
<li>SingleThreadExecutor。下面是Executors提供的，创建使用单个线程的SingleThreadExecutor的API。</li>
</ol>
<pre><code class="language-java">    public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue&lt;Runnable&gt;()));
    }

    public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue&lt;Runnable&gt;(),
                                    threadFactory));
    }
</code></pre>
<p>SingleThreadExecutor适用于需要保证顺序地执行各个任务；并且在任意时间点，不会有多个线程是活动的应用场景。</p>
<ol start="3">
<li>CachedThreadPool。下面是Executors提供的，创建一个会根据需要创建新线程的CachedThreadPool的API。</li>
</ol>
<pre><code class="language-java">   public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue&lt;Runnable&gt;());
    }

    public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue&lt;Runnable&gt;(),
                                      threadFactory);
    }
</code></pre>
<p>CachedThreadPool是大小无界的线程池，适用于执行很多的短期异步任务的小程序，或者是负载较轻的服务器。</p>
<p>（2）ScheduledThreadPoolExecutor</p>
<p>ScheduledThreadPoolExecutor通常使用工厂类Executors来创建。Executors可以创建2种类型的ScheduledThreadPoolExecutor，如下。</p>
<ol>
<li>ScheduledThreadPoolExecutor。包含若干个线程的ScheduledThreadPoolExecutor。</li>
<li>SingleThreadScheduledExecutor。只包含一个线程的ScheduledThreadPoolExecutor。</li>
</ol>
<p>ScheduledThreadPoolExecutor适用于需要多个后台线程执行周期任务，同时为了满足资源管理的需求而需要限制后台线程的数量的应用场景。</p>
<p>SingleThreadScheduledExecutor适用于需要单个后台线程执行周期任务，同时需要保证顺序地执行各个任务的应用场景。</p>
<p>（3）Future接口</p>
<p>Future接口和实现Future接口的FutureTask类用来表示异步计算的结果。当我们把Runnable接口或Callable接口的实现类提交（submit）给ThreadPoolExecutor或ScheduledThreadPoolExecutor时，ThreadPoolExecutor或ScheduledThreadPoolExecutor会向我们返回一个FutureTask对象。下面是对应的API。</p>
<pre><code class="language-java">&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);


&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);

Future&lt;?&gt; submit(Runnable task);
</code></pre>
<p>（4）Runnable接口和Callable接口</p>
<p>Runnable接口和Callable接口的实现类，都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行。它们之间的区别是Runnable不会返回结果，而Callable可以返回结果。</p>
<p>除了可以自己创建实现Callable接口的对象外，还可以使用工厂类Executors来把一个Runnable包装成一个Callable。</p>
<h2 id="92-threadpoolexecutor详解">9.2 ThreadPoolExecutor详解</h2>
<p>Executor框架最核心的类是ThreadPoolExecutor，它是线程池的实现类，主要由下列4个组件构成。</p>
<ol>
<li>corePool：核心线程池的大小。</li>
<li>maximumPool：最大线程池的大小。</li>
<li>BlockingQueue：用来暂时保存任务的工作队列。</li>
<li>RejectedExecutionHandler：当ThreadPoolExecutor已经关闭或ThreadPoolExecutor已经饱和时（达到了最大线程池大小且工作队列已满），execute()方法将要调用的Handler。</li>
</ol>
<p>通过Executor框架的工具类Executors，可以创建3种类型的ThreadPoolExecutor。<br>
FixedThreadPool<br>
SingleThreadExecutor<br>
CachedThreadPool</p>
<h3 id="921-fixedthreadpool详解">9.2.1 FixedThreadPool详解</h3>
<p>FixedThreadPool被称为可重用固定线程数的线程池。</p>
<p>FixedThreadPool的corePoolSize和maximumPoolSize都被设置为创建FixedThreadPool时指定的参数nThreads。</p>
<p>当线程池中的线程数大于corePoolSize时，keepAliveTime为多余的空闲线程等待新任务的最长时间，超过这个时间后多余的线程将被终止。这里把keepAliveTime设置为0L，意味着多余的空闲线程会被立即终止。</p>
<p>FixedThreadPool使用无界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer.MAX_VALUE）。使用无界队列作为工作队列会对线程池带来如下影响。</p>
<p>1）当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中<br>
的线程数不会超过corePoolSize。<br>
2）由于1，使用无界队列时maximumPoolSize将是一个无效参数。<br>
3）由于1和2，使用无界队列时keepAliveTime将是一个无效参数。<br>
4）由于使用无界队列，运行中的FixedThreadPool（未执行方法shutdown()或shutdownNow()）不会拒绝任务（不会调用RejectedExecutionHandler.rejectedExecution方法）。</p>
<h3 id="922-singlethreadexecutor详解">9.2.2 SingleThreadExecutor详解</h3>
<p>SingleThreadExecutor是使用单个worker线程的Executor。</p>
<p>SingleThreadExecutor的corePoolSize和maximumPoolSize被设置为1。其他参数与<br>
FixedThreadPool相同。SingleThreadExecutor使用无界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer.MAX_VALUE）。SingleThreadExecutor使用无界队列作为工作队列对线程池带来的影响与FixedThreadPool相同。</p>
<h3 id="923-cachedthreadpool详解">9.2.3 CachedThreadPool详解</h3>
<p>CachedThreadPool是一个会根据需要创建新线程的线程池。</p>
<p>CachedThreadPool的corePoolSize被设置为0，即corePool为空；maximumPoolSize被设置为<br>
Integer.MAX_VALUE，即maximumPool是无界的。这里把keepAliveTime设置为60L，意味着CachedThreadPool中的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。</p>
<p>CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列，但<br>
CachedThreadPool的maximumPool是无界的。这意味着，如果主线程提交任务的速度高于<br>
maximumPool中线程处理任务的速度时，CachedThreadPool会不断创建新线程。极端情况下，CachedThreadPool会因为创建过多线程而耗尽CPU和内存资源。</p>
<p>SynchronousQueue是一个没有容量的阻塞队列。每个插入操作必须等待另一个线程的对应移除操作，反之亦然。CachedThreadPool使用SynchronousQueue，把主线程提交的任务传递给空闲线程执行。</p>
<h2 id="93-scheduledthreadpoolexecutor详解">9.3 ScheduledThreadPoolExecutor详解</h2>
<p>ScheduledThreadPoolExecutor继承自ThreadPoolExecutor。它主要用来在给定的延迟之后运行任务，或者定期执行任务。</p>
<h2 id="94-futuretask详解">9.4 FutureTask详解</h2>
<p>Future接口和实现Future接口的FutureTask类，代表异步计算的结果。</p>
<h3 id="941-futuretask简介">9.4.1 FutureTask简介</h3>
<p>FutureTask除了实现Future接口外，还实现了Runnable接口。因此，FutureTask可以交给Executor执行，也可以由调用线程直接执行（FutureTask.run()）。根据FutureTask.run()方法被执行的时机，FutureTask可以处于下面3种状态。</p>
<p>1）未启动。FutureTask.run()方法还没有被执行之前，FutureTask处于未启动状态。当创建一个FutureTask，且没有执行FutureTask.run()方法之前，这个FutureTask处于未启动状态。<br>
2）已启动。FutureTask.run()方法被执行的过程中，FutureTask处于已启动状态。<br>
3）已完成。FutureTask.run()方法执行完后正常结束，或被取消（FutureTask.cancel（…）），或执行FutureTask.run()方法时抛出异常而异常结束，FutureTask处于已完成状态。</p>
<p>当FutureTask处于未启动或已启动状态时，执行FutureTask.get()方法将导致调用线程阻塞；当FutureTask处于已完成状态时，执行FutureTask.get()方法将导致调用线程立即返回结果或抛出异常。</p>
<p>当FutureTask处于未启动状态时，执行FutureTask.cancel()方法将导致此任务永远不会被执行；当FutureTask处于已启动状态时，执行FutureTask.cancel（true）方法将以中断执行此任务线程的方式来试图停止任务；当FutureTask处于已启动状态时，执行FutureTask.cancel（false）方法将不会对正在执行此任务的线程产生影响（让正在执行的任务运行完成）；当FutureTask处于已完成状态时，执行FutureTask.cancel（…）方法将返回false。</p>
<h3 id="942-futuretask的使用">9.4.2 FutureTask的使用</h3>
<p>可以把FutureTask交给Executor执行；也可以通过ExecutorService.submit（…）方法返回一个FutureTask，然后执行FutureTask.get()方法或FutureTask.cancel（…）方法。除此以外，还可以单独使用FutureTask。</p>
<p>当一个线程需要等待另一个线程把某个任务执行完后它才能继续执行，此时可以使用FutureTask。假设有多个线程执行若干任务，每个任务最多只能被执行一次。当多个线程试图同时执行同一个任务时，只允许一个线程执行任务，其他线程需要等待这个任务执行完后才能继续执行。下面是对应的示例代码。</p>
<pre><code class="language-java">package cm.atomic;

import java.util.concurrent.*;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/8/23 17:34
 */
public class FutureTaskTest {

    private final ConcurrentMap&lt;Object, Future&lt;String&gt;&gt; taskCache =
            new ConcurrentHashMap&lt;Object, Future&lt;String&gt;&gt;();

    private String executionTask(final String taskName)
            throws ExecutionException, InterruptedException {
        while (true) {
            Future&lt;String&gt; future = taskCache.get(taskName); // 1.1,2.1
            if (future == null) {
                Callable&lt;String&gt; task = new Callable&lt;String&gt;() {
                    public String call() throws InterruptedException {
                        return taskName;
                    }
                };

                FutureTask&lt;String&gt; futureTask = new FutureTask&lt;String&gt;(task);
                future = taskCache.putIfAbsent(taskName, futureTask); // 1.3
                if (future == null) {
                    future = futureTask;
                    futureTask.run(); // 1.4执行任务
                }
                try {
                    return future.get(); // 1.5,
                } catch (CancellationException e) {
                    taskCache.remove(taskName, future);
                }
            }
        }
    }
}
</code></pre>
<p>当两个线程试图同时执行同一个任务时，如果Thread 1执行1.3后Thread 2执行2.1，那么接下来Thread 2将在2.2等待，直到Thread 1执行完1.4后Thread 2才能从2.2（FutureTask.get()）返回。</p>
<h3 id="943-futuretask的实现">9.4.3 FutureTask的实现</h3>
<p>FutureTask的实现基于AbstractQueuedSynchronizer（以下简称为AQS）。java.util.concurrent中的很多可阻塞类（比如ReentrantLock）都是基于AQS来实现的。AQS是一个同步框架，它提供通用机制来原子性管理同步状态、阻塞和唤醒线程，以及维护被阻塞线程的队列。</p>
<p>每一个基于AQS实现的同步器都会包含两种类型的操作，如下。</p>
<p>至少一个acquire操作。这个操作阻塞调用线程，除非/直到AQS的状态允许这个线程继续执行。FutureTask的acquire操作为get()/get（long timeout，TimeUnit unit）方法调用。</p>
<p>至少一个release操作。这个操作改变AQS的状态，改变后的状态可允许一个或多个阻塞线程被解除阻塞。FutureTask的release操作包括run()方法和cancel（…）方法。</p>
<p>基于“复合优先于继承”的原则，FutureTask声明了一个内部私有的继承于AQS的子类Sync，对FutureTask所有公有方法的调用都会委托给这个内部子类。</p>
<p>FutureTask.run()的执行过程如下。</p>
<p>1）执行在构造函数中指定的任务（Callable.call()）。<br>
2）以原子方式来更新同步状态（调用AQS.compareAndSetState（int expect，int update），设置<br>
state为执行完成状态RAN）。如果这个原子操作成功，就设置代表计算结果的变量result的值为Callable.call()的返回值，然后调用AQS.releaseShared（int arg）。<br>
3）AQS.releaseShared（int arg）首先会回调在子类Sync中实现的tryReleaseShared（arg）来执行release操作（设置运行任务的线程runner为null，然会返回true）；AQS.releaseShared（int arg，<br>
然后唤醒线程等待队列中的第一个线程。<br>
4）调用FutureTask.done()。<br>
当执行FutureTask.get()方法时，如果FutureTask不是处于执行完成状态RAN或已取消状态CANCELLED，当前执行线程将到AQS的线程等待队列中等待。当某个线程执行FutureTask.run()方法或FutureTask.cancel（...）方法时，会唤醒线程等待队列的第一个线程。</p>
<h1 id="10-java并发编程实践">10 Java并发编程实践</h1>
<h2 id="101-生产者和消费者模式">10.1 生产者和消费者模式</h2>
<p>在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序整体处理数据的速度。</p>
<p>什么是生产者和消费者模式?</p>
<p>生产者和消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通信，而是通过<strong>阻塞队列</strong>来进行通信，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。</p>
<h3 id="1011-生产者消费者模式实战">10.1.1 生产者消费者模式实战</h3>
]]></content>
    </entry>
</feed>