<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://q456qq520.github.io</id>
    <title>LIKECAT</title>
    <updated>2022-10-11T08:21:10.136Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://q456qq520.github.io"/>
    <link rel="self" href="https://q456qq520.github.io/atom.xml"/>
    <subtitle>一条小咸鱼</subtitle>
    <logo>https://q456qq520.github.io/images/avatar.png</logo>
    <icon>https://q456qq520.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, LIKECAT</rights>
    <entry>
        <title type="html"><![CDATA[观察者模式]]></title>
        <id>https://q456qq520.github.io/post/guan-cha-zhe-mo-shi/</id>
        <link href="https://q456qq520.github.io/post/guan-cha-zhe-mo-shi/">
        </link>
        <updated>2022-10-11T07:40:53.000Z</updated>
        <summary type="html"><![CDATA[<p>观察者模式是一种行为设计模式， 允许你定义一种订阅机制， 可在对象事件发生时通知多个 “观察” 该对象的其他对象。</p>
]]></summary>
        <content type="html"><![CDATA[<p>观察者模式是一种行为设计模式， 允许你定义一种订阅机制， 可在对象事件发生时通知多个 “观察” 该对象的其他对象。</p>
<!-- more -->
<h2 id="1问题">1.问题</h2>
<p>假如你有两种类型的对象： ​ 顾客和 商店 。 顾客对某个特定品牌的产品非常感兴趣 （例如最新型号的 iPhone 手机）， 而该产品很快将会在商店里出售。</p>
<p>顾客可以每天来商店看看产品是否到货。 但如果商品尚未到货时， 绝大多数来到商店的顾客都会空手而归。</p>
<p>另一方面， 每次新产品到货时， 商店可以向所有顾客发送邮件 （可能会被视为垃圾邮件）。 这样， 部分顾客就无需反复前往商店了， 但也可能会惹恼对新产品没有兴趣的其他顾客。</p>
<p>我们似乎遇到了一个矛盾： 要么让顾客浪费时间检查产品是否到货， 要么让商店浪费资源去通知没有需求的顾客。</p>
<h2 id="2解决方案">2.解决方案</h2>
<p>拥有一些值得关注的状态的对象通常被称为目标，由于它要将自身的状态改变通知给其他对象， 我们也将其称为<strong>发布者</strong>（pub­lish­er）。 所有希望关注发布者状态变化的其他对象被称为<strong>订阅者</strong>（sub­scribers）。</p>
<p>观察者模式建议你为发布者类添加订阅机制， 让每个对象都能订阅或取消订阅发布者事件流。 不要害怕！ 这并不像听上去那么复杂。 实际上， 该机制包括 1） 一个用于存储订阅者对象引用的列表成员变量； 2） 几个用于添加或删除该列表中订阅者的公有方法。</p>
<figure data-type="image" tabindex="1"><img src="https://refactoringguru.cn/images/patterns/diagrams/observer/solution1-zh-2x.png" alt="订阅机制允许对象订阅事件通知" loading="lazy"></figure>
<p>订阅机制允许对象订阅事件通知。</p>
<p>现在， 无论何时发生了重要的发布者事件， 它都要遍历订阅者并调用其对象的特定通知方法。</p>
<p>实际应用中可能会有十几个不同的订阅者类跟踪着同一个发布者类的事件， 你不会希望发布者与所有这些类相耦合的。 此外如果他人会使用发布者类， 那么你甚至可能会对其中的一些类一无所知。</p>
<p>因此， 所有订阅者都必须实现同样的接口， 发布者仅通过该接口与订阅者交互。 接口中必须声明通知方法及其参数， 这样发布者在发出通知时还能传递一些上下文数据。</p>
<figure data-type="image" tabindex="2"><img src="https://refactoringguru.cn/images/patterns/diagrams/observer/solution2-zh-2x.png" alt="订阅机制允许对象订阅事件通知" loading="lazy"></figure>
<p>发布者调用订阅者对象中的特定通知方法来通知订阅者。</p>
<p>如果你的应用中有多个不同类型的发布者， 且希望订阅者可兼容所有发布者， 那么你甚至可以进一步让所有发布者遵循同样的接口。 该接口仅需描述几个订阅方法即可。 这样订阅者就能在不与具体发布者类耦合的情况下通过接口观察发布者的状态。</p>
<h2 id="3真实世界类比">3.真实世界类比</h2>
<p>如果你订阅了一份杂志或报纸， 那就不需要再去报摊查询新出版的刊物了。 出版社 （即应用中的 “发布者”） 会在刊物出版后 （甚至提前） 直接将最新一期寄送至你的邮箱中。</p>
<p>出版社负责维护订阅者列表， 了解订阅者对哪些刊物感兴趣。 当订阅者希望出版社停止寄送新一期的杂志时， 他们可随时从该列表中退出。</p>
<h2 id="4观察者模式结构">4.观察者模式结构</h2>
<figure data-type="image" tabindex="3"><img src="https://refactoringguru.cn/images/patterns/diagrams/observer/structure-2x.png" alt="观察者模式结构" loading="lazy"></figure>
<ol>
<li>
<p>发布者 （Pub­lish­er） 会向其他对象发送值得关注的事件。 事件会在发布者自身状态改变或执行特定行为后发生。 发布者中包含一个允许新订阅者加入和当前订阅者离开列表的订阅构架。</p>
</li>
<li>
<p>当新事件发生时， 发送者会遍历订阅列表并调用每个订阅者对象的通知方法。 该方法是在订阅者接口中声明的。</p>
</li>
<li>
<p>订阅者 （Sub­scriber） 接口声明了通知接口。 在绝大多数情况下， 该接口仅包含一个 update更新方法。 该方法可以拥有多个参数， 使发布者能在更新时传递事件的详细信息。</p>
</li>
<li>
<p>具体订阅者 （Con­crete Sub­scribers） 可以执行一些操作来回应发布者的通知。 所有具体订阅者类都实现了同样的接口， 因此发布者不需要与具体类相耦合。</p>
</li>
<li>
<p>订阅者通常需要一些上下文信息来正确地处理更新。 因此， 发布者通常会将一些上下文数据作为通知方法的参数进行传递。 发布者也可将自身作为参数进行传递， 使订阅者直接获取所需的数据。</p>
</li>
<li>
<p>客户端 （Client） 会分别创建发布者和订阅者对象， 然后为订阅者注册发布者更新。</p>
</li>
</ol>
<h2 id="5观察者模式适合应用场景">5.观察者模式适合应用场景</h2>
<ol>
<li>
<p>当一个对象状态的改变需要改变其他对象， 或实际对象是事先未知的或动态变化的时， 可使用观察者模式。<br>
当你使用图形用户界面类时通常会遇到一个问题。 比如， 你创建了自定义按钮类并允许客户端在按钮中注入自定义代码， 这样当用户按下按钮时就会触发这些代码。</p>
<p>观察者模式允许任何实现了订阅者接口的对象订阅发布者对象的事件通知。 你可在按钮中添加订阅机制， 允许客户端通过自定义订阅类注入自定义代码。</p>
</li>
<li>
<p>当应用中的一些对象必须观察其他对象时， 可使用该模式。 但仅能在有限时间内或特定情况下使用。<br>
订阅列表是动态的， 因此订阅者可随时加入或离开该列表。</p>
</li>
</ol>
<h2 id="6实现方式">6.实现方式</h2>
<ol>
<li>
<p>仔细检查你的业务逻辑， 试着将其拆分为两个部分： 独立于其他代码的核心功能将作为发布者； 其他代码则将转化为一组订阅类。</p>
</li>
<li>
<p>声明订阅者接口。 该接口至少应声明一个 update方法。</p>
</li>
<li>
<p>声明发布者接口并定义一些接口来在列表中添加和删除订阅对象。 记住发布者必须仅通过订阅者接口与它们进行交互。</p>
</li>
<li>
<p>确定存放实际订阅列表的位置并实现订阅方法。 通常所有类型的发布者代码看上去都一样， 因此将列表放置在直接扩展自发布者接口的抽象类中是显而易见的。 具体发布者会扩展该类从而继承所有的订阅行为。</p>
</li>
</ol>
<p>但是， 如果你需要在现有的类层次结构中应用该模式， 则可以考虑使用组合的方式： 将订阅逻辑放入一个独立的对象， 然后让所有实际订阅者使用该对象。</p>
<ol start="5">
<li>
<p>创建具体发布者类。 每次发布者发生了重要事件时都必须通知所有的订阅者。</p>
</li>
<li>
<p>在具体订阅者类中实现通知更新的方法。 绝大部分订阅者需要一些与事件相关的上下文数据。 这些数据可作为通知方法的参数来传递。</p>
</li>
</ol>
<p>但还有另一种选择。 订阅者接收到通知后直接从通知中获取所有数据。 在这种情况下， 发布者必须通过更新方法将自身传递出去。 另一种不太灵活的方式是通过构造函数将发布者与订阅者永久性地连接起来。</p>
<ol start="7">
<li>客户端必须生成所需的全部订阅者， 并在相应的发布者处完成注册工作。</li>
</ol>
<h2 id="7观察者模式优缺点">7.观察者模式优缺点</h2>
<table>
<thead>
<tr>
<th>优点</th>
<th style="text-align:center">缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>开闭原则。 你无需修改发布者代码就能引入新的订阅者类 （如果是发布者接口则可轻松引入发布者类）。</td>
<td style="text-align:center">订阅者的通知顺序是随机的。</td>
</tr>
<tr>
<td>你可以在运行时建立对象之间的联系。</td>
<td style="text-align:center">-</td>
</tr>
</tbody>
</table>
<h2 id="8与其他模式的关系">8.与其他模式的关系</h2>
<ol>
<li>
<p>责任链模式、 命令模式、 中介者模式和观察者模式用于处理请求发送者和接收者之间的不同连接方式：</p>
<ul>
<li>责任链按照顺序将请求动态传递给一系列的潜在接收者， 直至其中一名接收者对请求进行处理。</li>
<li>命令在发送者和请求者之间建立单向连接。</li>
<li>中介者清除了发送者和请求者之间的直接连接， 强制它们通过一个中介对象进行间接沟通。</li>
<li>观察者允许接收者动态地订阅或取消接收请求。</li>
</ul>
</li>
<li>
<p>中介者和观察者之间的区别往往很难记住。 在大部分情况下， 你可以使用其中一种模式， 而有时可以同时使用。 让我们来看看如何做到这一点。</p>
<p>中介者的主要目标是消除一系列系统组件之间的相互依赖。 这些组件将依赖于同一个中介者对象。 观察者的目标是在对象之间建立动态的单向连接， 使得部分对象可作为其他对象的附属发挥作用。</p>
<p>有一种流行的中介者模式实现方式依赖于观察者。 中介者对象担当发布者的角色， 其他组件则作为订阅者， 可以订阅中介者的事件或取消订阅。 当中介者以这种方式实现时， 它可能看上去与观察者非常相似。</p>
<p>当你感到疑惑时， 记住可以采用其他方式来实现中介者。 例如， 你可永久性地将所有组件链接到同一个中介者对象。 这种实现方式和观察者并不相同， 但这仍是一种中介者模式。</p>
<p>假设有一个程序， 其所有的组件都变成了发布者， 它们之间可以相互建立动态连接。 这样程序中就没有中心化的中介者对象， 而只有一些分布式的观察者。</p>
</li>
</ol>
<h2 id="9伪代码">9.伪代码</h2>
<p>在本例中， 观察者模式在文本编辑器的对象之间建立了间接的合作关系。 每当 编辑器  （Edi­tor） 对象改变时， 它都会通知其订阅者。 ​ 邮件通知监听器  （Email­Noti­fi­ca­tion­Lis­ten­er） 和 日志开启监听器  （Log­Open­Lis­ten­er） 都将通过执行其基本行为来对这些通知做出反应。</p>
<p>订阅者类不与编辑器类相耦合， 且能在需要时在其他应用中复用。 ​ 编辑器类仅依赖于抽象订阅者接口。 这样就能允许在不改变编辑器代码的情况下添加新的订阅者类型。</p>
<blockquote>
<p>EventManager.java: 基础发布者</p>
</blockquote>
<pre><code class="language-java">package com.publisher;

import java.io.File;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

/**
 * 基础发布者
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 16:05
 */
public class EventManager {
    Map&lt;String, List&lt;EventListener&gt;&gt; listeners = new HashMap&lt;&gt;();

    public EventManager(String... operations) {
        for (String operation : operations) {
            this.listeners.put(operation, new ArrayList&lt;&gt;());
        }
    }

    public void subscribe(String eventType, EventListener listener) {
        List&lt;EventListener&gt; users = listeners.get(eventType);
        users.add(listener);
    }

    public void unsubscribe(String eventType, EventListener listener) {
        List&lt;EventListener&gt; users = listeners.get(eventType);
        users.remove(listener);
    }

    public void notify(String eventType, File file) {
        List&lt;EventListener&gt; users = listeners.get(eventType);
        for (EventListener listener : users) {
            listener.update(eventType, file);
        }
    }
}

</code></pre>
<blockquote>
<p>Editor.java: 具体发布者， 由其他对象追踪</p>
</blockquote>
<pre><code class="language-java">package com.publisher;

import java.io.File;

/**
 * 具体发布者， 由其他对象追踪
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 16:06
 */
public class Editor {
    public EventManager events;
    private File file;

    public Editor() {
        this.events = new EventManager(&quot;open&quot;, &quot;save&quot;);
    }

    public void openFile(String filePath) {
        this.file = new File(filePath);
        events.notify(&quot;open&quot;, file);
    }

    public void saveFile() throws Exception {
        if (this.file != null) {
            events.notify(&quot;save&quot;, file);
        } else {
            throw new Exception(&quot;Please open a file first.&quot;);
        }
    }
}
</code></pre>
<blockquote>
<p>EventListener.java: 通用观察者接口</p>
</blockquote>
<pre><code class="language-java">package com.publisher;

import java.io.File;

/**
 * 通用观察者接口
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 16:07
 */
public interface EventListener {
    void update(String eventType, File file);
}
</code></pre>
<blockquote>
<p>EmailNotificationListener.java: 收到通知后发送邮件</p>
</blockquote>
<pre><code class="language-java">package com.publisher;

import java.io.File;

/**
 * 收到通知后发送邮件
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 16:09
 */
public class EmailNotificationListener implements EventListener {
    private String email;

    public EmailNotificationListener(String email) {
        this.email = email;
    }

    @Override
    public void update(String eventType, File file) {
        System.out.println(&quot;Email to &quot; + email + &quot;: Someone has performed &quot; + eventType + &quot; operation with the following file: &quot; + file.getName());
    }
}
</code></pre>
<blockquote>
<p>LogOpenListener.java: 收到通知后在日志中记录一条消息</p>
</blockquote>
<pre><code class="language-java">package com.publisher;

import java.io.File;

/**
 * 收到通知后在日志中记录一条消息
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 16:10
 */
public class LogOpenListener implements EventListener {
    private File log;

    public LogOpenListener(String fileName) {
        this.log = new File(fileName);
    }

    @Override
    public void update(String eventType, File file) {
        System.out.println(&quot;Save to log &quot; + log + &quot;: Someone has performed &quot; + eventType + &quot; operation with the following file: &quot; + file.getName());
    }
}
</code></pre>
<blockquote>
<p>Main</p>
</blockquote>
<pre><code class="language-java">package com.publisher;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 16:11
 */
public class Demo {
    public static void main(String[] args) {
        Editor editor = new Editor();
        editor.events.subscribe(&quot;open&quot;, new LogOpenListener(&quot;/path/to/log/file.txt&quot;));
        editor.events.subscribe(&quot;save&quot;, new EmailNotificationListener(&quot;admin@example.com&quot;));

        try {
            editor.openFile(&quot;test.txt&quot;);
            editor.saveFile();
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<blockquote>
<p>运行结果</p>
</blockquote>
<pre><code class="language-java">Save to log \path\to\log\file.txt: Someone has performed open operation with the following file: test.txt
Email to admin@example.com: Someone has performed save operation with the following file: test.txt
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[访问者模式]]></title>
        <id>https://q456qq520.github.io/post/fang-wen-zhe-mo-shi/</id>
        <link href="https://q456qq520.github.io/post/fang-wen-zhe-mo-shi/">
        </link>
        <updated>2022-10-11T03:23:34.000Z</updated>
        <summary type="html"><![CDATA[<p>访问者模式是一种行为设计模式， 它能将算法与其所作用的对象隔离开来。</p>
]]></summary>
        <content type="html"><![CDATA[<p>访问者模式是一种行为设计模式， 它能将算法与其所作用的对象隔离开来。</p>
<!-- more -->
<h2 id="1问题">1.问题</h2>
<p>假如你的团队开发了一款能够使用巨型图像中地理信息的应用程序。 图像中的每个节点既能代表复杂实体 （例如一座城市）， 也能代表更精细的对象 （例如工业区和旅游景点等）。 如果节点代表的真实对象之间存在公路， 那么这些节点就会相互连接。 在程序内部， 每个节点的类型都由其所属的类来表示， 每个特定的节点则是一个对象。</p>
<figure data-type="image" tabindex="1"><img src="https://refactoringguru.cn/images/patterns/diagrams/visitor/problem1-2x.png" alt="将图像导出为 XML" loading="lazy"></figure>
<p>一段时间后， 你接到了实现将图像导出到 XML 文件中的任务。 这些工作最初看上去非常简单。 你计划为每个节点类添加导出函数， 然后递归执行图像中每个节点的导出函数。 解决方案简单且优雅： 使用多态机制可以让导出方法的调用代码不会和具体的节点类相耦合。</p>
<p>但你不太走运， 系统架构师拒绝批准对已有节点类进行修改。 他认为这些代码已经是产品了， 不想冒险对其进行修改， 因为修改可能会引入潜在的缺陷。</p>
<figure data-type="image" tabindex="2"><img src="https://refactoringguru.cn/images/patterns/diagrams/visitor/problem1-2x.png" alt="将图像导出为 XML" loading="lazy"></figure>
<p>所有节点的类中都必须添加导出至 XML 文件的方法， 但如果在修改代码的过程中引入了任何缺陷， 那么整个程序都会面临风险。</p>
<p>此外， 他还质疑在节点类中包含导出 XML 文件的代码是否有意义。 这些类的主要工作是处理地理数据。 导出 XML 文件的代码放在这里并不合适。</p>
<p>还有另一个原因， 那就是在此项任务完成后， 营销部门很有可能会要求程序提供导出其他类型文件的功能， 或者提出其他奇怪的要求。 这样你很可能会被迫再次修改这些重要但脆弱的类。</p>
<h2 id="2解决方案">2.解决方案</h2>
<p>访问者模式建议将新行为放入一个名为访问者的独立类中， 而不是试图将其整合到已有类中。 现在， 需要执行操作的原始对象将作为参数被传递给访问者中的方法， 让方法能访问对象所包含的一切必要数据。</p>
<p>如果现在该操作能在不同类的对象上执行会怎么样呢？ 比如在我们的示例中， 各节点类导出 XML 文件的实际实现很可能会稍有不同。 因此， 访问者类可以定义一组 （而不是一个） 方法， 且每个方法可接收不同类型的参数， 如下所示：</p>
<pre><code class="language-java">class ExportVisitor implements Visitor {
    method doForCity(City c) { …… }
    method doForIndustry(Industry f) { …… }
    method doForSightSeeing(SightSeeing ss) { …… }
    // ……
}
</code></pre>
<p>但我们究竟应该如何调用这些方法 （尤其是在处理整个图像方面） 呢？ 这些方法的签名各不相同， 因此我们不能使用多态机制。 为了可以挑选出能够处理特定对象的访问者方法， 我们需要对它的类进行检查。 这是不是听上去像个噩梦呢？</p>
<pre><code class="language-java">for (Node node:graph) {
    if (node instanceof City)
        exportVisitor.doForCity((City) node)
    if (node instanceof Industry)
        exportVisitor.doForIndustry((Industry) node)
    // ……
}
</code></pre>
<p>你可能会问， 我们为什么不使用方法重载呢？ 就是使用相同的方法名称， 但它们的参数不同。 不幸的是， 即使我们的编程语言 （例如 Java 和 C#） 支持重载也不行。 由于我们无法提前知晓节点对象所属的类， 所以重载机制无法执行正确的方法。 方法会将 节点基类作为输入参数的默认类型。</p>
<p>但是， 访问者模式可以解决这个问题。 它使用了一种名为<strong>双分派</strong>的技巧， 不使用累赘的条件语句也可下执行正确的方法。 与其让客户端来选择调用正确版本的方法， 不如将选择权委派给作为参数传递给访问者的对象。 由于该对象知晓其自身的类， 因此能更自然地在访问者中选出正确的方法。 它们会 “接收” 一个访问者并告诉其应执行的访问者方法。</p>
<pre><code class="language-java">// 客户端代码
for (Node node:graph) {
    node.accept(exportVisitor)
}
// 城市
class City {
    method accept(Visitor v) is
        v.doForCity(this)
    // ……
}

// 工业区
class Industry {
    method accept(Visitor v) is
        v.doForIndustry(this)
    // ……
}
</code></pre>
<p>我承认最终还是修改了节点类， 但毕竟改动很小， 且使得我们能够在后续进一步添加行为时无需再次修改代码。</p>
<p>现在， 如果我们抽取出所有访问者的通用接口， 所有已有的节点都能与我们在程序中引入的任何访问者交互。 如果需要引入与节点相关的某个行为， 你只需要实现一个新的访问者类即可。</p>
<h2 id="3真实世界类比">3.真实世界类比</h2>
<p>假如有这样一位非常希望赢得新客户的资深保险代理人。 他可以拜访街区中的每栋楼， 尝试向每个路人推销保险。 所以， 根据大楼内组织类型的不同， 他可以提供专门的保单：</p>
<ol>
<li>如果建筑是居民楼， 他会推销医疗保险。</li>
<li>如果建筑是银行， 他会推销失窃保险。</li>
<li>如果建筑是咖啡厅， 他会推销火灾和洪水保险。</li>
</ol>
<h2 id="4访问者模式结构">4.访问者模式结构</h2>
<figure data-type="image" tabindex="3"><img src="https://refactoringguru.cn/images/patterns/diagrams/visitor/structure-zh-2x.png" alt="访问者模式结构" loading="lazy"></figure>
<ol>
<li>
<p>访问者 （Vis­i­tor） 接口声明了一系列以对象结构的具体元素为参数的访问者方法。 如果编程语言支持重载， 这些方法的名称可以是相同的， 但是其参数一定是不同的。</p>
</li>
<li>
<p>具体访问者 （Con­crete Vis­i­tor） 会为不同的具体元素类实现相同行为的几个不同版本。</p>
</li>
<li>
<p>元素 （Ele­ment） 接口声明了一个方法来 “接收” 访问者。 该方法必须有一个参数被声明为访问者接口类型。</p>
</li>
<li>
<p>具体元素 （Con­crete Ele­ment） 必须实现接收方法。 该方法的目的是根据当前元素类将其调用重定向到相应访问者的方法。 请注意， 即使元素基类实现了该方法， 所有子类都必须对其进行重写并调用访问者对象中的合适方法。</p>
</li>
<li>
<p>客户端 （Client） 通常会作为集合或其他复杂对象 （例如一个组合树） 的代表。 客户端通常不知晓所有的具体元素类， 因为它们会通过抽象接口与集合中的对象进行交互。</p>
</li>
</ol>
<h2 id="5访问者模式结构适合应用场景">5.访问者模式结构适合应用场景</h2>
<ol>
<li>
<p>如果你需要对一个复杂对象结构 （例如对象树） 中的所有元素执行某些操作， 可使用访问者模式。<br>
访问者模式通过在访问者对象中为多个目标类提供相同操作的变体， 让你能在属于不同类的一组对象上执行同一操作。</p>
</li>
<li>
<p>可使用访问者模式来清理辅助行为的业务逻辑。<br>
该模式会将所有非主要的行为抽取到一组访问者类中， 使得程序的主要类能更专注于主要的工作。</p>
</li>
<li>
<p>当某个行为仅在类层次结构中的一些类中有意义， 而在其他类中没有意义时， 可使用该模式。<br>
你可将该行为抽取到单独的访问者类中， 只需实现接收相关类的对象作为参数的访问者方法并将其他方法留空即可。</p>
</li>
</ol>
<h2 id="6实现方式">6.实现方式</h2>
<ol>
<li>
<p>在访问者接口中声明一组 “访问” 方法， 分别对应程序中的每个具体元素类。</p>
</li>
<li>
<p>声明元素接口。 如果程序中已有元素类层次接口， 可在层次结构基类中添加抽象的 “接收” 方法。 该方法必须接受访问者对象作为参数。</p>
</li>
<li>
<p>在所有具体元素类中实现接收方法。 这些方法必须将调用重定向到当前元素对应的访问者对象中的访问者方法上。</p>
</li>
<li>
<p>元素类只能通过访问者接口与访问者进行交互。 不过访问者必须知晓所有的具体元素类， 因为这些类在访问者方法中都被作为参数类型引用。</p>
</li>
<li>
<p>为每个无法在元素层次结构中实现的行为创建一个具体访问者类并实现所有的访问者方法。<br>
你可能会遇到访问者需要访问元素类的部分私有成员变量的情况。 在这种情况下， 你要么将这些变量或方法设为公有， 这将破坏元素的封装； 要么将访问者类嵌入到元素类中。</p>
</li>
<li>
<p>客户端必须创建访问者对象并通过 “接收” 方法将其传递给元素。</p>
</li>
</ol>
<h2 id="7访问者模式结构优缺点">7.访问者模式结构优缺点</h2>
<table>
<thead>
<tr>
<th>优点</th>
<th style="text-align:center">缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>开闭原则。 你可以引入在不同类对象上执行的新行为， 且无需对这些类做出修改。</td>
<td style="text-align:center">每次在元素层次结构中添加或移除一个类时， 你都要更新所有的访问者。</td>
</tr>
<tr>
<td>单一职责原则。 可将同一行为的不同版本移到同一个类中。</td>
<td style="text-align:center">在访问者同某个元素进行交互时， 它们可能没有访问元素私有成员变量和方法的必要权限。</td>
</tr>
<tr>
<td>访问者对象可以在与各种对象交互时收集一些有用的信息。 当你想要遍历一些复杂的对象结构 （例如对象树）， 并在结构中的每个对象上应用访问者时， 这些信息可能会有所帮助。</td>
<td style="text-align:center">-</td>
</tr>
</tbody>
</table>
<h2 id="8与其他模式的关系">8.与其他模式的关系</h2>
<ol>
<li>
<p>你可以将访问者模式视为命令模式的加强版本， 其对象可对不同类的多种对象执行操作。</p>
</li>
<li>
<p>你可以使用访问者对整个组合模式树执行操作。</p>
</li>
<li>
<p>可以同时使用访问者和迭代器模式来遍历复杂数据结构， 并对其中的元素执行所需操作， 即使这些元素所属的类完全不同。</p>
</li>
</ol>
<h2 id="9伪代码">9.伪代码</h2>
<p>在本例中， 我们希望将一系列几何形状导出为 XML 文件。 重点在于我们不希望直接修改形状代码， 或者至少能确保最小程度的修改。</p>
<p>最终， 访问者模式建立了一个框架， 允许我们在不修改已有类的情况下向形状层次结构中添加新的行为。</p>
<blockquote>
<p>Shape-通用形状接口</p>
</blockquote>
<pre><code class="language-java">package com.visitor;

/**
 * 通用形状接口
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 15:19
 */
public interface Shape {
    void move(int x, int y);

    void draw();
    
    String accept(Visitor visitor);
}
</code></pre>
<blockquote>
<p>Dot 点</p>
</blockquote>
<pre><code class="language-java">package com.visitor;

/**
 * 点
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 15:23
 */
public class Dot implements Shape {
    private int id;
    private int x;
    private int y;

    public Dot() {
    }

    public Dot(int id, int x, int y) {
        this.id = id;
        this.x = x;
        this.y = y;
    }

    @Override
    public void move(int x, int y) {
        // move shape
    }

    @Override
    public void draw() {
        // draw shape
    }

    @Override
    public String accept(Visitor visitor) {
        return visitor.visitDot(this);
    }

    public int getX() {
        return x;
    }

    public int getY() {
        return y;
    }

    public int getId() {
        return id;
    }
}
</code></pre>
<blockquote>
<p>Circle 圆形</p>
</blockquote>
<pre><code class="language-java">package com.visitor;

/**
 * 圆
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 15:24
 */
public class Circle extends Dot {
    private int radius;

    public Circle(int id, int x, int y, int radius) {
        super(id, x, y);
        this.radius = radius;
    }

    @Override
    public String accept(Visitor visitor) {
        return visitor.visitCircle(this);
    }

    public int getRadius() {
        return radius;
    }
}
</code></pre>
<blockquote>
<p>Rectangle 矩形</p>
</blockquote>
<pre><code class="language-java">package com.visitor;

/**
 * 矩形
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 15:25
 */
public class Rectangle implements Shape {
    private int id;
    private int x;
    private int y;
    private int width;
    private int height;

    public Rectangle(int id, int x, int y, int width, int height) {
        this.id = id;
        this.x = x;
        this.y = y;
        this.width = width;
        this.height = height;
    }

    @Override
    public String accept(Visitor visitor) {
        return visitor.visitRectangle(this);
    }

    @Override
    public void move(int x, int y) {
        // move shape
    }

    @Override
    public void draw() {
        // draw shape
    }

    public int getId() {
        return id;
    }

    public int getX() {
        return x;
    }

    public int getY() {
        return y;
    }

    public int getWidth() {
        return width;
    }

    public int getHeight() {
        return height;
    }
}
</code></pre>
<blockquote>
<p>CompoundShape 组合形状</p>
</blockquote>
<pre><code class="language-java">package com.visitor;

import java.util.ArrayList;
import java.util.List;

/**
 * 组合形状
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 15:26
 */
public class CompoundShape implements Shape {
    public int id;
    public List&lt;Shape&gt; children = new ArrayList&lt;&gt;();

    public CompoundShape(int id) {
        this.id = id;
    }

    @Override
    public void move(int x, int y) {
        // move shape
    }

    @Override
    public void draw() {
        // draw shape
    }

    public int getId() {
        return id;
    }

    @Override
    public String accept(Visitor visitor) {
        return visitor.visitCompoundGraphic(this);
    }

    public void add(Shape shape) {
        children.add(shape);
    }
}
</code></pre>
<blockquote>
<p>Visitor 通用访问者接口</p>
</blockquote>
<pre><code class="language-java">package com.visitor;

/**
 * 通用访问者接口
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 15:20
 */
public interface Visitor {
    String visitDot(Dot dot);

    String visitCircle(Circle circle);

    String visitRectangle(Rectangle rectangle);

    String visitCompoundGraphic(CompoundShape cg);
}
</code></pre>
<blockquote>
<p>XMLExportVisitor 具体访问者</p>
</blockquote>
<pre><code class="language-java">package com.visitor;

/**
 * 具体访问者
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 15:28
 */
public class XMLExportVisitor implements Visitor {

    public String export(Shape... args) {
        StringBuilder sb = new StringBuilder();
        sb.append(&quot;&lt;?xml version=\&quot;1.0\&quot; encoding=\&quot;utf-8\&quot;?&gt;&quot; + &quot;\n&quot;);
        for (Shape shape : args) {
            sb.append(shape.accept(this)).append(&quot;\n&quot;);
        }
        return sb.toString();
    }

    public String visitDot(Dot d) {
        return &quot;&lt;dot&gt;&quot; + &quot;\n&quot; +
                &quot;    &lt;id&gt;&quot; + d.getId() + &quot;&lt;/id&gt;&quot; + &quot;\n&quot; +
                &quot;    &lt;x&gt;&quot; + d.getX() + &quot;&lt;/x&gt;&quot; + &quot;\n&quot; +
                &quot;    &lt;y&gt;&quot; + d.getY() + &quot;&lt;/y&gt;&quot; + &quot;\n&quot; +
                &quot;&lt;/dot&gt;&quot;;
    }

    public String visitCircle(Circle c) {
        return &quot;&lt;circle&gt;&quot; + &quot;\n&quot; +
                &quot;    &lt;id&gt;&quot; + c.getId() + &quot;&lt;/id&gt;&quot; + &quot;\n&quot; +
                &quot;    &lt;x&gt;&quot; + c.getX() + &quot;&lt;/x&gt;&quot; + &quot;\n&quot; +
                &quot;    &lt;y&gt;&quot; + c.getY() + &quot;&lt;/y&gt;&quot; + &quot;\n&quot; +
                &quot;    &lt;radius&gt;&quot; + c.getRadius() + &quot;&lt;/radius&gt;&quot; + &quot;\n&quot; +
                &quot;&lt;/circle&gt;&quot;;
    }

    public String visitRectangle(Rectangle r) {
        return &quot;&lt;rectangle&gt;&quot; + &quot;\n&quot; +
                &quot;    &lt;id&gt;&quot; + r.getId() + &quot;&lt;/id&gt;&quot; + &quot;\n&quot; +
                &quot;    &lt;x&gt;&quot; + r.getX() + &quot;&lt;/x&gt;&quot; + &quot;\n&quot; +
                &quot;    &lt;y&gt;&quot; + r.getY() + &quot;&lt;/y&gt;&quot; + &quot;\n&quot; +
                &quot;    &lt;width&gt;&quot; + r.getWidth() + &quot;&lt;/width&gt;&quot; + &quot;\n&quot; +
                &quot;    &lt;height&gt;&quot; + r.getHeight() + &quot;&lt;/height&gt;&quot; + &quot;\n&quot; +
                &quot;&lt;/rectangle&gt;&quot;;
    }

    public String visitCompoundGraphic(CompoundShape cg) {
        return &quot;&lt;compound_graphic&gt;&quot; + &quot;\n&quot; +
                &quot;   &lt;id&gt;&quot; + cg.getId() + &quot;&lt;/id&gt;&quot; + &quot;\n&quot; +
                _visitCompoundGraphic(cg) +
                &quot;&lt;/compound_graphic&gt;&quot;;
    }

    private String _visitCompoundGraphic(CompoundShape cg) {
        StringBuilder sb = new StringBuilder();
        for (Shape shape : cg.children) {
            String obj = shape.accept(this);
            // Proper indentation for sub-objects.
            obj = &quot;    &quot; + obj.replace(&quot;\n&quot;, &quot;\n    &quot;) + &quot;\n&quot;;
            sb.append(obj);
        }
        return sb.toString();
    }
}
</code></pre>
<blockquote>
<p>Main</p>
</blockquote>
<pre><code class="language-java">package com.visitor;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 15:29
 */
public class Demo {
    public static void main(String[] args) {
        Dot dot = new Dot(1, 10, 55);
        Circle circle = new Circle(2, 23, 15, 10);
        Rectangle rectangle = new Rectangle(3, 10, 17, 20, 30);

        CompoundShape compoundShape = new CompoundShape(4);
        compoundShape.add(dot);
        compoundShape.add(circle);
        compoundShape.add(rectangle);

        CompoundShape c = new CompoundShape(5);
        c.add(dot);
        compoundShape.add(c);

        export(circle, compoundShape);
    }

    private static void export(Shape... shapes) {
        XMLExportVisitor exportVisitor = new XMLExportVisitor();
        System.out.println(exportVisitor.export(shapes));
    }
}
</code></pre>
<blockquote>
<p>运行结果</p>
</blockquote>
<pre><code class="language-java">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;circle&gt;
    &lt;id&gt;2&lt;/id&gt;
    &lt;x&gt;23&lt;/x&gt;
    &lt;y&gt;15&lt;/y&gt;
    &lt;radius&gt;10&lt;/radius&gt;
&lt;/circle&gt;
&lt;compound_graphic&gt;
   &lt;id&gt;4&lt;/id&gt;
    &lt;dot&gt;
        &lt;id&gt;1&lt;/id&gt;
        &lt;x&gt;10&lt;/x&gt;
        &lt;y&gt;55&lt;/y&gt;
    &lt;/dot&gt;
    &lt;circle&gt;
        &lt;id&gt;2&lt;/id&gt;
        &lt;x&gt;23&lt;/x&gt;
        &lt;y&gt;15&lt;/y&gt;
        &lt;radius&gt;10&lt;/radius&gt;
    &lt;/circle&gt;
    &lt;rectangle&gt;
        &lt;id&gt;3&lt;/id&gt;
        &lt;x&gt;10&lt;/x&gt;
        &lt;y&gt;17&lt;/y&gt;
        &lt;width&gt;20&lt;/width&gt;
        &lt;height&gt;30&lt;/height&gt;
    &lt;/rectangle&gt;
    &lt;compound_graphic&gt;
       &lt;id&gt;5&lt;/id&gt;
        &lt;dot&gt;
            &lt;id&gt;1&lt;/id&gt;
            &lt;x&gt;10&lt;/x&gt;
            &lt;y&gt;55&lt;/y&gt;
        &lt;/dot&gt;
    &lt;/compound_graphic&gt;
&lt;/compound_graphic&gt;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[模板方法模式]]></title>
        <id>https://q456qq520.github.io/post/mo-ban-fang-fa-mo-shi/</id>
        <link href="https://q456qq520.github.io/post/mo-ban-fang-fa-mo-shi/">
        </link>
        <updated>2022-10-10T08:57:19.000Z</updated>
        <summary type="html"><![CDATA[<p>模板方法模式是一种行为设计模式， 它在超类中定义了一个算法的框架， 允许子类在不修改结构的情况下重写算法的特定步骤。</p>
]]></summary>
        <content type="html"><![CDATA[<p>模板方法模式是一种行为设计模式， 它在超类中定义了一个算法的框架， 允许子类在不修改结构的情况下重写算法的特定步骤。</p>
<!-- more -->
<h2 id="1问题">1.问题</h2>
<p>假如你正在开发一款分析公司文档的数据挖掘程序。 用户需要向程序输入各种格式 （PDF、 DOC 或 CSV） 的文档， 程序则会试图从这些文件中抽取有意义的数据，并以统一的格式将其返回给用户。</p>
<p>该程序的首个版本仅支持 DOC 文件。 在接下来的一个版本中，程序能够支持 CSV 文件。一个月后，你 “教会” 了程序从PDF文件中抽取数据。</p>
<p>一段时间后， 你发现这三个类中包含许多相似代码。 尽管这些类处理不同数据格式的代码完全不同， 但数据处理和分析的代码却几乎完全一样。 如果能在保持算法结构完整的情况下去除重复代码， 这难道不是一件很棒的事情吗？</p>
<p>还有另一个与使用这些类的客户端代码相关的问题： 客户端代码中包含许多条件语句， 以根据不同的处理对象类型选择合适的处理过程。 如果所有处理数据的类都拥有相同的接口或基类， 那么你就可以去除客户端代码中的条件语句， 转而使用多态机制来在处理对象上调用函数。</p>
<h2 id="2解决方案">2.解决方案</h2>
<p>模板方法模式建议将算法分解为一系列步骤， 然后将这些步骤改写为方法， 最后在 “模板方法” 中依次调用这些方法。 步骤可以是 抽象的， 也可以有一些默认的实现。 为了能够使用算法， 客户端需要自行提供子类并实现所有的抽象步骤。 如有必要还需重写一些步骤 （但这一步中不包括模板方法自身）。</p>
<p>让我们考虑如何在数据挖掘应用中实现上述方案。 我们可为图中的三个解析算法创建一个基类， 该类将定义调用了一系列不同文档处理步骤的模板方法。</p>
<figure data-type="image" tabindex="1"><img src="https://refactoringguru.cn/images/patterns/diagrams/template-method/solution-zh-2x.png" alt="模板方法将算法分解为步骤" loading="lazy"></figure>
<p>模板方法将算法分解为步骤， 并允许子类重写这些步骤， 而非重写实际的模板方法。</p>
<p>首先， 我们将所有步骤声明为 抽象类型， 强制要求子类自行实现这些方法。 在我们的例子中， 子类中已有所有必要的实现， 因此我们只需调整这些方法的签名， 使之与超类的方法匹配即可。</p>
<p>现在， 让我们看看如何去除重复代码。 对于不同的数据格式， 打开和关闭文件以及抽取和解析数据的代码都不同， 因此无需修改这些方法。 但分析原始数据和生成报告等其他步骤的实现方式非常相似， 因此可将其提取到基类中， 以让子类共享这些代码。</p>
<p>正如你所看到的那样， 我们有两种类型的步骤：</p>
<ul>
<li>抽象步骤必须由各个子类来实现</li>
<li>可选步骤已有一些默认实现， 但仍可在需要时进行重写</li>
</ul>
<p>还有另一种名为钩子的步骤。 钩子是内容为空的可选步骤。 即使不重写钩子， 模板方法也能工作。 钩子通常放置在算法重要步骤的前后， 为子类提供额外的算法扩展点。</p>
<h2 id="3真实世界类比">3.真实世界类比</h2>
<p>模板方法可用于建造大量房屋。 标准房屋建造方案中可提供几个扩展点， 允许潜在房屋业主调整成品房屋的部分细节。</p>
<p>每个建造步骤 （例如打地基、 建造框架、 建造墙壁和安装水电管线等） 都能进行微调， 这使得成品房屋会略有不同。</p>
<h2 id="4模板方法模式结构">4.模板方法模式结构</h2>
<figure data-type="image" tabindex="2"><img src="https://refactoringguru.cn/images/patterns/diagrams/template-method/structure-2x.png" alt="模板方法模式结构" loading="lazy"></figure>
<ol>
<li>
<p>抽象类 （Abstract­Class） 会声明作为算法步骤的方法， 以及依次调用它们的实际模板方法。 算法步骤可以被声明为 抽象类型， 也可以提供一些默认实现。</p>
</li>
<li>
<p>具体类 （Con­crete­Class） 可以重写所有步骤， 但不能重写模板方法自身。</p>
</li>
</ol>
<h2 id="5模板方法模式适合应用场景">5.模板方法模式适合应用场景</h2>
<ol>
<li>
<p>当你只希望客户端扩展某个特定算法步骤， 而不是整个算法或其结构时， 可使用模板方法模式。<br>
模板方法将整个算法转换为一系列独立的步骤， 以便子类能对其进行扩展， 同时还可让超类中所定义的结构保持完整。</p>
</li>
<li>
<p>当多个类的算法除一些细微不同之外几乎完全一样时， 你可使用该模式。 但其后果就是， 只要算法发生变化， 你就可能需要修改所有的类。<br>
在将算法转换为模板方法时， 你可将相似的实现步骤提取到超类中以去除重复代码。 子类间各不同的代码可继续保留在子类中。</p>
</li>
</ol>
<h2 id="6实现方式">6.实现方式</h2>
<ol>
<li>
<p>分析目标算法， 确定能否将其分解为多个步骤。 从所有子类的角度出发， 考虑哪些步骤能够通用， 哪些步骤各不相同。</p>
</li>
<li>
<p>创建抽象基类并声明一个模板方法和代表算法步骤的一系列抽象方法。 在模板方法中根据算法结构依次调用相应步骤。 可用 final最终修饰模板方法以防止子类对其进行重写。</p>
</li>
<li>
<p>虽然可将所有步骤全都设为抽象类型， 但默认实现可能会给部分步骤带来好处， 因为子类无需实现那些方法。</p>
</li>
<li>
<p>可考虑在算法的关键步骤之间添加钩子。</p>
</li>
<li>
<p>为每个算法变体新建一个具体子类， 它必须实现所有的抽象步骤， 也可以重写部分可选步骤。</p>
</li>
</ol>
<h2 id="7模板方法模式优缺点">7.模板方法模式优缺点</h2>
<table>
<thead>
<tr>
<th>优点</th>
<th style="text-align:center">缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>你可仅允许客户端重写一个大型算法中的特定部分， 使得算法其他部分修改对其所造成的影响减小。</td>
<td style="text-align:center">部分客户端可能会受到算法框架的限制。</td>
</tr>
<tr>
<td>你可将重复代码提取到一个超类中。</td>
<td style="text-align:center">通过子类抑制默认步骤实现可能会导致违反里氏替换原则。</td>
</tr>
<tr>
<td>-</td>
<td style="text-align:center">模板方法中的步骤越多， 其维护工作就可能会越困难。</td>
</tr>
</tbody>
</table>
<h2 id="8与其他模式的关系">8.与其他模式的关系</h2>
<ol>
<li>
<p>工厂方法模式是模板方法模式的一种特殊形式。 同时， 工厂方法可以作为一个大型模板方法中的一个步骤。</p>
</li>
<li>
<p>模板方法基于继承机制： 它允许你通过扩展子类中的部分内容来改变部分算法。 策略模式基于组合机制： 你可以通过对相应行为提供不同的策略来改变对象的部分行为。 模板方法在类层次上运作， 因此它是静态的。 策略在对象层次上运作， 因此允许在运行时切换行为。</p>
</li>
</ol>
<h2 id="9伪代码">9.伪代码</h2>
<p>在本例中， 模版方法模式定义了一个可与社交网络协作的算法。 与特定社交网络相匹配的子类将根据社交网络所提供的 API 来实现这些步骤。</p>
<blockquote>
<p>networks-基础社交网络类</p>
</blockquote>
<pre><code class="language-java">package com.templateMethod;

/**
 * 基础社交网络类
 * @author likecat
 * @version 1.0
 * @date 2022/10/10 17:29
 */
public abstract class Network {
    String userName;
    String password;

    Network() {}

    /**
     * 数据发布
     */
    public boolean post(String message) {
        if (logIn(this.userName, this.password)) {
            // Send the post data.
            boolean result =  sendData(message.getBytes());
            logOut();
            return result;
        }
        return false;
    }

    //登陆
    abstract boolean logIn(String userName, String password);
    
    //发数据
    abstract boolean sendData(byte[] data);
    
    //登出
    abstract void logOut();
}
</code></pre>
<blockquote>
<p>Facebook-具体社交网络</p>
</blockquote>
<pre><code class="language-java">package com.templateMethod;

/**
 * 具体社交网络
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 10:57
 */
public class Facebook extends Network {
    public Facebook(String userName, String password) {
        this.userName = userName;
        this.password = password;
    }

    public boolean logIn(String userName, String password) {
        System.out.println(&quot;\nChecking user's parameters&quot;);
        System.out.println(&quot;Name: &quot; + this.userName);
        System.out.print(&quot;Password: &quot;);
        for (int i = 0; i &lt; this.password.length(); i++) {
            System.out.print(&quot;*&quot;);
        }
        //模拟延迟
        simulateNetworkLatency();
        System.out.println(&quot;\n\nLogIn success on Facebook&quot;);
        return true;
    }

    public boolean sendData(byte[] data) {
        boolean messagePosted = true;
        if (messagePosted) {
            System.out.println(&quot;Message: '&quot; + new String(data) + &quot;' was posted on Facebook&quot;);
            return true;
        } else {
            return false;
        }
    }

    public void logOut() {
        System.out.println(&quot;User: '&quot; + userName + &quot;' was logged out from Facebook&quot;);
    }

    private void simulateNetworkLatency() {
        try {
            int i = 0;
            System.out.println();
            while (i &lt; 10) {
                System.out.print(&quot;.&quot;);
                Thread.sleep(500);
                i++;
            }
        } catch (InterruptedException ex) {
            ex.printStackTrace();
        }
    }
}
</code></pre>
<blockquote>
<p>Twitter</p>
</blockquote>
<pre><code class="language-java">package com.templateMethod;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 11:01
 */
public class Twitter extends Network {

    public Twitter(String userName, String password) {
        this.userName = userName;
        this.password = password;
    }

    public boolean logIn(String userName, String password) {
        System.out.println(&quot;\nChecking user's parameters&quot;);
        System.out.println(&quot;Name: &quot; + this.userName);
        System.out.print(&quot;Password: &quot;);
        for (int i = 0; i &lt; this.password.length(); i++) {
            System.out.print(&quot;*&quot;);
        }
        simulateNetworkLatency();
        System.out.println(&quot;\n\nLogIn success on Twitter&quot;);
        return true;
    }

    public boolean sendData(byte[] data) {
        boolean messagePosted = true;
        if (messagePosted) {
            System.out.println(&quot;Message: '&quot; + new String(data) + &quot;' was posted on Twitter&quot;);
            return true;
        } else {
            return false;
        }
    }

    public void logOut() {
        System.out.println(&quot;User: '&quot; + userName + &quot;' was logged out from Twitter&quot;);
    }

    private void simulateNetworkLatency() {
        try {
            int i = 0;
            System.out.println();
            while (i &lt; 10) {
                System.out.print(&quot;.&quot;);
                Thread.sleep(500);
                i++;
            }
        } catch (InterruptedException ex) {
            ex.printStackTrace();
        }
    }
}
</code></pre>
<blockquote>
<p>Main</p>
</blockquote>
<pre><code class="language-java">package com.templateMethod;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/10/11 11:01
 */
public class Demo {
    public static void main(String[] args) throws IOException {
        BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));
        Network network = null;
        System.out.print(&quot;Input user name: &quot;);
        String userName = reader.readLine();
        System.out.print(&quot;Input password: &quot;);
        String password = reader.readLine();

        // Enter the message.
        System.out.print(&quot;Input message: &quot;);
        String message = reader.readLine();

        System.out.println(&quot;\nChoose social network for posting message.\n&quot; +
                &quot;1 - Facebook\n&quot; +
                &quot;2 - Twitter&quot;);
        int choice = Integer.parseInt(reader.readLine());

        // Create proper network object and send the message.
        if (choice == 1) {
            network = new Facebook(userName, password);
        } else if (choice == 2) {
            network = new Twitter(userName, password);
        }
        network.post(message);
    }
}
</code></pre>
<blockquote>
<p>运行结果</p>
</blockquote>
<pre><code class="language-java">Input user name: likecat
Input password: 123456
Input message: you pro?

Choose social network for posting message.
1 - Facebook
2 - Twitter
1

Checking user's parameters
Name: likecat
Password: ******
..........

LogIn success on Facebook
Message: 'you pro?' was posted on Facebook
User: 'likecat' was logged out from Facebook
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux 基础命令]]></title>
        <id>https://q456qq520.github.io/post/linux-ji-chu-ming-ling/</id>
        <link href="https://q456qq520.github.io/post/linux-ji-chu-ming-ling/">
        </link>
        <updated>2022-09-19T09:19:08.000Z</updated>
        <content type="html"><![CDATA[<h1 id="查询">查询</h1>
<ol>
<li>
<p>查看端口占用<br>
netstat -anp |grep 22</p>
</li>
<li>
<p>查看进程占用的端口<br>
netstat -anp |grep ssh</p>
</li>
</ol>
<h1 id="http请求">http请求</h1>
<ol>
<li>curl-post<br>
curl -H &quot;Content-Type: application/json&quot; -X POST -d '' http://xxx</li>
</ol>
<h1 id="mysql">mysql</h1>
<ol>
<li>
<p>连接<br>
mysql -uroot -p</p>
</li>
<li>
<p>查看表结构<br>
desc table<br>
describe table<br>
show columns from tbale</p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMq技术内幕笔记（三）]]></title>
        <id>https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-san/</id>
        <link href="https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-san/">
        </link>
        <updated>2022-09-15T03:54:22.000Z</updated>
        <summary type="html"><![CDATA[<h1 id="4-消息存储">4 消息存储</h1>
<h2 id="41-存储概要设计">4.1 存储概要设计</h2>
<p>RocketMQ主要存储的文件包括Comitlog文件、ConsumeQueue文件、IndexFile文<br>
件。</p>
]]></summary>
        <content type="html"><![CDATA[<h1 id="4-消息存储">4 消息存储</h1>
<h2 id="41-存储概要设计">4.1 存储概要设计</h2>
<p>RocketMQ主要存储的文件包括Comitlog文件、ConsumeQueue文件、IndexFile文<br>
件。</p>
<!-- more -->
<p>RocketMQ将所有主题的消息存储在同一个文件中，确保消息发送时顺序写文件。为了提高消息消费的效率， RocketMQ 引入了 ConsumeQueue 消息队列 文件，每个消息主题包含多个消息消费队列，每一个消息队列有一个消息文件 - IndexFile索引文件，其主要设计理念就是为了加速消息的检索性能，根据消息的属性快速从 Commitlog 文件中检索消息。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1663233972923.png" alt="RocketMQ 消息存储设计原理图" loading="lazy"></figure>
<p>1 ) CommitLog:消息存储文件，所有消息主题的消息都存储在 CommitLog 文件中 。<br>
2 ) ConsumeQueue :消息消费队列，消息到达CommitLog文件后，将异步转发到消息消费队列，供消息消费者消费 。<br>
3 ) IndexFile:消息索引文件，主要存储消息 Key 与 Offset 的对应关系 。<br>
4 )事务状态服务 : 存储每条消息的事务状态 。<br>
5 )定时消息服务:每一个延迟级别对应一个消息消费队列，存储延迟队列的消息拉取<br>
进度。</p>
<h2 id="42-初识消息存储">4.2 初识消息存储</h2>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1663311285978.png" alt="CommitLog" loading="lazy"></figure>
<ol>
<li>CommitLog 主要由几部分组成：</li>
</ol>
<p>MappedFileQueue： 主要用来操作相关数据存储文件。将一系列的MappedFile抽象成一个队列。<br>
FlushManager： 数据落地磁盘的管理，主要分为两类：实时数据刷盘(FlushRealTimeService),以及异步刷盘(GroupCommitService)<br>
FlushDiskWatcher： 刷盘观察者，处理队列中的刷盘请求，对于规定时间内没有刷盘成功的进行处理。</p>
<ol start="2">
<li>MappedFileQueue</li>
</ol>
<p>MappedFileQueue 是对数据存储文件的一个抽象，将多个数据文件抽象成为一个文件队列。通过这个文件队列对文件进行操作操作。同时保存一些 CommitLog 的属性。</p>
<ol start="3">
<li>MappedFile<br>
MappedFile 是对文件的抽象，包含了对RocketMQ数据文件的整个操作。例如获取文件名称、文件大小、判断文件是否可用、是否已经满了等等的操作。</li>
</ol>
<p>单个数据文件默认是 1G 。由于只用了一个字节保存Topic的长度所以Topic的最大长度是127字符。</p>
<p>消息存储实现类: org.apache.rocketmq.store.DefaultMessageStore。</p>
<blockquote>
<p>DefaultMessageStore的核心属性</p>
</blockquote>
<pre><code class="language-java">//消息存储配置属性
private final MessageStoreConfig messageStoreConfig;
//CommitLog 文件的存储实现类
private final CommitLog commitLog;
//消息队列存储
private final ConsumeQueueStore consumeQueueStore;
//消息队列文件 ConsumeQueue刷盘线程。
private final FlushConsumeQueueService flushConsumeQueueService;
//清除 CommitLog 文件服务
private final CleanCommitLogService cleanCommitLogService;
//清除 ConsumeQueue 文件服务
private final CleanConsumeQueueService cleanConsumeQueueService;

private final CorrectLogicOffsetService correctLogicOffsetService;

//索引文件实现类
private final IndexService indexService;
//MappedFile 分配服务
private final AllocateMappedFileService allocateMappedFileService;
//CommitLog消息分发，根据 CommitLog文件构建 ConsumeQueue、 IndexFile 文件 。
private ReputMessageService reputMessageService;
//存储 HA 机制
private HAService haService;
//消息堆内存缓存
private final StoreStatsService storeStatsService;
private final TransientStorePool transientStorePool;

private final RunningFlags runningFlags = new RunningFlags();
private final SystemClock systemClock = new SystemClock();

private final ScheduledExecutorService scheduledExecutorService;
private final BrokerStatsManager brokerStatsManager;
//消息拉取长轮询模式消息达到监听器
private final MessageArrivingListener messageArrivingListener;
//Broker配置属性
private final BrokerConfig brokerConfig;

private volatile boolean shutdown = true;
//文件刷盘检测点
private StoreCheckpoint storeCheckpoint;
private TimerMessageStore timerMessageStore;

private AtomicLong printTimes = new AtomicLong(0);
//CommitLog 文件转发请求
private final LinkedList&lt;CommitLogDispatcher&gt; dispatcherList;
</code></pre>
<h2 id="43-消息发送存储流程">4.3 消息发送存储流程</h2>
<p><img src="https://q456qq520.github.io/post-images/1663315678088.png" alt="消息存储时序图" loading="lazy"><br>
消息存储入口: org.apache.rocketmq.store.DefaultMessageStore#putMessage。</p>
<p><strong>Step 1</strong>:如果当前Broker停止工作或 Broker为SLAVE角色或当前Rocket不支持写入则拒绝消息写入;如果消息主题长度超过256个字符、消息属性长度超过65536个字符将拒绝该消息写人。</p>
<p><strong>Step 2</strong>:如果消息的延迟级别大于0，将消息的原主题名称与原消息队列 ID 存入消息属性中，用延迟消息主题SCHEDULE_TOPIC、消息队列 ID 更新原先消息的主题与队列。</p>
<p><strong>Step 3</strong>:获取当前可以写入的 Commitlog文件</p>
<pre><code class="language-java">MappedFile unlockMappedFile = null;
MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile();
</code></pre>
<p>Commitlog文件存储目录为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi>R</mi><mi>O</mi><mi>C</mi><mi>K</mi><mi>E</mi><msub><mi>T</mi><mi>H</mi></msub><mi>O</mi><mi>M</mi><mi>E</mi></mrow><mi mathvariant="normal">/</mi><mi>s</mi><mi>t</mi><mi>o</mi><mi>r</mi><mi>e</mi><mi mathvariant="normal">/</mi><mi>c</mi><mi>o</mi><mi>m</mi><mi>m</mi><mi>i</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi mathvariant="normal">目</mi><mi mathvariant="normal">录</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">每</mi><mi mathvariant="normal">一</mi><mi mathvariant="normal">个</mi><mi mathvariant="normal">文</mi><mi mathvariant="normal">件</mi><mi mathvariant="normal">默</mi><mi mathvariant="normal">认</mi><mn>1</mn><mi>G</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">一</mi><mi mathvariant="normal">个</mi><mi mathvariant="normal">文</mi><mi mathvariant="normal">件</mi><mi mathvariant="normal">写</mi><mi mathvariant="normal">满</mi><mi mathvariant="normal">后</mi><mi mathvariant="normal">再</mi><mi mathvariant="normal">创</mi><mi mathvariant="normal">建</mi><mi mathvariant="normal">另</mi><mi mathvariant="normal">外</mi><mi mathvariant="normal">一</mi><mi mathvariant="normal">个</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">以</mi><mi mathvariant="normal">该</mi><mi mathvariant="normal">文</mi><mi mathvariant="normal">件</mi><mi mathvariant="normal">中</mi><mi mathvariant="normal">第</mi><mi mathvariant="normal">一</mi><mi mathvariant="normal">个</mi><mi mathvariant="normal">偏</mi><mi mathvariant="normal">移</mi><mi mathvariant="normal">量</mi><mi mathvariant="normal">为</mi><mi mathvariant="normal">文</mi><mi mathvariant="normal">件</mi><mi mathvariant="normal">名</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">偏</mi><mi mathvariant="normal">移</mi><mi mathvariant="normal">量</mi><mi mathvariant="normal">小</mi><mi mathvariant="normal">于</mi><mn>20</mn><mi mathvariant="normal">位</mi><mi mathvariant="normal">用</mi><mn>0</mn><mi mathvariant="normal">补</mi><mi mathvariant="normal">齐</mi><mi mathvariant="normal">。</mi><mi>M</mi><mi>a</mi><mi>p</mi><mi>p</mi><mi>e</mi><mi>d</mi><mi>F</mi><mi>i</mi><mi>l</mi><mi>e</mi><mi>Q</mi><mi>u</mi><mi>e</mi><mi>u</mi><mi>e</mi><mi mathvariant="normal">可</mi><mi mathvariant="normal">以</mi><mi mathvariant="normal">看</mi><mi mathvariant="normal">作</mi><mi mathvariant="normal">是</mi></mrow><annotation encoding="application/x-tex">{ROCKET_HOME}/store/commitlog 目录，每一个文件默认1G，一个文件写满后再创建另外一个，以该文件中第一个偏移量为文件名，偏移量小于20位用0补齐。MappedFileQueue 可以看作是</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.08125em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span><span class="mord">/</span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord">/</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">m</span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord cjk_fallback">目</span><span class="mord cjk_fallback">录</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">每</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">件</span><span class="mord cjk_fallback">默</span><span class="mord cjk_fallback">认</span><span class="mord">1</span><span class="mord mathdefault">G</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">件</span><span class="mord cjk_fallback">写</span><span class="mord cjk_fallback">满</span><span class="mord cjk_fallback">后</span><span class="mord cjk_fallback">再</span><span class="mord cjk_fallback">创</span><span class="mord cjk_fallback">建</span><span class="mord cjk_fallback">另</span><span class="mord cjk_fallback">外</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">以</span><span class="mord cjk_fallback">该</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">件</span><span class="mord cjk_fallback">中</span><span class="mord cjk_fallback">第</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">偏</span><span class="mord cjk_fallback">移</span><span class="mord cjk_fallback">量</span><span class="mord cjk_fallback">为</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">件</span><span class="mord cjk_fallback">名</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">偏</span><span class="mord cjk_fallback">移</span><span class="mord cjk_fallback">量</span><span class="mord cjk_fallback">小</span><span class="mord cjk_fallback">于</span><span class="mord">2</span><span class="mord">0</span><span class="mord cjk_fallback">位</span><span class="mord cjk_fallback">用</span><span class="mord">0</span><span class="mord cjk_fallback">补</span><span class="mord cjk_fallback">齐</span><span class="mord cjk_fallback">。</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault">a</span><span class="mord mathdefault">p</span><span class="mord mathdefault">p</span><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">e</span><span class="mord mathdefault">Q</span><span class="mord mathdefault">u</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault">e</span><span class="mord cjk_fallback">可</span><span class="mord cjk_fallback">以</span><span class="mord cjk_fallback">看</span><span class="mord cjk_fallback">作</span><span class="mord cjk_fallback">是</span></span></span></span>  {ROCKET_HOME}/store/commitlog文件夹，而MappedFile则对应该文件夹下一个个的文件。</p>
<p><strong>Step 4</strong>:在写入Commitlog之前，先申请putMessageLock,也就是将消息存储到Commitlog文件中是串行的 。</p>
<pre><code class="language-java">putMessageLock.lock(); //spin or ReentrantLock ,depending on store config
</code></pre>
<p>**Step 5 **:设置消息的存储时间，如果mappedFile为空，表明$  {ROCKET_HOME}/store/Commitlog目录下不存在任何文件，说明本次消息是第一次消息发送，用偏移量0创建第一个commit文件，文件为 00000000000000000000，如果文件创建失败，抛出 CREATE MAPEDFILE FAILED，很有可能是磁盘空间不足或权限不够。</p>
<pre><code class="language-java">if (null == mappedFile || mappedFile.isFull()) {
    mappedFile = this.mappedFileQueue.getLastMappedFile(0); // Mark: NewFile may be cause noise
}
if (null == mappedFile) {
    log.error(&quot;create mapped file1 error, topic: &quot; + msg.getTopic() + &quot; clientAddr: &quot; + msg.getBornHostString());
    beginTimeInLock = 0;
    return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.CREATE_MAPPED_FILE_FAILED, null));
}
</code></pre>
<p><strong>Step 6</strong> :将消息追加到 MappedFile 中。 首先先获取 MappedFile 当前写指针，如果currentPos大于或等于文件大小则表明文件已写满，抛出 AppendMessageStatus.UNKNOWN_ ERROR。 如果 currentPos小于文件大小，通过 slice()方法创建一个与 MappedFile 的共享内存区，并设置position 为当前指针。</p>
<pre><code class="language-java">public AppendMessageResult appendMessagesInner(final MessageExt messageExt, final AppendMessageCallback cb,
                                                PutMessageContext putMessageContext) {
    assert messageExt != null;
    assert cb != null;

    int currentPos = WROTE_POSITION_UPDATER.get(this);

    if (currentPos &lt; this.fileSize) {
        ByteBuffer byteBuffer = appendMessageBuffer().slice();
        byteBuffer.position(currentPos);
        AppendMessageResult result;
        if (messageExt instanceof MessageExtBatch &amp;&amp; !((MessageExtBatch) messageExt).isInnerBatch()) {
            // traditional batch message
            result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos,
                    (MessageExtBatch) messageExt, putMessageContext);
        } else if (messageExt instanceof MessageExtBrokerInner) {
            // traditional single message or newly introduced inner-batch message
            result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos,
                    (MessageExtBrokerInner) messageExt, putMessageContext);
        } else {
            return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR);
        }
        WROTE_POSITION_UPDATER.addAndGet(this, result.getWroteBytes());
        this.storeTimestamp = result.getStoreTimestamp();
        return result;
    }
    log.error(&quot;MappedFile.appendMessage return null, wrotePosition: {} fileSize: {}&quot;, currentPos, this.fileSize);
    return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR);
}
</code></pre>
<p><strong>Step 7</strong>:创建全局唯一消息 ID，消息ID有16字节。前4字节为IP，中间4字节为端口号，最后8字节为消息偏移量。</p>
<pre><code class="language-java">long wroteOffset = fileFromOffset + byteBuffer.position();

Supplier&lt;String&gt; msgIdSupplier = () -&gt; {
    int sysflag = msgInner.getSysFlag();
    int msgIdLen = (sysflag &amp; MessageSysFlag.STOREHOSTADDRESS_V6_FLAG) == 0 ? 4 + 4 + 8 : 16 + 4 + 8;
    ByteBuffer msgIdBuffer = ByteBuffer.allocate(msgIdLen);
    MessageExt.socketAddress2ByteBuffer(msgInner.getStoreHost(), msgIdBuffer);
    msgIdBuffer.clear();//because socketAddress2ByteBuffer flip the buffer
    msgIdBuffer.putLong(msgIdLen - 8, wroteOffset);
    return UtilAll.bytes2string(msgIdBuffer.array());
};
</code></pre>
<p>可以通过 UtilAll.bytes2string方法将 msgld 字节数组转换成字符串，通过 Uti1All.string2bytes 方法将msgld字符串还原成16个字节的字节数组，从而根据提取消息偏移量，可以快速通过msgld找到消息内容。</p>
<p><strong>Step 8</strong> : 获取该消息在消息队列的偏移量。CommitLog中保存了当前所有消息队列的当前待写入偏移量。</p>
<p><strong>Step 9</strong>:根据消息、体的长度、主题的长度、属性的长度结合消息存储格式计算消息的总长度。</p>
<p><strong>Step l0</strong> :如果消息长度+END_FILE_MIN_BLANK_LENGTH大于CommitLog文件的空闲空间，则返回 AppendMessageStatus.END_OF_FILE, Broker会重新创建一个新的 CommitLog文件来存储该消息。 从这里可以看出，每个CommitLog文件最少会空闲 8个字 节，高4字节存储当前文件剩余空间，低4字节存储魔数 : CommitLog.BLANK MAGIC CODE 。</p>
<pre><code class="language-java">if ((msgLen + END_FILE_MIN_BLANK_LENGTH) &gt; maxBlank) {
    this.msgStoreItemMemory.clear();
    // 1 TOTALSIZE
    this.msgStoreItemMemory.putInt(maxBlank);
    // 2 MAGICCODE
    this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE);
    // 3 The remaining space may be any value
    // Here the length of the specially set maxBlank
    final long beginTimeMills = CommitLog.this.defaultMessageStore.now();
    byteBuffer.put(this.msgStoreItemMemory.array(), 0, 8);
    return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, wroteOffset,
        maxBlank, /* only wrote 8 bytes, but declare wrote maxBlank for compute write position */
        msgIdSupplier, msgInner.getStoreTimestamp(),
        queueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills);
}
</code></pre>
<p><strong>Step 11</strong> :将消息内容存储到ByteBuffer中，然后创建AppendMessageResult。 这里只是将消息存储在 MappedFile对应的内存映射Buffer中，并没有刷写到磁盘。</p>
<pre><code class="language-java">final long beginTimeMills = CommitLog.this.defaultMessageStore.now();
CommitLog.this.getMessageStore().getPerfCounter().startTick(&quot;WRITE_MEMORY_TIME_MS&quot;);
// Write messages to the queue buffer
byteBuffer.put(preEncodeBuffer);
CommitLog.this.getMessageStore().getPerfCounter().endTick(&quot;WRITE_MEMORY_TIME_MS&quot;);
msgInner.setEncodedBuff(null);
return new AppendMessageResult(AppendMessageStatus.PUT_OK, wroteOffset, msgLen, msgIdSupplier,msgInner.getStoreTimestamp(), queueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills, messageNum);
</code></pre>
<blockquote>
<p>AppendMessageResult核心属性</p>
</blockquote>
<pre><code class="language-java">public class AppendMessageResult {
    //消息追加结果  PUT_OK :追加成功;END_OF_FILE :超过文件大小;MESSAGE SIZE EXCEEDED :消息长度超过最大允许长度: PROPERTIES_SIZE_EXCEEDED :消息、属性超过最大允许长度; UNKNOWN ERROR :未知异常 。
    private AppendMessageStatus status;
    // 消息的物理偏移量
    private long wroteOffset;
    // 消息的大小
    private int wroteBytes;
    // 消息 ID
    private String msgId;
    private Supplier&lt;String&gt; msgIdSupplier;
    // 消息存储时间戳
    private long storeTimestamp;
    // 消息消费队列逻辑偏移量，类似于数组下标
    private long logicsOffset;
    private long pagecacheRT = 0;
    //消息条数，批量消息发送时消息条数
    private int msgNum = 1;
}
</code></pre>
<p><strong>Step 12</strong>:更新消息队列逻辑偏移量 。</p>
<p><strong>Step 13</strong>:处理完消息追加逻辑后将释放 putMessageLock锁。</p>
<p><strong>Step 14</strong> : DefaultAppendMessageCallback#doAppend 只是将消息追加在内存中， 需要根据是同步刷盘还是异步刷盘方式，将内存中的数据持久化到磁盘，然后执行 HA 主从同步复制。</p>
<h2 id="44-存储文件组织与内存映射">4.4 存储文件组织与内存映射</h2>
<p>RocketMQ通过使用内存映射文件来提高IO访问性能，无论是CommitLog、 ConsumeQueue还是 IndexFile，单个文件都被设计为固定长度，如果一个文件写满以后再创建一个新文件，文件名就为该文件第 一条消息对应的全局物理偏移量。</p>
<h3 id="441-mappedfilequeue-映射文件队列">4.4.1 MappedFileQueue 映射文件队列</h3>
<p>MappedFileQueu巳是 MappedFile 的管理容器， Mapp巳dFileQueue是对存储目录的封装，例如 CommitLog文件的存储路径${ROCKET_HOME}/store/commitlog/，该目录下会存在多个内存映射文件(MappedFile)。</p>
<pre><code class="language-java">public class MappedFileQueue implements Swappable {
    //存储目录
    protected final String storePath;
    //单个文件的存储大小
    protected final int mappedFileSize;
    //MappedFile 文件集合
    protected final CopyOnWriteArrayList&lt;MappedFile&gt; mappedFiles = new CopyOnWriteArrayList&lt;MappedFile&gt;();
    //创建 MappedFile服务类
    protected final AllocateMappedFileService allocateMappedFileService;
    //当前刷盘指针，表示该指针之前的所有数据全部持久化到磁盘
    protected long flushedWhere = 0;
    //当前数据提交指针，内存中ByteBuffer当前的写指针，该值大于等于flushedWhere
    protected long committedWhere = 0;

    protected volatile long storeTimestamp = 0;
}
</code></pre>
<blockquote>
<p>查找 MappedFile</p>
</blockquote>
<pre><code class="language-java">/**
    * 查找 MappedFile
    * @param timestamp
    * @return
    */
public MappedFile getMappedFileByTime(final long timestamp) {
    Object[] mfs = this.copyMappedFiles(0);

    if (null == mfs)
        return null;

    for (int i = 0; i &lt; mfs.length; i++) {
        MappedFile mappedFile = (MappedFile) mfs[i];
        if (mappedFile.getLastModifiedTimestamp() &gt;= timestamp) {
            return mappedFile;
        }
    }

    return (MappedFile) mfs[mfs.length - 1];
}
</code></pre>
<p>根据消息存储时间戳来查找 MappdFile。从MappedFile 列表中第一个文件开始查找，找到第一个最后一次更新时间大于待查找时间戳的文件，如果不存在，则返回最后一个MappedFile文件。</p>
<p>RocketMQ 采取定时删除存储文件的策略，也就是说在存储文件中， 第一个文件不一定是 00000000000000000000，因为该文件在某一时刻会被删除，故根据offset定位MappedFile的算法为</p>
<pre><code class="language-java">(int) ((offset / this.mappedFileSize) - (firstMappedFile.getFileFromOffset() / this.mappedFileSize));
</code></pre>
<blockquote>
<p>MappedFileQueue#findMappedFileByOffset</p>
</blockquote>
<pre><code class="language-java">public MappedFile findMappedFileByOffset(final long offset, final boolean returnFirstOnNotFound) {
    try {
        MappedFile firstMappedFile = this.getFirstMappedFile();
        MappedFile lastMappedFile = this.getLastMappedFile();
        if (firstMappedFile != null &amp;&amp; lastMappedFile != null) {
            if (offset &lt; firstMappedFile.getFileFromOffset() || offset &gt;= lastMappedFile.getFileFromOffset() + this.mappedFileSize) {
                LOG_ERROR.warn(&quot;Offset not matched. Request offset: {}, firstOffset: {}, lastOffset: {}, mappedFileSize: {}, mappedFiles count: {}&quot;,
                    offset,
                    firstMappedFile.getFileFromOffset(),
                    lastMappedFile.getFileFromOffset() + this.mappedFileSize,
                    this.mappedFileSize,
                    this.mappedFiles.size());
            } else {
                int index = (int) ((offset / this.mappedFileSize) - (firstMappedFile.getFileFromOffset() / this.mappedFileSize));
                MappedFile targetFile = null;
                try {
                    targetFile = this.mappedFiles.get(index);
                } catch (Exception ignored) {
                }

                if (targetFile != null &amp;&amp; offset &gt;= targetFile.getFileFromOffset()
                    &amp;&amp; offset &lt; targetFile.getFileFromOffset() + this.mappedFileSize) {
                    return targetFile;
                }

                for (MappedFile tmpMappedFile : this.mappedFiles) {
                    if (offset &gt;= tmpMappedFile.getFileFromOffset()
                        &amp;&amp; offset &lt; tmpMappedFile.getFileFromOffset() + this.mappedFileSize) {
                        return tmpMappedFile;
                    }
                }
            }

            if (returnFirstOnNotFound) {
                return firstMappedFile;
            }
        }
    } catch (Exception e) {
        log.error(&quot;findMappedFileByOffset Exception&quot;, e);
    }

    return null;
}
</code></pre>
<p>获取存储文件最小偏移量，从这里也可以看出，并不是直接返回0，而是返回Mapped­File的 getFileFormOffset()。</p>
<pre><code class="language-java">public long getMinOffset() {
    if (!this.mappedFiles.isEmpty()) {
        try {
            return this.mappedFiles.get(0).getFileFromOffset();
        } catch (IndexOutOfBoundsException e) {
            //continue;
        } catch (Exception e) {
            log.error(&quot;getMinOffset has exception.&quot;, e);
        }
    }
    return -1;
}
</code></pre>
<p>获取存储文件的最大偏移量。 返回最后一个Mapp巳dFile文件的fileFromOffset加上MappedFile 文件当前的读指针。</p>
<pre><code class="language-java">public long getMaxOffset() {
    MappedFile mappedFile = getLastMappedFile();
    if (mappedFile != null) {
        return mappedFile.getFileFromOffset() + mappedFile.getReadPosition();
    }
    return 0;
}
</code></pre>
<p>返回存储文件当前的写指针。 返回最后一个文件的 fileFromOffset加上当前写指针位置。</p>
<pre><code class="language-java">public long getMaxWrotePosition() {
    MappedFile mappedFile = getLastMappedFile();
    if (mappedFile != null) {
        return mappedFile.getFileFromOffset() + mappedFile.getWrotePosition();
    }
    return 0;
}
</code></pre>
<h3 id="442-mappedfile-内存映射文件">4.4.2 MappedFile 内存映射文件</h3>
<p>MappedFile 是RocketMQ内存映射文件的具体实现。</p>
<pre><code class="language-java">public class DefaultMappedFile extends AbstractMappedFile {
    //操作系统每页大小，默认4k
    public static final int OS_PAGE_SIZE = 1024 * 4;
    protected static final InternalLogger log = InternalLoggerFactory.getLogger(LoggerName.STORE_LOGGER_NAME);

    //当前JVM实例中Mapped File虚拟内存
    protected static final AtomicLong TOTAL_MAPPED_VIRTUAL_MEMORY = new AtomicLong(0);
    //当前JVM实例中MappedFile对象个数
    protected static final AtomicInteger TOTAL_MAPPED_FILES = new AtomicInteger(0);

    protected static final AtomicIntegerFieldUpdater&lt;DefaultMappedFile&gt; WROTE_POSITION_UPDATER;
    protected static final AtomicIntegerFieldUpdater&lt;DefaultMappedFile&gt; COMMITTED_POSITION_UPDATER;
    protected static final AtomicIntegerFieldUpdater&lt;DefaultMappedFile&gt; FLUSHED_POSITION_UPDATER;

    //当前该文件的写指针，从0开始
    protected volatile int wrotePosition;
    //当前文件的提交指针，如果开启transientStorePoolEnable 则数据会存储在TransientStorePool中，然后提交到内存映射ByteBuffer中，再刷写到磁盘。
    protected volatile int committedPosition;
    //刷写到磁盘指针，该指针之前的数据持久化到磁盘中
    protected volatile int flushedPosition;
    //文件大小
    protected int fileSize;
    //文件通道
    protected FileChannel fileChannel;
    /**
     * Message will put to here first, and then reput to FileChannel if writeBuffer is not null.
     */
    //堆内存ByteBuffer，如果不为空，数据首先将存储在该Buffer中，然后提交到MappedFile对应的内存映射文件Buffer。transientStorePoolEnable为true时不为空。
    protected ByteBuffer writeBuffer = null;
    //堆内存池， transientStorePoolEnable为true时启用。
    protected TransientStorePool transientStorePool = null;
    //文件名称
    protected String fileName;
    //该文件的初始偏移量
    protected long fileFromOffset;
    //物理文件
    protected File file;
    //物理文件对应的内存映射 Buffer
    protected MappedByteBuffer mappedByteBuffer;
    //文件最后一次 内容写入时间
    protected volatile long storeTimestamp = 0;
    //是否是MappedFileQueue队列中第一个文件
    protected boolean firstCreateInQueue = false;
    private long lastFlushTime = -1L;

    protected MappedByteBuffer mappedByteBufferWaitToClean = null;
    protected long swapMapTime = 0L;
    protected long mappedByteBufferAccessCountSinceLastSwap = 0L;
}
</code></pre>
<h4 id="1-mappedfile初始化">1. MappedFile初始化</h4>
<pre><code class="language-java">
根据是否开启 transientStorePoo!Enable 在两种初始化情况 transientStorePoolEnable
true表示内容先存储在堆外内存，然后通过 Commit 线程将数据提交到内存映射 uffer
中，再通过 Flush 线程将内存映射 Buffer中的数据持化到磁盘中。

&gt;初始化
private void init(final String fileName, final int fileSize) throws IOException {
    this.fileName = fileName;
    this.fileSize = fileSize;
    this.file = new File(fileName);

    //初始化 fileFromOffset 为文件名，也就是文件名代表该文件的起始偏移量
    this.fileFromOffset = Long.parseLong(this.file.getName());
    boolean ok = false;

    UtilAll.ensureDirOK(this.file.getParent());

    try {
        //创建读写文件通道，并将文件内容使用 NIO 的内存映射 Buffer将文件映 射到内存中。
        this.fileChannel = new RandomAccessFile(this.file, &quot;rw&quot;).getChannel();
        this.mappedByteBuffer = this.fileChannel.map(MapMode.READ_WRITE, 0, fileSize);
        TOTAL_MAPPED_VIRTUAL_MEMORY.addAndGet(fileSize);
        TOTAL_MAPPED_FILES.incrementAndGet();
        ok = true;
    } catch (FileNotFoundException e) {
        log.error(&quot;Failed to create file &quot; + this.fileName, e);
        throw e;
    } catch (IOException e) {
        log.error(&quot;Failed to map file &quot; + this.fileName, e);
        throw e;
    } finally {
        if (!ok &amp;&amp; this.fileChannel != null) {
            this.fileChannel.close();
        }
    }
}
</code></pre>
<p>如果transientstorePooIEnabIe 为 true，则初始化 MappedFile 的 writeBuffer。</p>
<blockquote>
<p>初始化</p>
</blockquote>
<pre><code class="language-java">@Override
public void init(final String fileName, final int fileSize,
                    final TransientStorePool transientStorePool) throws IOException {
    init(fileName, fileSize);
    this.writeBuffer = transientStorePool.borrowBuffer();
    this.transientStorePool = transientStorePool;
}
</code></pre>
<h4 id="2-mappedfile提交commit">2. MappedFile提交(commit)</h4>
<p>内存映射文件的提交动作由 MappedFile 的commit方法实现。</p>
<blockquote>
<p>Commit代码</p>
</blockquote>
<pre><code class="language-java">@Override
public int commit(final int commitLeastPages) {
    if (writeBuffer == null) {
        //no need to commit data to file channel, so just regard wrotePosition as committedPosition.
        //writeBuffer如果为空，直接返回 wrotePosition指针
        return WROTE_POSITION_UPDATER.get(this);
    }
    //判断是否达到最小提交页数,不满则不执行本次提交操作，待下次提交 
    if (this.isAbleToCommit(commitLeastPages)) {
        if (this.hold()) {
             //具体提交
            commit0();
            this.release();
        } else {
            log.warn(&quot;in commit, hold failed, commit offset = &quot; + COMMITTED_POSITION_UPDATER.get(this));
        }
    }

    // All dirty data has been committed to FileChannel.
    if (writeBuffer != null &amp;&amp; this.transientStorePool != null &amp;&amp; this.fileSize == COMMITTED_POSITION_UPDATER.get(this)) {
        this.transientStorePool.returnBuffer(writeBuffer);
        this.writeBuffer = null;
    }

    return COMMITTED_POSITION_UPDATER.get(this);
}
</code></pre>
<blockquote>
<p>判断是否需要提交</p>
</blockquote>
<pre><code class="language-java">protected boolean isAbleToCommit(final int commitLeastPages) {
    int commit = COMMITTED_POSITION_UPDATER.get(this);
    int write = WROTE_POSITION_UPDATER.get(this);
    //如果文件满了
    if (this.isFull()) {
        return true;
    }
    //如果 commitLeastPages大于 0, 则比较 wrotePosition( 当前 writeBuffer 的写指针)与上 一次提交的指针(committedPosition)
    // 的差值，除以 OS_PAGE_SIZE得到当前脏页的数量，如果大于 commitLeastPages则返回 true;
    if (commitLeastPages &gt; 0) {
        return ((write / OS_PAGE_SIZE) - (commit / OS_PAGE_SIZE)) &gt;= commitLeastPages;
    }
    // 如果 commitLeastPages 小 于 0 表示只要存在脏页就提交
    return write &gt; commit;
}
</code></pre>
<blockquote>
<p>具体提交</p>
</blockquote>
<pre><code class="language-java">protected void commit0() {
    int writePos = WROTE_POSITION_UPDATER.get(this);
    int lastCommittedPosition = COMMITTED_POSITION_UPDATER.get(this);

    if (writePos - lastCommittedPosition &gt; 0) {
        try {
            //创建 writeBuffer的共享缓存区
            ByteBuffer byteBuffer = writeBuffer.slice();

            //将新创建的 position 回 退到上一次提交的位置( lastCommittedPosition)
            byteBuffer.position(lastCommittedPosition);
            //设置 limit为 wrotePosition (当前最大有效数据指针)
            byteBuffer.limit(writePos);
            //更新committedPosition指针为wrotePosition
            this.fileChannel.position(lastCommittedPosition);
            //把lastCommittedPosition到wrotePosition的数据复制 (写入)到FileChannel中
            this.fileChannel.write(byteBuffer);
            COMMITTED_POSITION_UPDATER.set(this, writePos);
        } catch (Throwable e) {
            log.error(&quot;Error occurred when commit data to FileChannel.&quot;, e);
        }
    }
}
</code></pre>
<p>commit的作用就是将MappedFile#­ writeBuffer 中的数据提交到文件通道 FileChannel 中。</p>
<p><em>ByteBuffer 使用技巧 : slice() 方法创建 一 个共享缓存区 ，与原先的 ByteBuffer 共享内存但维护一套独立的指针 (position、 mark、 limit)。</em></p>
<h4 id="3-mappedfile刷盘flush">3. MappedFile刷盘(flush)</h4>
<p>刷盘指的是将内存中的数据刷写到磁盘，永久存储在磁盘中，其具体实现由MappedFile的flush方法实现。</p>
<blockquote>
<p>flush方法</p>
</blockquote>
<pre><code class="language-java">@Override
public int flush(final int flushLeastPages) {
    if (this.isAbleToFlush(flushLeastPages)) {
        if (this.hold()) {
            //获取最大读指针
            int value = getReadPosition();

            try {
                this.mappedByteBufferAccessCountSinceLastSwap++;

                //We only append data to fileChannel or mappedByteBuffer, never both.
                if (writeBuffer != null || this.fileChannel.position() != 0) {
                    this.fileChannel.force(false);
                } else {
                    this.mappedByteBuffer.force();
                }
                this.lastFlushTime = System.currentTimeMillis();
            } catch (Throwable e) {
                log.error(&quot;Error occurred when force data to disk.&quot;, e);
            }

            FLUSHED_POSITION_UPDATER.set(this, value);
            this.release();
        } else {
            log.warn(&quot;in flush, hold failed, flush offset = &quot; + FLUSHED_POSITION_UPDATER.get(this));
            FLUSHED_POSITION_UPDATER.set(this, getReadPosition());
        }
    }
    return this.getFlushedPosition();
}
</code></pre>
<p>刷写磁盘，直接调用mappedByteBuffer或fileChannel的force方法将内存中的数据持久化到磁盘，那么 flushedPosition应该等于MappedByteBuffer中的写指针;如果write­Buffer不为空，flushedPosition应等于上一次commit指针;因为上一次提交的数据就是进入到MappedByteBuffer中的数据;如果 writeBuffer为空，数据是直接进入到Mapped­ByteBuffer, wrotePosition代表的是 MappedByteBuffer中的指针，故设置flushedPosition为wrotePosition。</p>
<h4 id="4-获取-mappedfile-最大读指针-getreadposition">4. 获取 MappedFile 最大读指针( getReadPosition)</h4>
<blockquote>
<p>获取最大读指针</p>
</blockquote>
<pre><code class="language-java">public int getReadPosition() {
    return this.writeBuffer == null ? WROTE_POSITION_UPDATER.get(this) : COMMITTED_POSITION_UPDATER.get(this);
}
</code></pre>
<p>获取当前文件最大的可读指针。如果writeBuffer为空，则直接返回当前的写指针;如果writeBuffer不为空， 则返回上一次提交的指针。只有提交了的数据(写入到 MappedByteBuffer或 FileChannel中的数据 )才是安全的数据。</p>
<blockquote>
<p>MappedFile#selectMappedBuffer</p>
</blockquote>
<pre><code class="language-java">public SelectMappedBufferResult selectMappedBuffer(int pos, int size) {
    int readPosition = getReadPosition();
    if ((pos + size) &lt;= readPosition) {
        if (this.hold()) {
            this.mappedByteBufferAccessCountSinceLastSwap++;

            ByteBuffer byteBuffer = this.mappedByteBuffer.slice();
            byteBuffer.position(pos);
            ByteBuffer byteBufferNew = byteBuffer.slice();
            byteBufferNew.limit(size);
            return new SelectMappedBufferResult(this.fileFromOffset + pos, byteBufferNew, size, this);
        } else {
            log.warn(&quot;matched, but hold failed, request pos: &quot; + pos + &quot;, fileFromOffset: &quot;
                    + this.fileFromOffset);
        }
    } else {
        log.warn(&quot;selectMappedBuffer request pos invalid, request pos: &quot; + pos + &quot;, size: &quot; + size
                + &quot;, fileFromOffset: &quot; + this.fileFromOffset);
    }

    return null;
}
</code></pre>
<p>查找 pos 到当前最大可读之间的数据，由于在整个写入期间都未曾改变 MappedByte­Buffer的指针 ，所以mappedByteBuffer.slice()方法返回的共享缓存区空间为整个Mapped­File，然后通过设置 byteBuffer的position为待查找的值，读取字节为当前可读字节长度，最终返回的 ByteBuffer 的 limit (可读 最大长度)为 size。整个共享缓存区的容量为(MappedFile#fileSize-pos)，故在操作SelectMappedBufferResult不能对包含在里面的ByteBuffer调用flip方法。</p>
<p><em>操作ByteBuffer 时如果使用了slice()方法，对其ByteBuffer进行读取时一般手动指定position与limit 指针，而不是调用flip方法来切换读写状态。</em></p>
<h4 id="5-mappedfile-销毁-destory">5 . MappedFile 销毁( destory)</h4>
<p>MappedFile文件销毁的实现方法为public boolean destroy(final long intervalForcibly), intervalForcibly表示拒绝被销毁的最大存活时间。</p>
<p>Step 1:关闭MappedFile</p>
<blockquote>
<p>destroy -&gt; shutdown()</p>
</blockquote>
<pre><code class="language-java">public void shutdown(final long intervalForcibly) {
    if (this.available) {
        //初次调用时 this.available 为 true，设置 available 为 false
        this.available = false;
        //设置初次关闭的时间戳( firstShutdownTimestamp)为当前时间戳
        this.firstShutdownTimestamp = System.currentTimeMillis();
        //然后调用 release()方法 尝试释放资源，
        this.release();
    } else if (this.getRefCount() &gt; 0) {
        //引用次数大于0，对比当前时间与 firstShutdownTimestamp，如果已经超过了其最大拒绝存活期，每执行一次，将引用数减少 1000，直到引用数小于0
        if ((System.currentTimeMillis() - this.firstShutdownTimestamp) &gt;= intervalForcibly) {
            this.refCount.set(-1000 - this.getRefCount());
            this.release();
        }
    }
}
</code></pre>
<p>Step2 : 判断是否清理完成</p>
<blockquote>
<p>判断是否清理完成</p>
</blockquote>
<pre><code class="language-java">public boolean isCleanupOver() {
    //引用次数小于等于0并且 cleanupOver为 true, cleanupOver为true的触发条件是release成功将MappedByteBuffer资源释放。
    return this.refCount.get() &lt;= 0 &amp;&amp; this.cleanupOver;
}
</code></pre>
<p>Step3: 关闭文件通道， 删除物理文件。</p>
<pre><code class="language-java">long lastModified = getLastModifiedTimestamp();
this.fileChannel.close();
log.info(&quot;close file channel &quot; + this.fileName + &quot; OK&quot;);

long beginTime = System.currentTimeMillis();
boolean result = this.file.delete();
</code></pre>
<p>在整 MappedFile销毁过程，首先需要释放资源，释放资源的前提条件是该 Mapped­File 的引用小于等于 0，接下来重点看一下release方法的实现原理。</p>
<pre><code class="language-java">public void release() {
    long value = this.refCount.decrementAndGet();
    if (value &gt; 0)
        return;

    synchronized (this) {
        this.cleanupOver = this.cleanup(value);
    }
}
</code></pre>
<p>如果引用数小于等于0，则执行 cleanup 方法</p>
<blockquote>
<p>cleanup()</p>
</blockquote>
<pre><code class="language-java">public boolean cleanup(final long currentRef) {
    if (this.isAvailable()) {
        //available为true，表示MappedFile当前可用，无须清理
        log.error(&quot;this file[REF:&quot; + currentRef + &quot;] &quot; + this.fileName
                + &quot; have not shutdown, stop unmapping.&quot;);
        return false;
    }

    if (this.isCleanupOver()) {
        //资源已经被清除，返回true
        log.error(&quot;this file[REF:&quot; + currentRef + &quot;] &quot; + this.fileName
                + &quot; have cleanup, do not do it again.&quot;);
        return true;
    }

    //如果是堆外内存，调用堆外内存的cleanup方法清除
    UtilAll.cleanBuffer(this.mappedByteBuffer);
    UtilAll.cleanBuffer(this.mappedByteBufferWaitToClean);
    this.mappedByteBufferWaitToClean = null;
    TOTAL_MAPPED_VIRTUAL_MEMORY.addAndGet(this.fileSize * (-1));
    TOTAL_MAPPED_FILES.decrementAndGet();
    log.info(&quot;unmap file[REF:&quot; + currentRef + &quot;] &quot; + this.fileName + &quot; OK&quot;);
    return true;
}
</code></pre>
<h3 id="443-transientstorepool">4.4.3 TransientStorePool</h3>
<p>TransientStorePool: 短暂的存储池。 RocketMQ单独创建一个MappedByteBuffer内存缓存池，用来临 时存储数据，数据先写人该内存映射中，然后由commit线程定时将数据从该内存复制到与目的物理文件对应的内存映射中。主要作用提供一种内存锁定，将当前堆外内存一直锁定在内存中，避免被进程将内存交换到磁盘。</p>
<blockquote>
<p>核心属性</p>
</blockquote>
<pre><code class="language-java">public class TransientStorePool {
  //avaliableBuffers个数，可通过在broker中配置文件中设置 transient-StorePoolSize，默认为5。
    private final int poolSize;
    //每个 ByteBuffer大小， 默认为mappedFileSizeCommitLog，表明TransientStorePool为commitlog文件服务
    private final int fileSize;
    //ByteBuffer容器，双端队列
    private final Deque&lt;ByteBuffer&gt; availableBuffers;
    private final MessageStoreConfig storeConfig;
}
</code></pre>
<blockquote>
<p>初始化</p>
</blockquote>
<pre><code class="language-java">public void init() {
        //创建 poolSize个堆外内存 ， 并利用com.sun.jna.Library类库将该批内存锁定，避免被置换到交换区，提高存储性能
    for (int i = 0; i &lt; poolSize; i++) {
        ByteBuffer byteBuffer = ByteBuffer.allocateDirect(fileSize);

        final long address = ((DirectBuffer) byteBuffer).address();
        Pointer pointer = new Pointer(address);
        LibC.INSTANCE.mlock(pointer, new NativeLong(fileSize));

        availableBuffers.offer(byteBuffer);
    }
}
</code></pre>
<h2 id="45-rocketmq-存储文件">4.5 RocketMQ 存储文件</h2>
<p>RocketMQ 存储路径为${ROCKET_HOME}/store</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1664335193541.png" alt="file dir" loading="lazy"></figure>
<ol>
<li>commitlog:消息存储目录</li>
<li>config:运行期间一些配置信息，主要包括下列信息<br>
consumerFilter.json: 主题消息过滤信息<br>
consumerOffset.json: 集群消费模式消息消费进度<br>
delayOffset.json:延时消息队列拉取进度<br>
subscriptionGroup.json: 消息消费组配置信息<br>
topics.json: topic配置属性</li>
<li>consumequ巳ue:消息消费队列存储目录</li>
<li>index:消息索引文件存储目录。</li>
<li>abort :如果存在 abort文件说明 Broker非正常关闭，该文件默认启动时创建，正常<br>
退出之前删除 。</li>
<li>checkpoint:文件检测点，存储 commitlog文件最后一次刷盘时间戳、 consumequeue<br>
最后一次刷盘时间、 index 索引文件最后一次刷盘时间戳</li>
</ol>
<h3 id="451-commitlog-文件">4.5.1 Commitlog 文件</h3>
<p>Commitlog 文件存储的逻辑视图如下所示，每条消息的前面4个字节存储该条消息的总长度。<br>
<img src="https://q456qq520.github.io/post-images/1664335547565.png" alt="消息组织方式" loading="lazy"></p>
<p>分析消息的查找实现<br>
Step 1:获取当前 Commitlog 目录最小偏移量 ，首先获取目录下的第一个文件，如果该文件可用， 则返回该文件的起始偏移量，否则返回下一个文件的起始偏移量。</p>
<blockquote>
<p>获取最小偏移量</p>
</blockquote>
<pre><code class="language-java">public long getMinOffset() {
    MappedFile mappedFile = this.mappedFileQueue.getFirstMappedFile();
    if (mappedFile != null) {
        if (mappedFile.isAvailable()) {
            return mappedFile.getFileFromOffset();
        } else {
            return this.rollNextFile(mappedFile.getFileFromOffset());
        }
    }
    return -1;
}
</code></pre>
<blockquote>
<p>文件不可用</p>
</blockquote>
<pre><code class="language-java">public long rollNextFile(final long offset) {
        int mappedFileSize = this.defaultMessageStore.getMessageStoreConfig().getMappedFileSizeCommitLog();
        return offset + mappedFileSize - offset % mappedFileSize;
    }
</code></pre>
<p>根据该offset返回下一个文件的起始偏移量。首先获取一个文件的大小，减去(offset% mappedFileSize)其目的是回到下一文件的起始偏移量。</p>
<p>Step 2:根据偏移量与消息长度查找消息。</p>
<p>首先根据偏移找到所在的物理偏移量，然后用 offset 与文件长度取余得到在文件内的偏移量，从该偏移量读取size长度的内容返回即可。 如果只根据消息偏移查找消息， 则首先找到文件内的偏移量，然后尝试读取4个字节获取消息 的实际长度，最后读取指定字节即可。</p>
<pre><code class="language-java">public SelectMappedBufferResult getMessage(final long offset, final int size) {
    int mappedFileSize = this.defaultMessageStore.getMessageStoreConfig().getMappedFileSizeCommitLog();
    MappedFile mappedFile = this.mappedFileQueue.findMappedFileByOffset(offset, offset == 0);
    if (mappedFile != null) {
        int pos = (int) (offset % mappedFileSize);
        return mappedFile.selectMappedBuffer(pos, size);
    }
    return null;
}
</code></pre>
<h3 id="452-consumequeue-文件">4.5.2 ConsumeQueue 文件</h3>
<p>RocketMQ基于主题订阅模式实现消息消费，消费者关心的是一个主题下的所有消息，但由于同一主题的消息不连续地存储在commitlog文件中。设计了消息消费队列文件( Consumequeue)，该文件可以看成是 Commitlog关于消息消费的“索引”文件，consumequeue的第一级目录为消息主题，第二级目录为主题的消息队列。</p>
<p>每一个consumequeue条目不会存储全量消息，目的是为了快速检索。</p>
<p>单个ConsumeQueue文件中默认包含30万个条目，单个文件的长度为 30w×20 字节，单个ConsumeQueue文件可以看出是一个ConsumeQueue条目的数组，其下标为Consume­Queue的逻辑偏移量，消息消费进度存储的偏移量即逻辑偏移量。ConsumeQueue 即为 Commitlog文件的索引文件，其构建机制是当消息到达Commitlog文件后，由专门的线程产生消息转发任务，从而构建消息消费队列文件与下文提到的索引文件。</p>
<h3 id="453-index-索引文件">4.5.3 Index 索引文件</h3>
<p>消息消费队列是 RocketMQ专门为消息订阅构建的索引文件，提高根据主题与消息队列检索消息的速度，另外RocketMQ引入了Hash索引机制为消息建立索引。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1664355515340.png" alt="Index索引文件" loading="lazy"></figure>
<p>lndexFile总共包含 lndexHeader、Hash槽 、Hash 条目(数据)。</p>
<p>1 ) IndexHeader头部，包含40个字节，记录该IndexFile 的统计信息<br>
beginTimestamp: 该索引文件中包含消息的最小存储时间<br>
endTimestamp: 该索引文件中包含消息的最大存储时间<br>
beginPhyoffset: 该索引文件中包含消息的最小物理偏移量(commitlog文件偏移量)<br>
endPhyoffset:该索引文件中包含消息的最大物理偏移量( commitlog文件偏移量)<br>
hashslotCount: hashslot个数，并不是hash槽使用的个数，在这里意义不大<br>
indexCount: Index条目列表当前已使用的个数，Index条目在Index条目列表中按顺序存储。<br>
2) Hash槽，一个IndexFile默认包含500万个Hash槽，每个Hash槽存储的是落在该Hash槽的hashcode最新的Index的索引<br>
3 )Index条目列表，默认一个索引文件包含 2000万个条目<br>
hashcode: key的hashcode。<br>
phyoffset: 消息对应的物理偏移量<br>
timedif:该消息存储时间与第一条消息的时间戳的差值，小于0该消息无效<br>
prelndexNo:该条目的前一条记录的Index索引，当出现hash冲突时，构建的链表结构</p>
<h3 id="454-checkpoint文件">4.5.4 checkpoint文件</h3>
<p>checkpoint的作用是记录 Comitlog、ConsumeQueue、Index文件的刷盘时间点，文件<br>
固定长度为4k，其中只用该文件的前面24个字节。</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1664356272730.png" alt="checkpoint文件" loading="lazy"></figure>
<p>physicMsgTimestamp: commitlog文件刷盘时间点<br>
logicsMsgTimestamp: 消息消费队列文件刷盘时间点<br>
indexMsgTimestamp: 索引文件刷盘时间点</p>
<h2 id="46-实时更新消息消费队列与索引文件">4.6 实时更新消息消费队列与索引文件</h2>
<p>当消息生产者提交的消息存储在Commitlog文件中，ConsumeQueue、IndexFile需要及时更新，否则消 息无法及时被消费，根据消息属性查找消息也会出现较大延迟。RocketMQ通过开启一个线程 ReputMessageServcie来准实时转发CommitLog文件更新事件，相应的任务处理器根据转发的消息及时更新 ConsumeQueue、IndexFile文件。</p>
<p>Broker服务器在启动时会启动 ReputMessageService线程，并初始化一个非常关键的参数 reputFfomOffset，该参数的含义是 ReputMessageService从哪个物理偏移量开始转发消息给 ConsumeQueue和IndexFile。如果允许重复转发，reputFromOffset设置为CommitLog的提交指针;如果不允许重复转发，reputFromOffset设置为Commitlog的内存中最大偏移量。</p>
<blockquote>
<p>DefaultMessageStore#start</p>
</blockquote>
<pre><code class="language-java">if (this.getMessageStoreConfig().isDuplicationEnable()) {
    this.reputMessageService.setReputFromOffset(this.commitLog.getConfirmOffset());
} else {
    // It is [recover]'s responsibility to fully dispatch the commit log data before the max offset of commit log.
    this.reputMessageService.setReputFromOffset(this.commitLog.getMaxOffset());
}
this.reputMessageService.start();
</code></pre>
<p>ReputMessageService线程每执行一次任务推送休息1毫秒就继续尝试推送消息到消息消费队列和索引文件，消息消费转发的核心实现在doReput方法中实现。</p>
<blockquote>
<p>DefaultMessageStore#run</p>
</blockquote>
<pre><code class="language-java">@Override
public void run() {
    DefaultMessageStore.LOGGER.info(this.getServiceName() + &quot; service started&quot;);
    while (!this.isStopped()) {
        try {
            Thread.sleep(1);
            this.doReput();
        } catch (Exception e) {
            DefaultMessageStore.LOGGER.warn(this.getServiceName() + &quot; service has exception. &quot;, e);
        }
    }
    DefaultMessageStore.LOGGER.info(this.getServiceName() + &quot; service end&quot;);
}
</code></pre>
<p>Step 1 :返回reputFromOffset偏移量开始的全部有效数据(commitlog文件)。然后循环读取每一条消息</p>
<pre><code class="language-java">//返回reputFromOffset偏移量开始的全部有效数据(commitlog文件)。然后循环读取每一条消息 。
SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset);
</code></pre>
<p>Step 2:从result返回的ByteBuffer中循环读取消息，一次读取一条</p>
<pre><code class="language-java">//从result返回的ByteBuffer中循环读取消息，一次读取一条
DispatchRequest dispatchRequest =
    DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false, false);
int size = dispatchRequest.getBufferSize() == -1 ? dispatchRequest.getMsgSize() : dispatchRequest.getBufferSize();
</code></pre>
<p>Step 3</p>
<pre><code class="language-java">if (dispatchRequest.isSuccess()) {
        //如果消息长度大于0，则调用doDispatch方法
        //最终将分别调用CommitLogDispatcherBuildConsumeQueue (构建消息消费队列)、 CommitLogDispatcherBuildIndex(构建索引文件)。
        if (size &gt; 0) {
            DefaultMessageStore.this.doDispatch(dispatchRequest); 
            //.....    
    }
}
</code></pre>
<p>其中重点DispatchRequest的核心属性为：</p>
<blockquote>
<p>DispatchRequest</p>
</blockquote>
<pre><code class="language-java">public class DispatchRequest {
    //消息主题名称
    private final String topic;
    //消息队列ID
    private final int queueId;
    //消息物理偏移量
    private final long commitLogOffset;
    //消息长度
    private int msgSize;
    //消息过滤 tag hashcode
    private final long tagsCode;
    //消息存储时间戳
    private final long storeTimestamp;
    //消息队列偏移量
    private final long consumeQueueOffset;
    //消息索引key。多个索引key用空格隔开
    private final String keys;
    //是否成功解析到完整的消息
    private final boolean success;
    //消息唯一键
    private final String uniqKey;
    //消息系统标记
    private final int sysFlag;
    //消息预处理事务偏移量
    private final long preparedTransactionOffset;
    //消息属性
    private final Map&lt;String, String&gt; propertiesMap;
    //位图
    private byte[] bitMap;

    private int bufferSize = -1;//the buffer size maybe larger than the msg size if the message is wrapped by something

    // for batch consume queue
    private long  msgBaseOffset = -1;
    private short batchSize = 1;

    private long nextReputFromOffset = -1;
}
</code></pre>
<h3 id="461-根据消息更新-conumequeue">4.6.1 根据消息更新 ConumeQueue</h3>
<p>消息消费队列转发任务实现类为 : CommitLogDispatcherBuildConsumeQueue，内部最<br>
终将调用 putMessagePositioninfo方法。</p>
<p>Step 1:根据消息主题与队列ID，先获取活创建对应的ConumeQueue文件</p>
<blockquote>
<p>putMessagePositionInfoWrapper</p>
</blockquote>
<pre><code class="language-java">public void putMessagePositionInfoWrapper(DispatchRequest dispatchRequest) {
    ConsumeQueueInterface cq = this.findOrCreateConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId());
    this.putMessagePositionInfoWrapper(cq, dispatchRequest);
}
</code></pre>
<p>*每一个消息主题对应一个消息消费队列目录然后主题下每一个消息队列对应一个文件夹，然后取出该文件夹最后的ConsumeQueue文件即可 *</p>
<p>Step 2:</p>
<blockquote>
<p>putMessagePositionInfo</p>
</blockquote>
<pre><code class="language-java">private boolean putMessagePositionInfo(final long offset, final int size, final long tagsCode,
        final long cqOffset) {
        if (offset + size &lt;= this.maxPhysicOffset) {
            log.warn(&quot;Maybe try to build consume queue repeatedly maxPhysicOffset={} phyOffset={}&quot;, maxPhysicOffset, offset);
            return true;
        }
        //依次将消息偏移量、消息长度、tag hashcode写入到ByteBuffer中
        this.byteBufferIndex.flip();
        this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE);
        this.byteBufferIndex.putLong(offset);
        this.byteBufferIndex.putInt(size);
        this.byteBufferIndex.putLong(tagsCode);

        final long expectLogicOffset = cqOffset * CQ_STORE_UNIT_SIZE;

        //consumeQueueOffset计算ConsumeQueue中的物理地址，将内容追加到ConsumeQueue的内
        //存映射文件中(本操作只追击并不刷盘)，ConsumeQueue的刷盘方式固定为异步刷盘模式
        MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset);
        if (mappedFile != null) {
            //......
            this.maxPhysicOffset = offset + size;
            return mappedFile.appendMessage(this.byteBufferIndex.array());
        }
        return false;
    }
</code></pre>
<h3 id="462-根据消息更新-index索引文件">4.6.2 根据消息更新 Index索引文件</h3>
<p>Hash索引文件转发任务实现类 : CommitLogDispatcherBuildlndex</p>
<blockquote>
<p>CommitLogDispatcherBuildIndex</p>
</blockquote>
<pre><code class="language-java">class CommitLogDispatcherBuildIndex implements CommitLogDispatcher {
    @Override
    //如果messsagelndexEnable设置为true，则调用IndexService#buildlndex构建Hash索引，否则忽略本次转发任务 。
    public void dispatch(DispatchRequest request) {
        if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) {
            DefaultMessageStore.this.indexService.buildIndex(request);
        }
    }
}
</code></pre>
<p>Step1:获取或创建IndexFile文件并获取文件最大物理偏移量。如果该消息的物理偏移量小于索引文件中的物理偏移，则说明是重复数据，忽略本次索引构建。</p>
<p>Step2 :如果消息的唯一键不为空，则添加到 Hash索引中，以便加速根据唯一键检索消息。</p>
<p>Step3:构建索引键，RocketMQ 支持为同一个消息建立多个索引，多个索引键空格分开</p>
<blockquote>
<p>buildIndex</p>
</blockquote>
<pre><code class="language-java">public void buildIndex(DispatchRequest req) {
    //获取或创建IndexFile文件并获取文件最大物理偏移量
    IndexFile indexFile = retryGetAndCreateIndexFile();
    if (indexFile != null) {
        long endPhyOffset = indexFile.getEndPhyOffset();
        DispatchRequest msg = req;
        String topic = msg.getTopic();
        String keys = msg.getKeys();
        //如果该消息的物理偏移量小于索引文件中的物理偏移，则说明是重复数据，忽略本次索引构建。
        if (msg.getCommitLogOffset() &lt; endPhyOffset) {
            return;
        }

        final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag());
        switch (tranType) {
            case MessageSysFlag.TRANSACTION_NOT_TYPE:
            case MessageSysFlag.TRANSACTION_PREPARED_TYPE:
            case MessageSysFlag.TRANSACTION_COMMIT_TYPE:
                break;
            case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:
                return;
        }

        //如果消息的唯一键不为空，则添加到 Hash索引中，以便加速根据唯一键检索消息
        if (req.getUniqKey() != null) {
            indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey()));
            if (indexFile == null) {
                LOGGER.error(&quot;putKey error commitlog {} uniqkey {}&quot;, req.getCommitLogOffset(), req.getUniqKey());
                return;
            }
        }
        //Step3:构建索引键，RocketMQ 支持为同一个消息建立多个索引，多个索引键空格分开
        if (keys != null &amp;&amp; keys.length() &gt; 0) {
            String[] keyset = keys.split(MessageConst.KEY_SEPARATOR);
            for (int i = 0; i &lt; keyset.length; i++) {
                String key = keyset[i];
                if (key.length() &gt; 0) {
                    indexFile = putKey(indexFile, msg, buildKey(topic, key));
                    if (indexFile == null) {
                        LOGGER.error(&quot;putKey error commitlog {} uniqkey {}&quot;, req.getCommitLogOffset(), req.getUniqKey());
                        return;
                    }
                }
            }
        }
    } else {
        LOGGER.error(&quot;build index error, stop building index&quot;);
    }
}
</code></pre>
<h2 id="47-消息队列与索引文件恢复">4.7 消息队列与索引文件恢复</h2>
<p>RocketMQ存储首先将消息全量存储在Commitlog文件中，然后异步生成转发任务更新ConsumeQueue、Index文件。 如果消息成功存储到 Commitlog 文件中，转发任务未成功执行，此时消息服务器Broker由于某个原因宕机，导致Commitlog、ConsumeQueue、IndexFile文件数据不一致。如果不加以人工修复的话，会有一部分消息即便在Commitlog文件中存在，但由于并没有转发到 Consumequeue，这部分消息将永远不会被消费者消费 。 那RocketMQ 是如何使Commitlog、消息消费队列(ConsumeQueue)达到最终一致性的呢?</p>
<p>Step1:判断上一次退出是否正常。</p>
<p>其实现机制是Broker在启动时创建${ROC口T_ HOME}/store/abort文件，在退出时通过注册JVM钩子函数删除abort文件。如果下一次启动时存在abort文件。说明Broker是异常退出的 Commitlog与Consumequeue 数据有可能不一致，需要进行修复。</p>
<blockquote>
<p>isTempFileExist</p>
</blockquote>
<pre><code class="language-java">private boolean isTempFileExist() {
    String fileName = StorePathConfigHelper.getAbortFile(this.messageStoreConfig.getStorePathRootDir());
    File file = new File(fileName);
    return file.exists();
}
</code></pre>
<p>Step2:加载延迟队列</p>
<p>Step3 :加载Commitlog文件</p>
<blockquote>
<p>MappedFileQueue#doLoad</p>
</blockquote>
<pre><code class="language-java">public boolean doLoad(List&lt;File&gt; files) {
    // ascending order
    files.sort(Comparator.comparing(File::getName));

    for (File file : files) {
        //如果文件大小与配置文件的单个文件大小不一致，将忽略该目录下所有文件，
        if (file.length() != this.mappedFileSize) {
            log.warn(file + &quot;\t&quot; + file.length()
                    + &quot; length not matched message store config value, please check it manually&quot;);
            return false;
        }

        try {
            MappedFile mappedFile = new DefaultMappedFile(file.getPath(), mappedFileSize);
            //指针都设置为文件大小
            mappedFile.setWrotePosition(this.mappedFileSize);
            mappedFile.setFlushedPosition(this.mappedFileSize);
            mappedFile.setCommittedPosition(this.mappedFileSize);
            this.mappedFiles.add(mappedFile);
            log.info(&quot;load &quot; + file.getPath() + &quot; OK&quot;);
        } catch (IOException e) {
            log.error(&quot;load file &quot; + file + &quot; error&quot;, e);
            return false;
        }
    }
    return true;
}
</code></pre>
<p>Step4 :加载消息消费队列</p>
<p>Steps :加载存储检测点，检测点主要记录commitlog文件、Consumequeue文件、Index索引文件的刷盘点，将在下文的文件刷盘机制中再次提交。</p>
<blockquote>
<p>加载存储检测点</p>
</blockquote>
<pre><code class="language-java">this.storeCheckpoint =
    new StoreCheckpoint(StorePathConfigHelper.getStoreCheckpoint(this.messageStoreConfig.getStorePathRootDir()));
this.masterFlushedOffset = this.storeCheckpoint.getMasterFlushedOffset();
this.indexService.load(lastExitOK);
</code></pre>
<p>Step6 :加载索引文件，如果上次异常退出，而且索引文件上次刷盘时间小于该索引文件最大的消息时间戳该文件将立即销毁。</p>
<blockquote>
<p>this.indexService.load(lastExitOK);</p>
</blockquote>
<pre><code class="language-java">public boolean load(final boolean lastExitOK) {
    File dir = new File(this.storePath);
    File[] files = dir.listFiles();
    if (files != null) {
        // ascending order
        Arrays.sort(files);
        for (File file : files) {
            try {
                IndexFile f = new IndexFile(file.getPath(), this.hashSlotNum, this.indexNum, 0, 0);
                f.load();

                if (!lastExitOK) {
                    if (f.getEndTimestamp() &gt; this.defaultMessageStore.getStoreCheckpoint()
                        .getIndexMsgTimestamp()) {
                        f.destroy(0);
                        continue;
                    }
                }
                this.indexFileList.add(f);
            } catch (IOException e) {
                return false;
            } catch (NumberFormatException e) {
            }
        }
    }
    return true;
}
</code></pre>
<p>Step7 :根据Broker是否是正常停止执行不同的恢复策略</p>
<blockquote>
<p>恢复策略</p>
</blockquote>
<pre><code class="language-java">private void recover(final boolean lastExitOK) {
    long recoverCqStart = System.currentTimeMillis();
    long maxPhyOffsetOfConsumeQueue = this.recoverConsumeQueue();
    long recoverCqEnd = System.currentTimeMillis();

    if (lastExitOK) {
        this.commitLog.recoverNormally(maxPhyOffsetOfConsumeQueue);
    } else {
        this.commitLog.recoverAbnormally(maxPhyOffsetOfConsumeQueue);
    }
    long recoverClogEnd = System.currentTimeMillis();
    this.recoverTopicQueueTable();
    long recoverOffsetEnd = System.currentTimeMillis();
}
</code></pre>
<p>Step8:恢复 ConsumeQueue 文件后，将在CommitLog实例中保存每个消息消费队列当前的存储逻辑偏移量</p>
<h3 id="471-broker-正常停止文件恢复">4.7.1 Broker 正常停止文件恢复</h3>
<p>Step1 : Broker正常停止再重启时，从倒数第三个文件开始进行恢复，如果不足3个文件，则从第一个文件开始恢复。checkCRCOnRecover参数设置在进行文件恢复时查找消息时是否验证CRC。</p>
<p>Step2:遍历Commitlog文件，每次取出一条消息， 如果查找结果为true并且消息的长度大于0表示消 息正确，mappedFileOffset 指针向前移动本条消 息的长 度; 如果查找结果为true并且消息的长度等于0，表示已到该文件的末尾，如果还有下一个文件，则重置processOffset、mappedFileOffset重复步骤3，否则跳出循环; 如果查找结构为false，表明该文件未填满所有消息，跳出循环，结束遍历文件。</p>
<p>Step3: 更新MappedFileQueue的flushedWhere与commiteedWhere指针</p>
<p>Step4:删除offset之后的所有文件</p>
<h3 id="472-broker-异常停止文件恢复">4.7.2 Broker 异常停止文件恢复</h3>
<p>异常文件恢复的 步骤与正常停止文件恢复的流程基本相同，其主要差别有两个。首先正常停止默认从倒数第三个文件开始进行恢复，而异常停止则需要从最后一个文件往前走，找到第一个消息存储正常的文件 。 其次，如果commitlog目录没有消息文件，如果在消息消费队列目录下存在文件，则需要销毁。</p>
<p>如何判断一个消息文件是一个正确的文件呢?</p>
<p>Step1 :首先判断文件的魔数，如果不是MESSAGE MAGIC_CODE，返回false，表示该文件不符合commitlog消息文件的存储格式。</p>
<blockquote>
<p>isMappedFileMatchedRecover</p>
</blockquote>
<pre><code class="language-java">int magicCode = byteBuffer.getInt(MessageDecoder.MESSAGE_MAGIC_CODE_POSITION);
if (magicCode != MESSAGE_MAGIC_CODE) {
    return false;
}
</code></pre>
<p>Step2 :如果文件中第一条消息的存储时间等于0，返回false，说明该消息存储文件中未存储任何消息。<br>
Step3 :对比文件第一条消息的时间戳与检测点,文件第一条消息的时间戳小于文件检测点说明该文件部分消息是可靠的，则从该文件开始恢复。<br>
Step4 :如果根据前3步算法找 到 MappedFile，则遍历MappedFile中的消息，验证消息的合法性，并将消息重新转发到消息消费队列与索引文件<br>
Step5 :如果未找到有效 MappedFile，则设置commitlog目录的flushedWhere、committed­Where指针都为0，并销毁消息消费队列文件。</p>
<h2 id="48-文件刷盘机制">4.8 文件刷盘机制</h2>
<p>RocketMQ 的存储与读写是基于 JDK NIO 的内存映射机制，消息存储时首先将消息追加到内存，再根据配置的刷盘策略在不同时间进行刷写磁盘。如果是同步刷盘，消息追加到内存后，将同步调用MappedByteBuffer的force()方法;如果是异步刷盘，在消息追加到内存后立刻返回给消息发送端。RocketMQ使用一个单独的线程按照某一个设定的频率执行刷盘操作。</p>
<p><em>索引文件的刷盘并不是采取定时刷盘机制，而是每更新一次索引文件就会将上一次的改动刷写到磁盘</em></p>
<h3 id="481-broker-同步刷盘">4.8.1 Broker 同步刷盘</h3>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMq技术内幕笔记（二）]]></title>
        <id>https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-er/</id>
        <link href="https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-er/">
        </link>
        <updated>2022-09-13T11:18:59.000Z</updated>
        <summary type="html"><![CDATA[<h1 id="3-消息发送">3 消息发送</h1>
<p>RocketMQ 发送普通消息有 三 种实现方式:可靠同步发送 、 可靠异步发送 、 单向 (Oneway)发送。</p>
]]></summary>
        <content type="html"><![CDATA[<h1 id="3-消息发送">3 消息发送</h1>
<p>RocketMQ 发送普通消息有 三 种实现方式:可靠同步发送 、 可靠异步发送 、 单向 (Oneway)发送。</p>
<!-- more -->
<h2 id="31-rocketmq-消息发送">3.1 RocketMQ 消息发送</h2>
<p>RocketMQ 支持 3 种消息发送方式 :同步(sync)、 异步(async)、单向(oneway)。<br>
同步 : 发送者向 MQ 执行发送消息 API 时，同步等待， 直到消息服务器返回发送结果 。<br>
异步 : 发送者向 MQ 执行发送消息 API 时，调用消息发送Api后，立即返回，消息发送者线程不阻塞，直到运行结束，消息发送成功或失败的回调任务在一个新的线程中执行。<br>
单向:消息发送者向 MQ 执行发送消息 API时，直接返回，不等待消息服务器的结果，也不注册回调函数，简单地说，就是只管发，不在乎消息是否成功存储在消息服务器上 。</p>
<h2 id="32-认识rocketmq消息">3.2 认识RocketMQ消息</h2>
<p>RocketMQ 消息封装类是 org.apache.rocketmq.common.message.Message。</p>
<pre><code class="language-java">public class Message implements Serializable {
    private static final long serialVersionUID = 8445773977080406428L;

    private String topic;
    private int flag;
    private Map&lt;String, String&gt; properties;
    private byte[] body;
    private String transactionId;
}
</code></pre>
<p>Message 扩展属性主要包含下面几个 。<br>
tag:消息TAG，用于消息过滤 。<br>
keys: Message索引键，多个用空格隔开，RocketMQ可以根据这些 key快速检索到消息 。 waitStoreMsgOK:消息发送时是否等消息存储完成后再返回 。<br>
delayTimeLevel: 消息延迟级别，用于定时消息或消息重试 。</p>
<h2 id="33-生产者启动流程">3.3 生产者启动流程</h2>
<h3 id="331-初识-defaultmqproducer-消息发送者">3.3.1 初识 DefaultMQProducer 消息发送者</h3>
<p>DefaultMQProducer是默认的消息生产者实现类，它实现 MQAdmin 的接口。其主要接口有：</p>
<pre><code class="language-java">/**
    * @param key accesskey
    * @param newTopic 主题名称
    * @param queueNum 队列数量
    * @param topicSysFlag 主题系统标签，默认为0
    * @param attributes
    * @throws MQClientException if there is any client error.
    */
@Deprecated
@Override
public void createTopic(String key, String newTopic, int queueNum, int topicSysFlag, Map&lt;String, String&gt; attributes) throws MQClientException {
    this.defaultMQProducerImpl.createTopic(key, withNamespace(newTopic), queueNum, topicSysFlag);
}

/**
    * 根据 时间 戳从队列中查找其偏移量
    */
@Override
public long searchOffset(MessageQueue mq, long timestamp) throws MQClientException {
    return this.defaultMQProducerImpl.searchOffset(queueWithNamespace(mq), timestamp);
}

/**
    * 查找该消息 队列中 最大的物理偏移量
    */
@Deprecated
@Override
public long maxOffset(MessageQueue mq) throws MQClientException {
    return this.defaultMQProducerImpl.maxOffset(queueWithNamespace(mq));
}

/**
    * 查找该消息队列中最小物理偏移量
    */
@Deprecated
@Override
public long minOffset(MessageQueue mq) throws MQClientException {
    return this.defaultMQProducerImpl.minOffset(queueWithNamespace(mq));
}


/**
    * 根据消息偏移量查找消息
    */
@Deprecated
@Override
public MessageExt viewMessage(
    String offsetMsgId) throws RemotingException, MQBrokerException, InterruptedException, MQClientException {
    return this.defaultMQProducerImpl.viewMessage(offsetMsgId);
}

/**
    * 根据条件查询消息
    * @param topic message topic
    * @param key message key index word  消息索引字段
    * @param maxNum max message number 本次最多取出消息条数。
    * @param begin from when 开始时间
    * @param end to when 结束时间
    */
@Deprecated
@Override
public QueryResult queryMessage(String topic, String key, int maxNum, long begin, long end)
    throws MQClientException, InterruptedException {
    return this.defaultMQProducerImpl.queryMessage(withNamespace(topic), key, maxNum, begin, end);
}

    /**
    * 根据主题与消息 ID 查找消息
    * @throws InterruptedException if the sending thread is interrupted.
    */
@Deprecated
@Override
public MessageExt viewMessage(String topic,
    String msgId) throws RemotingException, MQBrokerException, InterruptedException, MQClientException {
    try {
        return this.viewMessage(msgId);
    } catch (Exception ignored) {
    }
    return this.defaultMQProducerImpl.queryMessageByUniqKey(withNamespace(topic), msgId);
}

/**
    * 查找该主题下所有的消息队列
    */
@Override
public List&lt;MessageQueue&gt; fetchPublishMessageQueues(String topic) throws MQClientException {
    return this.defaultMQProducerImpl.fetchPublishMessageQueues(withNamespace(topic));
}

    /**
    * 同步发送消息，具体发送到主题中的哪个消息队列由负载算法决定
    */
@Override
public SendResult send(
    Message msg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    return this.defaultMQProducerImpl.send(msg);
}

/**
    * 同步发送消息，如果发送超过 timeout 则抛出超时异常
    */
@Override
public SendResult send(Message msg,
    long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    return this.defaultMQProducerImpl.send(msg, timeout);
}

/**
    * 异步发送消息， sendCallback参数是消息发送成功后的回调方法 
    */
@Override
public void send(Message msg,
    SendCallback sendCallback) throws MQClientException, RemotingException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    this.defaultMQProducerImpl.send(msg, sendCallback);
}

/**
    * 异步发送消息 ，如果发送超过 timeout指定的值，则抛出超时异常
    */
@Override
public void send(Message msg, SendCallback sendCallback, long timeout)
    throws MQClientException, RemotingException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    this.defaultMQProducerImpl.send(msg, sendCallback, timeout);
}

    /**
    * 单向消息发送，就是不在乎发送结果，消息发送出去后该方法立即返回
    */
@Override
public void sendOneway(Message msg) throws MQClientException, RemotingException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    this.defaultMQProducerImpl.sendOneway(msg);
}

/**
    * 同步方式发送消息，发送到指定消息队列
    */
@Override
public SendResult send(Message msg, MessageQueue mq)
    throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    return this.defaultMQProducerImpl.send(msg, queueWithNamespace(mq));
}

/**
    * 同步方式发送消息，发送到指定消息队列 超时异常
    */
@Override
public SendResult send(Message msg, MessageQueue mq, long timeout)
    throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    return this.defaultMQProducerImpl.send(msg, queueWithNamespace(mq), timeout);
}

/**
    * 异步方式发送消息，发送到指定消息 队列 
    */
@Override
public void send(Message msg, MessageQueue mq, SendCallback sendCallback)
    throws MQClientException, RemotingException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    this.defaultMQProducerImpl.send(msg, queueWithNamespace(mq), sendCallback);
}

/**
    * 异步方式发送消息，发送到指定消息队列 超时异常
    */
@Override
public void send(Message msg, MessageQueue mq, SendCallback sendCallback, long timeout)
    throws MQClientException, RemotingException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    this.defaultMQProducerImpl.send(msg, queueWithNamespace(mq), sendCallback, timeout);
}

/**
    * 单向方式发送消息，发送到指定的消息队列
    */
@Override
public void sendOneway(Message msg,
    MessageQueue mq) throws MQClientException, RemotingException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    this.defaultMQProducerImpl.sendOneway(msg, queueWithNamespace(mq));
}

/**
    * 消息发送，指定消息选择算法，覆盖消息生产者默认的消息队列负载
    */
@Override
public SendResult send(Message msg, MessageQueueSelector selector, Object arg)
    throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    return this.defaultMQProducerImpl.send(msg, selector, arg);
}

/**
    * 同步批量消息发送
    */
@Override
public SendResult send(Collection&lt;Message&gt; msgs, MessageQueue messageQueue,
    long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    return this.defaultMQProducerImpl.send(batch(msgs), messageQueue, timeout);
}
</code></pre>
<blockquote>
<p>DefaultMQProducer核心属性</p>
</blockquote>
<pre><code class="language-java"> /**
    * 生产者所属组，消息服务器在回查事务状态时会随机选择该组中任何一个生产者发起事务回查请求 
    */
private String producerGroup;

/**
    * 默认 topicKey。
    */
private String createTopicKey = TopicValidator.AUTO_CREATE_TOPIC_KEY_TOPIC;

/**
    * 默认主题在每一个 Broker 队列数量。
    */
private volatile int defaultTopicQueueNums = 4;

/**
    * 发送消息默认超时时间， 默认 3s。
    */
private int sendMsgTimeout = 3000;

/**
    * 消息体超过该值则启用压缩，默认 4K。
    */
private int compressMsgBodyOverHowmuch = 1024 * 4;

/**
    *
    * 同 步方式发送消息重试次数，默认为 2，总共执行 3 次 。
    */
private int retryTimesWhenSendFailed = 2;

/**
    * 异步方式发送消息重试次数，默认为 2。
    */
private int retryTimesWhenSendAsyncFailed = 2;

/**
    * 消息重试时选择另外一个 Broker时是否不等 待存储结果就返回 ， 默认为 false。
    */
private boolean retryAnotherBrokerWhenNotStoreOK = false;

/**
    * 允许发送的最大消息长度，默认为 4M，眩值最大值为 2&quot;32-1
    */
private int maxMessageSize = 1024 * 1024 * 4; // 4M
</code></pre>
<h3 id="332-消息生产者启动流程">3.3.2 消息生产者启动流程</h3>
<p>消息生产者启动主要从DefaultMQProducerlmpl的start方法开始。</p>
<pre><code class="language-java">public void start(final boolean startFactory) throws MQClientException {
    switch (this.serviceState) {
        case CREATE_JUST:
            this.serviceState = ServiceState.START_FAILED;

//Step1:检查productGroup是否符合要求;并改变生产者的 instanceName为进程 ID。
            this.checkConfig();
            if (!this.defaultMQProducer.getProducerGroup().equals(MixAll.CLIENT_INNER_PRODUCER_GROUP)) {
                this.defaultMQProducer.changeInstanceNameToPID();
            }

 // /Step2 :创建 MQClientInstance实例。 整个JVM 实例中只存在一个 MQClientManager实例，维护一个MQClientInstance缓存表 ConcurrentMap&lt;String/*clientId灯，MQClientInstance&gt; factoryTable =new ConcurrentHashMap&lt;String， MQClientInstance&gt;()，也就是 同一个 clientId只 会创建一个 MQClientInstance。
            this.mQClientFactory = MQClientManager.getInstance().getOrCreateMQClientInstance(this.defaultMQProducer, rpcHook);


//Step3 :向 MQClientlnstance注册，将当前生产者加入到 MQClientlnstance管理中，方 便后续调用网络请求、进行心跳检测等。
//Step4 : 启动 MQClientlnstance，如果 MQC!ientlnstance 已经启动 ，则本次启 动不会真 正执行。
            boolean registerOK = mQClientFactory.registerProducer(this.defaultMQProducer.getProducerGroup(), this);
            if (!registerOK) {
                this.serviceState = ServiceState.CREATE_JUST;
                throw new MQClientException(&quot;The producer group[&quot; + this.defaultMQProducer.getProducerGroup()
                    + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL),
                    null);
            }

            this.topicPublishInfoTable.put(this.defaultMQProducer.getCreateTopicKey(), new TopicPublishInfo());

            if (startFactory) {
                mQClientFactory.start();
            }

            log.info(&quot;the producer [{}] start OK. sendMessageWithVIPChannel={}&quot;, this.defaultMQProducer.getProducerGroup(),
                this.defaultMQProducer.isSendMessageWithVIPChannel());
            this.serviceState = ServiceState.RUNNING;
            break;
        case RUNNING:
        case START_FAILED:
        case SHUTDOWN_ALREADY:
            throw new MQClientException(&quot;The producer service state not OK, maybe started once, &quot;
                + this.serviceState
                + FAQUrl.suggestTodo(FAQUrl.CLIENT_SERVICE_NOT_OK),
                null);
        default:
            break;
    }

    this.mQClientFactory.sendHeartbeatToAllBrokerWithLock();

    RequestFutureHolder.getInstance().startScheduledTask(this);

}
</code></pre>
<blockquote>
<p>MQClientManager</p>
</blockquote>
<pre><code class="language-java">public MQClientInstance getOrCreateMQClientInstance(final ClientConfig clientConfig, RPCHook rpcHook) {
    String clientId = clientConfig.buildMQClientId();
    MQClientInstance instance = this.factoryTable.get(clientId);
    if (null == instance) {
        instance =
            new MQClientInstance(clientConfig.cloneClientConfig(),
                this.factoryIndexGenerator.getAndIncrement(), clientId, rpcHook);
        MQClientInstance prev = this.factoryTable.putIfAbsent(clientId, instance);
        if (prev != null) {
            instance = prev;
            log.warn(&quot;Returned Previous MQClientInstance for clientId:[{}]&quot;, clientId);
        } else {
            log.info(&quot;Created new MQClientInstance for clientId:[{}]&quot;, clientId);
        }
    }

    return instance;
}
</code></pre>
<h2 id="34-消息发送基本流程">3.4 消息发送基本流程</h2>
<p>消息发送流程主要的步骤:验证消息、查找路由 、 消息发送 (包含异常处理机制) 。</p>
<blockquote>
<p>同步消息发送入口</p>
</blockquote>
<pre><code class="language-java">//DefaultMQProducer
public SendResult send(
    Message msg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    return this.defaultMQProducerImpl.send(msg);
}

//DefaultMQProducerImpl
public SendResult send(Message msg,
    long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    return this.sendDefaultImpl(msg, CommunicationMode.SYNC, null, timeout);
}
</code></pre>
<h3 id="341-消息长度验证">3.4.1 消息长度验证</h3>
<p>消息发送之前，首先确保生产者处于运行状态，然后验证消息是否符合相应的规范，具体的规范要求是主题名称、消息体不能为空、消息长度不能等于 0且默认不能超过允许 发送消息的最大长度 4M (maxMessageSize=1024 *1024 *4)。</p>
<pre><code class="language-java">public static void checkMessage(Message msg, DefaultMQProducer defaultMQProducer) throws MQClientException {
    if (null == msg) {
        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message is null&quot;);
    }
    // topic
    Validators.checkTopic(msg.getTopic());
    Validators.isNotAllowedSendTopic(msg.getTopic());

    // body
    if (null == msg.getBody()) {
        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message body is null&quot;);
    }

    if (0 == msg.getBody().length) {
        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message body length is zero&quot;);
    }

    if (msg.getBody().length &gt; defaultMQProducer.getMaxMessageSize()) {
        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL,
            &quot;the message body size over max value, MAX: &quot; + defaultMQProducer.getMaxMessageSize());
    }
}
</code></pre>
<h3 id="342-查找主题路由信息">3.4.2 查找主题路由信息</h3>
<p>消息发送之前，首先需要获取主题的路由信息，确认发送到具体的 Broker节点。。</p>
<pre><code class="language-java">private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) {
    TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic);
    if (null == topicPublishInfo || !topicPublishInfo.ok()) {
        this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo());
        this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic);
        topicPublishInfo = this.topicPublishInfoTable.get(topic);
    }

    if (topicPublishInfo.isHaveTopicRouterInfo() || topicPublishInfo.ok()) {
        return topicPublishInfo;
    } else {
        this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic, true, this.defaultMQProducer);
        topicPublishInfo = this.topicPublishInfoTable.get(topic);
        return topicPublishInfo;
    }
}
</code></pre>
<p>tryToFindTopicPublishlnfo是查找主题的路由信息的方法。如果生产者中缓存了 topic 的路由信息，如果该路由信息中包含了消息队列，则直接返回该路由信息，如果没有缓存或没有包含消息队列， 则向 NameServer查询该topic的路由信息。如果最终未找到路由信息，则抛出异常 : 无法找到主题相关路由信息异常。</p>
<blockquote>
<p>TopicPublishInfo</p>
</blockquote>
<pre><code class="language-java">public class TopicPublishInfo {
    private boolean orderTopic = false; //是否是顺序消息
    private boolean haveTopicRouterInfo = false; 
    private List&lt;MessageQueue&gt; messageQueueList = new ArrayList&lt;MessageQueue&gt;();  //该主题队列的消息队列
    private volatile ThreadLocalIndex sendWhichQueue = new ThreadLocalIndex(); // 每选择一次消息 队列， 该值会自增 l，如果 Integer.MAX_VALUE,则重置为 0，用于选择消息队列。
    private TopicRouteData topicRouteData;
}

public class TopicRouteData extends RemotingSerializable {
    private String orderTopicConf;
    private List&lt;QueueData&gt; queueDatas; //topic 队列元数据 。
    private List&lt;BrokerData&gt; brokerDatas; //topic 分布的 broker元数据 
    private HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable; //broker 上过滤服务器地址列表。
    //It could be null or empty
    private Map&lt;String/*brokerName*/, TopicQueueMappingInfo&gt; topicQueueMappingByBroker;
}
</code></pre>
<p>第一次发送消息时，本地没有缓存 topic 的路由信息，查询NameServer尝试获取，如果路由信息未找到，再次尝试用默认主题 DefaultMQProducerlmpl#createTopicKey去查询，如果 BrokerConfig#autoCreateTopicEnable为true时，NameServer将返回路由信息，如果 autoCreateTopicEnable为false将抛出无法找到topic路由异常。</p>
<blockquote>
<p>updateTopicRouteInfoFromNameServer</p>
</blockquote>
<pre><code class="language-java">public boolean updateTopicRouteInfoFromNameServer(final String topic, boolean isDefault,
    DefaultMQProducer defaultMQProducer) {
    try {
        //获取锁
        if (this.lockNamesrv.tryLock(LOCK_TIMEOUT_MILLIS, TimeUnit.MILLISECONDS)) {
            try {
//Step 1 :如果isDefault为true，则使用默认主题去查询，如果查询到路由信息，
// 则替换路由信息中读写队列个数为消息生产者默认的队列个数(defaultTopicQueueNums);如果
// isDefault为false，则使用参数 topic去查询;如果未查询到路由信息，则返回false，表示路由信息未变化
                TopicRouteData topicRouteData;
                if (isDefault &amp;&amp; defaultMQProducer != null) {
                    topicRouteData = this.mQClientAPIImpl.getDefaultTopicRouteInfoFromNameServer(defaultMQProducer.getCreateTopicKey(),
                        clientConfig.getMqClientApiTimeout());
                    if (topicRouteData != null) {
                        for (QueueData data : topicRouteData.getQueueDatas()) {
                            int queueNums = Math.min(defaultMQProducer.getDefaultTopicQueueNums(), data.getReadQueueNums());
                            data.setReadQueueNums(queueNums);
                            data.setWriteQueueNums(queueNums);
                        }
                    }
                } else {
                    topicRouteData = this.mQClientAPIImpl.getTopicRouteInfoFromNameServer(topic, clientConfig.getMqClientApiTimeout());
                }
                if (topicRouteData != null) {
                    TopicRouteData old = this.topicRouteTable.get(topic);
                      //Step2:如果路由信息找到，与本地缓存中的路由信息进行对比，判断路由信息是否发生了改变，如果未发生变化，则直接返回false。
                    boolean changed = topicRouteData.topicRouteDataChanged(old);
                    if (!changed) {
                        changed = this.isNeedUpdateTopicRouteInfo(topic);
                    } else {
                        log.info(&quot;the topic[{}] route info changed, old[{}] ,new[{}]&quot;, topic, old, topicRouteData);
                    }

      //Step3:更新 MQClientInstanceBroker地址缓存表。
                    if (changed) {
                        for (BrokerData bd : topicRouteData.getBrokerDatas()) {
                            this.brokerAddrTable.put(bd.getBrokerName(), bd.getBrokerAddrs());
                        }

                        // Update endpoint map
                        {
                            ConcurrentMap&lt;MessageQueue, String&gt; mqEndPoints = topicRouteData2EndpointsForStaticTopic(topic, topicRouteData);
                            if (!mqEndPoints.isEmpty()) {
                                topicEndPointsTable.put(topic, mqEndPoints);
                            }
                        }

                        // Update Pub info
                        {
                            TopicPublishInfo publishInfo = topicRouteData2TopicPublishInfo(topic, topicRouteData);
                            publishInfo.setHaveTopicRouterInfo(true);
                            for (Entry&lt;String, MQProducerInner&gt; entry : this.producerTable.entrySet()) {
                                MQProducerInner impl = entry.getValue();
                                if (impl != null) {
                                    impl.updateTopicPublishInfo(topic, publishInfo);
                                }
                            }
                        }

// step 4:根据 topicRouteData中的 List&lt;QueueData&gt;转换成topicPublishInfo的 List&lt;MessageQueue&gt;
//列表。其具体实现在topicRouteData2TopicPublishInfo， 然后会更新该 MQClientInstance所管辖的所有消息发送关于topic的路由信息
                        if (!consumerTable.isEmpty()) {
                            Set&lt;MessageQueue&gt; subscribeInfo = topicRouteData2TopicSubscribeInfo(topic, topicRouteData);
                            for (Entry&lt;String, MQConsumerInner&gt; entry : this.consumerTable.entrySet()) {
                                MQConsumerInner impl = entry.getValue();
                                if (impl != null) {
                                    impl.updateTopicSubscribeInfo(topic, subscribeInfo);
                                }
                            }
                        }
                        TopicRouteData cloneTopicRouteData = new TopicRouteData(topicRouteData);
                        log.info(&quot;topicRouteTable.put. Topic = {}, TopicRouteData[{}]&quot;, topic, cloneTopicRouteData);
                        this.topicRouteTable.put(topic, cloneTopicRouteData);
                        return true;
                    }
                } else {
                    log.warn(&quot;updateTopicRouteInfoFromNameServer, getTopicRouteInfoFromNameServer return null, Topic: {}. [{}]&quot;, topic, this.clientId);
                }
            } catch (MQClientException e) {
                if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX) &amp;&amp; !topic.equals(TopicValidator.AUTO_CREATE_TOPIC_KEY_TOPIC)) {
                    log.warn(&quot;updateTopicRouteInfoFromNameServer Exception&quot;, e);
                }
            } catch (RemotingException e) {
                log.error(&quot;updateTopicRouteInfoFromNameServer Exception&quot;, e);
                throw new IllegalStateException(e);
            } finally {
                this.lockNamesrv.unlock();
            }
        } else {
            log.warn(&quot;updateTopicRouteInfoFromNameServer tryLock timeout {}ms. [{}]&quot;, LOCK_TIMEOUT_MILLIS, this.clientId);
        }
    } catch (InterruptedException e) {
        log.warn(&quot;updateTopicRouteInfoFromNameServer Exception&quot;, e);
    }

    return false;
}
</code></pre>
<p>循环遍历路由信息的QueueData 信息，如果队列没有写权限，则继续遍历下一个QueueData ，根据 topic+序号创建 MessageQueue，填充 topicPublishlnfo的List<QuueMessage>。 完成消息发送的路由查找 。</p>
<blockquote>
<p>topicRouteData2TopicSubscribeInfo</p>
</blockquote>
<pre><code class="language-java">public static Set&lt;MessageQueue&gt; topicRouteData2TopicSubscribeInfo(final String topic, final TopicRouteData route) {
    Set&lt;MessageQueue&gt; mqList = new HashSet&lt;&gt;();
    if (route.getTopicQueueMappingByBroker() != null
            &amp;&amp; !route.getTopicQueueMappingByBroker().isEmpty()) {
        ConcurrentMap&lt;MessageQueue, String&gt; mqEndPoints = topicRouteData2EndpointsForStaticTopic(topic, route);
        return mqEndPoints.keySet();
    }
    List&lt;QueueData&gt; qds = route.getQueueDatas();
    for (QueueData qd : qds) {
        if (PermName.isReadable(qd.getPerm())) {
            for (int i = 0; i &lt; qd.getReadQueueNums(); i++) {
                MessageQueue mq = new MessageQueue(topic, qd.getBrokerName(), i);
                mqList.add(mq);
            }
        }
    }

    return mqList;
}
</code></pre>
<h3 id="343-选择消息队列">3.4.3 选择消息队列</h3>
<p>首先消息发送端采用重试机制 ，由retryTimesWhenSendFailed指定同步方式重试次数，异步重试机制在收到消息发送结构后执行回调之前进行重试。由retryTimesWhenSend-AsyncFailed指定，接下来就是循环执行，选择消息队列、发送消息，发送成功则返回，收到异常则重试。选择消息队列有两种方式。</p>
<p>1 ) sendLatencyFaultEnable=false，默认不启用Broker故障延迟机制。<br>
2 ) sendLatencyFaultEnable=true，启用Broker故障延迟机制。</p>
<h4 id="1-默认机制">1. 默认机制</h4>
<pre><code class="language-java">public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) {
    //判断启用不启用Broker故障延迟机制
    if (this.sendLatencyFaultEnable) {
        try {
            int index = tpInfo.getSendWhichQueue().incrementAndGet();
            for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) {
                int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size();
                if (pos &lt; 0)
                    pos = 0;
                MessageQueue mq = tpInfo.getMessageQueueList().get(pos);
                //验证该消息队列是否可用
                if (latencyFaultTolerance.isAvailable(mq.getBrokerName()))
                    return mq;
            }

            final String notBestBroker = latencyFaultTolerance.pickOneAtLeast();
            int writeQueueNums = tpInfo.getQueueIdByBroker(notBestBroker);
            if (writeQueueNums &gt; 0) {
                final MessageQueue mq = tpInfo.selectOneMessageQueue();
                if (notBestBroker != null) {
                    mq.setBrokerName(notBestBroker);
                    mq.setQueueId(tpInfo.getSendWhichQueue().incrementAndGet() % writeQueueNums);
                }
                return mq;
            } else {
                latencyFaultTolerance.remove(notBestBroker);
            }
        } catch (Exception e) {
            log.error(&quot;Error occurred when selecting message queue&quot;, e);
        }

        return tpInfo.selectOneMessageQueue();
    }
    //不启用Broker故障延迟机制
    return tpInfo.selectOneMessageQueue(lastBrokerName);
}
</code></pre>
<blockquote>
<p>TopicPublishInfo 启用Broker故障延迟机制</p>
</blockquote>
<pre><code class="language-java">public MessageQueue selectOneMessageQueue(final String lastBrokerName) {
    if (lastBrokerName == null) {
        return selectOneMessageQueue();
    } else {
        for (int i = 0; i &lt; this.messageQueueList.size(); i++) {
            int index = this.sendWhichQueue.incrementAndGet();
            int pos = Math.abs(index) % this.messageQueueList.size();
            if (pos &lt; 0)
                pos = 0;
            MessageQueue mq = this.messageQueueList.get(pos);
            if (!mq.getBrokerName().equals(lastBrokerName)) {
                return mq;
            }
        }
        return selectOneMessageQueue();
    }
}

public MessageQueue selectOneMessageQueue() {
    int index = this.sendWhichQueue.incrementAndGet();
    int pos = Math.abs(index) % this.messageQueueList.size();
    if (pos &lt; 0)
        pos = 0;
    return this.messageQueueList.get(pos);
}
</code></pre>
<p>首先在一次消息发送过程中，可能会多次执行选择消息队列这个方法，lastBrokerName就是上一次选择的执行发送消息失败的Broker。第一次执行消息队列选择时，lastBrokerName为null，此时直接用 sendWhichQueue自增再获取值，与当前路由表中消息队列个数取模，返回该位置的MessageQueue(selectOneMessageQueue()方法)，如果消息发送再失败的话，下次进行消息队列选择时规避上次 MesageQueue所在的Broker，否则还是很有可能再次失败。</p>
<p>该算法在一次消息发送过程中能成功规避故障的Broker，但如果 Broker若机，由于路 由算法中的消息队列是按 Broker排序的，如果上一次根据路由算法选择的是若机的Broker的第一个队列，那么随后的下次选择的是若机Broker的第二个队列，消息发送很有可能会失败，再次引发重试，带来不必要的性能损耗。</p>
<p>Broker不可用后，路由信息中为什么还会包含该 Broker的路由信息呢?其实这不难解释:首先， NameServer 检测Broker是否可用是有延迟的，最短为一次心跳检测间隔(10s); 其次，NameServer不会 检测到 Broker岩机后马上推送消息给消息生产者，而是消息生产者每隔 30s更新一次路由信息，所以消息生产者最快感知Broker最新的路由信息也需要30s。如果能引人一种机制，在 Broker若机期间，如果一次消息发送失败后，可以将该 Broker暂时排除在消息队列的选择范围中。</p>
<h4 id="2-broker故障延迟机制">2. Broker故障延迟机制</h4>
<p>代码如上</p>
<p>1 )根据对消息队列进行轮询获取一个消息队列 。<br>
2)验证该消息队列是否可用，latencyFaultTolerance.isAvailable(mq.getBrokerName())<br>
3)如果返回的 MessageQueue可用， 移除latencyFaultTolerance关于该topic条目， 表<br>
明该Broker故障已经恢复。</p>
<p><strong>Broker故障延迟机制核心类-LatencyFaultTolerance</strong></p>
<pre><code class="language-java">public interface LatencyFaultTolerance&lt;T&gt; {
    /**
     * 更新失败条目
     * @param name brokerName
     * @param currentLatency 消息发送故障延迟时间
     * @param notAvailableDuration 不可用持续时辰，在这个时间内Broker将被规避
     */
    void updateFaultItem(final T name, final long currentLatency, final long notAvailableDuration);

    /**
     * 判断 Broker是否可用
     * @param name
     * @return
     */
    boolean isAvailable(final T name);

    /**
     * 移除Fault条目，意味着Broker重新参与路由计算
     * @param name
     */
    void remove(final T name);

    /**
     * 尝试从规避的Broker中选择一个可用的Broker，如果没有找到，将返回null
     * @return
     */
    T pickOneAtLeast();
}
</code></pre>
<p><strong>Faultltem: 失败条目(规避规则条目)</strong></p>
<pre><code class="language-java">class FaultItem implements Comparable&lt;FaultItem&gt; {
    //条目唯一键，这里为brokerName
    private final String name;
    //本次消息发送延迟
    private volatile long currentLatency;
    //故障规避开始时间
    private volatile long startTimestamp;
}
</code></pre>
<p><strong>MQFaultStrategy:消息失败策略，延迟实现的门面类</strong></p>
<pre><code class="language-java">private long[] latencyMax = {50L, 100L, 550L, 1000L, 2000L, 3000L, 15000L};
private long[] notAvailableDuration = {0L, 0L, 30000L, 60000L, 120000L, 180000L, 600000L};
</code></pre>
<p>latencyMax根据currentLatency本次消息发送延迟，从latencyMax尾部向前找到<br>
第一个比currentLatency小的索引index，如果没有找到，返回0。然后根据这个索引从 notAvailableDuration数组中取出对应的时间，在这个时长内，Broker将设置为不可用。</p>
<blockquote>
<p><em>MQFaultStrategy#updateFaultltem</em></p>
</blockquote>
<pre><code class="language-java">/**
    * 更新失败条目
    * @param brokerName
    * @param currentLatency 本次消息发送延迟时间
    * @param isolation isolation，是否隔离，该参数的含义如果为 true，则使用默认时长30s来
    * 计算Broker故障规避时长，如果为false，则使用本次消息发送延迟时间来计算Broker故障规避时长。
    */
public void updateFaultItem(final String brokerName, final long currentLatency, boolean isolation) {
    if (this.sendLatencyFaultEnable) {
        long duration = computeNotAvailableDuration(isolation ? 30000 : currentLatency);
        this.latencyFaultTolerance.updateFaultItem(brokerName, currentLatency, duration);
    }
}

private long computeNotAvailableDuration(final long currentLatency) {
    for (int i = latencyMax.length - 1; i &gt;= 0; i--) {
        if (currentLatency &gt;= latencyMax[i])
            return this.notAvailableDuration[i];
    }

    return 0;
}
</code></pre>
<p>computeNotAvailableDuration的作用是计算因本次消息发送故障需要将 Broker 规避的时长，也就是接下来多久的时间内该 Broker将不参与消息发送队列负载。具体算法:从 latencyMax数组尾部开始寻找，找到第一个比currentLatency小的下标， 然后从notAvailableDuration数组中获取需要规避的时长，该方法最终调用LatencyFaultTolerance的updateFaultltem。</p>
<pre><code class="language-java">@Override
public void updateFaultItem(final String name, final long currentLatency, final long notAvailableDuration) {
    FaultItem old = this.faultItemTable.get(name);
    if (null == old) {
        final FaultItem faultItem = new FaultItem(name);
        faultItem.setCurrentLatency(currentLatency);
        faultItem.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);

        old = this.faultItemTable.putIfAbsent(name, faultItem);
        if (old != null) {
            old.setCurrentLatency(currentLatency);
            old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);
        }
    } else {
        old.setCurrentLatency(currentLatency);
        old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);
    }
}
</code></pre>
<p>根据 broker名称从缓存表中获取Faultitem，如果找到则更新Faultltem，否则创建Faultltem。这里有两个关键点。<br>
1)currentLatency、startTimeStamp被volatile修饰。<br>
2)startTimeStamp为当前系统时间加上需要规避的时长。startTimeStamp是判断broker当前是否可用的直接一句，请看 Faultltem#isAvailable方法。</p>
<pre><code class="language-java">public boolean isAvailable() {
    return (System.currentTimeMillis() - startTimestamp) &gt;= 0;
}
</code></pre>
<h3 id="344-消息发送">3.4.4 消息发送</h3>
<pre><code class="language-java">/**
    * 发送消息
    * @param msg 待发送消息
    * @param mq  消息将发送到该消息队列上
    * @param communicationMode 消息发送模式
    * @param sendCallback 异步消息回调函数
    * @param topicPublishInfo 主题路由信息
    * @param timeout 消息发送超时时间
    */
private SendResult sendKernelImpl(final Message msg,
    final MessageQueue mq,
    final CommunicationMode communicationMode,
    final SendCallback sendCallback,
    final TopicPublishInfo topicPublishInfo,
    final long timeout)
</code></pre>
<p>Step 1:根据MessageQueue获取Broker的网络地址。如果MQClientlnstance的brokerAddrTable禾缓存该Broker的信息，则从NameServer主动更新一下topic的路由信息。如果路由更新后还是找不到 Broker信息，则抛出MQClientException，提示Broker不存在。</p>
<blockquote>
<p>DefaultMQProducelmpl#sendKernellmpl</p>
</blockquote>
<pre><code class="language-java">String brokerName = this.mQClientFactory.getBrokerNameFromMessageQueue(mq);
String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(brokerName);
if (null == brokerAddr) {
    tryToFindTopicPublishInfo(mq.getTopic());
    brokerName = this.mQClientFactory.getBrokerNameFromMessageQueue(mq);
    brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(brokerName);
}
</code></pre>
<p>Step2:为消息分配全局唯一ID ，如果消息体默认超过 4K(compressMsgBodyOverHowmuch), 会对消息体采用 zip压缩，并设置消息的系统标记为 MessageSysFlag.COMPRESSED_FLAG。 如果是事务 Prepared消息，则设消息的系统标记为MessageSysFlag.TRANSACTION_ PREPARED_TYPE。</p>
<blockquote>
<p>DefaultMQProducelmpl#sendKernellmpl</p>
</blockquote>
<pre><code class="language-java">if (!(msg instanceof MessageBatch)) {
    MessageClientIDSetter.setUniqID(msg);
}

boolean topicWithNamespace = false;
if (null != this.mQClientFactory.getClientConfig().getNamespace()) {
    msg.setInstanceId(this.mQClientFactory.getClientConfig().getNamespace());
    topicWithNamespace = true;
}

int sysFlag = 0;
boolean msgBodyCompressed = false;
if (this.tryToCompressMessage(msg)) {//压缩消息
    sysFlag |= MessageSysFlag.COMPRESSED_FLAG;
    sysFlag |= compressType.getCompressionFlag();
    msgBodyCompressed = true;
}

final String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);
if (Boolean.parseBoolean(tranMsg)) {
    sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE;
}
</code></pre>
<p>Step3 :如果注册了消息发送钩子函数，则执行消息发送之前的增强逻辑。通过DefaultMQProducerlmpl#registerSendMessageHook注册钩子处理类，并且可以注册多个。</p>
<pre><code class="language-java">if (hasCheckForbiddenHook()) {
    CheckForbiddenContext checkForbiddenContext = new CheckForbiddenContext();
    checkForbiddenContext.setNameSrvAddr(this.defaultMQProducer.getNamesrvAddr());
    checkForbiddenContext.setGroup(this.defaultMQProducer.getProducerGroup());
    checkForbiddenContext.setCommunicationMode(communicationMode);
    checkForbiddenContext.setBrokerAddr(brokerAddr);
    checkForbiddenContext.setMessage(msg);
    checkForbiddenContext.setMq(mq);
    checkForbiddenContext.setUnitMode(this.isUnitMode());
    this.executeCheckForbiddenHook(checkForbiddenContext);
}

if (this.hasSendMessageHook()) {
    context = new SendMessageContext();
    context.setProducer(this);
    context.setProducerGroup(this.defaultMQProducer.getProducerGroup());
    context.setCommunicationMode(communicationMode);
    context.setBornHost(this.defaultMQProducer.getClientIP());
    context.setBrokerAddr(brokerAddr);
    context.setMessage(msg);
    context.setMq(mq);
    context.setNamespace(this.defaultMQProducer.getNamespace());
    String isTrans = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);
    if (isTrans != null &amp;&amp; isTrans.equals(&quot;true&quot;)) {
        context.setMsgType(MessageType.Trans_Msg_Half);
    }

    if (msg.getProperty(&quot;__STARTDELIVERTIME&quot;) != null || msg.getProperty(MessageConst.PROPERTY_DELAY_TIME_LEVEL) != null) {
        context.setMsgType(MessageType.Delay_Msg);
    }
    this.executeSendMessageHookBefore(context);
}
</code></pre>
<p>Step4 :构建消息发送请求包。 主要包含如下重要信息:生产者组、主题名称、默认创建主题 Key、该主题在单个Broker默认队列数 、队列ID (队列序号)、消息系统标记( MessageSysFlag)、消息发送时间、消息标记(RocketMQ对消息中的 flag不做任何处理，供应用程序使用)、消息扩展属性、消息重试次数、是否是批量消息等。</p>
<pre><code class="language-java">SendMessageRequestHeader requestHeader = new SendMessageRequestHeader();
requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup());
requestHeader.setTopic(msg.getTopic());
requestHeader.setDefaultTopic(this.defaultMQProducer.getCreateTopicKey());
requestHeader.setDefaultTopicQueueNums(this.defaultMQProducer.getDefaultTopicQueueNums());
requestHeader.setQueueId(mq.getQueueId());
requestHeader.setSysFlag(sysFlag);
requestHeader.setBornTimestamp(System.currentTimeMillis());
requestHeader.setFlag(msg.getFlag());
requestHeader.setProperties(MessageDecoder.messageProperties2String(msg.getProperties()));
requestHeader.setReconsumeTimes(0);
requestHeader.setUnitMode(this.isUnitMode());
requestHeader.setBatch(msg instanceof MessageBatch);
if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
    String reconsumeTimes = MessageAccessor.getReconsumeTime(msg);
    if (reconsumeTimes != null) {
        requestHeader.setReconsumeTimes(Integer.valueOf(reconsumeTimes));
        MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_RECONSUME_TIME);
    }

    String maxReconsumeTimes = MessageAccessor.getMaxReconsumeTimes(msg);
    if (maxReconsumeTimes != null) {
        requestHeader.setMaxReconsumeTimes(Integer.valueOf(maxReconsumeTimes));
        MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_MAX_RECONSUME_TIMES);
    }
}
</code></pre>
<p>Step5:根据消息发送方式，同步、异步、单向方式进行网络传输。</p>
<blockquote>
<p>MQClientAPIImpl#sendMessage</p>
</blockquote>
<pre><code class="language-java"> public SendResult sendMessage(
        final String addr,
        final String brokerName,
        final Message msg,
        final SendMessageRequestHeader requestHeader,
        final long timeoutMillis,
        final CommunicationMode communicationMode,
        final SendCallback sendCallback,
        final TopicPublishInfo topicPublishInfo,
        final MQClientInstance instance,
        final int retryTimesWhenSendFailed,
        final SendMessageContext context,
        final DefaultMQProducerImpl producer
    ) throws RemotingException, MQBrokerException, InterruptedException {
        long beginStartTime = System.currentTimeMillis();
        RemotingCommand request = null;
        String msgType = msg.getProperty(MessageConst.PROPERTY_MESSAGE_TYPE);
        boolean isReply = msgType != null &amp;&amp; msgType.equals(MixAll.REPLY_MESSAGE_FLAG);
        if (isReply) {
            if (sendSmartMsg) {
                SendMessageRequestHeaderV2 requestHeaderV2 = SendMessageRequestHeaderV2.createSendMessageRequestHeaderV2(requestHeader);
                request = RemotingCommand.createRequestCommand(RequestCode.SEND_REPLY_MESSAGE_V2, requestHeaderV2);
            } else {
                request = RemotingCommand.createRequestCommand(RequestCode.SEND_REPLY_MESSAGE, requestHeader);
            }
        } else {
            if (sendSmartMsg || msg instanceof MessageBatch) {
                SendMessageRequestHeaderV2 requestHeaderV2 = SendMessageRequestHeaderV2.createSendMessageRequestHeaderV2(requestHeader);
                request = RemotingCommand.createRequestCommand(msg instanceof MessageBatch ? RequestCode.SEND_BATCH_MESSAGE : RequestCode.SEND_MESSAGE_V2, requestHeaderV2);
            } else {
                request = RemotingCommand.createRequestCommand(RequestCode.SEND_MESSAGE, requestHeader);
            }
        }
        request.setBody(msg.getBody());

        switch (communicationMode) {
            case ONEWAY:
                this.remotingClient.invokeOneway(addr, request, timeoutMillis);
                return null;
            case ASYNC:
                final AtomicInteger times = new AtomicInteger();
                long costTimeAsync = System.currentTimeMillis() - beginStartTime;
                if (timeoutMillis &lt; costTimeAsync) {
                    throw new RemotingTooMuchRequestException(&quot;sendMessage call timeout&quot;);
                }
                this.sendMessageAsync(addr, brokerName, msg, timeoutMillis - costTimeAsync, request, sendCallback, topicPublishInfo, instance,
                    retryTimesWhenSendFailed, times, context, producer);
                return null;
            case SYNC:
                long costTimeSync = System.currentTimeMillis() - beginStartTime;
                if (timeoutMillis &lt; costTimeSync) {
                    throw new RemotingTooMuchRequestException(&quot;sendMessage call timeout&quot;);
                }
                return this.sendMessageSync(addr, brokerName, msg, timeoutMillis - costTimeSync, request);
            default:
                assert false;
                break;
        }

        return null;
    }
</code></pre>
<p>Step6:如果注册了消息发送钩子函数，执行 after逻辑。 注意，就算消息发送过程中发<br>
生 RemotingException、 MQBrokerException、 InterruptedException时该方法也会执行。</p>
<pre><code class="language-java">if (this.hasSendMessageHook()) {
    context.setSendResult(sendResult);
    this.executeSendMessageHookAfter(context);
}
</code></pre>
<h4 id="1-同步发送">1. 同步发送</h4>
<p>MQ客户端发送消息的入口是MQClientAPIImpl#sendMessage。请求命令是Request­<br>
Code.SEND_MESSAGE，我们可以找到该命令的处理类: org.apache.rocketmq.broker.processor. SendMessageProcessor。入口方法在 SendMessageProcessor#sendMessage。</p>
<pre><code class="language-java">public RemotingCommand sendMessage(final ChannelHandlerContext ctx,
    final RemotingCommand request,
    final SendMessageContext sendMessageContext,
    final SendMessageRequestHeader requestHeader,
    final TopicQueueMappingContext mappingContext,
    final SendMessageCallback sendMessageCallback) throws RemotingCommandException {
    //发送消息并且进行消息审查
    final RemotingCommand response = preSend(ctx, request, requestHeader);
    if (response.getCode() != -1) {
        return response;
    }

    final SendMessageResponseHeader responseHeader = (SendMessageResponseHeader) response.readCustomHeader();

    final byte[] body = request.getBody();

    int queueIdInt = requestHeader.getQueueId();
    TopicConfig topicConfig = this.brokerController.getTopicConfigManager().selectTopicConfig(requestHeader.getTopic());

    if (queueIdInt &lt; 0) {
        queueIdInt = randomQueueId(topicConfig.getWriteQueueNums());
    }

    MessageExtBrokerInner msgInner = new MessageExtBrokerInner();
    msgInner.setTopic(requestHeader.getTopic());
    msgInner.setQueueId(queueIdInt);

    Map&lt;String, String&gt; oriProps = MessageDecoder.string2messageProperties(requestHeader.getProperties());

    // Step2:如果消息重试次数超过允许的最大重试次数，消息将进入到 DLD 延迟队列 
    if (!handleRetryAndDLQ(requestHeader, response, request, msgInner, topicConfig, oriProps)) {
        return response;
    }

    msgInner.setBody(body);
    msgInner.setFlag(requestHeader.getFlag());

    String uniqKey = oriProps.get(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX);
    if (uniqKey == null || uniqKey.length() &lt;= 0) {
        uniqKey = MessageClientIDSetter.createUniqID();
        oriProps.put(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX, uniqKey);
    }

    MessageAccessor.setProperties(msgInner, oriProps);
    msgInner.setTagsCode(MessageExtBrokerInner.tagsString2tagsCode(topicConfig.getTopicFilterType(), msgInner.getTags()));
    msgInner.setBornTimestamp(requestHeader.getBornTimestamp());
    msgInner.setBornHost(ctx.channel().remoteAddress());
    msgInner.setStoreHost(this.getStoreHost());
    msgInner.setReconsumeTimes(requestHeader.getReconsumeTimes() == null ? 0 : requestHeader.getReconsumeTimes());
    String clusterName = this.brokerController.getBrokerConfig().getBrokerClusterName();
    MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_CLUSTER, clusterName);

    msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties()));

    // Map&lt;String, String&gt; oriProps = MessageDecoder.string2messageProperties(requestHeader.getProperties());
    String traFlag = oriProps.get(MessageConst.PROPERTY_TRANSACTION_PREPARED);
    boolean sendTransactionPrepareMessage = false;
    if (Boolean.parseBoolean(traFlag)
        &amp;&amp; !(msgInner.getReconsumeTimes() &gt; 0 &amp;&amp; msgInner.getDelayTimeLevel() &gt; 0)) { //For client under version 4.6.1
        if (this.brokerController.getBrokerConfig().isRejectTransactionMessage()) {
            response.setCode(ResponseCode.NO_PERMISSION);
            response.setRemark(
                &quot;the broker[&quot; + this.brokerController.getBrokerConfig().getBrokerIP1()
                    + &quot;] sending transaction message is forbidden&quot;);
            return response;
        }
        sendTransactionPrepareMessage = true;
    }

    long beginTimeMillis = this.brokerController.getMessageStore().now();

    if (brokerController.getBrokerConfig().isAsyncSendEnable()) {
        CompletableFuture&lt;PutMessageResult&gt; asyncPutMessageFuture;
        if (sendTransactionPrepareMessage) {
            asyncPutMessageFuture = this.brokerController.getTransactionalMessageService().asyncPrepareMessage(msgInner);
        } else {
            asyncPutMessageFuture = this.brokerController.getMessageStore().asyncPutMessage(msgInner);
        }

        final int finalQueueIdInt = queueIdInt;
        final MessageExtBrokerInner finalMsgInner = msgInner;
        asyncPutMessageFuture.thenAcceptAsync(putMessageResult -&gt; {
            RemotingCommand responseFuture =
                handlePutMessageResult(putMessageResult, response, request, finalMsgInner, responseHeader, sendMessageContext,
                    ctx, finalQueueIdInt, beginTimeMillis, mappingContext);
            if (responseFuture != null) {
                doResponse(ctx, request, responseFuture);
            }
            sendMessageCallback.onComplete(sendMessageContext, response);
        }, this.brokerController.getPutMessageFutureExecutor());
        // Returns null to release the send message thread
        return null;
    } else {
        PutMessageResult putMessageResult = null;
        if (sendTransactionPrepareMessage) {
            putMessageResult = this.brokerController.getTransactionalMessageService().prepareMessage(msgInner);
        } else {
            //调用 DefaultMessageStore#putMessage 进行消息 存储
            putMessageResult = this.brokerController.getMessageStore().putMessage(msgInner);
        }
        handlePutMessageResult(putMessageResult, response, request, msgInner, responseHeader, sendMessageContext, ctx, queueIdInt, beginTimeMillis, mappingContext);
        sendMessageCallback.onComplete(sendMessageContext, response);
        return response;
    }
}
</code></pre>
<blockquote>
<p>msgCheck</p>
</blockquote>
<pre><code class="language-java">protected RemotingCommand msgCheck(final ChannelHandlerContext ctx,
    final SendMessageRequestHeader requestHeader, final RemotingCommand request,
    final RemotingCommand response) {

    //1 )检查该Broker是否有写权限
    if (!PermName.isWriteable(this.brokerController.getBrokerConfig().getBrokerPermission())
        &amp;&amp; this.brokerController.getTopicConfigManager().isOrderTopic(requestHeader.getTopic())) {
        response.setCode(ResponseCode.NO_PERMISSION);
        response.setRemark(&quot;the broker[&quot; + this.brokerController.getBrokerConfig().getBrokerIP1()
            + &quot;] sending message is forbidden&quot;);
        return response;
    }

    //检查该Topic是否可以进行消息发送。主要针对默认主题，默认主题不能发送消息，仅仅供路由查找
    if (!TopicValidator.validateTopic(requestHeader.getTopic(), response)) {
        return response;
    }
    if (TopicValidator.isNotAllowedSendTopic(requestHeader.getTopic(), response)) {
        return response;
    }

    TopicConfig topicConfig =
        this.brokerController.getTopicConfigManager().selectTopicConfig(requestHeader.getTopic());
    if (null == topicConfig) {
        int topicSysFlag = 0;
        if (requestHeader.isUnitMode()) {
            if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
                topicSysFlag = TopicSysFlag.buildSysFlag(false, true);
            } else {
                topicSysFlag = TopicSysFlag.buildSysFlag(true, false);
            }
        }

        LOGGER.warn(&quot;the topic {} not exist, producer: {}&quot;, requestHeader.getTopic(), ctx.channel().remoteAddress());
        //在 NameServer端存储主题的配置信息，
        topicConfig = this.brokerController.getTopicConfigManager().createTopicInSendMessageMethod(
            requestHeader.getTopic(),
            requestHeader.getDefaultTopic(),
            RemotingHelper.parseChannelRemoteAddr(ctx.channel()),
            requestHeader.getDefaultTopicQueueNums(), topicSysFlag);

        if (null == topicConfig) {
            if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
                topicConfig =
                    this.brokerController.getTopicConfigManager().createTopicInSendMessageBackMethod(
                        requestHeader.getTopic(), 1, PermName.PERM_WRITE | PermName.PERM_READ,
                        topicSysFlag);
            }
        }

        if (null == topicConfig) {
            response.setCode(ResponseCode.TOPIC_NOT_EXIST);
            response.setRemark(&quot;topic[&quot; + requestHeader.getTopic() + &quot;] not exist, apply first please!&quot;
                + FAQUrl.suggestTodo(FAQUrl.APPLY_TOPIC_URL));
            return response;
        }
    }
    //4)检查队列，如果队列不合法，返回错误码 。
    int queueIdInt = requestHeader.getQueueId();
    int idValid = Math.max(topicConfig.getWriteQueueNums(), topicConfig.getReadQueueNums());
    if (queueIdInt &gt;= idValid) {
        String errorInfo = String.format(&quot;request queueId[%d] is illegal, %s Producer: %s&quot;,
            queueIdInt,
            topicConfig,
            RemotingHelper.parseChannelRemoteAddr(ctx.channel()));

        LOGGER.warn(errorInfo);
        response.setCode(ResponseCode.SYSTEM_ERROR);
        response.setRemark(errorInfo);

        return response;
    }
    return response;
}
</code></pre>
<blockquote>
<p>handleRetryAndDLQ</p>
</blockquote>
<pre><code class="language-java">private boolean handleRetryAndDLQ(SendMessageRequestHeader requestHeader, RemotingCommand response,
    RemotingCommand request,
    MessageExt msg, TopicConfig topicConfig, Map&lt;String, String&gt; properties) {
    String newTopic = requestHeader.getTopic();
    if (null != newTopic &amp;&amp; newTopic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
        String groupName = newTopic.substring(MixAll.RETRY_GROUP_TOPIC_PREFIX.length());
        SubscriptionGroupConfig subscriptionGroupConfig =
            this.brokerController.getSubscriptionGroupManager().findSubscriptionGroupConfig(groupName);
        if (null == subscriptionGroupConfig) {
            response.setCode(ResponseCode.SUBSCRIPTION_GROUP_NOT_EXIST);
            response.setRemark(
                &quot;subscription group not exist, &quot; + groupName + &quot; &quot; + FAQUrl.suggestTodo(FAQUrl.SUBSCRIPTION_GROUP_NOT_EXIST));
            return false;
        }

        int maxReconsumeTimes = subscriptionGroupConfig.getRetryMaxTimes();
        if (request.getVersion() &gt;= MQVersion.Version.V3_4_9.ordinal() &amp;&amp; requestHeader.getMaxReconsumeTimes() != null) {
            maxReconsumeTimes = requestHeader.getMaxReconsumeTimes();
        }
        int reconsumeTimes = requestHeader.getReconsumeTimes() == null ? 0 : requestHeader.getReconsumeTimes();
        // Using '&gt;' instead of '&gt;=' to compatible with the case that reconsumeTimes here are increased by client.

        // Step2:如果消息重试次数超过允许的最大重试次数，消息将进入到 DLD 延迟队列。延迟队列主题: %DLQ%+消费组名
        if (reconsumeTimes &gt; maxReconsumeTimes) {
            properties.put(MessageConst.PROPERTY_DELAY_TIME_LEVEL, &quot;-1&quot;);
            newTopic = MixAll.getDLQTopic(groupName);
            int queueIdInt = randomQueueId(DLQ_NUMS_PER_GROUP);
            topicConfig = this.brokerController.getTopicConfigManager().createTopicInSendMessageBackMethod(newTopic,
                DLQ_NUMS_PER_GROUP,
                PermName.PERM_WRITE | PermName.PERM_READ, 0
            );
            msg.setTopic(newTopic);
            msg.setQueueId(queueIdInt);
            msg.setDelayTimeLevel(0);
            if (null == topicConfig) {
                response.setCode(ResponseCode.SYSTEM_ERROR);
                response.setRemark(&quot;topic[&quot; + newTopic + &quot;] not exist&quot;);
                return false;
            }
        }
    }
    int sysFlag = requestHeader.getSysFlag();
    if (TopicFilterType.MULTI_TAG == topicConfig.getTopicFilterType()) {
        sysFlag |= MessageSysFlag.MULTI_TAGS_FLAG;
    }
    msg.setSysFlag(sysFlag);
    return true;
}
</code></pre>
<h4 id="2异步发送">2.异步发送</h4>
<p>消息异步发送是指消息生产者调用发送的 API后，无须阻塞等待消息服务器返回本次消息发送结果，只需要提供一个回调函数，供消息发送客户端在收到响应结果回调。 异步方 式相比同步方式，消息发送端的发送性能会显著提高，但为了保护消息服务器的负载压力， RocketMQ 对消息 发送的异步消息进行了井发控制，通过参数clientAsyncSemaphoreValue来控制，默认为65535。异步消息发送虽然也可以通过 DefaultMQProducer#retryTimes­WhenSendAsyncFailed 属性来控制消息重试次数，但是重试的调用人 口是在收到服务端响应包时进行的，如果出现网络异常、网络超时等将不会重试。</p>
<h4 id="3-单向发送">3. 单向发送</h4>
<p>单向发送是指消息生产者调用消息发送的API后，无须等待消息服务器返回本次消息发送结果，并且无须提供回调函数，表示消息发送压根就不关心本次消息发送是否成功，其实现原理与异步消息发送相同，只是消息发送客户端在收到响应结果后什么都不做而已，并且没有重试机制。</p>
<h2 id="35-批量消息发送">3.5 批量消息发送</h2>
<p>批量消息发送是将同一主题的多条消息一起打包发送到消息服务端，减少网络调用次数，提高网络传输效率 。</p>
<p>当然，并不是在同一批次中发送的消息数量越多性能就越好，其判断依据是单条消息的长度，如果单条消息内容比较长，则打包多条消息发送会影响其他线程发送消息的响应时间，并且单批次消息发送总长度不能超过 DefaultMQProducer#maxMessageSize。</p>
<blockquote>
<p>RemotingCommand</p>
</blockquote>
<pre><code class="language-java">//请求命令编码，请求命令类型
private int code;
private LanguageCode language = LanguageCode.JAVA;

//版本号
private int version = 0;

//客户端请求序号
private int opaque = requestId.getAndIncrement();

//标记。倒数第一位表示请求类型，O:请求; 1:返回。倒数第二位，1:表示oneway
private int flag = 0;

//描述
private String remark;
//扩展属性
private HashMap&lt;String, String&gt; extFields;
//每个请求对应 的请求头信息
private transient CommandCustomHeader customHeader;

private SerializeType serializeTypeCurrentRPC = serializeTypeConfigInThisServer;
//请求体
private transient byte[] body;
</code></pre>
<p>单条消息发送时，消息体的内容将保存在body中。 批量消息发送 ，需要将多条消息体的内容存储在body中。</p>
<p>RocketMQ采取的方式是，对单条消息内容使用固定格式进行存储。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1663150413082.png" alt="消息封装格式" loading="lazy"></figure>
<blockquote>
<p>DefaultMQProducer#send 消息批量发迭</p>
</blockquote>
<pre><code class="language-java">@Override
public SendResult send(
    Collection&lt;Message&gt; msgs) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    return this.defaultMQProducerImpl.send(batch(msgs));
}
</code></pre>
<p>首先在消息发送端，调用batch方法，将一批消息封装成MessageBatch对象。Message­Batch继承自Message对象，MessageBatch内部持有List<Message> messages。这样的话，批量消息发送与单条消息发送的处理流程完全一样。MessageBatch只需要将该集合中的每条消息的消息体 body聚合成一个 byte数组，在消息服务端能够从该 byte[] 数值中正确解析出消息即可。</p>
<p>在创建RemotingCommand对象时将调用messageBatch#encode()方法填充到Remoting-Command的body域中。</p>
<pre><code class="language-java">public static byte[] encodeMessages(List&lt;Message&gt; messages) {
    //TO DO refactor, accumulate in one buffer, avoid copies
    List&lt;byte[]&gt; encodedMessages = new ArrayList&lt;byte[]&gt;(messages.size());
    int allSize = 0;
    for (Message message : messages) {
        byte[] tmp = encodeMessage(message);
        encodedMessages.add(tmp);
        allSize += tmp.length;
    }
    byte[] allBytes = new byte[allSize];
    int pos = 0;
    for (byte[] bytes : encodedMessages) {
        System.arraycopy(bytes, 0, allBytes, pos, bytes.length);
        pos += bytes.length;
    }
    return allBytes;
}

public static byte[] encodeMessage(Message message) {
    //only need flag, body, properties
    byte[] body = message.getBody();
    int bodyLen = body.length;
    String properties = messageProperties2String(message.getProperties());
    byte[] propertiesBytes = properties.getBytes(CHARSET_UTF8);
    //note properties length must not more than Short.MAX
    short propertiesLength = (short) propertiesBytes.length;
    int sysFlag = message.getFlag();
    int storeSize = 4 // 1 TOTALSIZE
        + 4 // 2 MAGICCOD
        + 4 // 3 BODYCRC
        + 4 // 4 FLAG
        + 4 + bodyLen // 4 BODY
        + 2 + propertiesLength;
    ByteBuffer byteBuffer = ByteBuffer.allocate(storeSize);
    // 1 TOTALSIZE
    byteBuffer.putInt(storeSize);

    // 2 MAGICCODE
    byteBuffer.putInt(0);

    // 3 BODYCRC
    byteBuffer.putInt(0);

    // 4 FLAG
    int flag = message.getFlag();
    byteBuffer.putInt(flag);

    // 5 BODY
    byteBuffer.putInt(bodyLen);
    byteBuffer.put(body);

    // 6 properties
    byteBuffer.putShort(propertiesLength);
    byteBuffer.put(propertiesBytes);

    return byteBuffer.array();
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMq技术内幕笔记（一）]]></title>
        <id>https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-yi/</id>
        <link href="https://q456qq520.github.io/post/rocketmq-ji-zhu-nei-mu-bi-ji-yi/">
        </link>
        <updated>2022-09-07T09:47:04.000Z</updated>
        <summary type="html"><![CDATA[<h1 id="1-大纲">1 大纲</h1>
<h2 id="11-rocketmq-原代码的目录结构">1.1 RocketMQ 原代码的目录结构</h2>
<p>RocketMQ 核心目 录说明如下 。</p>
<ol>
<li>broker: broker模块(broker启动进程) 。</li>
</ol>
]]></summary>
        <content type="html"><![CDATA[<h1 id="1-大纲">1 大纲</h1>
<h2 id="11-rocketmq-原代码的目录结构">1.1 RocketMQ 原代码的目录结构</h2>
<p>RocketMQ 核心目 录说明如下 。</p>
<ol>
<li>broker: broker模块(broker启动进程) 。</li>
</ol>
<!-- more --> 
<ol start="3">
<li>client:消息客户端，包含消息生产者、消息消费者相关类。</li>
<li>common:公共包。</li>
<li>dev:开发者信息(非源代码)。</li>
<li>distribution:部署实例文件夹(非源代码)。</li>
<li>example: RocketMQ 示例代码 。</li>
<li>filter:消息过滤相关基础类。</li>
<li>filtersrv: 消息过滤服务器实现相关类(Filter启动进程)。</li>
<li>logappender:日志实现相关类。</li>
<li>namesrv : NameServer 实现相关类(Names巳rver启动进程) 。</li>
<li>openmessaging: 消息开放标准，正在制定中 。</li>
<li>remoting: 远程通信模块，基于 Netty。</li>
<li>srvutil:服务器工具类。</li>
<li>store:消息存储实现相关类 。</li>
<li>style: checkstyle相关实现。</li>
<li>test: 测试相关类。</li>
<li>tools: 工具类，监控命令相关实现类。</li>
</ol>
<h2 id="12-rocketmq-的设计理念和目标">1.2 RocketMQ 的设计理念和目标</h2>
<h3 id="121-设计理念">1.2.1 设计理念</h3>
<p>RocketMQ 设计基于主题的发布与 订阅 模式 ， (Broker)、消息消费。</p>
<p>NameServer：实现元数据的管理(Topic路由信息等)，因为 Topic 路由信息无须在集群之 间保持强一致，追求最终一致性，并且能容 忍分钟级的 不一致 。</p>
<p>高效的IO存储机制：RocketMQ追求消息发送的高吞吐量， RocketMQ 的消息存储文件设计成文件组的概念，组内单个文件大小固定，方便引人内存 l映射机制，所 有主 题的消息存储基于顺序写，极大地提高了消息写性能， 同时为了兼顾消息消费与消息查找，引入了消息消费队列文件与索引文件。</p>
<h3 id="122-设计能力">1.2.2 设计能力</h3>
<ol>
<li>
<p>架构模式<br>
RocketMQ 与大部分消息中间件一样，采用发布订阅模式，基本的参与组件主要包括 :<br>
消息发送者、消息服务器(消息存储)、消息消费、路由发现 。</p>
</li>
<li>
<p>顺序消息<br>
所谓顺序消息，就是消息消费者按照消息达到消息存储服务器的顺序消费 。 RocketMQ 可以严格保证消息有序 。</p>
</li>
<li>
<p>消息过滤<br>
RocketMQ 消息过滤支持在服务端与消费端的消息过滤机制 。<br>
1 )消息在 Broker 端过滤。Broker只将消息消费者感兴趣的消息发送给消息消费者 。<br>
2 )消息在消息消费端过滤，消息过滤方式完全由消息消费者自定义，但缺点是有很多无用的消息会从 Broker传输到消费端。</p>
</li>
<li>
<p>消息存储<br>
RocketMQ 追求消息存储的高性能，引人内存映射机制，所有主题的消息顺序存储在同一个文件中 。 同时为了避免消息无限在消息存储服务器中累积，引入了消息文件过期机制与文件存储空间报警机制。</p>
</li>
<li>
<p>消息高可用性<br>
通常影响消息可靠性的有以下几种情况 。</p>
</li>
</ol>
<ol>
<li>Broker正常关机。</li>
<li>Broker异常 Crash。</li>
<li>OS Crash。</li>
<li>机器断电，但 是 能立即恢复供电情况 。</li>
<li>机器无法开机(可能是 CPU、主板、 内存等关键设备损 坏)。</li>
<li>磁盘设备损坏。<br>
情况 1~4 的 RocketMQ 在同步刷盘机制下可以确保不丢失消息，在异步刷盘模式下，会丢失少量消息 。 情况 5-6 属于单点故障，一旦发生，该节点上的消息全 部丢失，如果开启了异步复制机制， RoketMQ 能保证只丢失少量消息。</li>
</ol>
<ol start="6">
<li>
<p>消息到达 (消费)低延迟<br>
RocketMQ在消息不发生消息堆积时，以长轮询模式实现准实时的消息推送模式。</p>
</li>
<li>
<p>确保消息必须被消费一次<br>
RocketMQ 通过消息消费确认机制(ACK)来确保消息至少被消费一次，但由于ACK消息有可能丢失等其他原因，RocketMQ无法做到消息只被消费一次，有重复消费的可能。</p>
</li>
<li>
<p>回溯消息<br>
回溯消息是指消息消费端已经消费成功的消息，由于业务要求需要重新消费消息。 RocketMQ 支持按时间回溯消息，时间维度可精确到毫秒，可以向前或向后回溯。</p>
</li>
<li>
<p>消息堆积<br>
RocketMQ 消息存储使用磁盘文件 (内存映射机制)，并且在物理布局上为多个大小相等的文件组成逻辑文件组，可以无限循环使用。 RocketMQ消息存储文件并不是永久存储在消息服务器端，而是提供了过期机制，默认保留3天。</p>
</li>
<li>
<p>定时消息<br>
定 时消息 是指消息发送到 Broker 后， 不能被消息消费端立即消费，要到特定的时间点或者等待特定的时间后才能被消费。 如果要支持任意精度的定时消息消费，必须在消息服务端对消息进行排序，势必带来很大的性能损耗，故RocketMQ不支持任意精度的定时消息，而只支持特定延迟级别。</p>
</li>
<li>
<p>消息重试机制<br>
消息重试是指消息在消费时，如果发送异常，消息中间件需要支持消息重新投递，RocketMQ支持消息重试机制。</p>
</li>
</ol>
<h1 id="2-rocketmq路由中心nameserver">2 RocketMQ路由中心NameServer</h1>
<h2 id="21-nameserver-架构设计">2.1 NameServer 架构设计</h2>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1663034308783.png" alt="RocketMQ 物理部署图" loading="lazy"></figure>
<p>Broker消息服务器在启动时向所有 NameServer注册，消息生产者(Producer)在发送消 息之前先从 NameServer获取Broker 服务器地址列表，然后根据负载算法从列表中选择一 台消息服务器进行消息发送。NameServer与每台 Broker 服务器保持长连接，并间隔30s检测Broker是否存活，如果检测到 Broker右机，则从路由注册表中将其移除。但是路由变化不会马上通知消息生产者。</p>
<p>NameServer本身的高可用可通过部 署多台 NameServer服务器来实现，但彼此之间互不通信，也就是 NameServer服务器之间在某一时刻的数据并不会完全相同，但这对消 息发送不会造成任何影响。</p>
<h2 id="22-nameserver-启动流程">2.2 NameServer 启动流程</h2>
<p>NameServer启动类 : org.apache.rocketmq.namesrv.NamesrvStartup。</p>
<ol>
<li>Step 1: 首先来解析配置文件，需要填充 NameServerConfig、NettyServerConfig属性值。</li>
</ol>
<pre><code class="language-java">  public static void parseCommandlineAndConfigFile(String[] args) throws Exception {
        System.setProperty(RemotingCommand.REMOTING_VERSION_KEY, Integer.toString(MQVersion.CURRENT_VERSION));
        //PackageConflictDetect.detectFastjson();

        Options options = ServerUtil.buildCommandlineOptions(new Options());
        CommandLine commandLine = ServerUtil.parseCmdLine(&quot;mqnamesrv&quot;, args, buildCommandlineOptions(options), new PosixParser());
        if (null == commandLine) {
            System.exit(-1);
            return;
        }

        namesrvConfig = new NamesrvConfig();
        nettyServerConfig = new NettyServerConfig();
        nettyClientConfig = new NettyClientConfig();
        nettyServerConfig.setListenPort(9876);
        controllerConfig = new ControllerConfig();
        if (commandLine.hasOption('c')) {
            String file = commandLine.getOptionValue('c');
            if (file != null) {
                InputStream in = new BufferedInputStream(Files.newInputStream(Paths.get(file)));
                properties = new Properties();
                properties.load(in);
                MixAll.properties2Object(properties, namesrvConfig);
                MixAll.properties2Object(properties, nettyServerConfig);
                MixAll.properties2Object(properties, nettyClientConfig);
                MixAll.properties2Object(properties, controllerConfig);

                namesrvConfig.setConfigStorePath(file);

                System.out.printf(&quot;load config properties file OK, %s%n&quot;, file);
                in.close();
            }
        }

        if (commandLine.hasOption('p')) {
            MixAll.printObjectProperties(null, namesrvConfig);
            MixAll.printObjectProperties(null, nettyServerConfig);
            MixAll.printObjectProperties(null, nettyClientConfig);
            MixAll.printObjectProperties(null, controllerConfig);
            System.exit(0);
        }

        MixAll.properties2Object(ServerUtil.commandLine2Properties(commandLine), namesrvConfig);

        if (null == namesrvConfig.getRocketmqHome()) {
            System.out.printf(&quot;Please set the %s variable in your environment to match the location of the RocketMQ installation%n&quot;, MixAll.ROCKETMQ_HOME_ENV);
            System.exit(-2);
        }

        LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory();
        JoranConfigurator configurator = new JoranConfigurator();
        configurator.setContext(lc);
        lc.reset();
        configurator.doConfigure(namesrvConfig.getRocketmqHome() + &quot;/conf/logback_namesrv.xml&quot;);

        log = InternalLoggerFactory.getLogger(LoggerName.NAMESRV_LOGGER_NAME);

        MixAll.printObjectProperties(log, namesrvConfig);
        MixAll.printObjectProperties(log, nettyServerConfig);
    }
</code></pre>
<p>创建 NameServerConfig ( NameServer业务参数)、NettyServer-Config ( NameServer网络参数)，然后在解析启动时把指定的配置文件或启动命令中的选项 值，填充到 nameServerConfig,nettyServerConfig对象。</p>
<pre><code class="language-java">public class NamesrvConfig {
    //rocketmq 主目录，可以通过 -Drocketmq.home.dir=path或通过设置环境变量 ROCKETMQ_HOME 来配置 RocketMQ 的主目录 。
    private String rocketmqHome = System.getProperty(MixAll.ROCKETMQ_HOME_PROPERTY, System.getenv(MixAll.ROCKETMQ_HOME_ENV));

    //NameServer存储 KV 配置属性 的持久化路径 
    private String kvConfigPath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;kvConfig.json&quot;;

    //NameServer 默认配置文件路径
    private String configStorePath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;namesrv.properties&quot;;
    private String productEnvName = &quot;center&quot;;
    private boolean clusterTest = false;

    //是否支持顺序消息，默认是不支持
    private boolean orderMessageEnable = false;
    private boolean returnOrderTopicConfigToBroker = true;
}
</code></pre>
<pre><code class="language-java">public class NettyServerConfig implements Cloneable {

    //NameServer监昕端口，该值默认会被初始化为 9876
    private int listenPort = 0;

    //Netty业务线程池线程个数。
    private int serverWorkerThreads = 8;

    //Netty public任务线程池线程个数，Netty网络设计，
    //根据业务类型会创建不同的线程池，比如处理消息发送、消息消费、心跳检测等 。
    //如果该业务类型(RequestCode)未注册线程池， 则由 public线程池执行。
    private int serverCallbackExecutorThreads = 0;

    //IO线程池线程个数，主要是 NameServer、Broker端解析请求、返回相应的线程个数，这类线程主要是处理网络请求的解析请求包，然后转发到
    //各个业务线程池完成具体的业务操作，然后将结果再返回调用方 。
    private int serverSelectorThreads = 3;

    //send oneway 消息请求井发度
    private int serverOnewaySemaphoreValue = 256;

    //异步消息发送最大并发度
    private int serverAsyncSemaphoreValue = 64;

    //网络连接最大空闲时间，默认120s。 如果连接空闲时间超过该参数设置的值，连接将被关闭。
    private int serverChannelMaxIdleTimeSeconds = 120;

    //网络 socket发送缓存区大小， 默认 64k
    private int serverSocketSndBufSize = NettySystemConfig.socketSndbufSize;
    //网络 socket接收缓存区大小 ，默认 64k
    private int serverSocketRcvBufSize = NettySystemConfig.socketRcvbufSize;
    private int writeBufferHighWaterMark = NettySystemConfig.writeBufferHighWaterMark;
    private int writeBufferLowWaterMark = NettySystemConfig.writeBufferLowWaterMark;
    private int serverSocketBacklog = NettySystemConfig.socketBacklog;
    //ByteBuffer是否开启缓存 ， 建议开启
    private boolean serverPooledByteBufAllocatorEnable = true;

    /**
     * make install
     * ../glibc-2.10.1/configure \ --prefix=/usr \ --with-headers=/usr/include \
     * --host=x86_64-linux-gnu \ --build=x86_64-pc-linux-gnu \ --without-gd
     */
    //是否启用EpollIO模型， Linux环境建议开启。
    private boolean useEpollNativeSelector = false;
}
</code></pre>
<blockquote>
<p>️启动 NameServer时，可以先使用/mqnameserver-c configFile -p 打印当前加载的配置属性</p>
</blockquote>
<ol start="2">
<li>Step2:根据启动属性创建 NamesrvController实例，并初始化该实例，实例为NameServer核心控制器。</li>
</ol>
<pre><code class="language-java">  public boolean initialize() {
        //加载kvConfigPath下kvConfig.json配置文件里的KV配置，然后将这些配置放到KVConfigManager#configTable属性中
        loadConfig();
        //根据nettyServerConfig初始化一个netty服务器。
        initiateNetworkComponents();
        //初始化负责处理Netty网络交互数据的线程池，默认线程数是16个
        initiateThreadExecutors();
        ////注册Netty服务端业务处理逻辑，如果开启了clusterTest，那么注册的请求处理类是ClusterTestRequestProcessor，否则请求处理类是DefaultRequestProcessor
        registerProcessor();
        //注册心跳机制线程池，延迟5毫秒启动，每隔5秒遍历RouteInfoManager#brokerLiveTable这个属性，用来扫描不存活的broker
        //注册打印KV配置线程池，延迟1分钟启动、每10分钟打印出kvConfig配置
        startScheduleService();
        initiateSslContext();
        initiateRpcHooks();
        return true;
    }
</code></pre>
<ol start="3">
<li>Step3 :注册JVM钩子函数并启动服务器，以便监昕 Broker、消息生产者的网络请求 。</li>
</ol>
<pre><code class="language-java">//在 JVM 进程关闭之前，先将线程池关闭，及时释放资源 。
        Runtime.getRuntime().addShutdownHook(new ShutdownHookThread(log, (Callable&lt;Void&gt;) () -&gt; {
            controller.shutdown();
            return null;
        }));

        controller.start();
</code></pre>
<h2 id="23-nameserver-路由注册-故障剔除">2.3 NameServer 路由注册、故障剔除</h2>
<p>NameServer主要作用是为消息生产者和消息消费者提供关于主题Topic的路由信息，那么NameServer需要存储路由的基础信息，还要能够管理Broker节点，包括路由注册、 路由删除等功能。</p>
<h3 id="231-路由元信息">2.3.1 路由元信息</h3>
<p>NameServer路由实现类: org.apache.rocketmq.namesrv.routeinfo.RoutelnfoManager</p>
<blockquote>
<p>RoutelnfoManage 路由元数据</p>
</blockquote>
<pre><code class="language-java">public class RouteInfoManager {
    private static final InternalLogger log = InternalLoggerFactory.getLogger(LoggerName.NAMESRV_LOGGER_NAME);
    private final static long DEFAULT_BROKER_CHANNEL_EXPIRED_TIME = 1000 * 60 * 2;
    private final ReadWriteLock lock = new ReentrantReadWriteLock();

    //Topic 消息队列路由信息，消息发送时根据路由表进行负 载均衡 。
    private final Map&lt;String/* topic */, Map&lt;String, QueueData&gt;&gt; topicQueueTable;

    //Broker 基础信息， 包含 brokerName、 所属集群名称 、 主备 Broker地址。
    private final Map&lt;String/* brokerName */, BrokerData&gt; brokerAddrTable;

    //Broker 集群信息，存储集群中所有 Broker 名称 。
    private final Map&lt;String/* clusterName */, Set&lt;String/* brokerName */&gt;&gt; clusterAddrTable;
    //Broker 状态信息 。 NameServer 每次 收到心跳包时会 替换该信 息
    private final Map&lt;BrokerAddrInfo/* brokerAddr */, BrokerLiveInfo&gt; brokerLiveTable;
    // Broker上的 FilterServer列表，用于类模式消息过滤
    private final Map&lt;BrokerAddrInfo/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable;
    private final Map&lt;String/* topic */, Map&lt;String/*brokerName*/, TopicQueueMappingInfo&gt;&gt; topicQueueMappingInfoTable;

    private final BatchUnregistrationService unRegisterService;

    private final NamesrvController namesrvController;
    private final NamesrvConfig namesrvConfig;
}
</code></pre>
<p>RocketMQ基于订阅发布机制，一个Topic拥有多个消息队列 ，一个Broker为每一主题默认创建4个读队列4个写队列。多个Broker组成一个集群，BrokerName由相同的多台Broker组成Master-Slave架构 ， brokerId为0代表 Master，大于0表示Slave。 BrokerLivelnfo中的lastUpdateTimestamp 存储上次收到Broker心跳包的时间。</p>
<h3 id="232-路由注册">2.3.2 路由注册</h3>
<p>RocketMQ路由注册是通过 Broker与NameServer的心跳功能实现的。Broker启动时 向 集群中 所有的 NameServer发送心跳语句，每隔30s向 集群 中所 有 NameServer发送心跳包，NameServer收到Broker心跳包时会更新brokerLiveTable缓存中BrokerLivelnfo的lastUpdateTimestamp，然后NameServer每隔10s扫描 brokerLiveTable，如果连续120s没有收到心跳包， NameServer将移除该 Broker的路由信息同时关闭Socket连接。</p>
<ol>
<li>Broker发送心跳包</li>
</ol>
<blockquote>
<p>Broker端心跳包发送</p>
</blockquote>
<pre><code class="language-java">  scheduledFutures.add(this.scheduledExecutorService.scheduleAtFixedRate(new AbstractBrokerRunnable(this.getBrokerIdentity()) {
            @Override
            public void run2() {
                try {
                    if (System.currentTimeMillis() &lt; shouldStartTime) {
                        BrokerController.LOG.info(&quot;Register to namesrv after {}&quot;, shouldStartTime);
                        return;
                    }
                    if (isIsolated) {
                        BrokerController.LOG.info(&quot;Skip register for broker is isolated&quot;);
                        return;
                    }
                    BrokerController.this.registerBrokerAll(true, false, brokerConfig.isForceRegister());
                } catch (Throwable e) {
                    BrokerController.LOG.error(&quot;registerBrokerAll Exception&quot;, e);
                }
            }
        }, 1000 * 10, Math.max(10000, Math.min(brokerConfig.getRegisterNameServerPeriod(), 60000)), TimeUnit.MILLISECONDS));
</code></pre>
<blockquote>
<p>registerBrokerAll</p>
</blockquote>
<pre><code class="language-java">   final List&lt;RegisterBrokerResult&gt; registerBrokerResultList = new CopyOnWriteArrayList&lt;&gt;();

final CountDownLatch countDownLatch = new CountDownLatch(nameServerAddressList.size());
    for (final String namesrvAddr : nameServerAddressList) {
        brokerOuterExecutor.execute(new AbstractBrokerRunnable(brokerIdentity) {
            @Override
            public void run2() {
                try {
                    RegisterBrokerResult result = registerBroker(namesrvAddr, oneway, timeoutMills, requestHeader, body);
                    if (result != null) {
                        registerBrokerResultList.add(result);
                    }

                    LOGGER.info(&quot;Registering current broker to name server completed. TargetHost={}&quot;, namesrvAddr);
                } catch (Exception e) {
                    LOGGER.error(&quot;Failed to register current broker to name server. TargetHost={}&quot;, namesrvAddr, e);
                } finally {
                    countDownLatch.countDown();
                }
            }
        });
    }

        try {
        if (!countDownLatch.await(timeoutMills, TimeUnit.MILLISECONDS)) {
            LOGGER.warn(&quot;Registration to one or more name servers does NOT complete within deadline. Timeout threshold: {}ms&quot;, timeoutMills);
        }
    } catch (InterruptedException ignore) {
    }
</code></pre>
<p>该方法主要是遍历 NameServer列表，Broker消息服务器依次向 NameServer发送心跳包。</p>
<pre><code class="language-java">  private RegisterBrokerResult registerBroker(
            final String namesrvAddr,
            final boolean oneway,
            final int timeoutMills,
            final RegisterBrokerRequestHeader requestHeader,
            final byte[] body
    ) throws RemotingCommandException, MQBrokerException, RemotingConnectException, RemotingSendRequestException, RemotingTimeoutException,
            InterruptedException {
        RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.REGISTER_BROKER, requestHeader);
        request.setBody(body);

        if (oneway) {
            try {
                this.remotingClient.invokeOneway(namesrvAddr, request, timeoutMills);
            } catch (RemotingTooMuchRequestException e) {
                // Ignore
            }
            return null;
        }
        //....
    }
</code></pre>
<p>发送心跳包具体逻辑，首先封装请求包头( Header)。</p>
<p>brokerAddr: broker 地址 。<br>
brokerId: brokerld,0:Master;大 0: Slave。<br>
brokerName:broker名称。<br>
clusterName: 集群名称。<br>
haServerAddr: master 地址，初次请求时该值为空，slave 向Nameserver注册后返回。<br>
requestBody:<br>
filterServerList：消息过滤服务器列表。<br>
topicConfigWrapper：主题配置。</p>
<pre><code class="language-java">    final RegisterBrokerRequestHeader requestHeader = new RegisterBrokerRequestHeader();
    requestHeader.setBrokerAddr(brokerAddr);
    requestHeader.setBrokerId(brokerId);
    requestHeader.setBrokerName(brokerName);
    requestHeader.setClusterName(clusterName);
    requestHeader.setHaServerAddr(haServerAddr);
    requestHeader.setEnableActingMaster(enableActingMaster);
    requestHeader.setCompressed(false);

    RegisterBrokerBody requestBody = new RegisterBrokerBody();
    requestBody.setTopicConfigSerializeWrapper(TopicConfigAndMappingSerializeWrapper.from(topicConfigWrapper));
    requestBody.setFilterServerList(filterServerList);
</code></pre>
<blockquote>
<p>RocketMQ网络传输基于 Netty,每一个请求，RocketMQ都会定义一个RequestCode，然后在服务端会对应相应的网络处理器 (processor包中)。</p>
</blockquote>
<ol start="2">
<li>NameServer处理心跳包</li>
</ol>
<p>org.apache.rocketmq.namesrv.processor.DefaultRequestProcessor 网络处理器解析请求类型， 如果请求类型为RequestCode.REGISTER_BROKER，则请求最终转发到RoutelnfoMan ager#registerBroker。</p>
<pre><code class="language-java">this.lock.writeLock().lockInterruptibly();

//init or update the cluster info
Set&lt;String&gt; brokerNames = this.clusterAddrTable.computeIfAbsent(clusterName, k -&gt; new HashSet&lt;&gt;());
brokerNames.add(brokerName);
</code></pre>
<ul>
<li>Step1:路由注册需要加写锁，防止并发修改RoutelnfoManager中的路由表。</li>
</ul>
<pre><code class="language-java">// 是否第一个注册
boolean registerFirst = false; 
BrokerData brokerData = this.brokerAddrTable.get(brokerName);
if (null == brokerData) {
    registerFirst = true;
    brokerData = new BrokerData(clusterName, brokerName, new HashMap&lt;&gt;());
    this.brokerAddrTable.put(brokerName, brokerData);
}

boolean isOldVersionBroker = enableActingMaster == null;
brokerData.setEnableActingMaster(!isOldVersionBroker &amp;&amp; enableActingMaster);
brokerData.setZoneName(zoneName);

//省略

String oldAddr = brokerAddrsMap.put(brokerId, brokerAddr);
registerFirst = registerFirst || (StringUtils.isEmpty(oldAddr));
</code></pre>
<p>Step2 :维护BrokerData信息，首先从brokerAddrTable根据 BrokerName尝试获取 Broker信息，如果不存在，则新建BrokerData并放入到brokerAddrTable, registerFirst设置为 true;如果存在，直接替换原先的，registerFirst设置为false，表示非第一次注册。</p>
<pre><code class="language-java">boolean isMaster = MixAll.MASTER_ID == brokerId;
boolean isPrimeSlave = !isOldVersionBroker &amp;&amp; !isMaster
        &amp;&amp; brokerId == Collections.min(brokerAddrsMap.keySet());
if (null != topicConfigWrapper &amp;&amp; (isMaster || isPrimeSlave)) {

        ConcurrentMap&lt;String, TopicConfig&gt; tcTable =
                topicConfigWrapper.getTopicConfigTable();
        if (tcTable != null) {
            for (Map.Entry&lt;String, TopicConfig&gt; entry : tcTable.entrySet()) {
                if (registerFirst || this.isTopicConfigChanged(clusterName, brokerAddr,
                        topicConfigWrapper.getDataVersion(), brokerName,
                        entry.getValue().getTopicName())) {
                    final TopicConfig topicConfig = entry.getValue();
                    if (isPrimeSlave) {
                        // Wipe write perm for prime slave
                        topicConfig.setPerm(topicConfig.getPerm() &amp; (~PermName.PERM_WRITE));
                    }
                    this.createAndUpdateQueueData(brokerName, topicConfig);
                }
            }
        }
}
</code></pre>
<ul>
<li>Step3 :如果Broker为Master，并且BrokerTopic配置信息发生变化或者是初次注册，则需要创建或更新 Topic路由元数据，填充topicQueueTable，其实就是为默认主题自动注 册路由信息其中包含 MixAII.DEFAULT_TOPIC的路由信息。当消息生产者发送主题时，如果该主题未创建并且BrokerConfig的autoCreateTopicEnable为true时，将返回MixAII. DEFAULT_TOPIC的路由信息。</li>
</ul>
<pre><code class="language-java">private void createAndUpdateQueueData(final String brokerName, final TopicConfig topicConfig) {
    QueueData queueData = new QueueData();
    queueData.setBrokerName(brokerName);
    queueData.setWriteQueueNums(topicConfig.getWriteQueueNums());
    queueData.setReadQueueNums(topicConfig.getReadQueueNums());
    queueData.setPerm(topicConfig.getPerm());
    queueData.setTopicSysFlag(topicConfig.getTopicSysFlag());

    Map&lt;String, QueueData&gt; queueDataMap = this.topicQueueTable.get(topicConfig.getTopicName());
    if (null == queueDataMap) {
        queueDataMap = new HashMap&lt;&gt;();
        queueDataMap.put(brokerName, queueData);
        this.topicQueueTable.put(topicConfig.getTopicName(), queueDataMap);
        log.info(&quot;new topic registered, {} {}&quot;, topicConfig.getTopicName(), queueData);
    } else {
        final QueueData existedQD = queueDataMap.get(brokerName);
        if (existedQD == null) {
            queueDataMap.put(brokerName, queueData);
        } else if (!existedQD.equals(queueData)) {
            log.info(&quot;topic changed, {} OLD: {} NEW: {}&quot;, topicConfig.getTopicName(), existedQD,
                queueData);
            queueDataMap.put(brokerName, queueData);
        }
    }
}
</code></pre>
<p>根据 TopicConfig创建 QueueData数据结构 ，然后更新 topicQueueTable。</p>
<pre><code class="language-java">BrokerAddrInfo brokerAddrInfo = new BrokerAddrInfo(clusterName, brokerAddr);
BrokerLiveInfo prevBrokerLiveInfo = this.brokerLiveTable.put(brokerAddrInfo,
        new BrokerLiveInfo(
                System.currentTimeMillis(),
                timeoutMillis == null ? DEFAULT_BROKER_CHANNEL_EXPIRED_TIME : timeoutMillis,
                topicConfigWrapper == null ? new DataVersion() : topicConfigWrapper.getDataVersion(),
                channel,
                haServerAddr));
if (null == prevBrokerLiveInfo) {
    log.info(&quot;new broker registered, {} HAService: {}&quot;, brokerAddrInfo, haServerAddr);
}
</code></pre>
<ul>
<li>Step4: 更新BrokerLivelnfo，存活Broker信息表， BrokeLivelnfo是执行路由删除的重要依据。</li>
</ul>
<pre><code class="language-java">if (filterServerList != null) {
    if (filterServerList.isEmpty()) {
        this.filterServerTable.remove(brokerAddrInfo);
    } else {
        this.filterServerTable.put(brokerAddrInfo, filterServerList);
    }
}

if (MixAll.MASTER_ID != brokerId) {
    String masterAddr = brokerData.getBrokerAddrs().get(MixAll.MASTER_ID);
    if (masterAddr != null) {
        BrokerAddrInfo masterAddrInfo = new BrokerAddrInfo(clusterName, masterAddr);
        BrokerLiveInfo masterLiveInfo = this.brokerLiveTable.get(masterAddrInfo);
        if (masterLiveInfo != null) {
            result.setHaServerAddr(masterLiveInfo.getHaServerAddr());
            result.setMasterAddr(masterAddr);
        }
    }
}
</code></pre>
<ul>
<li>Step5 : 注册Broker的过滤器Server地址列表，一个Broker上会关联多个FilterServer消息过滤服务器;如果此Broker为从节点，则需要查找该Broker的Master 的节点信息，并更新对应的masterAddr属性 。</li>
</ul>
<blockquote>
<p>NameServe与Broker保持长连接， Broker状态存储在 brokerLiveTable中，NameServer每收到一个心跳包，将更新 brokerLiveTable中关于Broker的状态信息以及路 由表( topicQueueTable、 brokerAddrTable、brokerLiveTable、filterServerTable)。 更新上述 路由表( HashTable)使用了锁粒度较少的<strong>读写锁</strong>，允许多个消息发送者( Producer)并发读，保证消息发送时的高并发。但同一时刻NameServer只处理一个Broker心跳包，多个心跳包请求串行执行。</p>
</blockquote>
<h3 id="233-路由删除">2.3.3 路由删除</h3>
<p>NameServer会每隔10s扫描brokerLiveTable状态表，如果BrokerLive的lastUpdateTimestamp的时间戳距当前时间超过 120s，则认为Broker失效，移除该 Broker, 关闭与Broker连接，并同时更新topicQueueTable、brokerAddrTable、brokerLiveTable、filterServerTable。</p>
<p>RocktMQ有两个触发点来触发路由删除。</p>
<ol>
<li>NameServer定时扫描 brokerLiveTable检测上次心跳包与当前系统时间的时间差，如果时间戳大于 120s则需要移除该 Broker信息 。<br>
2 ) Broker在正常被关闭的情况下会执行unregisterBroker指令。</li>
</ol>
<pre><code class="language-java">public void scanNotActiveBroker() {
    try {
        log.info(&quot;start scanNotActiveBroker&quot;);
        for (Entry&lt;BrokerAddrInfo, BrokerLiveInfo&gt; next : this.brokerLiveTable.entrySet()) {
            long last = next.getValue().getLastUpdateTimestamp();
            long timeoutMillis = next.getValue().getHeartbeatTimeoutMillis();
            if ((last + timeoutMillis) &lt; System.currentTimeMillis()) {
                RemotingUtil.closeChannel(next.getValue().getChannel());
                log.warn(&quot;The broker channel expired, {} {}ms&quot;, next.getKey(), timeoutMillis);
                this.onChannelDestroy(next.getKey());
            }
        }
    } catch (Exception e) {
        log.error(&quot;scanNotActiveBroker exception&quot;, e);
    }
}
</code></pre>
<pre><code class="language-java">public void onChannelDestroy(BrokerAddrInfo brokerAddrInfo) {
    UnRegisterBrokerRequestHeader unRegisterRequest = new UnRegisterBrokerRequestHeader();
    boolean needUnRegister = false;
    if (brokerAddrInfo != null) {
        try {
            try {
                this.lock.readLock().lockInterruptibly();
                needUnRegister = setupUnRegisterRequest(unRegisterRequest, brokerAddrInfo);
            } finally {
                this.lock.readLock().unlock();
            }
        } catch (Exception e) {
            log.error(&quot;onChannelDestroy Exception&quot;, e);
        }
    }

    if (needUnRegister) {
        boolean result = this.submitUnRegisterBrokerRequest(unRegisterRequest);
        log.info(&quot;the broker's channel destroyed, submit the unregister request at once, &quot; +
            &quot;broker info: {}, submit result: {}&quot;, unRegisterRequest, result);
    }
}
</code></pre>
<p>Step1 :申请写锁，把需要移除的broker添加到阻塞队列。</p>
<pre><code class="language-java">public void unRegisterBroker(Set&lt;UnRegisterBrokerRequestHeader&gt; unRegisterRequests) {
        try {
            try {
                Set&lt;String&gt; removedBroker = new HashSet&lt;&gt;();
                Set&lt;String&gt; reducedBroker = new HashSet&lt;&gt;();
                Map&lt;String, BrokerStatusChangeInfo&gt; needNotifyBrokerMap = new HashMap&lt;&gt;();

                this.lock.writeLock().lockInterruptibly();
                for (final UnRegisterBrokerRequestHeader unRegisterRequest : unRegisterRequests) {
                    final String brokerName = unRegisterRequest.getBrokerName();
                    final String clusterName = unRegisterRequest.getClusterName();

                    BrokerAddrInfo brokerAddrInfo = new BrokerAddrInfo(clusterName, unRegisterRequest.getBrokerAddr());

                    BrokerLiveInfo brokerLiveInfo = this.brokerLiveTable.remove(brokerAddrInfo);
                    log.info(&quot;unregisterBroker, remove from brokerLiveTable {}, {}&quot;,
                        brokerLiveInfo != null ? &quot;OK&quot; : &quot;Failed&quot;,
                        brokerAddrInfo
                    );

                    this.filterServerTable.remove(brokerAddrInfo);

                    boolean removeBrokerName = false;
                    boolean isMinBrokerIdChanged = false;
                    BrokerData brokerData = this.brokerAddrTable.get(brokerName);
                    if (null != brokerData) {
                        if (!brokerData.getBrokerAddrs().isEmpty() &amp;&amp;
                            unRegisterRequest.getBrokerId().equals(Collections.min(brokerData.getBrokerAddrs().keySet()))) {
                            isMinBrokerIdChanged = true;
                        }
                        String addr = brokerData.getBrokerAddrs().remove(unRegisterRequest.getBrokerId());
                        log.info(&quot;unregisterBroker, remove addr from brokerAddrTable {}, {}&quot;,
                            addr != null ? &quot;OK&quot; : &quot;Failed&quot;,
                            brokerAddrInfo
                        );
                        if (brokerData.getBrokerAddrs().isEmpty()) {
                            this.brokerAddrTable.remove(brokerName);
                            log.info(&quot;unregisterBroker, remove name from brokerAddrTable OK, {}&quot;,
                                brokerName
                            );

                            removeBrokerName = true;
                        } else if (isMinBrokerIdChanged) {
                            needNotifyBrokerMap.put(brokerName, new BrokerStatusChangeInfo(
                                brokerData.getBrokerAddrs(), addr, null));
                        }
                    }

                    if (removeBrokerName) {
                        Set&lt;String&gt; nameSet = this.clusterAddrTable.get(clusterName);
                        if (nameSet != null) {
                            boolean removed = nameSet.remove(brokerName);
                            log.info(&quot;unregisterBroker, remove name from clusterAddrTable {}, {}&quot;,
                                removed ? &quot;OK&quot; : &quot;Failed&quot;,
                                brokerName);

                            if (nameSet.isEmpty()) {
                                this.clusterAddrTable.remove(clusterName);
                                log.info(&quot;unregisterBroker, remove cluster from clusterAddrTable {}&quot;,
                                    clusterName
                                );
                            }
                        }
                        removedBroker.add(brokerName);
                    } else {
                        reducedBroker.add(brokerName);
                    }
                }

                cleanTopicByUnRegisterRequests(removedBroker, reducedBroker);

                if (!needNotifyBrokerMap.isEmpty() &amp;&amp; namesrvConfig.isNotifyMinBrokerIdChanged()) {
                    notifyMinBrokerIdChanged(needNotifyBrokerMap);
                }
            } finally {
                this.lock.writeLock().unlock();
            }
        } catch (Exception e) {
            log.error(&quot;unregisterBroker Exception&quot;, e);
        }
    }
</code></pre>
<p>Step2 :统一删除每个map中元数据。</p>
<pre><code class="language-java">private void cleanTopicByUnRegisterRequests(Set&lt;String&gt; removedBroker, Set&lt;String&gt; reducedBroker) {
    Iterator&lt;Entry&lt;String, Map&lt;String, QueueData&gt;&gt;&gt; itMap = this.topicQueueTable.entrySet().iterator();
    while (itMap.hasNext()) {
        Entry&lt;String, Map&lt;String, QueueData&gt;&gt; entry = itMap.next();

        String topic = entry.getKey();
        Map&lt;String, QueueData&gt; queueDataMap = entry.getValue();

        for (final String brokerName : removedBroker) {
            final QueueData removedQD = queueDataMap.remove(brokerName);
            if (removedQD != null) {
                log.debug(&quot;removeTopicByBrokerName, remove one broker's topic {} {}&quot;, topic, removedQD);
            }
        }

        if (queueDataMap.isEmpty()) {
            log.debug(&quot;removeTopicByBrokerName, remove the topic all queue {}&quot;, topic);
            itMap.remove();
        }

        for (final String brokerName : reducedBroker) {
            final QueueData queueData = queueDataMap.get(brokerName);

            if (queueData != null) {
                if (this.brokerAddrTable.get(brokerName).isEnableActingMaster()) {
                    // Master has been unregistered, wipe the write perm
                    if (isNoMasterExists(brokerName)) {
                        queueData.setPerm(queueData.getPerm() &amp; (~PermName.PERM_WRITE));
                    }
                }
            }
        }
    }
}
</code></pre>
<p>Step3 :删除Topic队列中元数据。</p>
<h3 id="234-路由发现">2.3.4 路由发现</h3>
<p>RocketMQ路由发现是非实时的，当Topic路由出现变化后，NameServer不主动推送给客户端，而是由客户端定时拉取主题最新的路由。根据主题名称拉取路由信息的命令编码为: GET_ROUTEINTO_BY_TOPIC。</p>
<pre><code class="language-java">public class TopicRouteData extends RemotingSerializable {

    //顺序消息配置内容，来自于 kvConfig。
    private String orderTopicConf;
    //topic 队列元数据 
    private List&lt;QueueData&gt; queueDatas;
    //topic分布的 broker元数据
    private List&lt;BrokerData&gt; brokerDatas;
    //broker上过滤服务器地址列表。
    private HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable;
    //It could be null or empty
    private Map&lt;String/*brokerName*/, TopicQueueMappingInfo&gt; topicQueueMappingByBroker;
}
</code></pre>
<pre><code class="language-java">public RemotingCommand getRouteInfoByTopic(ChannelHandlerContext ctx,
        RemotingCommand request) throws RemotingCommandException {
        final RemotingCommand response = RemotingCommand.createResponseCommand(null);
        final GetRouteInfoRequestHeader requestHeader =
            (GetRouteInfoRequestHeader) request.decodeCommandCustomHeader(GetRouteInfoRequestHeader.class);

        TopicRouteData topicRouteData = this.namesrvController.getRouteInfoManager().pickupTopicRouteData(requestHeader.getTopic());

        if (topicRouteData != null) {
            if (this.namesrvController.getNamesrvConfig().isOrderMessageEnable()) {
                String orderTopicConf =
                    this.namesrvController.getKvConfigManager().getKVConfig(NamesrvUtil.NAMESPACE_ORDER_TOPIC_CONFIG,
                        requestHeader.getTopic());
                topicRouteData.setOrderTopicConf(orderTopicConf);
            }

            byte[] content;
            Boolean standardJsonOnly = requestHeader.getAcceptStandardJsonOnly();
            if (request.getVersion() &gt;= MQVersion.Version.V4_9_4.ordinal() || (null != standardJsonOnly &amp;&amp; standardJsonOnly)) {
                content = topicRouteData.encode(SerializerFeature.BrowserCompatible,
                    SerializerFeature.QuoteFieldNames, SerializerFeature.SkipTransientField,
                    SerializerFeature.MapSortField);
            } else {
                content = topicRouteData.encode();
            }

            response.setBody(content);
            response.setCode(ResponseCode.SUCCESS);
            response.setRemark(null);
            return response;
        }

        response.setCode(ResponseCode.TOPIC_NOT_EXIST);
        response.setRemark(&quot;No topic route info in name server for the topic: &quot; + requestHeader.getTopic()
            + FAQUrl.suggestTodo(FAQUrl.APPLY_TOPIC_URL));
        return response;
    }
</code></pre>
<p>Step1:调用 RouterlnfoManager 的方法，从路由 表 topicQueueTable、 brokerAddrTable、 filterServerTable中分别填充TopicRouteData中的List<QueueData>、List<BrokerData>和 filterServer 地址表 。<br>
Step2 : 如果找到主题对应的路由信息并且该主题为顺序消息，则从 NameServer KVconfig 中获取关于顺序消息相关 的配置填充路由信息 。</p>
<p>如果找不到路由信息CODE则使用 TOPIC_NOT_EXISTS ，表示没有找到对应的路由 。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1663067880142.png" alt="NameServer 路由 注册、删除机制" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis6.0的新特性]]></title>
        <id>https://q456qq520.github.io/post/redis60-de-xin-te-xing/</id>
        <link href="https://q456qq520.github.io/post/redis60-de-xin-te-xing/">
        </link>
        <updated>2022-09-07T07:26:39.000Z</updated>
        <summary type="html"><![CDATA[<p>Redis 6.0版本中新出的多线程特性。</p>
]]></summary>
        <content type="html"><![CDATA[<p>Redis 6.0版本中新出的多线程特性。</p>
<!-- more -->
<h1 id="1-从单线程处理网络请求到多线程处理">1 从单线程处理网络请求到多线程处理</h1>
<p>在Redis 6.0中，非常受关注的第一个新特性就是多线程。这是因为，Redis一直被大家熟知的就是它的单线程架构，虽然有些命令操作可以用后台线程或子进程执行（比如数据删除、快照生成、AOF重写），但是，从网络IO处理到实际的读写命令处理，都是由单个线程完成的。</p>
<p>**Redis的多IO线程只是用来处理网络请求的，对于读写命令，Redis仍然使用单线程来处理。**这是因为，Redis处理请求时，网络处理经常是瓶颈，通过多个IO线程并行处理网络操作，可以提升实例的整体处理性能。而继续使用单线程执行命令操作，就不用为了保证Lua脚本、事务的原子性，额外开发多线程互斥机制了。</p>
<h2 id="11-主线程和io线程具体是怎么协作完成请求处理的">1.1 主线程和IO线程具体是怎么协作完成请求处理的?</h2>
<p>可以把主线程和多IO线程的协作分成四个阶段。</p>
<h3 id="111-阶段一服务端和客户端建立socket连接并分配处理线程">1.1.1 阶段一：服务端和客户端建立Socket连接，并分配处理线程</h3>
<p>首先，主线程负责接收建立连接请求。当有客户端请求和实例建立Socket连接时，主线程会创建和客户端的连接，并把 Socket 放入全局等待队列中。紧接着，主线程通过轮询方法把Socket连接分配给IO线程。</p>
<h3 id="112-阶段二io线程读取并解析请求">1.1.2 阶段二：IO线程读取并解析请求</h3>
<p>主线程一旦把Socket分配给IO线程，就会进入阻塞状态，等待IO线程完成客户端请求读取和解析。因为有多个IO线程在并行处理。</p>
<h3 id="113-阶段三主线程执行请求操作">1.1.3 阶段三：主线程执行请求操作</h3>
<p>等到IO线程解析完请求，主线程还是会以单线程的方式执行这些命令操作。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662536175466.png" alt="主线程执行请求操作" loading="lazy"></figure>
<h3 id="114-阶段四io线程回写socket和主线程清空全局队列">1.1.4 阶段四：IO线程回写Socket和主线程清空全局队列</h3>
<p>当主线程执行完请求操作后，会把需要返回的结果写入缓冲区，然后，主线程会阻塞等待IO线程把这些结果回写到Socket中，并返回给客户端。</p>
<p>和IO线程读取和解析请求一样，IO线程回写Socket时，也是有多个线程在并发执行，所以回写Socket的速度也很快。等到IO线程回写Socket完毕，主线程会清空全局队列，等待客户端的后续请求。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662536234785.png" alt="IO线程回写Socket和主线程清空全局队列" loading="lazy"></figure>
<h2 id="12-开启多线程">1.2 开启多线程</h2>
<p>在Redis 6.0中，多线程机制默认是关闭的，如果需要使用多线程功能，需要在redis.conf中完成两个设置。</p>
<ol>
<li><strong>设置io-thread-do-reads配置项为yes，表示启用多线程。</strong></li>
</ol>
<blockquote>
<p>io-threads-do-reads yes</p>
</blockquote>
<ol start="2">
<li><strong>设置线程个数</strong></li>
</ol>
<p>一般来说，线程个数要小于Redis实例所在机器的CPU核个数，例如，对于一个8核的机器来说，Redis官方建议配置6个IO线程。</p>
<blockquote>
<p>io-threads  6</p>
</blockquote>
<h1 id="2-实现服务端协助的客户端缓存">2 实现服务端协助的客户端缓存</h1>
<p>和之前的版本相比，Redis 6.0新增了一个重要的特性，就是实现了服务端协助的客户端缓存功能，也称为跟踪（Tracking）功能。有了这个功能，业务应用中的Redis客户端就可以把读取的数据缓存在业务应用本地了，应用就可以直接在本地快速读取数据了。</p>
<p>不过，当把数据缓存在客户端本地时，我们会面临一个问题：如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理？</p>
<p>6.0实现的Tracking功能实现了两种模式，来解决这个问题。</p>
<h2 id="21-普通模式">2.1 普通模式</h2>
<p>在这个模式下，实例会在服务端记录客户端读取过的key，并监测key是否有修改。一旦key的值发生变化，服务端会给客户端发送<strong>invalidate</strong>消息，通知客户端缓存失效了。</p>
<p>在使用普通模式时，服务端对于记录的key只会报告一次invalidate消息，也就是说，服务端在给客户端发送过一次invalidate消息后，如果key再被修改，此时，服务端就不会再次给客户端发送invalidate消息。</p>
<p>只有当客户端再次执行读命令时，服务端才会再次监测被读取的key，并在key修改时发送invalidate消息。这样设计的考虑是节省有限的内存空间。毕竟，如果客户端不再访问这个key了，而服务端仍然记录key的修改情况，就会浪费内存资源。</p>
<p>通过执行下面的命令，打开或关闭普通模式下的Tracking功能。</p>
<blockquote>
<p>CLIENT TRACKING ON|OFF</p>
</blockquote>
<h2 id="22-广播模式">2.2 广播模式</h2>
<p>在这个模式下，服务端会给客户端广播所有key的失效情况，不过，这样做了之后，如果key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。</p>
<p>所以，在实际应用时，我们会让客户端注册希望跟踪的key的前缀，当带有注册前缀的key被修改时，服务端会把失效消息广播给所有注册的客户端。</p>
<p><strong>和普通模式不同，在广播模式下，即使客户端还没有读取过key，但只要它注册了要跟踪的key，服务端都会把key失效消息通知给这个客户端。</strong></p>
<p>注册命令如下：</p>
<blockquote>
<p>CLIENT TRACKING ON BCAST PREFIX user</p>
</blockquote>
<p>普通模式和广播模式，需要客户端使用RESP 3协议，RESP 3协议是6.0新启用的通信协议。</p>
<h2 id="23-resp-2协议">2.3 RESP 2协议</h2>
<p>对于使用RESP 2协议的客户端来说，就需要使用另一种模式，也就是<strong>重定向模式（redirect）</strong>。在重定向模式下，想要获得失效消息通知的客户端，就需要执行订阅命令<strong>SUBSCRIBE</strong>，专门订阅用于发送失效消息的频道_redis_:invalidate。同时，再使用另外一个客户端，执行CLIENT TRACKING命令，设置服务端将失效消息转发给使用RESP 2协议的客户端。</p>
<p>假设客户端B想要获取失效消息，但是客户端B只支持RESP 2协议，客户端A支持RESP 3协议。我们可以分别在客户端B和A上执行SUBSCRIBE和CLIENT TRACKING，如下所示：</p>
<pre><code class="language-redis">//客户端B执行，客户端B的ID号是303
SUBSCRIBE _redis_:invalidate

//客户端A执行
CLIENT TRACKING ON BCAST REDIRECT 303
</code></pre>
<p>这样设置以后，如果有键值对被修改了，客户端B就可以通过_redis_:invalidate频道，获得失效消息了。</p>
<h1 id="3-实例的访问权限控制列表功能access-control-listacl">3 实例的访问权限控制列表功能（Access Control List，ACL）</h1>
<h2 id="31-从简单的基于密码访问到细粒度的权限控制">3.1 从简单的基于密码访问到细粒度的权限控制</h2>
<p>在Redis 6.0 版本之前，要想实现实例的安全访问，只能通过设置密码来控制，例如，客户端连接实例前需要输入密码。</p>
<p>此外，对于一些高风险的命令（例如KEYS、FLUSHDB、FLUSHALL等），在Redis 6.0 之前，我们也只能通过rename-command来重新命名这些命令，避免客户端直接调用。</p>
<p>Redis 6.0 提供了更加细粒度的访问权限控制，这主要有两方面的体现。</p>
<p>首先，6.0版本支持创建不同用户来使用Redis。在6.0版本前，所有客户端可以使用同一个密码进行登录使用，但是没有用户的概念，而在6.0中，我们可以使用ACL SETUSER命令创建用户。例如，我们可以执行下面的命令，创建并启用一个用户normaluser，把它的密码设置为“abc”：</p>
<blockquote>
<p>ACL SETUSER normaluser on &gt; abc</p>
</blockquote>
<p>另外，6.0版本还支持以用户为粒度设置命令操作的访问权限。加号（+）和减号（-）就分别表示给用户赋予或撤销命令的调用权限。</p>
<p>假设我们要设置用户normaluser只能调用Hash类型的命令操作，而不能调用String类型的命令操作，我们可以执行如下命令：</p>
<blockquote>
<p>ACL SETUSER normaluser +@hash -@string</p>
</blockquote>
<p>除了设置某个命令或某类命令的访问控制权限，6.0版本还支持以key为粒度设置访问权限。</p>
<p>具体的做法是使用波浪号“~”和key的前缀来表示控制访问的key。例如，我们执行下面命令，就可以设置用户normaluser只能对以“user:”为前缀的key进行命令操作：</p>
<blockquote>
<p>ACL SETUSER normaluser ~user:* +@all</p>
</blockquote>
<h1 id="4-启用resp-3协议">4 启用RESP 3协议</h1>
<p>Redis 6.0实现了RESP 3通信协议，而之前都是使用的RESP 2。在RESP 2中，客户端和服务器端的通信内容都是以字节数组形式进行编码的，客户端需要根据操作的命令或是数据类型自行对传输的数据进行解码，增加了客户端开发复杂度。</p>
<p>而RESP 3直接支持多种数据类型的区分编码，包括空值、浮点数、布尔值、有序的字典集合、无序的集合等。</p>
<p>所谓区分编码，就是指直接通过不同的开头字符，区分不同的数据类型，这样一来，客户端就可以直接通过判断传递消息的开头字符，来实现数据转换操作了，提升了客户端的效率。除此之外，RESP 3协议还可以支持客户端以普通模式和广播模式实现客户端缓存。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java并发 - 锁]]></title>
        <id>https://q456qq520.github.io/post/java-bing-fa-suo/</id>
        <link href="https://q456qq520.github.io/post/java-bing-fa-suo/">
        </link>
        <updated>2022-09-06T07:57:36.000Z</updated>
        <summary type="html"><![CDATA[<p>Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。</p>
]]></summary>
        <content type="html"><![CDATA[<p>Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。</p>
<!-- more -->
<h1 id="1-乐观锁-vs-悲观锁">1. 乐观锁 VS 悲观锁</h1>
<blockquote>
<p>乐观锁与悲观锁是一种广义上的概念，体现了看待线程同步的不同角度。在Java和数据库中都有此概念对应的实际应用。</p>
</blockquote>
<p>对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，<strong>synchronized关键字</strong>和<strong>Lock</strong>的实现类都是悲观锁。</p>
<p>而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。</p>
<p>乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。</p>
<p>根据从上面的概念描述我们可以发现：</p>
<ul>
<li>悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。</li>
<li>乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。</li>
</ul>
<pre><code class="language-java">// ------------------------- 悲观锁的调用方式 -------------------------
// synchronized
public synchronized void testMethod() {
	// 操作同步资源
}
// ReentrantLock
private ReentrantLock lock = new ReentrantLock(); // 需要保证多个线程使用的是同一个锁
public void modifyPublicResources() {
	lock.lock();
	// 操作同步资源
	lock.unlock();
}

// ------------------------- 乐观锁的调用方式 -------------------------
private AtomicInteger atomicInteger = new AtomicInteger();  // 需要保证多个线程使用的是同一个AtomicInteger
atomicInteger.incrementAndGet(); //执行自增1
</code></pre>
<h1 id="2-自旋锁-vs-适应性自旋锁">2. 自旋锁 VS 适应性自旋锁</h1>
<p>阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。</p>
<p>在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。</p>
<p>而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。</p>
<p>自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。</p>
<p>自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。</p>
<h1 id="3-无锁-vs-偏向锁-vs-轻量级锁-vs-重量级锁">3. 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁</h1>
<p>这四种锁是指锁的状。</p>
<p>偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。</p>
<p>锁膨胀方向： 无锁 → 偏向锁 → 轻量级锁 → 重量级锁 (此过程是不可逆的)</p>
<p>参考链接:<a href="/post/java-bing-fa">Java并发(一)</a></p>
<h1 id="4-公平锁-vs-非公平锁">4. 公平锁 VS 非公平锁</h1>
<p>公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。</p>
<p>非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。</p>
<h1 id="5-可重入锁-vs-非可重入锁">5. 可重入锁 VS 非可重入锁</h1>
<p>可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。下面用示例代码来进行分析：</p>
<pre><code class="language-java">public class Widget {
    public synchronized void doSomething() {
        System.out.println(&quot;方法1执行...&quot;);
        doOthers();
    }

    public synchronized void doOthers() {
        System.out.println(&quot;方法2执行...&quot;);
    }
}
</code></pre>
<p>在上面的代码中，类中的两个方法都是被内置锁synchronized修饰的，doSomething()方法中调用doOthers()方法。因为内置锁是可重入的，所以同一个线程在调用doOthers()时可以直接获得当前对象的锁，进入doOthers()进行操作。</p>
<p>如果是一个不可重入锁，那么当前线程在调用doOthers()之前需要将执行doSomething()时获取当前对象的锁释放掉，实际上该对象锁已被当前线程所持有，且无法释放。所以此时会出现死锁。</p>
<p>ReentrantLock和synchronized都是重入锁。</p>
<p>首先ReentrantLock和NonReentrantLock都继承父类AQS，其父类AQS中维护了一个同步状态status来计数重入次数，status初始值为0。</p>
<p>当线程尝试获取锁时，可重入锁先尝试获取并更新status值，如果status == 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。而非可重入锁是直接去获取并尝试更新当前status的值，如果status != 0的话会导致其获取锁失败，当前线程阻塞。</p>
<p>释放锁时，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放。</p>
<h1 id="6-独享锁排他锁-vs-共享锁">6. 独享锁(排他锁) VS 共享锁</h1>
<p>独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。</p>
<p>共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。</p>
<p>独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。</p>
<p>ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。</p>
<p>在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java基础 - LinkedHashSet&Map]]></title>
        <id>https://q456qq520.github.io/post/java-ji-chu-linkedhashsetandmap/</id>
        <link href="https://q456qq520.github.io/post/java-ji-chu-linkedhashsetandmap/">
        </link>
        <updated>2022-09-06T07:19:31.000Z</updated>
        <content type="html"><![CDATA[<h1 id="总体介绍">总体介绍</h1>
<p>LinkedHashSet和LinkedHashMap在Java里也有着相同的实现，前者仅仅是对后者做了一层包装，也就是说LinkedHashSet里面有一个LinkedHashMap(适配器模式)。</p>
<p>LinkedHashMap实现了Map接口，即允许放入key为null的元素，也允许插入value为null的元素。从名字上可以看出该容器是linked list和HashMap的混合体，也就是说它同时满足HashMap和linked list的某些特性。可将LinkedHashMap看作采用linked list增强的HashMap。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1662449233623.png" alt="base" loading="lazy"></figure>
<p>事实上LinkedHashMap是HashMap的直接子类，<strong>二者唯一的区别是LinkedHashMap在HashMap的基础上，采用双向链表(doubly-linked list)的形式将所有entry连接起来，这样是为保证元素的迭代顺序跟插入顺序相同</strong>。上图给出了LinkedHashMap的结构图，主体部分跟HashMap完全一样，多了header指向双向链表的头部(是一个哑元)，该双向链表的迭代顺序就是entry的插入顺序。</p>
<p>除了可以保迭代历顺序，这种结构还有一个好处 :  <strong>迭代LinkedHashMap时不需要像HashMap那样遍历整个table，而只需要直接遍历header指向的双向链表即可</strong>，也就是说LinkedHashMap的迭代时间就只跟entry的个数相关，而跟table的大小无关。</p>
<p>有两个参数可以影响LinkedHashMap的性能: 初始容量(inital capacity)和负载系数(load factor)。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。</p>
<p>将对象放入到LinkedHashMap或LinkedHashSet中时，有两个方法需要特别关心: hashCode()和equals()。hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到LinkedHashMap或LinkedHashSet中，需要@Override hashCode()和equals()方法。</p>
<p>出于性能原因，LinkedHashMap是非同步的(not synchronized)，如果需要在多线程环境使用，需要程序员手动同步；或者通过如下方式将LinkedHashMap包装成(wrapped)同步的:</p>
<pre><code class="language-java">Map m = Collections.synchronizedMap(new LinkedHashMap(...));
</code></pre>
<h1 id="方法剖析">方法剖析</h1>
<h2 id="get">get()</h2>
<p>get(Object key)方法根据指定的key值返回对应的value。该方法跟HashMap.get()方法的流程几乎完全一样，参考链接:<a href="/post/java-ji-chu-hashmap">Java基础-HashMap</a></p>
<h2 id="put">put()</h2>
<p>put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于get()方法；如果没有找到，则会通过addEntry(int hash, K key, V value, int bucketIndex)方法插入新的entry。</p>
<p>注意，这里的插入有两重含义:</p>
<blockquote>
<p>从table的角度看，新的entry需要插入到对应的bucket里，当有哈希冲突时，采用头插法将新的entry插入到冲突链表的头部。<br>
从header的角度看，新的entry需要插入到双向链表的尾部。</p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1662449865619.png" alt="addEntry" loading="lazy"></figure>
<pre><code class="language-java">// LinkedHashMap.addEntry()
void addEntry(int hash, K key, V value, int bucketIndex) {
    if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) {
        resize(2 * table.length);// 自动扩容，并重新哈希
        hash = (null != key) ? hash(key) : 0;
        bucketIndex = hash &amp; (table.length-1);// hash%table.length
    }
    // 1.在冲突链表头部插入新的entry
    HashMap.Entry&lt;K,V&gt; old = table[bucketIndex];
    Entry&lt;K,V&gt; e = new Entry&lt;&gt;(hash, key, value, old);
    table[bucketIndex] = e;
    // 2.在双向链表的尾部插入新的entry
    e.addBefore(header);
    size++;
}
</code></pre>
<p>上述代码中用到了addBefore()方法将新entry e插入到双向链表头引用header的前面，这样e就成为双向链表中的最后一个元素。addBefore()的代码如下:</p>
<pre><code class="language-java">// LinkedHashMap.Entry.addBefor()，将this插入到existingEntry的前面
private void addBefore(Entry&lt;K,V&gt; existingEntry) {
    after  = existingEntry;
    before = existingEntry.before;
    before.after = this;
    after.before = this;
}
</code></pre>
<p>上述代码只是简单修改相关entry的引用而已。</p>
<h2 id="remove">remove()</h2>
<p>remove(Object key)的作用是删除key值对应的entry，该方法的具体逻辑是在removeEntryForKey(Object key)里实现的。removeEntryForKey()方法会首先找到key值对应的entry，然后删除该entry(修改链表的相应引用)。查找过程跟get()方法类似。</p>
<p>注意，这里的删除也有两重含义:</p>
<blockquote>
<p>从table的角度看，需要将该entry从对应的bucket里删除，如果对应的冲突链表不空，需要修改冲突链表的相应引用。<br>
从header的角度来看，需要将该entry从双向链表中删除，同时修改链表中前面以及后面元素的相应引用。</p>
</blockquote>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1662450018650.png" alt="remove" loading="lazy"></figure>
<pre><code class="language-java">// LinkedHashMap.removeEntryForKey()，删除key值对应的entry
final Entry&lt;K,V&gt; removeEntryForKey(Object key) {
	......
	int hash = (key == null) ? 0 : hash(key);
    int i = indexFor(hash, table.length);// hash&amp;(table.length-1)
    Entry&lt;K,V&gt; prev = table[i];// 得到冲突链表
    Entry&lt;K,V&gt; e = prev;
    while (e != null) {// 遍历冲突链表
        Entry&lt;K,V&gt; next = e.next;
        Object k;
        if (e.hash == hash &amp;&amp;
            ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) {// 找到要删除的entry
            modCount++; size--;
            // 1. 将e从对应bucket的冲突链表中删除
            if (prev == e) table[i] = next;
            else prev.next = next;
            // 2. 将e从双向链表中删除
            e.before.after = e.after;
            e.after.before = e.before;
            return e;
        }
        prev = e; e = next;
    }
    return e;
}
</code></pre>
<h1 id="linkedhashset">LinkedHashSet</h1>
<pre><code class="language-java">public class LinkedHashSet&lt;E&gt;
    extends HashSet&lt;E&gt;
    implements Set&lt;E&gt;, Cloneable, java.io.Serializable {
    ......
    // LinkedHashSet里面有一个LinkedHashMap
    public LinkedHashSet(int initialCapacity, float loadFactor) {
        map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);
    }
	......
    public boolean add(E e) {//简单的方法转换
        return map.put(e, PRESENT)==null;
    }
    ......
}
</code></pre>
<h1 id="linkedhashmap经典用法">LinkedHashMap经典用法</h1>
<p>LinkedHashMap除了可以保证迭代顺序外，还有一个非常有用的用法: 可以轻松实现一个采用了FIFO替换策略的缓存。具体说来，LinkedHashMap有一个子类方法protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest)，该方法的作用是告诉Map是否要删除“最老”的Entry，所谓最老就是当前Map中最早插入的Entry，如果该方法返回true，最老的那个元素就会被删除。在每次插入新元素的之后LinkedHashMap会自动询问removeEldestEntry()是否要删除最老的元素。这样只需要在子类中重载该方法，当元素个数超过一定数量时让removeEldestEntry()返回true，就能够实现一个固定大小的FIFO策略的缓存。示例代码如下:</p>
<pre><code class="language-java">/** 一个固定大小的FIFO替换策略的缓存 */
class FIFOCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt;{
    private final int cacheSize;
    public FIFOCache(int cacheSize){
        this.cacheSize = cacheSize;
    }

    // 当Entry个数超过cacheSize时，删除最老的Entry
    @Override
    protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) {
       return size() &gt; cacheSize;
    }
}
</code></pre>
]]></content>
    </entry>
</feed>