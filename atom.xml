<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://q456qq520.github.io</id>
    <title>LIKECAT</title>
    <updated>2023-02-09T10:43:43.498Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://q456qq520.github.io"/>
    <link rel="self" href="https://q456qq520.github.io/atom.xml"/>
    <subtitle>一条小咸鱼</subtitle>
    <logo>https://q456qq520.github.io/images/avatar.png</logo>
    <icon>https://q456qq520.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, LIKECAT</rights>
    <entry>
        <title type="html"><![CDATA[SpringBoot启动流程]]></title>
        <id>https://q456qq520.github.io/post/springboot/</id>
        <link href="https://q456qq520.github.io/post/springboot/">
        </link>
        <updated>2023-02-09T02:35:00.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="1-springboot启动流程">1 Springboot启动流程</h2>
]]></summary>
        <content type="html"><![CDATA[<h2 id="1-springboot启动流程">1 Springboot启动流程</h2>
<!-- more -->
<h3 id="11-springapplication创建">1.1 SpringApplication创建</h3>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1675939261552.png" alt="" loading="lazy"></figure>
<h4 id="111-入口">1.1.1 入口</h4>
<pre><code class="language-java">public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) {
    this.sources = new LinkedHashSet();
    this.bannerMode = Mode.CONSOLE;
    this.logStartupInfo = true;
    this.addCommandLineProperties = true;
    this.headless = true;
    this.registerShutdownHook = true;
    this.additionalProfiles = new HashSet();
    this.isCustomEnvironment = false;
    this.resourceLoader = resourceLoader;
    Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;);
    // 将 Main Class 设置为自己的元素
    this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources));
    // 检查当先的 app 类型
    this.webApplicationType = WebApplicationType.deduceFromClasspath();
    // 先从 Spring.factories 文件中加载 ApplicationContextInitializer 类信息。
    setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class));
    // 先从 Spring.factories 文件中加载 ApplicationListener 类信息。
    setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));
    // 获取 main class 信息，并设置到本地属性中
    this.mainApplicationClass = deduceMainApplicationClass();
}
</code></pre>
<h4 id="112-检查应用类型">1.1.2 检查应用类型</h4>
<p>在将Main class 设置primarySources 后，调用了 WebApplicationType.deduceFromClasspath() 方法，该方法是为了检查当前的应用类型，并设置给 webApplicationType。</p>
<pre><code class="language-java">static WebApplicationType deduceFromClasspath() {
        if (ClassUtils.isPresent(&quot;org.springframework.web.reactive.DispatcherHandler&quot;, (ClassLoader)null) &amp;&amp; !ClassUtils.isPresent(&quot;org.springframework.web.servlet.DispatcherServlet&quot;, (ClassLoader)null) &amp;&amp; !ClassUtils.isPresent(&quot;org.glassfish.jersey.servlet.ServletContainer&quot;, (ClassLoader)null)) {
            return REACTIVE;
        } else {
            String[] var0 = SERVLET_INDICATOR_CLASSES;
            int var1 = var0.length;

            for(int var2 = 0; var2 &lt; var1; ++var2) {
                String className = var0[var2];
                if (!ClassUtils.isPresent(className, (ClassLoader)null)) {
                    return NONE;
                }
            }
        }
    }
</code></pre>
<p>这里主要是通过类加载器判断是否存在 <code>REACTIVE</code>相关的类信息，假如有就代表是一个 REACTIVE 的应用，假如不是就检查是否存在<code>Servelt</code>和 <code>ConfigurableWebApplicationContext</code> ，假如都没有，就代表应用为非 WEB 类应用，返回 <code>NONE</code>，默认返回<code>SERVLET</code>类型</p>
<h4 id="113-设置初始化器-initializer">1.1.3 设置初始化器 Initializer</h4>
<p>我们设置完成应用类型后，就寻找所有的 Initializer 实现类，并设置到SpringApplication 的 Initializers 中。</p>
<p>容器刷新之前调用此类的initialize方法。这个点允许被用户自己扩展。用户可以在整个spring容器还没被初始化之前做一些事情。可以想到的场景可能为，在最开始激活一些配置，或者利用这时候class还没被类加载器加载的时机，进行动态字节码注入等操作。</p>
<p>这里先说一下 getSpringFactoriesInstances 方法，我们知道在我们使用 SpringBoot 程序中，会经常在 META-INF/spring.factories 目录下看到一些EnableAutoConfiguration，来出发 config 类注入到容器中，我们知道一般一个 config 类要想被 SpringBoot 扫描到需要使用 @CompnentScan 来扫描具体的路径，对于 jar 包来说这无疑是非常不方便的，所以 SpringBoot 提供了另外一种方式来实现，就是使用 spring.factories。但是要实现，得先进行加载，过程如下：</p>
<pre><code class="language-java">private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) {
    ClassLoader classLoader = getClassLoader();
    // Use names and ensure unique to protect against duplicates
    Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader));
    List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names);
    AnnotationAwareOrderComparator.sort(instances);
    return instances;
}
</code></pre>
<p>我们先来看一下传入参数，这里需要注意的是 args，这个是初始化对应 type 的时候传入的构造参数，我们先看一下 SpringFactoriesLoader#loadFactoryNames 方法：</p>
<pre><code class="language-java">public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, @Nullable ClassLoader classLoader) {
    String factoryClassName = factoryClass.getName();
    return (List)loadSpringFactories(classLoader).getOrDefault(factoryClassName, Collections.emptyList());
}

private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader) {
    MultiValueMap&lt;String, String&gt; result = (MultiValueMap)cache.get(classLoader);
    if (result != null) {
        return result;
    } else {
        try {
            //加载配置文件
            Enumeration&lt;URL&gt; urls = classLoader != null ? classLoader.getResources(&quot;META-INF/spring.factories&quot;) : ClassLoader.getSystemResources(&quot;META-INF/spring.factories&quot;);
            LinkedMultiValueMap result = new LinkedMultiValueMap();

            while(urls.hasMoreElements()) {
                URL url = (URL)urls.nextElement();
                UrlResource resource = new UrlResource(url);
                Properties properties = PropertiesLoaderUtils.loadProperties(resource);
                Iterator var6 = properties.entrySet().iterator();

                while(var6.hasNext()) {
                    Entry&lt;?, ?&gt; entry = (Entry)var6.next();
                    List&lt;String&gt; factoryClassNames = Arrays.asList(StringUtils.commaDelimitedListToStringArray((String)entry.getValue()));
                    result.addAll((String)entry.getKey(), factoryClassNames);
                }
            }

            cache.put(classLoader, result);
            return result;
        } catch (IOException var9) {
            throw new IllegalArgumentException(&quot;Unable to load factories from location [META-INF/spring.factories]&quot;, var9);
        }
    }
}
</code></pre>
<p>首先是会先检查缓存，假如缓存中存在就直接返回，假如没有就调用 classLoader#getResources 方法，传入META-INF/spring.factories，即获取所有 jar 包下的对应文件，并封装成 UrlResource ，然后使用 PropertiesLoaderUtils 将这些信息读取成一个对一对的 properties，我们观察一下 spring.factories 都是按 properties 格式排版的，假如有多个就用逗号隔开，所以这里还需要将逗号的多个类分隔开来，并加到 result 中，由于 result 是一个 LinkedMultiValueMap 类型，支持多个值插入，最后放回缓存中。最终完成加载 META-INF/spring.factories 中的配置。</p>
<p>在获取到所有的 Initializer 后接下来是调用 createSpringFactoriesInstances 方法进行初始化。</p>
<pre><code class="language-java">private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) {
    ClassLoader classLoader = Thread.currentThread().getContextClassLoader();
    Set&lt;String&gt; names = new LinkedHashSet(SpringFactoriesLoader.loadFactoryNames(type, classLoader));
    List&lt;T&gt; instances = this.createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names);
    AnnotationAwareOrderComparator.sort(instances);
    return instances;
}
</code></pre>
<pre><code class="language-java">private &lt;T&gt; List&lt;T&gt; createSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, ClassLoader classLoader, Object[] args, Set&lt;String&gt; names) {
    List&lt;T&gt; instances = new ArrayList(names.size());
    Iterator var7 = names.iterator();
  // 这里包括很多初始化类信息，包括 apollo , shardingShepre 都是在这里初始化。
    while(var7.hasNext()) {
        String name = (String)var7.next();

        try {
            Class&lt;?&gt; instanceClass = ClassUtils.forName(name, classLoader);
            Assert.isAssignable(type, instanceClass);
            Constructor&lt;?&gt; constructor = instanceClass.getDeclaredConstructor(parameterTypes);
            T instance = BeanUtils.instantiateClass(constructor, args);
            instances.add(instance);
        } catch (Throwable var12) {
            throw new IllegalArgumentException(&quot;Cannot instantiate &quot; + type + &quot; : &quot; + name, var12);
        }
    }
    return instances;
}
</code></pre>
<p>这里的 names 就是我们上面通过类加载器加载到的类名，到这里会先通过反射生成 class 对象，然后判断该类是否继承与 ApplicationContextInitializer ，最后通过反射的方式获取这个类的构造方法，并调用该构造方法，传入已经定义好的构造参数，对于 ApplicationContextInitializer 是无参的构造方法，然后初始化实例并返回，回到原来的方法，这里会先对所有的 ApplicationContextInitializer 进行排序，调用 <code>AnnotationAwareOrderComparator#sort(instances)</code>方法，这里就是根据 @Order 中的顺序进行排序。</p>
<h4 id="114-设置监听器">1.1.4 设置监听器</h4>
<p>接下来是设置 ApplicationListener，我们跟进去就会发现这里和上面获取 ApplicationContextInitializer 的方法如出一辙。这里不过多介绍。</p>
<h3 id="12-springapplication-run">1.2 SpringApplication run()</h3>
<p>在完成 SpringApplication 对象的初始化后，我们进入了他的 run 方法，这个方法几乎涵盖了 SpringBoot 生命周期的所有内容，主要分为九个步骤。</p>
<pre><code class="language-java">public ConfigurableApplicationContext run(String... args) {
    // 启动计时器计算初始化完成耗时
    StopWatch stopWatch = new StopWatch();
    stopWatch.start();
    ConfigurableApplicationContext context = null;
    configureHeadlessProperty();
    // 第一步：获取 SpringApplicationRunListener， 然后调用他的 staring 方法启动监听器。
    SpringApplicationRunListeners listeners = getRunListeners(args);
    listeners.starting();
    try {
        ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);
        // 第二步:根据 SpringApplicationRunListeners以及参数来准备环境
        ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments);
        configureIgnoreBeanInfo(environment);
        // 准备打印 Banner
        Banner printedBanner = printBanner(environment);
        // 第三步：创建 Spring 容器
        context = createApplicationContext();
        // 第四步： Spring 容器的前置处理
        prepareContext(context, environment, listeners, applicationArguments, printedBanner);
        // 第五步：刷新 Spring 容器
        refreshContext(context);
        // 第六步： Spring 容器的后置处理器
        afterRefresh(context, applicationArguments);
        // 停止计时
        stopWatch.stop();
        if (this.logStartupInfo) {
            new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch);
        }
        //第七步：通知所有 listener 结束启动
        listeners.started(context);
        //第八步：调用所有 runner 的 run 方法
        callRunners(context, applicationArguments);
    }
    catch (Throwable ex) {
        handleRunFailure(context, ex, listeners);
        throw new IllegalStateException(ex);
    }
    //第九步：通知所有 listener running 事件
    try {
        listeners.running(context);
    }
    catch (Throwable ex) {
        handleRunFailure(context, ex, null);
        throw new IllegalStateException(ex);
    }
    return context;
}
</code></pre>
<h4 id="121-获取-springapplicationrunlistener">1.2.1 获取 SpringApplicationRunListener</h4>
<pre><code class="language-java">private SpringApplicationRunListeners getRunListeners(String[] args) {
    Class&lt;?&gt;[] types = new Class[]{SpringApplication.class, String[].class};
    return new SpringApplicationRunListeners(logger, this.getSpringFactoriesInstances(SpringApplicationRunListener.class, types, this, args));
}
</code></pre>
<p>这里和上面获取 initializer 和 listener 的方式基本一致，都是通过 getSpringFactoriesInstances, 最终只找到一个类就是：org.springframework.boot.context.event.EventPublishingRunListener ，然后调用其构造方法并传入产生 args , 和 SpringApplication 本身:</p>
<pre><code class="language-java">public class EventPublishingRunListener implements SpringApplicationRunListener, Ordered {

   private final SpringApplication application;

   private final String[] args;

   private final SimpleApplicationEventMulticaster initialMulticaster;

   public EventPublishingRunListener(SpringApplication application, String[] args) {
       this.application = application;
       this.args = args;
       this.initialMulticaster = new SimpleApplicationEventMulticaster();
       for (ApplicationListener&lt;?&gt; listener : application.getListeners()) {
           this.initialMulticaster.addApplicationListener(listener);
       }
   }
}
</code></pre>
<p>我们先看一下构造函数，首先将我们获取到的ApplicationListener 集合添加到<code>initialMulticaster</code>中， 最后都是通过操作<code>SimpleApplicationEventMulticaster</code> 来进行广播，我，他继承于 <code>AbstractApplicationEventMulticaster</code>。</p>
<h4 id="122-环境准备">1.2.2 环境准备</h4>
<pre><code class="language-java">private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners,
        ApplicationArguments applicationArguments) {
    // 根据类型创建对应的 environment
    ConfigurableEnvironment environment = getOrCreateEnvironment();
    // 配置 environment 信息
    configureEnvironment(environment, applicationArguments.getSourceArgs());
    ConfigurationPropertySources.attach(environment);
    // 发送 prepareEnviroment 事件
    listeners.environmentPrepared(environment);
    bindToSpringApplication(environment);
    if (!this.isCustomEnvironment) {
        environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment,
                deduceEnvironmentClass());
    }
    ConfigurationPropertySources.attach(environment);
    return environment;
}
</code></pre>
<p>首先是调用 <code>getOrCreateEnvironment</code>方法来创建<code>environment</code>，我们跟进去可以发现这里是根据我们上面设置的环境的类型来进行选择的。</p>
<pre><code class="language-java">private ConfigurableEnvironment getOrCreateEnvironment() {
    if (this.environment != null) {
        return this.environment;
    } else {
        switch(this.webApplicationType) {
        case SERVLET:
            return new StandardServletEnvironment();
        case REACTIVE:
            return new StandardReactiveWebEnvironment();
        default:
            return new StandardEnvironment();
        }
    }
}
</code></pre>
<p>在创建完成 Environment 后，接下来就到了调用 configureEnvironment 方法：</p>
<pre><code class="language-java">protected void configureEnvironment(ConfigurableEnvironment environment, String[] args) {
    if (this.addConversionService) {
        ConversionService conversionService = ApplicationConversionService.getSharedInstance();
        environment.setConversionService((ConfigurableConversionService) conversionService);
    }
    // 配置PropertySources
    configurePropertySources(environment, args);
    // 配置Profiles
    configureProfiles(environment, args);
}
</code></pre>
<p>我们先看一下 <code>configurePropertySources</code> 方法，这里主要分两部分，首先是查询当前是否存在 <code>defaultProperties</code> ，假如不为空就会添加到 <code>environment</code>的<code>propertySources</code>中，接着是处理命令行参数，将命令行参数作为一个<code>CompositePropertySource</code>或者<code>SimpleCommandLinePropertySource</code>添加到 <code>environment</code>的<code>propertySources</code>里面，</p>
<pre><code class="language-java">protected void configurePropertySources(ConfigurableEnvironment environment, String[] args) {
    MutablePropertySources sources = environment.getPropertySources();
    if (this.defaultProperties != null &amp;&amp; !this.defaultProperties.isEmpty()) {
        sources.addLast(new MapPropertySource(&quot;defaultProperties&quot;, this.defaultProperties));
    }
    if (this.addCommandLineProperties &amp;&amp; args.length &gt; 0) {
        String name = &quot;commandLineArgs&quot;;
        if (sources.contains(name)) {
            PropertySource&lt;?&gt; source = sources.get(name);
            CompositePropertySource composite = new CompositePropertySource(name);
            composite.addPropertySource(new SimpleCommandLinePropertySource(&quot;springApplicationCommandLineArgs&quot;, args));
            composite.addPropertySource(source);
            sources.replace(name, composite);
        } else {
            sources.addFirst(new SimpleCommandLinePropertySource(args));
        }
    }
}
</code></pre>
<p>接着调用 <code>ConfigurationPropertySources#attach</code>方法,他会先去 environment 中查找 configurationProperties , 假如寻找到了，先检查 configurationProperties 和当前 environment 是否匹配，假如不相等，就先去除，最后添加 configurationProperties 并将其 sources 属性设置进去。</p>
<pre><code class="language-java">public static void attach(Environment environment) {
    Assert.isInstanceOf(ConfigurableEnvironment.class, environment);
    MutablePropertySources sources = ((ConfigurableEnvironment) environment).getPropertySources();
    PropertySource&lt;?&gt; attached = sources.get(ATTACHED_PROPERTY_SOURCE_NAME);
    if (attached != null &amp;&amp; attached.getSource() != sources) {
        sources.remove(ATTACHED_PROPERTY_SOURCE_NAME);
        attached = null;
    }
    if (attached == null) {
        sources.addFirst(new ConfigurationPropertySourcesPropertySource(ATTACHED_PROPERTY_SOURCE_NAME,
                new SpringConfigurationPropertySources(sources)));
    }
}
</code></pre>
<p>下一步是通知观察者，发送<code>ApplicationEnvironmentPreparedEvent</code>事件，调用的是 <code>SpringApplicationRunListeners#environmentPrepared</code>方法。会唤醒<code>ConfigFileApplicationListener</code>监听器执行相应逻辑。最主要的加载方法load中，首先会获取到配置文件的搜索路径。如果设置了<code>spring.config.location</code>则会去指定目录下搜索，否则就去默认的搜索目录下<code>classpath:/,classpath:/config/,file:./,file:./config/</code>。</p>
<p>拿到所有待搜索目录后，遍历每个目录获取需要加载的配置文件。如果指定了spring.config.name，则加载指定名称的配置文件。否则使用默认的application作为配置文件的前缀名。然后，会利用<code>PropertiesPropertySourceLoader</code>和<code>YamlPropertySourceLoader</code>加载后缀名为<code>properties</code>、<code>xml</code>、<code>yml</code>或者<code>yaml</code>的文件。</p>
<p>拿到文件目录和文件名后，就可以去对应的路径下加载配置文件了。核心的过程是利用输入流读取配置文件，并根据读到的分隔符进行判断来切分配置文件的key和value。并将内容以key-value键值对的形式封装成一个<code>OriginTrackedMapPropertySource</code>，最后再将一个个配置文件封装成<code>Document</code>。最后遍历这些<code>Documents</code>，调用consumer.accept(profile, document));供上层调用访问。</p>
<p>由于监听器的真正执行是通过调用<code>listener.onApplicationEvent(event)</code>方法来执行的，因此我们从该方法开始分析：</p>
<pre><code class="language-java">public void onApplicationEvent(ApplicationEvent event) {
    if (event instanceof ApplicationEnvironmentPreparedEvent) {
        this.onApplicationEnvironmentPreparedEvent((ApplicationEnvironmentPreparedEvent)event);
    }

    if (event instanceof ApplicationPreparedEvent) {
        this.onApplicationPreparedEvent(event);
    }

}

private void onApplicationEnvironmentPreparedEvent(ApplicationEnvironmentPreparedEvent event) {
    List&lt;EnvironmentPostProcessor&gt; postProcessors = this.loadPostProcessors();
    postProcessors.add(this);
    AnnotationAwareOrderComparator.sort(postProcessors);
    Iterator var3 = postProcessors.iterator();

    while(var3.hasNext()) {
        EnvironmentPostProcessor postProcessor = (EnvironmentPostProcessor)var3.next();
        postProcessor.postProcessEnvironment(event.getEnvironment(), event.getSpringApplication());
    }

}
</code></pre>
<p>这里loadPostProcessors方法就是从spring.factories中加载EnvironmentPostProcessor接口对应的实现类，并把当前对象也添加进去(因为ConfigFileApplicationListener也实现了EnvironmentPostProcessor接口，所以可以添加)。因此在下方遍历时，会访问该类下的postProcessEnvironment方法，从该方法中进入：</p>
<pre><code class="language-java">public void load() {
    this.profiles = new LinkedList();
    this.processedProfiles = new LinkedList();
    this.activatedProfiles = false;
    this.loaded = new LinkedHashMap();
    this.initializeProfiles();

    while(!this.profiles.isEmpty()) {
        ConfigFileApplicationListener.Profile profile = (ConfigFileApplicationListener.Profile)this.profiles.poll();
        if (profile != null &amp;&amp; !profile.isDefaultProfile()) {
            this.addProfileToEnvironment(profile.getName());
        }

        this.load(profile, this::getPositiveProfileFilter, this.addToLoaded(MutablePropertySources::addLast, false));
        this.processedProfiles.add(profile);
    }

    this.resetEnvironmentProfiles(this.processedProfiles);
    this.load((ConfigFileApplicationListener.Profile)null, this::getNegativeProfileFilter, this.addToLoaded(MutablePropertySources::addFirst, true));
    this.addLoadedPropertySources();
}
</code></pre>
<p>其中 apply 方法主要是加载 defaultProperties ，假如已经存在，就进行替换，而替换的目标 PropertySource 就是 load这里最后的一个 consumer 函数加载出来的，这里列一下主要做的事情：<br>
1、加载系统中设置的所有的 Profile 。<br>
2、遍历所有的 Profile，假如是默认的 Profile， 就将这个 Profile 加到 environment 中。<br>
3、调用load 方法，加载配置，我们深入看一下这个方法：</p>
<pre><code class="language-java">private void load(ConfigFileApplicationListener.Profile profile, ConfigFileApplicationListener.DocumentFilterFactory filterFactory, ConfigFileApplicationListener.DocumentConsumer consumer) {
        this.getSearchLocations().forEach((location) -&gt; {
            boolean isFolder = location.endsWith(&quot;/&quot;);
            Set&lt;String&gt; names = isFolder ? this.getSearchNames() : ConfigFileApplicationListener.NO_SEARCH_NAMES;
            names.forEach((name) -&gt; {
                this.load(location, name, profile, filterFactory, consumer);
            });
        });
    }
</code></pre>
<p>首先调用了getSearchLocations方法</p>
<pre><code class="language-java">private Set&lt;String&gt; getSearchLocations() {
    if (this.environment.containsProperty(&quot;spring.config.location&quot;)) {
        return this.getSearchLocations(&quot;spring.config.location&quot;);
    } else {
        Set&lt;String&gt; locations = this.getSearchLocations(&quot;spring.config.additional-location&quot;);
        locations.addAll(this.asResolvedSet(ConfigFileApplicationListener.this.searchLocations, &quot;classpath:/,classpath:/config/,file:./,file:./config/&quot;));
        return locations;
    }
}
</code></pre>
<p>该方法用于获取配置文件的路径，如果利用spring.config.location指定了配置文件路径，则根据该路径进行加载。否则则根据默认路径加载，而默认路径就是我们最初提到的那四个路径。接下来，再深入asResolvedSet方法内部分析一下:</p>
<pre><code class="language-java">private Set&lt;String&gt; asResolvedSet(String value, String fallback) {
        List&lt;String&gt; list = Arrays.asList(StringUtils.trimArrayElements(StringUtils.commaDelimitedListToStringArray(value != null ? this.environment.resolvePlaceholders(value) : fallback)));
        Collections.reverse(list);
        return new LinkedHashSet(list);
    }
</code></pre>
<p>这里的value表示ConfigFileApplicationListener初始化时设置的搜索路径，而fallback就是<code>DEFAULT_SEARCH_LOCATIONS</code>默认搜索路径<code>。StringUtils.trimArrayElements(StringUtils.commaDelimitedListToStringArray()）</code>方法就是以逗号作为分隔符对&quot;<code>classpath:/,classpath:/config/,file:./,file:./config/</code>&quot;进行切割，并返回一个字符数组。而这里的<code>Collections.reverse(list)</code>;之后，就是体现优先级的时候了，先被扫描到的配置文件会优先生效。</p>
<p>这里我们拿到搜索路径之后，load方法里对每个搜索路径进行遍历，首先调用了getSearchNames()方法</p>
<pre><code class="language-java">private Set&lt;String&gt; getSearchNames() {
    if (this.environment.containsProperty(&quot;spring.config.name&quot;)) {
        String property = this.environment.getProperty(&quot;spring.config.name&quot;);
        return this.asResolvedSet(property, (String)null);
    } else {
        return this.asResolvedSet(ConfigFileApplicationListener.this.names, &quot;application&quot;);
    }
}
</code></pre>
<p>该方法中如果我们通过spring.config.name设置了要检索的配置文件前缀，会按设置进行加载，否则加载默认的配置文件前缀即application。<br>
拿到所有需要加载的配置文件前缀后，则遍历每个需要加载的配置文件，进行搜索加载，加载过程如下：</p>
<pre><code class="language-java">private void load(String location, String name, ConfigFileApplicationListener.Profile profile, ConfigFileApplicationListener.DocumentFilterFactory filterFactory, ConfigFileApplicationListener.DocumentConsumer consumer) {
     //下面的if分支默认是不走的，除非我们设置spring.config.name为空或者null
    //或者是spring.config.location指定了配置文件的完整路径，也就是入参location的值
    if (!StringUtils.hasText(name)) {
        Iterator var6 = this.propertySourceLoaders.iterator();

        while(var6.hasNext()) {
            PropertySourceLoader loader = (PropertySourceLoader)var6.next();
            //检查配置文件名的后缀是否符合要求，
            //文件名后缀要求是properties、xml、yml或者yaml
            if (this.canLoadFileExtension(loader, location)) {
                this.load(loader, location, profile, filterFactory.getDocumentFilter(profile), consumer);
                return;
            }
        }
    }

    Set&lt;String&gt; processed = new HashSet();
    Iterator var14 = this.propertySourceLoaders.iterator();
    //propertySourceLoaders属性是在Load类的构造方法中设置的，可以加载文件后缀为properties、xml、yml或者yaml的文件
    while(var14.hasNext()) {
        PropertySourceLoader loaderx = (PropertySourceLoader)var14.next();
        String[] var9 = loaderx.getFileExtensions();
        int var10 = var9.length;

        for(int var11 = 0; var11 &lt; var10; ++var11) {
            String fileExtension = var9[var11];
            if (processed.add(fileExtension)) {
                this.loadForFileExtension(loaderx, location + name, &quot;.&quot; + fileExtension, profile, filterFactory, consumer);
            }
        }
    }

}
</code></pre>
<p><code>this.propertySourceLoaders</code>既包含了上面提到的两个<code>PropertiesPropertySourceLoader</code>和<code>YamlPropertySourceLoader</code>，PropertiesPropertySourceLoader可以加载文件扩展名为properties和xml的文件，YamlPropertySourceLoader可以加载文件扩展名为yml和yaml的文件。获取到搜索路径、文件名和扩展名后，就可以到对应的路径下去检索配置文件并加载了。</p>
<pre><code class="language-java">private void loadForFileExtension(PropertySourceLoader loader, String prefix, String fileExtension, ConfigFileApplicationListener.Profile profile, ConfigFileApplicationListener.DocumentFilterFactory filterFactory, ConfigFileApplicationListener.DocumentConsumer consumer) {
    ConfigFileApplicationListener.DocumentFilter defaultFilter = filterFactory.getDocumentFilter((ConfigFileApplicationListener.Profile)null);
    ConfigFileApplicationListener.DocumentFilter profileFilter = filterFactory.getDocumentFilter(profile);
    if (profile != null) {
         //在文件名上加上profile值，之后调用load方法加载配置文件，入参带有过滤器，可以防止重复加载
        String profileSpecificFile = prefix + &quot;-&quot; + profile + fileExtension;
        this.load(loader, profileSpecificFile, profile, defaultFilter, consumer);
        this.load(loader, profileSpecificFile, profile, profileFilter, consumer);
        Iterator var10 = this.processedProfiles.iterator();

        while(var10.hasNext()) {
            ConfigFileApplicationListener.Profile processedProfile = (ConfigFileApplicationListener.Profile)var10.next();
            if (processedProfile != null) {
                String previouslyLoaded = prefix + &quot;-&quot; + processedProfile + fileExtension;
                this.load(loader, previouslyLoaded, profile, profileFilter, consumer);
            }
        }
    }
    //加载不带profile的配置文件
    this.load(loader, prefix + fileExtension, profile, profileFilter, consumer);
}
</code></pre>
<pre><code class="language-java">// 加载配置文件
private void load(PropertySourceLoader loader, String location, Profile profile, DocumentFilter filter,
                DocumentConsumer consumer) {
    try {
               //调用Resource类到指定路径加载配置文件
               // location比如file:./config/application.properties
        Resource resource = this.resourceLoader.getResource(location);
        if (resource == null || !resource.exists()) {
            if (this.logger.isTraceEnabled()) {
                StringBuilder description = getDescription(&quot;Skipped missing config &quot;, location, resource,
                        profile);
                this.logger.trace(description);
            }
            return;
        }
        if (!StringUtils.hasText(StringUtils.getFilenameExtension(resource.getFilename()))) {
            if (this.logger.isTraceEnabled()) {
                StringBuilder description = getDescription(&quot;Skipped empty config extension &quot;, location,
                        resource, profile);
                this.logger.trace(description);
            }
            return;
        }
        String name = &quot;applicationConfig: [&quot; + location + &quot;]&quot;;
               //读取配置文件内容，将其封装到Document类中，解析文件内容主要是找到
        //配置spring.profiles.active和spring.profiles.include的值
        List&lt;Document&gt; documents = loadDocuments(loader, name, resource);
               //如果文件没有配置数据，则跳过
        if (CollectionUtils.isEmpty(documents)) {
            if (this.logger.isTraceEnabled()) {
                StringBuilder description = getDescription(&quot;Skipped unloaded config &quot;, location, resource,
                        profile);
                this.logger.trace(description);
            }
            return;
        }
        List&lt;Document&gt; loaded = new ArrayList&lt;&gt;();
               //遍历配置文件，处理里面配置的profile
        for (Document document : documents) {
            if (filter.match(document)) {
                       //将配置文件中配置的spring.profiles.active和
                   //spring.profiles.include的值写入集合profiles中，
                   //上层调用方法会读取profiles集合中的值，并读取对应的配置文件
                   //addActiveProfiles方法只在第一次调用时会起作用，里面有判断
                addActiveProfiles(document.getActiveProfiles());
                addIncludedProfiles(document.getIncludeProfiles());
                loaded.add(document);
            }
        }
        Collections.reverse(loaded);
        if (!loaded.isEmpty()) {
            loaded.forEach((document) -&gt; consumer.accept(profile, document));
            if (this.logger.isDebugEnabled()) {
                StringBuilder description = getDescription(&quot;Loaded config file &quot;, location, resource, profile);
                this.logger.debug(description);
            }
        }
    }
    catch (Exception ex) {
        throw new IllegalStateException(&quot;Failed to load property source from location '&quot; + location + &quot;'&quot;, ex);
    }
}
</code></pre>
<p>该方法首先调用<code>this.resourceLoader.getResource(location)</code>;用来判断<code>location路径</code>下的文件是否存在，如果存在，会调用loadDocuments方法对配置文件进行加载：</p>
<pre><code class="language-java">private List&lt;ConfigFileApplicationListener.Document&gt; loadDocuments(PropertySourceLoader loader, String name, Resource resource) throws IOException {
    ConfigFileApplicationListener.DocumentsCacheKey cacheKey = new ConfigFileApplicationListener.DocumentsCacheKey(loader, resource);
    List&lt;ConfigFileApplicationListener.Document&gt; documents = (List)this.loadDocumentsCache.get(cacheKey);
    if (documents == null) {
        List&lt;PropertySource&lt;?&gt;&gt; loaded = loader.load(name, resource);
        documents = this.asDocuments(loaded);
        this.loadDocumentsCache.put(cacheKey, documents);
    }

    return documents;
}
</code></pre>
<p>再内部根据不同的<code>PropertySourceLoader</code>调用相应的load方法和<code>loadProperties(resource)</code>方法</p>
<pre><code class="language-java">public List&lt;PropertySource&lt;?&gt;&gt; load(String name, Resource resource) throws IOException {
    Map&lt;String, ?&gt; properties = this.loadProperties(resource);
    return properties.isEmpty() ? Collections.emptyList() : Collections.singletonList(new OriginTrackedMapPropertySource(name, properties));
}

private Map&lt;String, ?&gt; loadProperties(Resource resource) throws IOException {
    String filename = resource.getFilename();
    return (Map)(filename != null &amp;&amp; filename.endsWith(&quot;.xml&quot;) ? PropertiesLoaderUtils.loadProperties(resource) : (new OriginTrackedPropertiesLoader(resource)).load());
}
</code></pre>
<p>由于我们目前的配置文件只有application.properties，也就是文件结尾不是以xml作为扩展名。因此loadProperties方法会进入到<code>new OriginTrackedPropertiesLoader</code>。因此再进入到<code>new OriginTrackedPropertiesLoader(resource).load()</code>;。</p>
<pre><code class="language-java">public Map&lt;String, OriginTrackedValue&gt; load(boolean expandLists) throws IOException {
    OriginTrackedPropertiesLoader.CharacterReader reader = new OriginTrackedPropertiesLoader.CharacterReader(this.resource);
    Throwable var3 = null;

    try {
        Map&lt;String, OriginTrackedValue&gt; result = new LinkedHashMap();
        StringBuilder buffer = new StringBuilder();

        while(reader.read()) {
            String key = this.loadKey(buffer, reader).trim();
            if (expandLists &amp;&amp; key.endsWith(&quot;[]&quot;)) {
                key = key.substring(0, key.length() - 2);
                int var19 = 0;

                while(true) {
                    OriginTrackedValue value = this.loadValue(buffer, reader, true);
                    this.put(result, key + &quot;[&quot; + var19++ + &quot;]&quot;, value);
                    if (!reader.isEndOfLine()) {
                        reader.read();
                    }

                    if (reader.isEndOfLine()) {
                        break;
                    }
                }
            } else {
                OriginTrackedValue value = this.loadValue(buffer, reader, false);
                this.put(result, key, value);
            }
        }

        LinkedHashMap var18 = result;
        return var18;
    } catch (Throwable var16) {
        var3 = var16;
        throw var16;
    } 
}
</code></pre>
<pre><code class="language-java">CharacterReader(Resource resource) throws IOException {
            this.reader = new LineNumberReader(new InputStreamReader(resource.getInputStream(), StandardCharsets.ISO_8859_1));
        }
</code></pre>
<pre><code class="language-java">private String loadKey(StringBuilder buffer, OriginTrackedPropertiesLoader.CharacterReader reader) throws IOException {
    buffer.setLength(0);
    boolean previousWhitespace = false;

    while(!reader.isEndOfLine()) {
        // 判断读取到的字节是否为'=' 或者为 ':'，如果是则直接返回读取都的buffer内容
        if (reader.isPropertyDelimiter()) {
            reader.read();
            return buffer.toString();
        }

        if (!reader.isWhiteSpace() &amp;&amp; previousWhitespace) {
            return buffer.toString();
        }

        previousWhitespace = reader.isWhiteSpace();
        buffer.append(reader.getCharacter());
        reader.read();
    }

    return buffer.toString();
}

private OriginTrackedValue loadValue(StringBuilder buffer, OriginTrackedPropertiesLoader.CharacterReader reader, boolean splitLists) throws IOException {
    buffer.setLength(0);

    while(reader.isWhiteSpace() &amp;&amp; !reader.isEndOfLine()) {
        reader.read();
    }

    Location location = reader.getLocation();

    while(!reader.isEndOfLine() &amp;&amp; (!splitLists || !reader.isListDelimiter())) {
        buffer.append(reader.getCharacter());
        reader.read();
    }

    Origin origin = new TextResourceOrigin(this.resource, location);
    return OriginTrackedValue.of(buffer.toString(), origin);
}
</code></pre>
<p>在这个方法里，首先<code>CharacterReader</code>方法将我们的resource也就是配置文件转为了<code>输入流</code>，然后利用<code>reader.read()</code>进行读取，在loadKey方法中我们看到，这里判断读取到的是否为<code>'='</code>或者为<code>':'</code>，也就是我们在配置文件中以'='或者':'分割的key-value。因此看到这里，我们可以直观的感受到这里应该是读取配置文件，并切分key和value的地方。<br>
最终，对配置文件读取完成后，会将其以key-value的形式封装到一个<code>Map集合</code>中进行返回，然后封装到<code>OriginTrackedMapPropertySource</code>中作为一个<code>MapPropertySource</code>对象。再层层往上回退发现会最终封装成一个<code>asDocuments(loaded)</code>;Document对象。最后回到最上层的load方法中，loadDocuments(loader, name, resource);方法即返回我们加载好的配置文件Document对象集合。并对集合中的每一个配置文件document对象进行遍历，调用loaded.forEach((document) -&gt; consumer.accept(profile, document));</p>
<h4 id="123-创建-applicationcontext">1.2.3 创建 ApplicationContext</h4>
<p>首先是检查 Application的类型，然后获取对应的<code>ApplicationContext</code>类，我们这里是获取到了 <code>org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext</code>接着调用 <code>BeanUtils.instantiateClass(contextClass)</code>; 方法进行对象的初始化。</p>
<pre><code class="language-java">protected ConfigurableApplicationContext createApplicationContext() {
    Class&lt;?&gt; contextClass = this.applicationContextClass;
    if (contextClass == null) {
        try {
            switch(this.webApplicationType) {
            case SERVLET:
                contextClass = Class.forName(&quot;org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext&quot;);
                break;
            case REACTIVE:
                contextClass = Class.forName(&quot;org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext&quot;);
                break;
            default:
                contextClass = Class.forName(&quot;org.springframework.context.annotation.AnnotationConfigApplicationContext&quot;);
            }
        } catch (ClassNotFoundException var3) {
            throw new IllegalStateException(&quot;Unable create a default ApplicationContext, please specify an ApplicationContextClass&quot;, var3);
        }
    }

    return (ConfigurableApplicationContext)BeanUtils.instantiateClass(contextClass);
}
</code></pre>
<p>终其实是调用了 <code>AnnotationConfigServletWebServerApplicationContext</code>的默认构造方法。我们看一下这个方法做了什么事情。这里只是简单的设置了一个 <code>reader</code>和一个 <code>scanner</code>，作用于 bean 的扫描工作。</p>
<p>接下来是获取 ExceptionReporter，获取 ExceptionReporter 的方式主要还是和之前 Listener 的方式一致,通过 getSpringFactoriesInstances 来获取所有的 SpringBootExceptionReporter。</p>
<h4 id="124-准备容器">1.2.4 准备容器</h4>
<pre><code class="language-java">private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment,
        SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) {
    // 为 ApplicationContext 设置 environment
    context.setEnvironment(environment);
    // 执行容器后置处理器
    postProcessApplicationContext(context);
    // 执行容器中的ApplicationContextInitializer
    applyInitializers(context);
        // 发送 ContextPrepareEvent，通知各个监听器。
    listeners.contextPrepared(context);
    if (this.logStartupInfo) {
        // 打印启动新包括 pid 和 用户等。
        logStartupInfo(context.getParent() == null);
        // 打印 Profile 信息
        logStartupProfileInfo(context);
    }
    // Add boot specific singleton beans
    ConfigurableListableBeanFactory beanFactory = context.getBeanFactory();
    // 将启动参数作为 bean 注入到容器中
    beanFactory.registerSingleton(&quot;springApplicationArguments&quot;, applicationArguments);
    if (printedBanner != null) {
        // 将banner 注入到容器中
        beanFactory.registerSingleton(&quot;springBootBanner&quot;, printedBanner);
    }
    if (beanFactory instanceof DefaultListableBeanFactory) {
        // 设置不允许定义同名的BeanDefinition，重复注册时抛出异常
        ((DefaultListableBeanFactory) beanFactory)
                .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding);
    }
    if (this.lazyInitialization) {
        // 如果是懒加载，则添加懒加载后置处理器。
        context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor());
    }
    // 获取启动类的参数
    Set&lt;Object&gt; sources = getAllSources();
    Assert.notEmpty(sources, &quot;Sources must not be empty&quot;);
    // 加载启动类，并将其注入到容器中
    load(context, sources.toArray(new Object[0]));
    // 发布 ApplicationPreparedEvent 事件
    listeners.contextLoaded(context);
}
</code></pre>
<p><strong>postProcessApplicationContext</strong><br>
其主要实现如下：<br>
1、首先是指定<code>beanNameGenerator</code>,默认情况下不会进入这里，在没有自定义 beanNameGenerator的情况下，<code>AnnotatedBeanDefinitionReader</code>和<code>ClassPathBeanDefinitionScanner</code>的默认实现是AnnotationBeanNameGenerator，即看是否有 value 定义值，假如没有就将首字母变成小写做为bean的名称。<br>
2、查看是否存在<code>resourceLoader</code>有的话就添加到 beanFactory 中。</p>
<pre><code class="language-java">protected void postProcessApplicationContext(ConfigurableApplicationContext context) {
    if (this.beanNameGenerator != null) {
        context.getBeanFactory().registerSingleton(&quot;org.springframework.context.annotation.internalConfigurationBeanNameGenerator&quot;, this.beanNameGenerator);
    }

    if (this.resourceLoader != null) {
        if (context instanceof GenericApplicationContext) {
            ((GenericApplicationContext)context).setResourceLoader(this.resourceLoader);
        }

        if (context instanceof DefaultResourceLoader) {
            ((DefaultResourceLoader)context).setClassLoader(this.resourceLoader.getClassLoader());
        }
    }
}
</code></pre>
<p><strong>执行 initializer</strong><br>
我们上面提到在初始化 SpringApplication 的时候会加载所有的 ApplicationContextInitializer，到这里就使用到了这些 initializer ，调用每个initializer 的 initialize 方法，并将 Context 作为参数传递进去。</p>
<pre><code class="language-java">protected void applyInitializers(ConfigurableApplicationContext context) {
    Iterator var2 = this.getInitializers().iterator();

    while(var2.hasNext()) {
        ApplicationContextInitializer initializer = (ApplicationContextInitializer)var2.next();
        Class&lt;?&gt; requiredType = GenericTypeResolver.resolveTypeArgument(initializer.getClass(), ApplicationContextInitializer.class);
        Assert.isInstanceOf(requiredType, context, &quot;Unable to call initializer.&quot;);
        initializer.initialize(context);
    }
}
</code></pre>
<p>1、DelegatingApplicationContextInitializer: 从environment中获取context.initializer.classes属性，默认为 null，可以使用多个使用逗号隔开，然后将调用这些类的 initialize 方法。<br>
2、SharedMetadataReaderFactoryContextInitializer 主要是在 beanFactory 中添加一个CachingMetadataReaderFactoryPostProcessor 会在 refreshContext 中被执行。<br>
3、ContextIdApplicationContextInitializer 将 Spring.application.name 作为 ContextId 设置到容器中。<br>
4、ConfigurationWarningsApplicationContextInitializer 向beanFacotory 中注册一个 ConfigurationWarningsPostProcessor 作用是添加一下检查。默认有一个ComponentScanPackageCheck，作用是检查@ComponentScan扫描的包路径是否合法.<br>
5、ServerPortInfoApplicationContextInitializer 向 ApplicationContext 中注册一个 ApplicationListener 用于监听WebServerInitializedEvent事件，向Environment中添加端口号local.sever.port。<br>
ConditionEvaluationReportLoggingListener 向容器中注册一个 ConditionEvaluationReportListener 主要用于打印日志。</p>
<p><strong>执行 ApplicationPrepareContext 通知</strong></p>
<p><strong>load 加载</strong></p>
<pre><code class="language-java">protected void load(ApplicationContext context, Object[] sources) {
    // 打印日志
    if (logger.isDebugEnabled()) {
        logger.debug(&quot;Loading source &quot; + StringUtils.arrayToCommaDelimitedString(sources));
    }
    // 初始化 BeanDefinitionLoader
    BeanDefinitionLoader loader = createBeanDefinitionLoader(getBeanDefinitionRegistry(context), sources);
    // 假如 BeanDefinition 不为空，就将其设置到 loader 中。
    if (this.beanNameGenerator != null) {
        loader.setBeanNameGenerator(this.beanNameGenerator);
    }
    // 如果 resourceLoader  不为空，就将 resourceLoader 设置到 loader 中
    if (this.resourceLoader != null) {
        loader.setResourceLoader(this.resourceLoader);
    }
    // 如果 environment  不为空，就将 environment 设置到 loader 中
    if (this.environment != null) {
        loader.setEnvironment(this.environment);
    }
    // 调用 loader 的 load 方法
    loader.load();
}
</code></pre>
<p>我们先来看一下 createBeanDefinitionLoader 方法：</p>
<pre><code class="language-java">BeanDefinitionLoader(BeanDefinitionRegistry registry, Object... sources) {
    Assert.notNull(registry, &quot;Registry must not be null&quot;);
    Assert.notEmpty(sources, &quot;Sources must not be empty&quot;);
    this.sources = sources;
    this.annotatedReader = new AnnotatedBeanDefinitionReader(registry);
    this.xmlReader = new XmlBeanDefinitionReader(registry);
    if (this.isGroovyPresent()) {
        this.groovyReader = new GroovyBeanDefinitionReader(registry);
    }

    this.scanner = new ClassPathBeanDefinitionScanner(registry);
    this.scanner.addExcludeFilter(new BeanDefinitionLoader.ClassExcludeFilter(sources));
}
</code></pre>
<p>主要做了两件事情：<br>
1、设置 Reader ，包括 AnnotatedBeanDefinitionReader 和 XmlBeanDefinitionReader 假如是Groovy 环境就生成 GroovyBeanDefinitionReader 。<br>
2、设置 Scanner ，主要是 ClassPathBeanDefinitionScanner ,然后检查 Application 中是否存在 ExcludeFilter ，有的话加入到 scanner 中。</p>
<p>接着看load方法：</p>
<pre><code class="language-java">public int load() {
    int count = 0;
    Object[] var2 = this.sources;
    int var3 = var2.length;

    for(int var4 = 0; var4 &lt; var3; ++var4) {
        Object source = var2[var4];
        count += this.load(source);
    }

    return count;
}
</code></pre>
<p>这里的主要逻辑是遍历所有的 sources，这里的其实就是我们的 Main 类。最终调用了 load(Class&lt;?&gt; source) 方法，最终调用了 annotatedReader#register(source)方法。</p>
<h4 id="125-刷新容器">1.2.5 刷新容器</h4>
<pre><code class="language-java">private void refreshContext(ConfigurableApplicationContext context) {
    this.refresh(context);
    if (this.registerShutdownHook) {
        try {
            context.registerShutdownHook();
        } catch (AccessControlException var3) {
        }
    }
}
</code></pre>
<p>主要做两件事情：<br>
1、假如需要注册关闭钩子的话，向 Context 注册关闭钩子。<br>
2、调用 refresh 方法，刷新容器。<br>
我们直接来看一下 refresh 方法，其最终调用了 AbstractApplicationContext 的 refresh 方法。其主要内容如下：</p>
<pre><code class="language-java"> public void refresh() throws BeansException, IllegalStateException {
        synchronized(this.startupShutdownMonitor) {
            //1、准备刷新容器。
            this.prepareRefresh();
            ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory();
            this.prepareBeanFactory(beanFactory);

            try {
                this.postProcessBeanFactory(beanFactory);
                this.invokeBeanFactoryPostProcessors(beanFactory);
                this.registerBeanPostProcessors(beanFactory);
                this.initMessageSource();
                this.initApplicationEventMulticaster();
                this.onRefresh();
                this.registerListeners();
                this.finishBeanFactoryInitialization(beanFactory);
                this.finishRefresh();
            } catch (BeansException var9) {
                if (this.logger.isWarnEnabled()) {
                    this.logger.warn(&quot;Exception encountered during context initialization - cancelling refresh attempt: &quot; + var9);
                }

                this.destroyBeans();
                this.cancelRefresh(var9);
                throw var9;
            } finally {
                this.resetCommonCaches();
            }
        }
    }
</code></pre>
<p>这个方法主要有如下步骤：<br>
1、准备刷新容器。<br>
2、初始化 BeanFactory。<br>
3、对 BeanFactory 进行各种功能的填充，如对 @Autowrite 和 @Qualify 的支持就是这步加入的。<br>
4、调用 postProcessBeanFactory 的扩展点。<br>
5、激活各种 beanFactory 处理器。<br>
6、注册拦截 bean 创建的 bean处理器，这里仅仅是创建而已，最后 getBean 的时候才会真正的调用。<br>
7、初始化 Context 的 MessageSource，为一些国际化的内容。<br>
8、初始化 ApplicationEventMulticaster 并放到 bean 工厂中。<br>
9、扩展点，为其他的 Context 子类来初始化其 bean。<br>
10、在所有的 bean 中找到 listener bean，并将其注册到广播器中。<br>
11、初始化剩下的单例 （no-lazy-init）<br>
12、完成刷新过程，并发出 ContextRefreshEvent 通知。<br>
13、清除缓存。</p>
<h5 id="1251-准备刷新容器">1.2.5.1 准备刷新容器</h5>
<pre><code class="language-java">protected void prepareRefresh() {
    this.startupDate = System.currentTimeMillis();
    this.closed.set(false);
    this.active.set(true);
    if (this.logger.isInfoEnabled()) {
        this.logger.info(&quot;Refreshing &quot; + this);
    }

    this.initPropertySources();
    this.getEnvironment().validateRequiredProperties();
    this.earlyApplicationEvents = new LinkedHashSet();
}
</code></pre>
<p>上面代码比较简单，主要做了如下事情：<br>
1、设置容器启动时间。<br>
2、设置启动状态。<br>
3、调用 initPropertySources 方法，调用到的是 GenericWebApplicationContext 的 initPropertySources 方法，最终调用如下方法：<br>
4、将当前的 ApplicationListeners 放置到 earlyApplicationListeners 中。</p>
<pre><code class="language-java">public static void initServletPropertySources(MutablePropertySources sources, @Nullable ServletContext servletContext, @Nullable ServletConfig servletConfig) {
    Assert.notNull(sources, &quot;'propertySources' must not be null&quot;);
    String name = &quot;servletContextInitParams&quot;;
    if (servletContext != null &amp;&amp; sources.contains(name) &amp;&amp; sources.get(name) instanceof StubPropertySource) {
        sources.replace(name, new ServletContextPropertySource(name, servletContext));
    }

    name = &quot;servletConfigInitParams&quot;;
    if (servletConfig != null &amp;&amp; sources.contains(name) &amp;&amp; sources.get(name) instanceof StubPropertySource) {
        sources.replace(name, new ServletConfigPropertySource(name, servletConfig));
    }

    //1、如果 `servletContext` 不为空，且是 StubPropertySource 的子类，那么将其转为 `ServletContextPropertySource`.
    //2、如果 `servletConfig` 不为空，且是 StubPropertySource 的子类，那么将其转为 `ServletContextPropertySource`.
    //但是这里的  `servletContext`  和  `servletConfig`  都为空，所以不会进入。
}
</code></pre>
<h5 id="1252-初始化-beanfactory">1.2.5.2 初始化 BeanFactory</h5>
<pre><code class="language-java">protected ConfigurableListableBeanFactory obtainFreshBeanFactory() {
    this.refreshBeanFactory();
    ConfigurableListableBeanFactory beanFactory = this.getBeanFactory();
    if (this.logger.isDebugEnabled()) {
        this.logger.debug(&quot;Bean factory for &quot; + this.getDisplayName() + &quot;: &quot; + beanFactory);
    }

    return beanFactory;
}
</code></pre>
<p>主要做两件事情， <code>refreshBeanFactory</code>，<code>初始化BeanFactory</code>，最终调用了 <code>GenericApplicationContext#refreshBeanFactory</code>，如下：</p>
<pre><code class="language-java">protected final void refreshBeanFactory() throws IllegalStateException {
    if (!this.refreshed.compareAndSet(false, true)) {
        throw new IllegalStateException(&quot;GenericApplicationContext does not support multiple refresh attempts: just call 'refresh' once&quot;);
    } else {
        this.beanFactory.setSerializationId(this.getId());
    }
}
</code></pre>
<p>1、设置 refresh 的状态为 <code>TRUE</code>。<br>
2、为 beanFactory 设置<code>setSerializationId</code> ，这个里是 <code>application</code>，其主要由三段式组成 <code>ApplicationName:profile:port</code>。</p>
<p>接下来分析一下 getBeanFactory 方法：</p>
<pre><code class="language-java">public final ConfigurableListableBeanFactory getBeanFactory() {
    return this.beanFactory;
}
</code></pre>
<p>最终还是调用了返回当前 context 的beanFactory，返回一个<code>DefaultListableBeanFactory</code>。</p>
<h5 id="1253-preparebeanfactory">1.2.5.3 prepareBeanFactory</h5>
<pre><code class="language-java">protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) {
    beanFactory.setBeanClassLoader(this.getClassLoader());
    beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader()));
    beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, this.getEnvironment()));
    beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this));
    beanFactory.ignoreDependencyInterface(EnvironmentAware.class);
    beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class);
    beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class);
    beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class);
    beanFactory.ignoreDependencyInterface(MessageSourceAware.class);
    beanFactory.ignoreDependencyInterface(ApplicationContextAware.class);
    beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory);
    beanFactory.registerResolvableDependency(ResourceLoader.class, this);
    beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this);
    beanFactory.registerResolvableDependency(ApplicationContext.class, this);
    beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this));
    if (beanFactory.containsBean(&quot;loadTimeWeaver&quot;)) {
        beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));
        beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));
    }

    if (!beanFactory.containsLocalBean(&quot;environment&quot;)) {
        beanFactory.registerSingleton(&quot;environment&quot;, this.getEnvironment());
    }

    if (!beanFactory.containsLocalBean(&quot;systemProperties&quot;)) {
        beanFactory.registerSingleton(&quot;systemProperties&quot;, this.getEnvironment().getSystemProperties());
    }

    if (!beanFactory.containsLocalBean(&quot;systemEnvironment&quot;)) {
        beanFactory.registerSingleton(&quot;systemEnvironment&quot;, this.getEnvironment().getSystemEnvironment());
    }
}
</code></pre>
<p>1、为 beanFactory 设置类加载器，为当前 context 的类加载器。<br>
2、设置 beanFactory 的 BeanExpressionResolver 为 StandardBeanExpressionResolver。<br>
3、beanFactory增加一个默认的 PropertyEditor,主要用于对 bean 的属性设置进行管理。<br>
4、为 beanFactory 增加一个 BeanPostProcessor 为 ApplicationContextAwareProcessor。<br>
5、将 EnvironmentAware、EmbeddedValueResolverAware、ResourceLoaderAware、ApplicationEventPublisherAware、MessageSourceAware、ApplicationContextAware、添加到忽略自动装配的接口中。,当spring将ApplicationContextAwareProcessor注册后,那么在invokeAwareInterfaces中直接,调用的Aware类已经不是普通的bean了,如ResourceLoaderAware,那么需要在spring做bean的依赖注入时忽略它们。<br>
6、将当前 Context 注册为解析如下依赖的注入对象，包括 BeanFactory、ResourceLoader、ApplicationEventPublisher、ApplicationContext。比如说我们调用 @Autowrite 注入 ApplicationContext 就是注入当前的 Context。<br>
7、注册 BeanPostProcessor ， ApplicationListenerDetector 。<br>
8、添加默认的系统环境bean。</p>
<h5 id="1254-postprocessbeanfactory">1.2.5.4 postProcessBeanFactory</h5>
<p>该方法最终调用了子类的 <code>AnnotationConfigServletWebApplicationContext#postProcessBeanFactory</code> ,</p>
<pre><code class="language-java">protected void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) {
    super.postProcessBeanFactory(beanFactory);
    if (this.basePackages != null &amp;&amp; this.basePackages.length &gt; 0) {
        this.scanner.scan(this.basePackages);
    }

    if (!this.annotatedClasses.isEmpty()) {
        this.reader.register(ClassUtils.toClassArray(this.annotatedClasses));
    }
}
</code></pre>
<p>主要做了三件事情：<br>
1、为 BeanFactory 设置了一个为ServletContextAwareProcessor 类型的 BeanPostProcessor，并设置了忽略接口ServletContextAware.<br>
2、假如basePackage 大于 0 的话，就调用 scanner 的 scan 方法。<br>
3、如果 annotatedClasses 大于 0 的话，就调用 AnnotatedBeanDefinitionReader 的 register 方法。</p>
<h5 id="1255-激活各种-bean-处理器">1.2.5.5 激活各种 bean 处理器</h5>
<pre><code class="language-java">protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) {
    PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, this.getBeanFactoryPostProcessors());
    if (beanFactory.getTempClassLoader() == null &amp;&amp; beanFactory.containsBean(&quot;loadTimeWeaver&quot;)) {
        beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));
        beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));
    }
}
</code></pre>
<p>1、调用PostProcessorRegistrationDelegate#invokeBeanFactoryPostProcessors.<br>
2、如果beanFactory.getTempClassLoader() 等于null并且 beanFactory含有loadTimeWeaver的定义的话,就向beanFactory添加一个LoadTimeWeaverAwareProcessor,然后设置TempClassLoader 为 ContextTypeMatchClassLoader.</p>
<p>其中最重要的就是调用 invokeBeanDefinitionRegistryPostProcessors 方法中，调用了 <code>ConfigurationClassPostProcessor</code>,主要负责加载大部分的 <code>BeanDefinition</code>注册到 registry 中。具体流程如下：</p>
<pre><code class="language-java">public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) {
    int registryId = System.identityHashCode(registry);
    if (this.registriesPostProcessed.contains(registryId)) {
        throw new IllegalStateException(&quot;postProcessBeanDefinitionRegistry already called on this post-processor against &quot; + registry);
    } else if (this.factoriesPostProcessed.contains(registryId)) {
        throw new IllegalStateException(&quot;postProcessBeanFactory already called on this post-processor against &quot; + registry);
    } else {
        this.registriesPostProcessed.add(registryId);
        this.processConfigBeanDefinitions(registry);
    }
}
</code></pre>
<p>主要做了两件事情：<br>
1、生成当前 registry 的 id，然后到 <code>registriesPostProcessed</code>和 <code>registriesPostProcessed</code>中查找，是否存在，主要作用是去重。<br>
2、假如没有重复调用 <code>processConfigBeanDefinitions</code>去加载。</p>
<p>我们进入<code>processConfigBeanDefinitions</code>中：</p>
<pre><code class="language-java">public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) {
    List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;();
// 获取已经注册的 bean 名称，这里一般是我们的启动 Application 类。
    String[] candidateNames = registry.getBeanDefinitionNames();

    for (String beanName : candidateNames) {
        BeanDefinition beanDef = registry.getBeanDefinition(beanName);
// 假如 beanDefinition 中的 ConfigurationClass 属性为 full 或者 lite 那代表已经解析过了，跳过。
        if (beanDef.getAttribute(ConfigurationClassUtils.CONFIGURATION_CLASS_ATTRIBUTE) != null) {
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;Bean definition has already been processed as a configuration class: &quot; + beanDef);
            }
        }
// 判断当前类是否是 config 类，假如是就加入到 configCandidates 中。
        else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) {
            configCandidates.add(new BeanDefinitionHolder(beanDef, beanName));
        }
    }
// 假如 configCandidates 为空就返回
    if (configCandidates.isEmpty()) {
        return;
    }
// 对 configCandidates 使用 @Order 注解进行排序
    configCandidates.sort((bd1, bd2) -&gt; {
        int i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition());
        int i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition());
        return Integer.compare(i1, i2);
    });

    // Detect any custom bean name generation strategy supplied through the enclosing application context
    SingletonBeanRegistry sbr = null;
    if (registry instanceof SingletonBeanRegistry) {
        sbr = (SingletonBeanRegistry) registry;
        if (!this.localBeanNameGeneratorSet) {
            BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(
                    AnnotationConfigUtils.CONFIGURATION_BEAN_NAME_GENERATOR);
            if (generator != null) {
// 设置 beanNameGenerator
                this.componentScanBeanNameGenerator = generator;
                this.importBeanNameGenerator = generator;
            }
        }
    }
    if (this.environment == null) {
        this.environment = new StandardEnvironment();
    }
//实例化 ConfigurationClassParser 为后续解析准备。
    ConfigurationClassParser parser = new ConfigurationClassParser(
            this.metadataReaderFactory, this.problemReporter, this.environment,
            this.resourceLoader, this.componentScanBeanNameGenerator, registry);
// 初始话 candidates 和 alreadyParsed 两个集合
    Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates);
    Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size());
    do {
// 进行解析
        parser.parse(candidates);
        parser.validate();
// 获取解析到的 ConfigurationClass
        Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses());
        configClasses.removeAll(alreadyParsed);
        // Read the model and create bean definitions based on its content
        if (this.reader == null) {
            this.reader = new ConfigurationClassBeanDefinitionReader(
                    registry, this.sourceExtractor, this.resourceLoader, this.environment,
                    this.importBeanNameGenerator, parser.getImportRegistry());
        }
// 加载 ConfigurationClass 的 beanDefinition
        this.reader.loadBeanDefinitions(configClasses);
// 添加到 ConfigurationClass 中。
        alreadyParsed.addAll(configClasses);
        candidates.clear();
        if (registry.getBeanDefinitionCount() &gt; candidateNames.length) {
            String[] newCandidateNames = registry.getBeanDefinitionNames();
            Set&lt;String&gt; oldCandidateNames = new HashSet&lt;&gt;(Arrays.asList(candidateNames));
            Set&lt;String&gt; alreadyParsedClasses = new HashSet&lt;&gt;();
            for (ConfigurationClass configurationClass : alreadyParsed) {
                alreadyParsedClasses.add(configurationClass.getMetadata().getClassName());
            }
            for (String candidateName : newCandidateNames) {
                if (!oldCandidateNames.contains(candidateName)) {
                    BeanDefinition bd = registry.getBeanDefinition(candidateName);
                    if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp;
                            !alreadyParsedClasses.contains(bd.getBeanClassName())) {
                        candidates.add(new BeanDefinitionHolder(bd, candidateName));
                    }
                }
            }
            candidateNames = newCandidateNames;
        }
    }
    while (!candidates.isEmpty());
    // Register the ImportRegistry as a bean in order to support ImportAware @Configuration classes
    if (sbr != null &amp;&amp; !sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) {
        sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry());
    }

    if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) {
        // Clear cache in externally provided MetadataReaderFactory; this is a no-op
        // for a shared cache since it'll be cleared by the ApplicationContext.
        ((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache();
    }
}
</code></pre>
<p>主要做了如下7件事情：<br>
1、获取已经注册的bean名称进行遍历：<br>
2、对configCandidates 进行 排序,按照@Order 配置的值进行排序。<br>
3、如果BeanDefinitionRegistry 是SingletonBeanRegistry 子类的话,将registry强转为SingletonBeanRegistry。<br>
4、实例化ConfigurationClassParser 为了解析各个配置类.实例化2个set,candidates 用于将之前加入的configCandidates 进行去重,alreadyParsed 用于判断是否处理过。<br>
5、进行解析。<br>
6、如果SingletonBeanRegistry 不包含org.springframework.context.annotation.ConfigurationClassPostProcessor.importRegistry,则注册一个,bean 为 ImportRegistry. 一般都会进行注册的。<br>
7、清除缓存。</p>
<p>我们先来看一下判断该 bean 是否为<code>configClass</code>的方法。</p>
<pre><code class="language-java">public static boolean checkConfigurationClassCandidate(
        BeanDefinition beanDef, MetadataReaderFactory metadataReaderFactory) {
// 获取类名，假如不存在则返回。
    String className = beanDef.getBeanClassName();
    if (className == null || beanDef.getFactoryMethodName() != null) {
        return false;
    }
// 获取 AnnotationMetadata
    AnnotationMetadata metadata;
    if (beanDef instanceof AnnotatedBeanDefinition &amp;&amp;
            className.equals(((AnnotatedBeanDefinition) beanDef).getMetadata().getClassName())) {
// 检查是否可以是 AnnotatedBeanDefinition ，是就直接从 BeanDefinition 中获取
        metadata = ((AnnotatedBeanDefinition) beanDef).getMetadata();
    }
    else if (beanDef instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) beanDef).hasBeanClass()) {
// 如果BeanDefinition 是 AnnotatedBeanDefinition的实例,并且beanDef 有 beanClass 属性存在没有则实例化StandardAnnotationMetadata
        Class&lt;?&gt; beanClass = ((AbstractBeanDefinition) beanDef).getBeanClass();
        if (BeanFactoryPostProcessor.class.isAssignableFrom(beanClass) ||
                BeanPostProcessor.class.isAssignableFrom(beanClass) ||
                AopInfrastructureBean.class.isAssignableFrom(beanClass) ||
                EventListenerFactory.class.isAssignableFrom(beanClass)) {
            return false;
        }
        metadata = AnnotationMetadata.introspect(beanClass);
    }
    else {
        try {
// 否则 通过MetadataReaderFactory 中的MetadataReader 进行读取
            MetadataReader metadataReader = metadataReaderFactory.getMetadataReader(className);
            metadata = metadataReader.getAnnotationMetadata();
        }
        catch (IOException ex) {
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;Could not find class file for introspecting configuration annotations: &quot; +
                        className, ex);
            }
            return false;
        }
    }
// 如果存在Configuration 注解,则为BeanDefinition 设置configurationClass属性为full
    Map&lt;String, Object&gt; config = metadata.getAnnotationAttributes(Configuration.class.getName());
    if (config != null &amp;&amp; !Boolean.FALSE.equals(config.get(&quot;proxyBeanMethods&quot;))) {
        beanDef.setAttribute(CONFIGURATION_CLASS_ATTRIBUTE, CONFIGURATION_CLASS_FULL);
    }
// 如果AnnotationMetadata 中有Component,ComponentScan,Import,ImportResource 注解中的任意一个,或者存在 被@bean 注解的方法,则返回true
    else if (config != null || isConfigurationCandidate(metadata)) {
        beanDef.setAttribute(CONFIGURATION_CLASS_ATTRIBUTE, CONFIGURATION_CLASS_LITE);
    }
    else {
        return false;
    }
    Integer order = getOrder(metadata);
    if (order != null) {
        beanDef.setAttribute(ORDER_ATTRIBUTE, order);
    }
    return true;
}
</code></pre>
<p>接着来看<code>ConfigurationClassParser</code>的<code>parser()</code>:</p>
<pre><code class="language-java">public void parse(Set&lt;BeanDefinitionHolder&gt; configCandidates) {
    for (BeanDefinitionHolder holder : configCandidates) {
        BeanDefinition bd = holder.getBeanDefinition();
        try {
            if (bd instanceof AnnotatedBeanDefinition) {
                parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName());
            }
            else if (bd instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) bd).hasBeanClass()) {
                parse(((AbstractBeanDefinition) bd).getBeanClass(), holder.getBeanName());
            }
            else {
                parse(bd.getBeanClassName(), holder.getBeanName());
            }
        }
        catch (BeanDefinitionStoreException ex) {
            throw ex;
        }
        catch (Throwable ex) {
            throw new BeanDefinitionStoreException(
                    &quot;Failed to parse configuration class [&quot; + bd.getBeanClassName() + &quot;]&quot;, ex);
        }
    }
    this.deferredImportSelectorHandler.process();
}
</code></pre>
<p>其主要做了两件事情：<br>
1、遍历configCandidates ,进行处理.根据BeanDefinition 的类型 做不同的处理,一般都会调用ConfigurationClassParser#parse 进行解析。<br>
2、处理ImportSelect。<br>
我们先来看一下第一步：</p>
<pre><code class="language-java">protected void processConfigurationClass(ConfigurationClass configClass, Predicate&lt;String&gt; filter) throws IOException {
    if (this.conditionEvaluator.shouldSkip(configClass.getMetadata(), ConfigurationPhase.PARSE_CONFIGURATION)) {
        return;
    }
    ConfigurationClass existingClass = this.configurationClasses.get(configClass);
    if (existingClass != null) {
        if (configClass.isImported()) {
            if (existingClass.isImported()) {
                existingClass.mergeImportedBy(configClass);
            }
            // Otherwise ignore new imported config class; existing non-imported class overrides it.
            return;
        }
        else {
            // Explicit bean definition found, probably replacing an import.
            // Let's remove the old one and go with the new one.
            this.configurationClasses.remove(configClass);
            this.knownSuperclasses.values().removeIf(configClass::equals);
        }
    }

    // Recursively process the configuration class and its superclass hierarchy.
    SourceClass sourceClass = asSourceClass(configClass, filter);
    do {
        sourceClass = doProcessConfigurationClass(configClass, sourceClass, filter);
    }
    while (sourceClass != null);

    this.configurationClasses.put(configClass, configClass);
}
</code></pre>
<p>主要做如下4件事情：<br>
1、调用 shouldSkip 方法来判断该 configClass 是否需要 跳过。<br>
2、处理Imported 的情况。<br>
3、递归调用进行解析。<br>
4、添加到configurationClasses中。<br>
我们先来看一下真正解析的步骤 <code>doProcessConfigurationClass</code> 方法：</p>
<pre><code class="language-java">protected final SourceClass doProcessConfigurationClass(
        ConfigurationClass configClass, SourceClass sourceClass, Predicate&lt;String&gt; filter)
        throws IOException {

    if (configClass.getMetadata().isAnnotated(Component.class.getName())) {
        // Recursively process any member (nested) classes first
        processMemberClasses(configClass, sourceClass, filter);
    }

    // Process any @PropertySource annotations
    for (AnnotationAttributes propertySource : AnnotationConfigUtils.attributesForRepeatable(
            sourceClass.getMetadata(), PropertySources.class,
            org.springframework.context.annotation.PropertySource.class)) {
        if (this.environment instanceof ConfigurableEnvironment) {
            processPropertySource(propertySource);
        }
        else {
            logger.info(&quot;Ignoring @PropertySource annotation on [&quot; + sourceClass.getMetadata().getClassName() +
                    &quot;]. Reason: Environment must implement ConfigurableEnvironment&quot;);
        }
    }

    // Process any @ComponentScan annotations
    Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable(
            sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class);
    if (!componentScans.isEmpty() &amp;&amp;
            !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) {
        for (AnnotationAttributes componentScan : componentScans) {
            // The config class is annotated with @ComponentScan -&gt; perform the scan immediately
            Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions =
                    this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName());
            // Check the set of scanned definitions for any further config classes and parse recursively if needed
            for (BeanDefinitionHolder holder : scannedBeanDefinitions) {
                BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition();
                if (bdCand == null) {
                    bdCand = holder.getBeanDefinition();
                }
                if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) {
                    parse(bdCand.getBeanClassName(), holder.getBeanName());
                }
            }
        }
    }
    // Process any @Import annotations
    processImports(configClass, sourceClass, getImports(sourceClass), filter, true);
    // Process any @ImportResource annotations
    AnnotationAttributes importResource =
            AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(), ImportResource.class);
    if (importResource != null) {
        String[] resources = importResource.getStringArray(&quot;locations&quot;);
        Class&lt;? extends BeanDefinitionReader&gt; readerClass = importResource.getClass(&quot;reader&quot;);
        for (String resource : resources) {
            String resolvedResource = this.environment.resolveRequiredPlaceholders(resource);
            configClass.addImportedResource(resolvedResource, readerClass);
        }
    }
    // Process individual @Bean methods
    Set&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(sourceClass);
    for (MethodMetadata methodMetadata : beanMethods) {
        configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass));
    }

    // Process default methods on interfaces
    processInterfaces(configClass, sourceClass);

    // Process superclass, if any
    if (sourceClass.getMetadata().hasSuperClass()) {
        String superclass = sourceClass.getMetadata().getSuperClassName();
        if (superclass != null &amp;&amp; !superclass.startsWith(&quot;java&quot;) &amp;&amp;
                !this.knownSuperclasses.containsKey(superclass)) {
            this.knownSuperclasses.put(superclass, configClass);
            // Superclass found, return its annotation metadata and recurse
            return sourceClass.getSuperClass();
        }
    }
    // No superclass -&gt; processing is complete
    return null;
}
</code></pre>
<p>主要做了如下8件事情：<br>
1、如果该类使用 @Component 注解，调用 processMemberClasses 方法，其主要作用是将类放到 importStack 中，并且判断是否有循环依赖度问题。<br>
2、处理@PropertySource.通过遍历该类中的@PropertySource的注解,如果该类中的environment是ConfigurableEnvironment 子类的话,则调用processPropertySource进行处理。<br>
3、处理@ComponentScan,通过遍历该类上的@ComponentScan 注解，并使用 conditionEvaluator.shouldSkip 进行判断是否需要跳过。没有就通过ComponentScanAnnotationParser#parse方法进行扫描：<br>
4、处理@Import 注解<br>
5、处理 @ImportResource 注解，先重 config 类中查找是否存在该注解，假如存在，就获取其 location 属性，然后遍历 location 位置中的 bean，加入到 configClass 中的 ImportedResource。<br>
6、处理 @Bean 的方法，遍历 @Bean 的方法，并放到 configClass 的 BeanMethod 中。<br>
7、遍历 configClass 的所有接口的 @Bean 的方法，并放到 configClass 的 BeanMethod 中。<br>
8、如果存在父类的话，就将父类放到 knownSuperclasses 中，并返回，返回就类似于递归调用。否则返回 null。</p>
<p>我们回到ConfigurationClassPostProcessor的processConfigBeanDefinitions方法中，接下来是调用 ConfigurationClassBeanDefinitionReader#loadBeanDefinitions 方法。</p>
<pre><code class="language-java">public void loadBeanDefinitions(Set&lt;ConfigurationClass&gt; configurationModel) {
    TrackedConditionEvaluator trackedConditionEvaluator = new TrackedConditionEvaluator();
    for (ConfigurationClass configClass : configurationModel) {
        loadBeanDefinitionsForConfigurationClass(configClass, trackedConditionEvaluator);
    }
}
</code></pre>
<p>主要做两件事情：<br>
1、实例化 TrackedConditionEvaluator；<br>
2、遍历configurationModel ，使用loadBeanDefinitionsForConfigurationClass 方法加载 BeanDefinition。</p>
<pre><code class="language-java">private void loadBeanDefinitionsForConfigurationClass(
        ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) {

    if (trackedConditionEvaluator.shouldSkip(configClass)) {
        String beanName = configClass.getBeanName();
        if (StringUtils.hasLength(beanName) &amp;&amp; this.registry.containsBeanDefinition(beanName)) {
            this.registry.removeBeanDefinition(beanName);
        }
        this.importRegistry.removeImportingClass(configClass.getMetadata().getClassName());
        return;
    }

    if (configClass.isImported()) {
        registerBeanDefinitionForImportedConfigurationClass(configClass);
    }
    for (BeanMethod beanMethod : configClass.getBeanMethods()) {
        loadBeanDefinitionsForBeanMethod(beanMethod);
    }

    loadBeanDefinitionsFromImportedResources(configClass.getImportedResources());
    loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars());
}
</code></pre>
<p>主要做了如下几件事情：<br>
1、调用 trackedConditionEvaluator 来判断条件注解，是否需要跳过这个 config 类。如果需要，就将这个类从容器中移除，并且从 importRegistry 中移除。<br>
2、如果当前类中存在@Import 注解，调用 registerBeanDefinitionForImportedConfigurationClass 方法进行注册<br>
3、遍历BeanMethods,依次对其调用loadBeanDefinitionsForBeanMethod进行注册。<br>
4、处理 @ImportResource 注解,具体如下：</p>
<pre><code class="language-java">private void loadBeanDefinitionsFromImportedResources(
        Map&lt;String, Class&lt;? extends BeanDefinitionReader&gt;&gt; importedResources) {
    Map&lt;Class&lt;?&gt;, BeanDefinitionReader&gt; readerInstanceCache = new HashMap&lt;&gt;();
// 遍历所有的 importedResources
    importedResources.forEach((resource, readerClass) -&gt; {
// 如果是 BeanDefinitionReader，就查看是否是 groovy 类，假如不是就使用 XmlBeanDefinitionReader 类
        if (BeanDefinitionReader.class == readerClass) {
            if (StringUtils.endsWithIgnoreCase(resource, &quot;.groovy&quot;)) {
                readerClass = GroovyBeanDefinitionReader.class;
            }
            else {
                readerClass = XmlBeanDefinitionReader.class;
            }
        }
// 尝试重 readerInstanceCache 读取 BeanDefinitionReader 假如没有就实例化。
        BeanDefinitionReader reader = readerInstanceCache.get(readerClass);
        if (reader == null) {
            try {
                reader = readerClass.getConstructor(BeanDefinitionRegistry.class).newInstance(this.registry);
                if (reader instanceof AbstractBeanDefinitionReader) {
                    AbstractBeanDefinitionReader abdr = ((AbstractBeanDefinitionReader) reader);
                    abdr.setResourceLoader(this.resourceLoader);
                    abdr.setEnvironment(this.environment);
                }
                readerInstanceCache.put(readerClass, reader);
            }
            catch (Throwable ex) {
                throw new IllegalStateException(
                        &quot;Could not instantiate BeanDefinitionReader class [&quot; + readerClass.getName() + &quot;]&quot;);
            }
        }
// 加载 bean
        reader.loadBeanDefinitions(resource);
    });
}
</code></pre>
<p>主要做了四件事情：<br>
1、遍历所有的 importedResources 。<br>
2、选择 BeanDefinitionReader，假如是 groovy 类，就使用 GroovyBeanDefinitionReader 不是就使用 XmlBeanDefinitionReader<br>
3、尝试从readerInstanceCache中获取对应的BeanDefinitionReader,如果不存在,则实例化一个,然后放入到readerInstanceCache缓存中。<br>
4、调用 BeanDefinitionReader#loadBeanDefinitions 进行加载 bean。<br>
5、注册@Import注解中的ImportBeanDefinitionRegistrar接口的registerBeanDefinitions。</p>
<p>接下来，我们继续看容器刷新流程</p>
<h5 id="1256-registerbeanpostprocessors-方法">1.2.5.6 registerBeanPostProcessors 方法</h5>
<p>这个方法最终调用了 PostProcessorRegistrationDelegate#registerBeanPostProcessors，如下：</p>
<pre><code class="language-java">public static void registerBeanPostProcessors(
        ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) {

    String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false);

    // Register BeanPostProcessorChecker that logs an info message when
    // a bean is created during BeanPostProcessor instantiation, i.e. when
    // a bean is not eligible for getting processed by all BeanPostProcessors.
    int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length;
    beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount));

    // Separate between BeanPostProcessors that implement PriorityOrdered,
    // Ordered, and the rest.
    List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;();
    List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;&gt;();
    List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;();
    List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;();
    for (String ppName : postProcessorNames) {
        if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {
            BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);
            priorityOrderedPostProcessors.add(pp);
            if (pp instanceof MergedBeanDefinitionPostProcessor) {
                internalPostProcessors.add(pp);
            }
        }
        else if (beanFactory.isTypeMatch(ppName, Ordered.class)) {
            orderedPostProcessorNames.add(ppName);
        }
        else {
            nonOrderedPostProcessorNames.add(ppName);
        }
    }

    // First, register the BeanPostProcessors that implement PriorityOrdered.
    sortPostProcessors(priorityOrderedPostProcessors, beanFactory);
    registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors);

    // Next, register the BeanPostProcessors that implement Ordered.
    List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(orderedPostProcessorNames.size());
    for (String ppName : orderedPostProcessorNames) {
        BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);
        orderedPostProcessors.add(pp);
        if (pp instanceof MergedBeanDefinitionPostProcessor) {
            internalPostProcessors.add(pp);
        }
    }
    sortPostProcessors(orderedPostProcessors, beanFactory);
    registerBeanPostProcessors(beanFactory, orderedPostProcessors);

    // Now, register all regular BeanPostProcessors.
    List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(nonOrderedPostProcessorNames.size());
    for (String ppName : nonOrderedPostProcessorNames) {
        BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);
        nonOrderedPostProcessors.add(pp);
        if (pp instanceof MergedBeanDefinitionPostProcessor) {
            internalPostProcessors.add(pp);
        }
    }
    registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors);

    // Finally, re-register all internal BeanPostProcessors.
    sortPostProcessors(internalPostProcessors, beanFactory);
    registerBeanPostProcessors(beanFactory, internalPostProcessors);

    // Re-register post-processor for detecting inner beans as ApplicationListeners,
    // moving it to the end of the processor chain (for picking up proxies etc).
    beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));
}
</code></pre>
<p>1、先从 beanFactory 中获取 BeanPostProcessor 类型的 bean。<br>
2、添加一个BeanPostProcessor ， BeanPostProcessorChecker ，主要用于日志打印。<br>
3、遍历所有的 postProcessorNames ：<br>
（1）将所有实现了 PriorityOrdered 接口的 bean 放到 priorityOrderedPostProcessors 中。<br>
（2）如果bean 即实现了 PriorityOrdered 接口，也实现了 MergedBeanDefinitionPostProcessor 接口的话，将其放到 internalPostProcessors 中。<br>
（3）假如 bean 实现了 Ordered 接口放到 orderedPostProcessorNames 中。<br>
（4）假如都没有，就放到 nonOrderedPostProcessorNames 中。<br>
4、注册 priorityOrderedPostProcessors 的 BPP<br>
5、注册 orderedPostProcessors 的 BPP<br>
6、注册所有 nonOrderedPostProcessors 的 BPP<br>
7、 注册所有MergedBeanDefinitionPostProcessor类型的BeanPostProcessor,并非是重复注册.如下:<br>
8、在最后新增一个BPP 是 ApplicationListenerDetector。</p>
<h5 id="1257-initmessagesource-方法">1.2.5.7 initMessageSource 方法</h5>
<p>1、从 beanFactory 中读取 messageSource ，看是否存在，假如存在，获取之，然后判断是是HierarchicalMessageSource 类型假如是，就将其 ParentMessageSource 设置为 nternalParentMessageSource。<br>
2、如果不存在，就实例化 DelegatingMessageSource 作为 getInternalParentMessageSource 调用的结果。</p>
<h5 id="1258-初始化-applicationeventmulticaster">1.2.5.8 初始化 ApplicationEventMulticaster</h5>
<p>这里的逻辑主要是 如果存在用户自定义的广播器，那么就将其设置为默认广播器。假如不存在就初始化 SimpleApplicationEventMulticaster 作为默认的广播器。</p>
<h5 id="1259-onrefresh">1.2.5.9 Onrefresh</h5>
<p>这个接口是留给子类的扩展点 ServletWebServerApplicationContext 的代码如下：</p>
<pre><code class="language-java">@Override
protected void onRefresh() {
    super.onRefresh();
    try {
        createWebServer();
    }
    catch (Throwable ex) {
        throw new ApplicationContextException(&quot;Unable to start web server&quot;, ex);
    }
}
</code></pre>
<p>1 、先调用父类的 onRefresh 方法<br>
2、调用完父类的 Onfresh 后，创建一个嵌入的Servlet容器.</p>
<pre><code class="language-java">public static ThemeSource initThemeSource(ApplicationContext context) {
    if (context.containsLocalBean(THEME_SOURCE_BEAN_NAME)) {
        ThemeSource themeSource = context.getBean(THEME_SOURCE_BEAN_NAME, ThemeSource.class);
        // Make ThemeSource aware of parent ThemeSource.
        if (context.getParent() instanceof ThemeSource &amp;&amp; themeSource instanceof HierarchicalThemeSource) {
            HierarchicalThemeSource hts = (HierarchicalThemeSource) themeSource;
            if (hts.getParentThemeSource() == null) {
                // Only set parent context as parent ThemeSource if no parent ThemeSource
                // registered already.
                hts.setParentThemeSource((ThemeSource) context.getParent());
            }
        }
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;Using ThemeSource [&quot; + themeSource + &quot;]&quot;);
        }
        return themeSource;
    }
    else {
        // Use default ThemeSource to be able to accept getTheme calls, either
        // delegating to parent context's default or to local ResourceBundleThemeSource.
        HierarchicalThemeSource themeSource = null;
        if (context.getParent() instanceof ThemeSource) {
            themeSource = new DelegatingThemeSource();
            themeSource.setParentThemeSource((ThemeSource) context.getParent());
        }
        else {
            themeSource = new ResourceBundleThemeSource();
        }
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;Unable to locate ThemeSource with name '&quot; + THEME_SOURCE_BEAN_NAME +
                    &quot;': using default [&quot; + themeSource + &quot;]&quot;);
        }
        return themeSource;
    }
}
</code></pre>
<p>1、如果context中有themeSource的定义<br>
（1）从context 获取,id 为themeSource type为ThemeSource 的 bean<br>
（2）如果父容器实现了ThemeSource,并且ThemeSource 是HierarchicalThemeSource 的子类,并且HierarchicalThemeSource 的ParentThemeSource 没有进行设置.则将父容器赋值给HierarchicalThemeSource的ParentThemeSource<br>
2、如果context中没有themeSource的定义<br>
（1）如果父容器为ThemeSource的子类,则实例化DelegatingThemeSource,并将父容器赋值给DelegatingThemeSource的ParentThemeSource<br>
（2）否则实例化为DelegatingThemeSource</p>
<h5 id="12510-registerlisteners-注册监听器">1.2.5.10 registerListeners 注册监听器</h5>
<p>这个方法的主要作用是初始化所有的 listener</p>
<pre><code class="language-java">protected void registerListeners() {
    // Register statically specified listeners first.
    for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) {
        getApplicationEventMulticaster().addApplicationListener(listener);
    }

    // Do not initialize FactoryBeans here: We need to leave all regular beans
    // uninitialized to let post-processors apply to them!
    String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false);
    for (String listenerBeanName : listenerBeanNames) {
        getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName);
    }

    // Publish early application events now that we finally have a multicaster...
    Set&lt;ApplicationEvent&gt; earlyEventsToProcess = this.earlyApplicationEvents;
    this.earlyApplicationEvents = null;
    if (!CollectionUtils.isEmpty(earlyEventsToProcess)) {
        for (ApplicationEvent earlyEvent : earlyEventsToProcess) {
            getApplicationEventMulticaster().multicastEvent(earlyEvent);
        }
    }
}
</code></pre>
<p>1、硬编码方式注册的监听器添加到SimpleApplicationEventMulticaster中的defaultRetriever的applicationListeners<br>
2、将注册到配置文件中的 ApplicationListener 找出来，并添加到SimpleApplicationEventMulticaster中的defaultRetriever。<br>
3、 将之前发生的 earlyApplicationEvents 重复发送一遍。</p>
<h5 id="12511-finishbeanfactoryinitialization">1.2.5.11 finishBeanFactoryInitialization</h5>
<p>该方法主要作用是 初始化剩余的单例（non-lazy-init)）</p>
<pre><code class="language-java">protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) {
    // Initialize conversion service for this context.
    if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp;
        beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) {
        beanFactory.setConversionService(
                beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class));
    }

    // Register a default embedded value resolver if no bean post-processor
    // (such as a PropertyPlaceholderConfigurer bean) registered any before:
    // at this point, primarily for resolution in annotation attribute values.
    if (!beanFactory.hasEmbeddedValueResolver()) {
        beanFactory.addEmbeddedValueResolver(strVal -&gt; getEnvironment().resolvePlaceholders(strVal));
    }

    // Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early.
    String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false);
    for (String weaverAwareName : weaverAwareNames) {
        getBean(weaverAwareName);
    }

    // Stop using the temporary ClassLoader for type matching.
    beanFactory.setTempClassLoader(null);

    // Allow for caching all bean definition metadata, not expecting further changes.
    beanFactory.freezeConfiguration();

    // Instantiate all remaining (non-lazy-init) singletons.
    beanFactory.preInstantiateSingletons();
}
</code></pre>
<p>1、如果 beaFactory 中存在 CONVERSION_SERVICE_BEAN_NAME name 的 bean，并且类型为 ConversionService.class ，将其设置到 beanFactory 中。<br>
2、如果 beanFactory 中没有 EmbeddedValueResolver，添加一个。<br>
3、设置 type 为 LoadTimeWeaverAware 的bean。<br>
4、设置TempClassLoader 为null<br>
5、冻结所有 bean 的定义，也就是从这里开始，所有的 bean 后面都不允许被修改了。<br>
6、初始化剩下的单实例.</p>
<h5 id="12512-finishrefresh">1.2.5.12 finishRefresh</h5>
<pre><code class="language-java">protected void finishRefresh() {
    // Clear context-level resource caches (such as ASM metadata from scanning).
    clearResourceCaches();

    // Initialize lifecycle processor for this context.
    initLifecycleProcessor();

    // Propagate refresh to lifecycle processor first.
    getLifecycleProcessor().onRefresh();

    // Publish the final event.
    publishEvent(new ContextRefreshedEvent(this));

    // Participate in LiveBeansView MBean, if active.
    LiveBeansView.registerApplicationContext(this);
}
</code></pre>
<p>1、清理 resource caches。<br>
2、初始化LifecycleProcessor.<br>
3、调用 LifecycleProcessor 的 onrefresh 方法。<br>
4、发布ContextRefreshedEvent 事件.</p>
<h5 id="12513-resetcommoncaches">1.2.5.13 resetCommonCaches</h5>
<p>1、清除 ReflectionUtils 缓存。<br>
2、清除 AnnotationUtils 缓存。<br>
3、清除 ResolvableType 缓存。</p>
<h4 id="126-afterrefresh-spring-容器的后置处理器">1.2.6 afterRefresh Spring 容器的后置处理器</h4>
<h4 id="127-通知所有-listener-结束启动">1.2.7 通知所有 listener 结束启动</h4>
<p>这里最终调用了 EventPublishingRunListener#started 方法：</p>
<pre><code class="language-java">public void started(ConfigurableApplicationContext context) {
    context.publishEvent(new ApplicationStartedEvent(this.application, this.args, context));
    AvailabilityChangeEvent.publish(context, LivenessState.CORRECT);
}
</code></pre>
<p>1、首先是调用 context.publishEvent 来发布启动完成事件。<br>
2、调用 AvailabilityChangeEvent 发布 CORRECT 事件，代表启动成功。</p>
<h4 id="128-调用所有-runner-的-run-方法">1.2.8 调用所有 runner 的 run 方法</h4>
<pre><code class="language-java">private void callRunners(ApplicationContext context, ApplicationArguments args) {
    List&lt;Object&gt; runners = new ArrayList&lt;&gt;();
    runners.addAll(context.getBeansOfType(ApplicationRunner.class).values());
    runners.addAll(context.getBeansOfType(CommandLineRunner.class).values());
    AnnotationAwareOrderComparator.sort(runners);
    for (Object runner : new LinkedHashSet&lt;&gt;(runners)) {
        if (runner instanceof ApplicationRunner) {
            callRunner((ApplicationRunner) runner, args);
        }
        if (runner instanceof CommandLineRunner) {
            callRunner((CommandLineRunner) runner, args);
        }
    }
}
</code></pre>
<p>首先查找所有的 ApplicationRunner 和 CommandLineRunner ，然后遍历调用他们的 run 方法。</p>
<h4 id="129-通知所有-listener-running-事件">1.2.9 通知所有 listener running 事件。</h4>
<blockquote>
<p>⚠️大家可以参考这个图，因为没钱买，只能放链接了 <a href="https://www.processon.com/view/60605358f346fb6d9ef1bd9c?fromnew=1" title="springboot启动流程">springboot启动流程</a></p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semaphore实现原理]]></title>
        <id>https://q456qq520.github.io/post/semaphore-shi-xian-yuan-li/</id>
        <link href="https://q456qq520.github.io/post/semaphore-shi-xian-yuan-li/">
        </link>
        <updated>2023-02-07T02:31:24.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="1-构造方法">1 构造方法</h2>
<p>从概念上讲，Semaphore维护一组许可，由一个可以递增或递减的计数器值表示，用来控制同时访问特定资源的线程数目。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="1-构造方法">1 构造方法</h2>
<p>从概念上讲，Semaphore维护一组许可，由一个可以递增或递减的计数器值表示，用来控制同时访问特定资源的线程数目。</p>
<!-- more -->
<p>Semaphore信号量来实现线程间通信，Semaphore支持公平锁和非公平锁，Semaphore底层是通过共享锁来实现的，其支持两种构造函数，如下所示：</p>
<pre><code class="language-java"> // 默认使用非公平锁实现
 public Semaphore(int permits) {
     sync = new NonfairSync(permits);
 }
 ​
 public Semaphore(int permits, boolean fair) {
     sync = fair ? new FairSync(permits) : new NonfairSync(permits);
 }
</code></pre>
<h2 id="2-semaphore方法">2 Semaphore方法</h2>
<pre><code class="language-java">//尝试获取一个信号量，如果信号量不为0，那么将信号量-1，返回
//如果信号量为0，WAITING直到信号量不为0
//可中断
public void acquire() throws InterruptedException

//尝试获取多个信号量，如果信号量足够，那么将信号量-permits，返回
//如果信号量不够，WAITING直到信号量不为0
//可中断 
public void acquire(int permits) throws InterruptedException
    
//同acquire()，但不可中断
public void acquireUninterruptibly()
    
//同acquire(int permits),但不可中断
public void acquireUninterruptibly(int permits)

//释放一个信号量
public void release()
    
//释放permits个信号量
public void release(int permits)

</code></pre>
<h2 id="3-semaphore内部类及继承关系">3 Semaphore内部类及继承关系</h2>
<p><img src="https://q456qq520.github.io/post-images/1675737631273.png" alt="" loading="lazy"><br>
Semaphore与ReentrantLock的内部类的结构相同，类内部总共存在Sync、NonfairSync、FairSync三个类，NonfairSync与FairSync类继承自Sync类，Sync类继承自AbstractQueuedSynchronizer抽象类。</p>
<h3 id="31-类的内部类-sync类">3.1 类的内部类 - Sync类</h3>
<pre><code class="language-java">// 内部类，继承自AQS
abstract static class Sync extends AbstractQueuedSynchronizer {
    // 版本号
    private static final long serialVersionUID = 1192457210091910933L;
    
    // 构造函数
    Sync(int permits) {
        // 设置状态数
        setState(permits);
    }
    
    // 获取许可
    final int getPermits() {
        return getState();
    }

    // 共享模式下非公平策略获取
    final int nonfairTryAcquireShared(int acquires) {
        for (;;) { // 无限循环
            // 获取许可数
            int available = getState();
            // 剩余的许可
            int remaining = available - acquires;
            if (remaining &lt; 0 ||
                compareAndSetState(available, remaining)) // 许可小于0或者比较并且设置状态成功
                return remaining;
        }
    }
    
    // 共享模式下进行释放
    protected final boolean tryReleaseShared(int releases) {
        for (;;) { // 无限循环
            // 获取许可
            int current = getState();
            // 可用的许可
            int next = current + releases;
            if (next &lt; current) // overflow
                throw new Error(&quot;Maximum permit count exceeded&quot;);
            if (compareAndSetState(current, next)) // 比较并进行设置成功
                return true;
        }
    }

    // 根据指定的缩减量减小可用许可的数目
    final void reducePermits(int reductions) {
        for (;;) { // 无限循环
            // 获取许可
            int current = getState();
            // 可用的许可
            int next = current - reductions;
            if (next &gt; current) // underflow
                throw new Error(&quot;Permit count underflow&quot;);
            if (compareAndSetState(current, next)) // 比较并进行设置成功
                return;
        }
    }

    // 获取并返回立即可用的所有许可
    final int drainPermits() {
        for (;;) { // 无限循环
            // 获取许可
            int current = getState();
            if (current == 0 || compareAndSetState(current, 0)) // 许可为0或者比较并设置成功
                return current;
        }
    }
}
</code></pre>
<h3 id="32-类的内部类-nonfairsync类">3.2 类的内部类 - NonfairSync类</h3>
<pre><code class="language-java">static final class NonfairSync extends Sync {
    // 版本号
    private static final long serialVersionUID = -2694183684443567898L;
    
    // 构造函数
    NonfairSync(int permits) {
        super(permits);
    }
    // 共享模式下获取
    protected int tryAcquireShared(int acquires) {
        return nonfairTryAcquireShared(acquires);
    }
}
</code></pre>
<p>从tryAcquireShared方法的源码可知，其会调用父类Sync的nonfairTryAcquireShared方法，表示按照非公平策略进行资源的获取。</p>
<h3 id="33-类的内部类-fairsync类">3.3 类的内部类 - FairSync类</h3>
<pre><code class="language-java">protected int tryAcquireShared(int acquires) {
    for (;;) { // 无限循环
        if (hasQueuedPredecessors()) // 同步队列中存在其他节点
            return -1;
        // 获取许可
        int available = getState();
        // 剩余的许可
        int remaining = available - acquires;
        if (remaining &lt; 0 ||
            compareAndSetState(available, remaining)) // 剩余的许可小于0或者比较设置成功
            return remaining;
    }
}
</code></pre>
<p>从tryAcquireShared方法的源码可知，它使用公平策略来获取资源，它会判断同步队列中是否存在其他的等待节点。</p>
<h3 id="34-类的属性">3.4 类的属性</h3>
<pre><code class="language-java">public class Semaphore implements java.io.Serializable {
    // 版本号
    private static final long serialVersionUID = -3222578661600680210L;
    // 属性
    private final Sync sync;
}
</code></pre>
<p>Semaphore自身只有两个属性，最重要的是sync属性，基于Semaphore对象的操作绝大多数都转移到了对sync的操作。</p>
<h2 id="4-semaphoreacquire流程分析以非公平锁为例">4 Semaphore.acquire流程分析(以非公平锁为例)</h2>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1675737423342.png" alt="" loading="lazy"></figure>
<p>从上图可以看出，针对阻塞线程的部分实现，和ReentrantLock基本一致，我们不做赘述，主要来看下前半部分的源码实现：</p>
<pre><code class="language-java"> // Semaphore.java
 public void acquire() throws InterruptedException {
     sync.acquireSharedInterruptibly(1);
 }
</code></pre>
<pre><code class="language-java"> // AbstractQueuedSynchronizer.java
 public final void acquireSharedInterruptibly(int arg)
         throws InterruptedException {
     // 如果线程是中断状态，抛出异常
     if (Thread.interrupted())
         throw new InterruptedException();
     // 尝试获取共享资源
     if (tryAcquireShared(arg) &lt; 0)
         doAcquireSharedInterruptibly(arg);
 }
</code></pre>
<p>从源码可以看出acquire主要依赖于tryAcquireShared和doAcquireSharedInterruptibly。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1675740380818.png" alt="" loading="lazy"></figure>
<h3 id="41-tryacquireshared">4.1 tryAcquireShared</h3>
<pre><code class="language-java">static final class NonfairSync extends Sync {
    private static final long serialVersionUID = -2694183684443567898L;

    NonfairSync(int permits) {
        super(permits);
    }

    protected int tryAcquireShared(int acquires) {
        return nonfairTryAcquireShared(acquires);
    }
}
</code></pre>
<pre><code class="language-java">final int nonfairTryAcquireShared(int acquires) {
    for (;;) {
        int available = getState();
        //判断是否还有令牌
        int remaining = available - acquires;
        //无论是否还有令牌，都要返回
        if (remaining &lt; 0 ||
            compareAndSetState(available, remaining))
            return remaining;
    }
}
</code></pre>
<pre><code class="language-java"> // AbstractQueuedSynchronizer.java
 protected final boolean compareAndSetState(int expect, int update) {
     // See below for intrinsics setup to support this
     return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
 }
</code></pre>
<p>从代码可以看出这里主要是根据申请的许可证数量，比较时否有许可证数量，如果可用许可证数量小于0，则直接返回，如果大于0，则通过CAS将state设置为可用许可证数量。</p>
<h3 id="42-doacquiresharedinterruptibly">4.2 doAcquireSharedInterruptibly</h3>
<p>当tryAcquireShared中返回的可用许可证数量小于0时，执行doAcquireSharedInterruptibly流程，代码如下：</p>
<pre><code class="language-java">private void doAcquireSharedInterruptibly(int arg)
    throws InterruptedException {
    //加入同步队列
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        //自旋获取锁
        for (;;) {
            final Node p = node.predecessor();
            //判断上一个节点是否是头节点
            if (p == head) {
                //如果是头节点则尝试获取锁
                int r = tryAcquireShared(arg);
                if (r &gt;= 0) {
                    //获取到锁，通知其他节点
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    failed = false;
                    return;
                }
            }
            //判断是否需要阻塞线程，设置waitStatus并阻塞
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                throw new InterruptedException();
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
</code></pre>
<pre><code class="language-java"> // AbstractQueuedSynchronizer.java
 // 在队尾新建Node对象并添加
 private Node addWaiter(Node mode) {
     Node node = new Node(Thread.currentThread(), mode);
     // Try the fast path of enq; backup to full enq on failure
     Node pred = tail;
     if (pred != null) {
         node.prev = pred;
         if (compareAndSetTail(pred, node)) {
             pred.next = node;
             return node;
         }
     }
     enq(node);
     return node;
 }
</code></pre>
<pre><code class="language-java">private void setHeadAndPropagate(Node node, int propagate) {
    Node h = head; // Record old head for check below
    setHead(node);

    if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 ||
        (h = head) == null || h.waitStatus &lt; 0) {
        Node s = node.next;
        if (s == null || s.isShared())
            doReleaseShared();
    }
}
</code></pre>
<p>执行setHeadAndPropagate的主要目的在于，这里能获取到说明在该线程自旋过程中有线程释放了许可证，释放的许可证数量有可能还有剩余，所以传递给其他节点的线程，唤醒其他阻塞状态的线程也尝试去获取许可证。</p>
<h2 id="5-semaphorerelease流程分析以非公平锁为例">5 Semaphore.release流程分析(以非公平锁为例)</h2>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1675738215229.png" alt="" loading="lazy"></figure>
<p>Semaphore.release流程相对而言，就比较简单，将release传递到AQS内部通过CAS更新许可证数量信息，更新完成后，遍历队列中Node节点，将Node waitStatus设置为0，并对对应线程执行unpark，相关代码如下：</p>
<pre><code class="language-java">@ReservedStackAccess
public final boolean releaseShared(int arg) {
    if (tryReleaseShared(arg)) {
        doReleaseShared();
        return true;
    }
    return false;
}
</code></pre>
<pre><code class="language-java">protected final boolean tryReleaseShared(int releases) {
    for (;;) {
        int current = getState();
        int next = current + releases;
        if (next &lt; current) // overflow
            throw new Error(&quot;Maximum permit count exceeded&quot;);
        // 通过CAS更新许可证数量
        if (compareAndSetState(current, next))
            return true;
    }
}
</code></pre>
<pre><code class="language-java">private void doReleaseShared() {
    for (;;) {
        Node h = head;
        if (h != null &amp;&amp; h != tail) {
            int ws = h.waitStatus;
            if (ws == Node.SIGNAL) {
                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                    continue;            // loop to recheck cases
                unparkSuccessor(h);
            }
            else if (ws == 0 &amp;&amp;
                        !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                continue;                // loop on failed CAS
        }
        if (h == head)                   // loop if head changed
            break;
    }
}
</code></pre>
<pre><code class="language-java">private void unparkSuccessor(Node node) {
    int ws = node.waitStatus;
    if (ws &lt; 0)
        compareAndSetWaitStatus(node, ws, 0);

    Node s = node.next;
    if (s == null || s.waitStatus &gt; 0) {
        s = null;
        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)
            if (t.waitStatus &lt;= 0)
                s = t;
    }
    if (s != null)
        LockSupport.unpark(s.thread);
}

// 许可证数量更新完成后，调用该方法唤醒线程
private void doReleaseShared() {
    // 自旋
    for (;;) {
        Node h = head;
        if (h != null &amp;&amp; h != tail) {
            int ws = h.waitStatus;
            if (ws == Node.SIGNAL) {
                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                    continue;            // loop to recheck cases
                // 唤醒后继节点线程抢占许可证
                unparkSuccessor(h);
            }
            else if (ws == 0 &amp;&amp;
                     !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                continue;                // loop on failed CAS
        }
        if (h == head)                   // loop if head changed
            break;
    }
}
</code></pre>
<h2 id="6-公平锁">6 公平锁</h2>
<p>我们分析了Smaphore非公平锁的实现，公平锁的实现其本质区别在于在tryAcquireShared中只有当等待队列为空时，才会去尝试更新剩余许可证数量。</p>
<pre><code class="language-java">protected int tryAcquireShared(int acquires) {
    for (;;) {
        //判断是否是头节点
        if (hasQueuedPredecessors())
            return -1;
        int available = getState();
        int remaining = available - acquires;
        if (remaining &lt; 0 ||
            compareAndSetState(available, remaining))
            return remaining;
    }
}

public final boolean hasQueuedPredecessors() {
    // The correctness of this depends on head being initialized
    // before tail and on head.next being accurate if the current
    // thread is first in queue.
    Node t = tail; // Read fields in reverse initialization order
    Node h = head;
    Node s;
    return h != t &amp;&amp;
        ((s = h.next) == null || s.thread != Thread.currentThread());
}
</code></pre>
<h2 id="7-semaphore和reentrantlock的区别">7 Semaphore和ReentrantLock的区别</h2>
<ol>
<li>可重入的性质<br>
Semaphores在本质上是非可重入的 ，这意味着我们不能在同一个线程中第二次获得Semaphore。试图这样做会导致死锁（一个线程与自己死锁）。<br>
另一方面， 可重入锁在本质上是可重入的，允许一个线程使用lock() 方法多次锁定一个特定的资源。</li>
<li>同步机制<br>
Semaphores很适合信号传递（信号机制），线程使用acquire()&amp;release() 方法来标记访问关键资源的开始和结束。<br>
ReentrantLock 使用锁定机制，使用lock() 方法锁定一个特定的资源 ，在对该资源进行特定操作后，使用unlock() 方法释放该锁。</li>
<li>死锁恢复<br>
Semaphores提供了一个强大的死锁恢复机制，因为它使用了一个非所有权的释放机制，因此任何线程都可以释放一个许可，以恢复一个卡住或等待的线程的死锁情况。<br>
在 ReentrantLock的情况下，死锁恢复是有点困难的，因为它使用线程对资源的所有权，通过物理锁定它，只有所有者线程可以解锁该资源。如果所有者Thread进入无限等待或睡眠状态，就不可能释放该特定资源的锁，从而导致死锁情况。</li>
<li>抛出IllegalMonitorStateException<br>
在Semaphores中，没有线程拥有获取或释放许可的所有权，所以任何线程都可以调用release() 方法来释放任何其他线程的许可，没有线程会引发 IllegalMonitorStateException。<br>
在可重入锁中，一个Thread 通过调用lock() 方法成为一个关键共享资源的所有者，如果其他Thread在没有拥有锁的情况下调用unlock() 方法，那么 它将会产生 IllegalMonitorStateException。</li>
<li>修改<br>
任何线程都可以使用Semaphore的acquire() 和release() 方法来修改它的可用许可。<br>
只有通过lock()方法拥有资源的当前所有者线程可以修改ReentrantLock，而其他线程不允许这样做。</li>
</ol>
<p>Semaphores可以用于非所有权-释放语义，即不止一个Thread 可以进入一个关键部分，并且不需要锁定机制来锁定一个共享资源。根据设计，Semaphore对哪个线程调用acquisition()和release()方法是盲目的，它所关心的是许可成为可用的。<br>
如果我们需要可重入互斥或一个简单的互斥 ，那么 ReentrantLock是最好的选择。可重入锁 提供了对锁机制更好的控制，并且允许每次只有一个线程访问关键部分，从而提供了同步性，并消除了在多线程应用程序中工作时的数据不一致问题。</p>
<h2 id="8-场景问题">8 场景问题</h2>
<p><code>semaphore初始化有10个令牌，11个线程同时各调用1次acquire方法，会发生什么?</code><br>
答案：拿不到令牌的线程阻塞，不会继续往下运行。</p>
<p><code>semaphore初始化有10个令牌，一个线程重复调用11次acquire方法，会发生什么?</code><br>
答案：线程阻塞，不会继续往下运行。可能你会考虑类似于锁的重入的问题，很好，但是，令牌没有重入的概念。你只要调用一次acquire方法，就需要有一个令牌才能继续运行。</p>
<p><code>semaphore初始化有1个令牌，1个线程调用一次acquire方法，然后调用两次release方法，之后另外一个线程调用acquire(2)方法，此线程能够获取到足够的令牌并继续运行吗?</code><br>
答案：能，原因是release方法会添加令牌，并不会以初始化的大小为准。</p>
<p><code>semaphore初始化有2个令牌，一个线程调用1次release方法，然后一次性获取3个令牌，会获取到吗?</code><br>
答案：能，原因是release会添加令牌，并不会以初始化的大小为准。Semaphore中release方法的调用并没有限制要在acquire后调用。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题（一）]]></title>
        <id>https://q456qq520.github.io/post/mian-shi-ti-yi/</id>
        <link href="https://q456qq520.github.io/post/mian-shi-ti-yi/">
        </link>
        <updated>2023-02-01T06:50:06.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-java基础">一 JAVA基础</h2>
<h3 id="1-equals与hashcode的区别与联系">1.==、equals与HashCode的区别与联系</h3>
<p>1、equals用于判断两个对象是否相等  == 判断的是地址是否相等（两个实例），具备自反性、一致性、传递性<br>
2、hashCode 返回对象的哈希值int类型，用于再HashTable、HashSet计算存放下标使用（先通过计算hashCode获取下标，下标一致再根据equals判断是否相同的两个对象）</p>
<p>再使用HashCode的类散列表情况下 hashCode和equals具备以下关系：<br>
1)、如果两个对象相等，那么它们的hashCode()值一定相同。<br>
这里的相等是指，通过equals()比较两个对象时返回true。<br>
2)、如果两个对象hashCode()相等，它们并不一定相等。<br>
因为在散列表中，hashCode()相等，即两个键值对的哈希值相等。然而哈希值相等，并不一定能得出键值对相等。补充说一句：“两个不同的键值对，哈希值相等”，这就是哈希冲突。所以这时候 一般我们修改 equals方法时，也需要修改 hashCode方法，不然即使equals方法返回TRUE，但是再HashMap里面因为hashCode的不同，所以不会调用equals方法，导致结果不正确。</p>
<h3 id="2深克隆与浅克隆">2.深克隆与浅克隆</h3>
<p>1.浅克隆：只复制基本类型（包含String类型）的数据，引用类型的数据只复制了引用的地址，引用的对象并没有复制，在新的对象中修改引用类型的数据会影响原对象中的引用。<br>
2.深克隆：是在引用类型的类中也实现了clone，是clone的嵌套，复制后的对象与原对象之间完全不会影响。<br>
3.使用序列化也能完成深复制的功能：对象序列化后写入流中，此时也就不存在引用什么的概念了，再从流中读取，生成新的对象，新对象和原对象之间也是完全互不影响的。<br>
4.使用clone实现的深克隆其实是浅克隆中嵌套了浅克隆，与toString方法类似</p>
<h3 id="3hashmap数据结构hashtable数据结构">3.HashMap数据结构,HashTable数据结构</h3>
<p>哈希表是一种组合的数据结构，它通常的实现方式是数组加链表，或者数组加红黑树。</p>
<p><code>HashMap</code><br>
<a href="/post/java-ji-chu-hashmap">java基础-HashMap</a></p>
<p><code>HashTable</code><br>
HashTable类继承自Dictionary类， 实现了Map接口。 大部分的操作都是通过synchronized锁保护的，是线程安全的，key、value都不可以为null， 每次put方法不允许null值，如果发现是null，则直接抛出异常。它的数据结构：主要是<mark>数组+链表</mark>。</p>
<p>如果在非线程安全的情况下使用，建议使用HashMap替换，如果在线程安全的情况下使用，建议使用ConcurrentHashMap替换。</p>
<h3 id="4concurrenthashmap数据结构">4.ConcurrentHashMap数据结构</h3>
<p><a href="/post/java-bing-fa-san">ConcurrentHashMap数据结构</a></p>
<h3 id="5代理模式及动态代理详解">5.代理模式及动态代理详解</h3>
<p>代理模式的定义：为其他对象提供一种代理以控制对这个对象的访问。在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用。</p>
<p><code>静态代理</code><br>
代理对象与目标对象一起实现相同的接口或者继承相同父类，由程序员创建或特定工具自动生成源代码，即在编译时就已经确定了接口，目标类，代理类等。在程序运行之前，代理类的 .class 文件就已经生成。<br>
静态代理优缺点：<br>
优点：在不修改目标对象的功能前提下，可以对目标功能扩展。<br>
缺点：假如又有一个目标类，也要做增强，则还需要新增相对应的代理类，导致我们要手动编写很多代理类。同时，一旦接口增加方法，目标对象与代理对象都要维护。</p>
<p><code>动态代理</code><br>
代理类在程序运行时才创建的代理方式被称为动态代理。</p>
<ol>
<li>
<p>基于JDK原生动态代理实现<br>
JDK动态代理是基于反射机制，生成一个实现代理接口的匿名类，然后重写方法进行方法增强。在调用具体方法前通过调用 InvokeHandler 的 invoke 方法来处理。通过JDK源码分析其实是 Proxy 类的 newProxyInstance方法在运行时动态生成字节码生成代理类（缓存在Java虚拟机内存中），从而创建了一个动态代理对象。<br>
代理类继承了 Proxy 类，因为在Java中是单继承的，所以这就是为什么JDK动态代理中，目标对象一定要实现接口。<br>
它的特点是生成代理类速度很快，但是运行时调用方法操作会比较慢，因为是基于反射机制的，而且只能针对接口编程，即目标对象要实现接口。</p>
</li>
<li>
<p>CGLIB动态代理<br>
Cglib（Code Generation Library）是一个强大的，高性能，高质量的Code生成类库，它是开源的。动态代理是利用 asm 开源包，将目标对象类的 class 文件加载进来，然后修改其字节码生成新的子类来进行扩展处理。即可以在运行期扩展Java类和实现Java接口。<br>
Cglib动态代理注意的2点：</p>
</li>
</ol>
<ul>
<li>被代理类不能是 final 修饰的。</li>
<li>需要扩展的方法不能有 final 或 static 关键字修饰，不然不会被拦截，即执行方法只会执行目标对象的方法，不会执行方法扩展的内容。</li>
</ul>
<p>两种动态代理区别</p>
<ol>
<li>JDK动态代理是基于反射机制，生成一个实现代理接口的匿名类。而Cglib动态代理是基于继承机制，继承被代理类，底层是基于asm第三方框架对代理对象类的class文件加载进来,通过修改其字节码生成子类来处理。</li>
<li>JDK动态代理是生成类的速度快，后续执行类的方法操作慢；Cglib动态代理是生成类的速度慢，后续执行类的方法操作快。</li>
<li>JDK只能针对接口编程，Cglib可以针对类和接口。在Springboot项目中，在配置文件中增加 spring.aop.proxy-target-class=true 即可强制使用Cglib动态代理实现AOP。</li>
<li>如果目标对象实现了接口，默认情况下是采用JDK动态实现AOP，如果目标对象没有实现接口，必须采用CGLIB库动态实现AOP。</li>
</ol>
<h3 id="6进程-线程-协程">6.进程、线程、协程</h3>
<p><code>进程与线程</code><br>
进程是操作系统进行资源分配的基本单位，每个进程都有自己的独立内存空间。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。</p>
<p>线程又叫做轻量级进程，是进程的一个实体，是处理器任务调度和执行的基本单位位。它是比进程更小的能独立运行的基本单位。线程只拥有一点在运行中必不可少的资源(如程序计数器，一组寄存器和栈)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。</p>
<p>对于操作系统来说，一个任务就是一个进程（Process）。一个进程至少有一个线程，多个线程可以同时执行，多线程的执行方式和多进程是一样的，也是由操作系统在多个线程之间快速切换，让每个线程都短暂地交替运行，看起来就像同时执行一样。</p>
<p>线程进程的区别体现在6个方面：<br>
根本区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。<br>
资源开销：每个进程都有独立的代码和数据空间，程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一进程的线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器，线程之间切换的开销小。<br>
包含关系：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的。<br>
内存分配：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的。<br>
影响关系：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。<br>
执行过程：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。两者均可并发执行。</p>
<p><code>协程</code><br>
协程，又称微线程，是一种用户态的轻量级线程，协程的调度完全由用户控制（也就是在用户态执行）。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到线程的堆区，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。<br>
协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和线程切换相比，线程数量越多，协程的性能优势就越明显。不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。此外，一个线程的内存在MB级别，而协程只需要KB级别。</p>
<p>协程与线程的区别</p>
<ol>
<li>一个线程可以有多个协程。</li>
<li>大多数业务场景下，线程进程可以看做是同步机制，而协程则是异步。</li>
<li>线程是抢占式，而协程是非抢占式的，所以需要用户代码释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。</li>
<li>协程并不是取代线程，而且抽象于线程之上。线程是被分割的CPU资源, 协程是组织好的代码流程, 协程需要线程来承载运行。</li>
</ol>
<h3 id="7linux中java的线程模型">7.linux中，java的线程模型</h3>
<p>JVM 没有限定 Java 线程需要使用哪种线程模型来实现， JVM 只是封装了底层操作系统的差异，而不同的操作系统可能使用不同的线程模型，例如 Linux 和 windows 可能使用了一对一模型，solaris 和 unix 某些版本可能使用多对多模型。所以一谈到 Java 语言的多线程模型，需要针对具体 JVM 实现。</p>
<ol>
<li>使用用户线程实现（多对一模型 M:1）<br>
多个用户线程映射到一个内核线程，用户线程建立在用户空间的线程库上，用户线程的建立、同步、销毁和调度完全在用户态中完成，对内核透明。<br>
<img src="https://q456qq520.github.io/post-images/1675246200667.png" alt="" loading="lazy"><br>
优点：</li>
</ol>
<ol>
<li>线程的上下文切换都发生在用户空间，避免了模态切换（mode switch），减少了性能的开销。</li>
<li>用户线程的创建不受内核资源的限制，可以支持更大规模的线程数量。</li>
</ol>
<p>缺点：</p>
<ol>
<li>所有的线程基于一个内核调度实体即内核线程，这意味着只有一个处理器可以被利用，浪费了其它处理器资源，不支持并行，在多处理器环境下这是不能够被接受的，如果线程因为 I/O 操作陷入了内核态，内核态线程阻塞等待 I/O 数据，则所有的线程都将会被阻塞。</li>
<li>增加了复杂度，所有的线程操作都需要用户程序自己处理，而且在用户空间要想自己实现 “阻塞的时候把线程映射到其他处理器上” 异常困难</li>
</ol>
<ol start="2">
<li>使用内核线程实现（一对一模型 1:1）<br>
每个用户线程都映射到一个内核线程，每个线程都成为一个独立的调度单元，由内核调度器独立调度，一个线程的阻塞不会影响到其他线程，从而保障整个进程继续工作。<br>
<img src="https://q456qq520.github.io/post-images/1675246283087.png" alt="" loading="lazy"><br>
优点：</li>
</ol>
<ol>
<li>每个线程都成为一个独立的调度单元，使用内核提供的线程调度功能及处理器映射，可以完成线程的切换，并将线程的任务映射到其他处理器上，充分利用多核处理器的优势，实现真正的并行。</li>
</ol>
<p>缺点：</p>
<ol>
<li>每创建一个用户级线程都需要创建一个内核级线程与其对应，因此需要消耗一定的内核资源,而内核资源是有限的，所以能创建的线程数量也是有限的。</li>
<li>模态切换频繁，各种线程操作，如创建、析构及同步，都需要进行系统调用，需要频繁的在用户态和内核态之间切换，开销大。</li>
</ol>
<ol start="3">
<li>使用用户线程加轻量级进程混合实现（多对多模型 M:N）<br>
内核线程和用户线程的数量比为 M : N，这种模型需要内核线程调度器和用户空间线程调度器相互操作，本质上是多个线程被映射到了多个内核线程。<br>
<img src="https://q456qq520.github.io/post-images/1675246296511.png" alt="" loading="lazy"><br>
综合了前面两种模型的优点：</li>
</ol>
<ol>
<li>用户线程的创建、切换、析构及同步依然发生在用户空间，能创建数量更多的线程，支持更大规模的并发。</li>
<li>大部分的线程上下文切换都发生在用户空间，减少了模态切换带来的开销。</li>
<li>可以使用内核提供的线程调度功能及处理器映射，充分利用多核处理器的优势，实现真正的并行，并降低了整个进程被完全阻塞的风险。</li>
</ol>
<h3 id="8java线程状态-runnable-blockedtime_waitingwaiting">8.java线程状态, runnable、blocked，time_waiting，waiting</h3>
<p>1.NEW(创建)<br>
创建态：当一个已经被创建的线程处于未被启动时，即：还没有调用start方法时，就处于这个状态。</p>
<p>2.RUNNABLE(运行时)<br>
运行态：当线程已被占用，在Java虚拟机中正常执行时，就处于此状态。</p>
<p>3.BLOCKED(排队时)<br>
阻塞态：当一个线程试图获取一个对象锁，而该对象锁被其他的线程持有，则该线程进入Blocked状态。当该线程持有锁时，该线程将自动变成RUNNABLE状态。</p>
<p>4.WAITING(休眠)<br>
休眠态：一个线程在等待另一个线程执行一个(唤醒)动作时，该线程进入Waiting状态。进入这个状态后是不能自动唤醒的，必须等待另一个线程调用notify或者notifyAll方法才能够唤醒。</p>
<p>5.TIMED_WAITING (指定休眠时间)<br>
指定时间休眠态：基本同WAITING状态，多了个超时参数，调用对应方法时线程将进入TIMED_WAITING状态，这一状态将一直保持到超时期满或者接收到唤醒通知，带有超时参数的常用方法有Thread.sleep、锁对象.wait() 。</p>
<p>6.TERMINATED (结束)<br>
结束态：从RUNNABLE状态正常退出而死亡，或者因为没有捕获的异常终止了RUNNABLE状态而死亡。</p>
<h3 id="9线程池有哪些核心的参数">9.线程池有哪些核心的参数</h3>
<ol>
<li>
<p>核心线程数：corePoolSize<br>
线程池中活跃的线程数，即使它们是空闲的，除非设置了allowCoreThreadTimeOut为true。allowCoreThreadTimeOut的值是控制核心线程数是否在没有任务时是否停止活跃的线程，当它的值为true时，在线程池没有任务时，所有的工作线程都会停止。</p>
</li>
<li>
<p>最大线程数：maximumPoolSize<br>
线程池所允许存在的最大线程数。</p>
</li>
<li>
<p>多余线程存活时长：keepAliveTime<br>
线程池中除核心线程数之外的线程（多余线程）的最大存活时间，如果在这个时间范围内，多余线程没有任务需要执行，则多余线程就会停止。(注意：多余线程数 = 最大线程数 - 核心线程数)</p>
</li>
<li>
<p>时间单位：unit<br>
多余线程存活时间的单位，可以是分钟、秒、毫秒等。</p>
</li>
<li>
<p>任务队列：workQueue<br>
线程池的任务队列，使用线程池执行任务时，任务会先提交到这个队列中，然后工作线程取出任务进行执行，当这个队列满了，线程池就会执行拒绝策略。</p>
</li>
<li>
<p>线程工厂：threadFactory<br>
创建线程池的工厂，线程池将使用这个工厂来创建线程池，自定义线程工厂需要实现ThreadFactory接口。</p>
</li>
<li>
<p>拒绝执行处理器（也称拒绝策略）：handler<br>
当线程池无空闲线程，并且任务队列已满，此时将线程池将使用这个处理器来处理新提交的任务。</p>
</li>
</ol>
<h3 id="10线程池空闲的线程是如何回收">10.线程池空闲的线程是如何回收？</h3>
<p>超过corePoolSize的空闲线程由线程池回收，线程池Worker启动跑第一个任务之后就一直循环遍历线程池任务队列，超过指定超时时间获取不到任务就remove Worker，最后由垃圾回收器回收。</p>
<blockquote>
<p>Worker是线程池ThreadPoolExecutor的一个内部类，其有一个成员变量thread（线程），所以我们可以把一个Worker假以理解为一个线程。</p>
</blockquote>
<p>ThreadPoolExecutor回收工作线程，一条线程getTask()返回null，就会被回收。<br>
分两种场景。<br>
1、未调用shutdown() ，RUNNING状态下全部任务执行完成的场景<br>
线程数量大于corePoolSize，线程超时阻塞，超时唤醒后CAS减少工作线程数，如果CAS成功，返回null，线程回收。否则进入下一次循环。当工作者线程数量小于等于corePoolSize，就可以一直阻塞了。<br>
2、调用shutdown() ，全部任务执行完成的场景<br>
shutdown() 会向所有线程发出中断信号，这时有两种可能。<br>
2.1）所有线程都在阻塞<br>
中断唤醒，进入循环，都符合第一个if判断条件，都返回null，所有线程回收。<br>
2.2）任务还没有完全执行完<br>
至少会有一条线程被回收。在processWorkerExit(Worker w, boolean completedAbruptly)方法里会调用tryTerminate()，向任意空闲线程发出中断信号。所有被阻塞的线程，最终都会被一个个唤醒，回收。</p>
<h3 id="11java线程状态为-blocked-场景">11.java线程状态为 blocked 场景</h3>
<p>BLOCKED 状态跟 I/O 的阻塞是不同的，它不是一般意义上的阻塞，而是特指被 synchronized 块阻塞，即是跟线程同步有关的一个状态。</p>
<p>一旦一个线程获取锁进入同步块，在其出来之前，如果其它线程想进入，就会因为获取不到锁而阻塞在同步块之外，这时的状态就是 BLOCKED。</p>
<p>简单来说，大致有两种情况可以让线程处于这个状态。</p>
<ol>
<li>线程A想进入某个同步快，但是由于该同步锁被其他线程占用，所以自己只能等待该锁，此时线程A为BLOCKED状态。</li>
<li>线程A已经获取该锁，进入同步块，但调用了wait方法后释放了该锁，然后其他线程内执行了同一把锁对象的notify或者notifyAll后，此时线程A为BLOCKED状态。</li>
</ol>
<h3 id="12sleep-和-wait-区别">12.sleep 和 wait 区别</h3>
<p>sleep() 方法让当前线程停止运行一段时间，到期自动继续执行。<br>
wait() 方法让线程停止运行，在 notify() 或 notifyAll() 后继续执行。</p>
<p><mark>相同</mark></p>
<ol>
<li>sleep() 和 wait() 调用都会暂停当前线程并让出 CPU</li>
</ol>
<p><mark>不同</mark></p>
<ol>
<li>定义位置不同：sleep() 是线程类（Thread）的方法；wait() 是顶级类 Object 的方法；</li>
<li>调用地方不同：sleep 方法可以在任何地方使用；wait 方法则只能在同步方法或同步块中使用；</li>
<li>锁资源释放方式不同：sleep 方法只让出了CPU，没有释放同步资源锁！ wait方法则是指当前线程让自己暂时退让出同步资源锁，以便其他正在等待该资源的线程得到该资源进而运行，只有调用了notify方法，之前调用wait()的线程才会解除wait状态，可以去参与竞争同步资源锁，进而得到执行。</li>
<li>恢复方式不同：sleep调用后停止运行期间仍持有同步锁，所以到时间会继续执行；wait调用会放弃对象锁，进入等待队列，待调用notify()/notifyAll()唤醒指定的线程或者所有线程，才会进入锁池，再次获得对象锁后才会进入运行状态，在没有获取对象锁之前不会继续执行；</li>
<li>异常捕获：sleep需要捕获或者抛出异常，而wait/notify/notifyAll则不需要。</li>
</ol>
<h3 id="13reentrantlock-和-sychnozied-区别">13.reentrantLock 和 sychnozied 区别</h3>
<p>相似点：<br>
这两种同步方式有很多相似之处，它们都是加锁方式同步，而且都是阻塞式的同步，也就是说当如果一个线程获得了对象锁，进入了同步块，其他访问该同步块的线程都必须阻塞在同步块外面等待。</p>
<p>不同点：</p>
<ol>
<li>Synchronized是java语言的关键字，是原生语法层面的互斥，需要jvm实现。而ReentrantLock它是JDK 1.5之后提供的API层面的互斥锁，需要lock()和unlock()方法配合try/finally语句块来完成。</li>
<li>Synchronized等待不可中断，reentrantLock等待可中断。</li>
<li>synchronized的锁是非公平锁，ReentrantLock默认情况下也是非公平锁，但可以通过带布尔值的构造函数要求使用公平锁。</li>
<li>ReentrantLock可以同时绑定多个Condition对象，只需多次调用newCondition方法即可。<br>
synchronized中，锁对象的wait()和notify()或notifyAll()方法可以实现一个隐含的条件。但如果要和多于一个的条件关联的时候，就不得不额外添加一个锁。</li>
</ol>
<h3 id="14sychnozied-锁升级设计思想偏向锁轻量级重量级">14.sychnozied 锁升级设计思想，偏向锁，轻量级，重量级</h3>
<p>每个java对象都有一个对象头，对象头由类型指针和标记字段组成。在64位虚拟机中，未开启压缩指针，标记字段占64位，类型指针占64位，共计16个字节。markword是java对象数据结构中的一部分，markword数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，它的最后2bit是锁状态标志位，用来标记当前对象的状态，对象的所处的状态，决定了markword存储的内容，00表示轻量级锁，01表示无锁或偏向锁，10表示重量级锁。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1675325742033.png" alt="" loading="lazy"></figure>
<ol>
<li>检测Mark Word里面是不是当前线程的ID，如果是则表示当前线程处于偏向锁；</li>
<li>如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1；</li>
<li>如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁；</li>
<li>当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁；</li>
<li>如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁；</li>
<li>如果自旋成功则依然处于轻量级状态；</li>
<li>如果自旋失败，则升级为重量级锁；</li>
</ol>
<p>偏向锁是在无锁争用的情况下使用的，也就是同步开在当前线程没有执行完之前，没有其它线程会执行该同步块，一旦有了第二个线程的争用，偏向锁就会升级为轻量级锁，如果轻量级锁自旋到达阈值后，没有获取到锁，就会升级为重量级锁。</p>
<h3 id="15sychnozied-偏向锁是怎么撤销的">15.sychnozied 偏向锁是怎么撤销的</h3>
<p>偏向锁的撤销，需要等待全局安全点（safe point，代表了一个状态，在该状态下所有线程都是暂停的，stop-the-world，在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的会被执行，并升级为轻量级锁，最后唤醒暂停的线程。</p>
<h3 id="16threadlocals-使用场景实现原理">16.threadLocals 使用场景，实现原理</h3>
<p><code>场景一：代替参数的显式传递</code><br>
当我们在写API接口的时候，通常Controller层会接受来自前端的入参，当这个接口功能比较复杂的时候，可能我们调用的Service层内部还调用了 很多其他的很多方法，通常情况下，我们会在每个调用的方法上加上需要传递的参数。<br>
但是如果我们将参数存入ThreadLocal中，那么就不用显式的传递参数了，而是只需要ThreadLocal中获取即可。<br>
<code>场景二：全局存储用户信息</code><br>
我们会选择在拦截器的业务中， 获取到保存的用户信息，然后存入ThreadLocal，那么当前线程在任何地方如果需要拿到用户信息都可以使用ThreadLocal的get()方法 (异步程序中ThreadLocal是不可靠的)<br>
<code>场景三：解决线程安全问题</code><br>
在Spring的Web项目中，我们通常会将业务分为Controller层，Service层，Dao层， 由于Dao层使用单例，那么负责数据库连接的Connection也只有一个， 如果每个请求线程都去连接数据库，那么就会造成线程不安全的问题，当每个请求线程使用Connection的时候， 都会从ThreadLocal获取一次，如果为null，说明没有进行过数据库连接，连接后存入ThreadLocal中，如此一来，每一个请求线程都保存有一份 自己的Connection。</p>
<p>每一个线程都有一个对应的Thread对象，而Thread类有一个成员变量，它是一个Map集合，这个Map集合的key就是ThreadLocal的引用，而value就是当前线程在key所对应的ThreadLocal中存储的值。当某个线程需要获取存储在ThreadLocal变量中的值时，ThreadLocal底层会获取当前线程的Thread对象中的Map集合，然后以ThreadLocal作为key，从Map集合中查找value值。</p>
<p>参考：<a href="https://www.cnblogs.com/tuyang1129/p/12713815.html" title="深入分析ThreadLocal的实现原理">深入分析ThreadLocal的实现原理</a></p>
<h3 id="17synchronize-使用场景实现原理">17.synchronize 使用场景，实现原理</h3>
<p>Synchronized进过编译，会在同步块的前后分别形成monitorenter和monitorexit这个两个字节码指令。在执行monitorenter指令时，首先要尝试获取对象锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象锁，把锁的计算器加1，相应的，在执行monitorexit指令时会将锁计算器就减1，当计算器为0时，锁就被释放了。如果获取对象锁失败，那当前线程就要阻塞，直到对象锁被另一个线程释放为止。</p>
<blockquote>
<p>monitorenter和monitorexit指令的底层是lock和unlock指令。</p>
</blockquote>
<h3 id="18wait-notify-使用场景实现原理">18.wait、notify 使用场景，实现原理</h3>
<p>Monitor（管程）的结构，其中有一块叫做waitSet的区域，里面存放的是状态为WAITING状态的线程。如下图虚线框中的内容：<br>
<img src="https://q456qq520.github.io/post-images/1675329321527.png" alt="" loading="lazy"></p>
<p>调用wait方法，首先会获取监视器锁，获得成功以后，会让当前线程进入等待状态进入等待队列并且释放锁；然后 当其他线程调用notify或者notifyall以后，会选择从等待队列中唤醒任意一个线程，而执行完notify方法以后，并不会立马唤醒线程，原因是当前的线程仍然持有这把锁，处于等待状态的线程无法获得锁。必须要等到当前的线程执行完按monitorexit指令以后，也就是锁被释放以后，处于等待队列中的线程就可以开始竞争锁了。</p>
<h3 id="19join-使用场景实现原理">19.join 使用场景，实现原理</h3>
<p>join()是Thread类的一个方法，等待该线程终止. 需要明确的是主线程等待子线程(假设有个子线程thread)的终止。即在主线程的代码块中，如果碰到了thread.join()方法，此时主线程需要等子线程thread结束了(Waits for this thread to die.),才能继续执行thread.join()之后的代码块。</p>
<pre><code class="language-java">public final void join() throws InterruptedException {
    join(0);
}

public final synchronized void join(long millis)
throws InterruptedException {
    long base = System.currentTimeMillis();
    long now = 0;

    if (millis &lt; 0) {
        throw new IllegalArgumentException(&quot;timeout value is negative&quot;);
    }

    if (millis == 0) {
        while (isAlive()) {
            wait(0);
        }
    } else {
        while (isAlive()) {
            long delay = millis - now;
            if (delay &lt;= 0) {
                break;
            }
            wait(delay);
            now = System.currentTimeMillis() - base;
        }
    }
}
</code></pre>
<p>当子线程执行结束的时候，jvm会自动唤醒阻塞主线程。</p>
<h3 id="20interrupted-使用场景实现原理">20.interrupted 使用场景，实现原理</h3>
<p>java interrupt中断机制是当主线程向目标线程发起interrupt中断命令后，目标线程的中断标志位被置为true，目标线程通过查询中断标志位自行决定是否停止当前线程的执行。</p>
<pre><code class="language-java">public void interrupt() {
    if (this != Thread.currentThread())
        checkAccess();

    synchronized (blockerLock) {
        Interruptible b = blocker;
        if (b != null) {
            //打断的主要方法，该方法的主要作用是设置一个打断标记
            interrupt0();
            b.interrupt(this);
            return;
        }
    }
    interrupt0();
}
</code></pre>
<p>interrupted()是静态方法而isInterrupted()是实例方法，他们的实现都是调用同一个native方法。主要的区别是他们的形参ClearInterrupted传的不一样。interrupted()在返回中断标志位后会清除标志位，isInterrupted()则不清除中断标志位。</p>
<pre><code class="language-java">public static boolean interrupted() {
    return currentThread().isInterrupted(true);
}

public boolean isInterrupted() {
    return isInterrupted(false);
}

private native boolean isInterrupted(boolean ClearInterrupted);
</code></pre>
<p><code>使用场景</code></p>
<ol>
<li>ThreadPoolExecutor中的 shutdownNow 方法会遍历线程池中的工作线程并调用线程的 interrupt 方法来中断线程。</li>
<li>FutureTask 中的 cancel 方法，如果传入的参数为 true，它将会在正在运行异步任务的线程上调用 interrupt 方法，如果正在执行的异步任务中的代码没有对中断做出响应，那么 cancel 方法中的参数将不会起到什么效果。</li>
</ol>
<h3 id="21volatile-使用场景实现原理">21.volatile 使用场景，实现原理</h3>
<p>volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令，lock前缀指令实际上相当于一个内存屏障（也成内存栅栏) ，内存屏障会提供3个功能：</p>
<ul>
<li>它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；</li>
<li>它会强制将对缓存的修改操作立即写入主存；（每个线程都有自己的工作内存）</li>
<li>如果是写操作，它会导致其他CPU中对应的缓存行无效。</li>
</ul>
<h3 id="22指令重排序可以解决什么问题">22.指令重排序可以解决什么问题</h3>
<p>为了使处理器内部的运算单元能尽量被充分利用，处理器可能会对输入的代码进行乱序执行优化，处理器会在计算之后将乱序执行的结果重组，并确保这一结果和顺序执行结果是一致的，但是这个过程并不保证各个语句计算的先后顺序和输入代码中的顺序一致。这就是指令重排序。</p>
<ol>
<li>
<p>编译器优化<br>
编译器（包括 JVM、JIT 编译器等）出于优化的目的，例如当前有了数据 a，把对 a 的操作放到一起效率会更高，避免读取 b 后又返回来重新读取 a 的时间开销，此时在编译的过程中会进行一定程度的重排。不过重排序并不意味着可以任意排序，它需要需要保证重排序后，不改变单线程内的语义，否则如果能任意排序的话，程序早就逻辑混乱了。</p>
</li>
<li>
<p>CPU 重排序<br>
CPU 同样会有优化行为，这里的优化和编译器优化类似，都是通过乱序执行的技术来提高整体的执行效率。所以即使之前编译器不发生重排，CPU 也可能进行重排，我们在开发中，一定要考虑到重排序带来的后果。</p>
</li>
<li>
<p>内存的“重排序”<br>
内存系统内不存在真正的重排序，但是内存会带来看上去和重排序一样的效果，所以这里的“重排序”打了双引号。由于内存有缓存的存在，在 JMM 里表现为主存和本地内存，而主存和本地内存的内容可能不一致，所以这也会导致程序表现出乱序的行为。</p>
</li>
</ol>
<p>重排序通过减少执行指令，从而提高整体的运行速度。</p>
<h3 id="23volatile-指令重排序可见性">23.volatile 指令重排序，可见性</h3>
<p>可见性： volatile的功能就是被修饰的变量在被修改后可以立即同步到主内存，被修饰的变量在每次是用之前都从主内存刷新。本质也是通过内存屏障来实现可见性 写内存屏障（Store Memory Barrier）可以促使处理器将当前store buffer（存储缓存）的值写回主存。读内存屏障（Load Memory Barrier）可以促使处理器处理invalidate queue（失效队列）。进而避免由于Store Buffer和Invalidate Queue的非实时性带来的问题。</p>
<p>禁止指令重排序： volatile是通过内存屏障来禁止指令重排序</p>
<pre><code class="language-java">public class Singleton {
	//volatile是防止指令重排
    private static volatile Singleton singleton;
    // 无参构造
    private Singleton() {}
    public static Singleton getInstance() {
        //第一层判断singleton是不是为null
        //如果不为null直接返回，这样就不必加锁了
        if (singleton == null) {
            //现在再加锁
            synchronized (Singleton.class){
                //第二层判断
                //如果A,B两个线程都在synchronized等待
                //A创建完对象之后，B还会再进入，如果不再检查一遍，B又会创建一个对象
                if (singleton == null) {
                    /*volatile主要是防止这里：
                    下面字节码会生成三个操作：
                    一是为Singleton对象在堆中分配空间
                    二是执行Singleton的构造函数
                    三是将新生成的Singleton对象的引用赋给singleton字段
                    而在重排序之后，上面的顺序有可能变成 一、三、二，那么这对象是残缺不全的--半对象
                    于是，在多线程情况下，别的线程可能会访问到一个singleton不为null却没有执行完构造函数的无效引用
                    */
                    singleton = new Singleton();
                }
            }
        }
        return singleton;
    }
}
</code></pre>
<h3 id="24cas-使用场景aba的问题如何解决">24.cas 使用场景，aba的问题如何解决</h3>
<h3 id="25aqs-是什么数据结构volatilecaslocksupportunparkunpark">25.aqs 是什么数据结构，volatile，cas，LockSupport.unpark/unpark</h3>
<h3 id="26伪共享问题是如何发生的">26.伪共享问题是如何发生的</h3>
<p>缓存系统中的缓存是以缓存行（cache line）为单位存储的，Cache Line 是 CPU 和主存之间数据传输的最小单位，缓存行通常是 64 字节。当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，因为都会导致同一个缓存行失效而会无意中影响彼此的性能，这就是伪共享（false sharing）。</p>
<p>为了避免由于 false sharing 导致 Cache Line 从 L1,L2,L3 到主存之间重复载入，我们可以使用数据填充追加字节的方式来避免，即单个数据填充满一个CacheLine，该方法本质上是一种空间换时间的做法。<br>
JDK 8开始,提供了一个sun.misc.Contended 注解，用来解决伪共享问题，加上这个注解的类会自动补齐缓存行。</p>
<h3 id="27disruptor-使用场景数据结构优势">27.Disruptor 使用场景，数据结构，优势</h3>
<h2 id="二-计算机网络">二 计算机网络</h2>
<h3 id="1-网络分层思想链路层网络层传输层应用层">1. 网络分层思想，链路层，网络层，传输层，应用层</h3>
<p>1）物理层<br>
该层负责比特流在节点间的传输，即负责物理传输。该层的协议既与链路有关，业余传输介质有关。通俗来讲就是把计算机连接起来的物理手段。<br>
2）数据链路层<br>
该层控制网络层与物理层之间的通信，其主要功能是如何在不可靠的物理线路上进行数据的可靠传递。为了保证传输，从网络层接收到的数据被分割成特定的可被物理层传输的帧。帧是用来移动数据的结构包，它不仅包括原始数据，还包括发送方和接收方的物理地址以及纠错和控制信息。其中的地址确定了帧将发送到何处，而纠错和控制信息则确保帧无差错到达。如果在传送数据时，接收点检测到所传数据中有差错，就要通知发送方重发这一帧。<br>
3）网络层<br>
该层决定如何将数据从发送方路由到接收方。网络层通过综合考虑发送优先权、网络拥塞程度、服务质量以及可选路由的花费来决定从一个网络中的节点 A 到另一个网络中节点 B 的最佳路径。<br>
4）传输层<br>
该层为两台主机上的应用程序提供端到端的通信。相比之下，网络层的功能是建立主机到主机的通<br>
信。传输层有两个传输协议：TCP（传输控制协议）和UDP（用户数据报协议）。其中，TCP是一个可靠的面向连接的协议，UDP是不可靠的或者说无连接的协议。<br>
5）应用层<br>
应用程序收到传输层的数据后，接下来就要进行解读。解读必须事先规定好格式，而应用层就是规定应用程序的数据格式的。它的主要协议有HTTP、FTP、Telnet、SMTP、POP3等。</p>
<h3 id="2-交换机是在链路层工作mac层协议中mtu-最大传输单元">2. 交换机是在链路层工作，MAC层协议中，MTU 最大传输单元</h3>
<h3 id="3-路由器是在网络层工作ip层协议中ttlip分片">3. 路由器是在网络层工作，IP层协议中，TTL，IP分片</h3>
<h3 id="4-udp是传输层协议有哪些使用场景">4. UDP是传输层协议，有哪些使用场景</h3>
<p>UDP是无连接的，不可靠传输，尽最大努力交付数据，协议简单、资源要求少、传输速度快、实时性高的特点，适用于对传输效率要求高，但准确率要求低的应用场景，比如域名转换(DNS)、远程文件服务器(NFS)等。</p>
<h3 id="5-udp需要三次握手吗">5. UDP需要三次握手吗？</h3>
<h3 id="6三次握手原理为什么不是两次挥手为什么是4次">6.三次握手原理，为什么不是两次，挥手为什么是4次</h3>
<p>答：建立连接的过程是利用客户服务器模式，假设主机A为客户端，主机B为服务器端。</p>
<p>（1）TCP的三次握手过程：主机A向B发送连接请求；主机B对收到的主机A的报文段进行确认；主机A再次对主机B的确认进行确认。<br>
（2）采用三次握手是为了防止失效的连接请求报文段突然又传送到主机B，因而产生错误。失效的连接请求报文段是指：主机A发出的连接请求没有收到主机B的确认，于是经过一段时间后，主机A又重新向主机B发送连接请求，且建立成功，顺序完成数据传输。考虑这样一种特殊情况，主机A第一次发送的连接请求并没有丢失，而是因为网络节点导致延迟达到主机B，主机B以为是主机A又发起的新连接，于是主机B同意连接，并向主机A发回确认，但是此时主机A根本不会理会，主机B就一直在等待主机A发送数据，导致主机B的资源浪费。<br>
（3）如果不采用三次握手，我们考虑以下场景：<br>
采用一次握手：<br>
首先A发送一个(SYN)到B，意思是A要和B建立连接进行通信；<br>
如果是只有一次握手的话，这样肯定是不行的，A压根都不知道B是不是收到了这个请求。<br>
采用二次握手：<br>
B收到A要建立连接的请求之后，发送一个确认(SYN+ACK)给A，意思是收到A的消息了，B这里也是通的，表示可以建立连接；<br>
如果只有两次通信的话，这时候B不确定A是否收到了确认消息，有可能这个确认消息由于某些原因丢了。<br>
采用三次握手：<br>
A如果收到了B的确认消息之后，再发出一个确认(ACK)消息，意思是告诉B，这边是通的，然后A和B就可以建立连接相互通信了；<br>
这个时候经过了三次握手，A和B双方确认了两边都是通的，可以相互通信了，已经可以建立一个可靠的连接，并且可以相互发送数据。</p>
<p>因为TCP有个半关闭状态，假设A.B要释放连接，那么A发送一个释放连接报文给B，B收到后发送确认，这个时候A不发数据，但是B如果发数据A还是要接收，这叫半关闭。然后B还要发给A连接释放报文，然后A发确认，所以是4次。</p>
<h3 id="7tcp数据结构关键字段序号滑动窗口">7.TCP数据结构关键字段：序号，滑动窗口</h3>
<p><code>Sequence Number（序列号）</code>：占 4 个字节，范围是[0， 232 - 1]，序号增加到 232 - 1 后，下一个序号就又回到 0。在 TCP 连接中传送的字节流中的每一个字节都要按顺序编号，起始序号在连接建立时就完成设置。因此序列号可以用来解决网络包乱序（reordering）问题。</p>
<p>例如，一个报文段的序号是 301，而携带的数据共有 100 个字节。这就表明：本报文段的数据的第一个字节的序号是 301，最后一个字节的序号是 400。显然下一个报文段的数据序号要从 401 开始。</p>
<p><code>Window（窗口）</code>：占 2 个字节，窗口值是一个 [0， 216 - 1] 之间的整数。窗口指的是发送本报文段的一方的接收窗口（而不是自己的发送窗口）。窗口值用于告诉对方：从本报文段首部中的确认号算起，接受方目前允许对方发送的数据量（以字节为单位）。之所以要有这个限制，是因为接受方的数据空间是有限的。</p>
<p>例如：发送了一个报文段，其确认号是 701，窗口字段值为 1000。这就告诉对方：“从 701 序号开始算起，我（发送此报文段的一方）的接收缓存空间还可以接收 1000 个字节数据，字节序号是 701 - 1700，你在给我发送数据时，必须要考虑到这一点”。窗口字段值明确的指出了现在允许对方发送的数据量，窗口值通常是在不断的动态变化着。</p>
<h3 id="8tcp相对udp有哪些优点顺序发送超时重试流量控制拥塞控制">8.TCP相对UDP有哪些优点：顺序发送，超时重试，流量控制，拥塞控制</h3>
<h3 id="9tcp顺序发送如何解决顺序发送问题-自增序号三次握手确定序号">9.TCP顺序发送：如何解决顺序发送问题? 自增序号，三次握手确定序号</h3>
<h3 id="10tcp超时重试有哪些重试的方法-快速重传接受地图">10.TCP超时重试：有哪些重试的方法? 快速重传，接受地图</h3>
<h3 id="11tcp拥塞控制如何解决拥塞问题">11.TCP拥塞控制：如何解决拥塞问题</h3>
<h3 id="12tcp粘包拆包是如何发生的">12.TCP：粘包/拆包是如何发生的</h3>
<p>粘包：两个包较小，间隔时间短，发生粘包，合并成一个包发送；<br>
拆包：一个包过大，超过缓存区大小，拆分成两个或多个包发送；<br>
拆包和粘包：Packet1过大，进行了拆包处理，而拆出去的一部分又与Packet2进行粘包处理。</p>
<p>对于粘包和拆包问题，常见的解决方案有四种：</p>
<ol>
<li>发送端将每个包都封装成固定的长度，比如100字节大小。如果不足100字节可通过补0或空等进行填充到指定长度；</li>
<li>发送端在每个包的末尾使用固定的分隔符，例如\r\n。如果发生拆包需等待多个包发送过来之后再找到其中的\r\n进行合并；例如，FTP协议；</li>
<li>将消息分为头部和消息体，头部中保存整个消息的长度，只有读取到足够长度的消息之后才算是读到了一个完整的消息；</li>
<li>通过自定义协议进行粘包和拆包的处理。</li>
</ol>
<h3 id="13dns是如何工作的本地电脑发起一个百度的请求">13.DNS是如何工作的，本地电脑发起一个百度的请求</h3>
<h3 id="14linux操作系统的用户态和内核态">14.Linux操作系统的，用户态和内核态</h3>
<h3 id="15零拷贝怎么理解mmap-sendfile-虚拟内存">15.零拷贝怎么理解，mmap、sendfile。虚拟内存</h3>
<h3 id="16dma是什么">16.DMA是什么</h3>
<h3 id="17io多路复用主要解决什么问题">17.IO多路复用主要解决什么问题？</h3>
<p><code>同步阻塞（BIO）：</code><br>
服务端采用单线程，当 accept 一个请求后，在 recv 或 send 调用阻塞时，将无法 accept 其他请求（必须等上一个请求处理 recv 或 send 完 ）（无法处理并发）<br>
服务端采用多线程，当 accept 一个请求后，开启线程进行 recv，可以完成并发处理，但随着请求数增加需要增加系统线程，大量的线程占用很大的内存空间，并且线程切换会带来很大的开销，10000个线程真正发生读写实际的线程数不会超过20%，每次accept都开一个线程也是一种资源浪费。</p>
<p><code>同步非阻塞（NIO）：</code><br>
服务器端当 accept 一个请求后，加入 fds 集合，每次轮询一遍 fds 集合 recv (非阻塞)数据，没有数据则立即返回错误，每次轮询所有 fd （包括没有发生读写实际的 fd）会很浪费 CPU。</p>
<p><code>IO多路复用：</code><br>
服务器端采用单线程通过 select/poll/epoll 等系统调用获取 fd 列表，遍历有事件的 fd 进行 accept/recv/send ，使其能支持更多的并发连接请求。</p>
<h3 id="18io多路复用epoll原理等待队列红黑树就绪队列">18.IO多路复用，EPOLL原理，等待队列，红黑树，就绪队列</h3>
<p>epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是**事件驱动（每个事件关联上fd）**的，此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)）。</p>
<p><code>epoll函数接口</code><br>
当某一进程调用epoll_create方法时，Linux内核会创建一个eventpoll结构体，这个结构体中有两个成员与epoll的使用方式密切相关。eventpoll结构体如下所示：</p>
<pre><code class="language-c">#include &lt;sys/epoll.h&gt;

// 数据结构
// 每一个epoll对象都有一个独立的eventpoll结构体
// 用于存放通过epoll_ctl方法向epoll对象中添加进来的事件
// epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可
struct eventpoll {
    /*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*/
    struct rb_root  rbr;
    /*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*/
    struct list_head rdlist;
};

// API
int epoll_create(int size); // 内核中间加一个 ep 对象，把所有需要监听的 socket 都放到 ep 对象中
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // epoll_ctl 负责把 socket 增加、删除到内核红黑树
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);// epoll_wait 负责检测可读队列，没有可读 socket 则阻塞进程
</code></pre>
<p>每一个epoll对象都有一个独立的eventpoll结构体，用于存放通过epoll_ctl方法向epoll对象中添加进来的事件。这些事件都会挂载在红黑树中，如此，重复添加的事件就可以通过红黑树而高效的识别出来(红黑树的插入时间效率是lgn，其中n为红黑树元素个数)。<br>
而所有添加到epoll中的事件都会与设备(网卡)驱动程序建立回调关系，也就是说，当相应的事件发生时会调用这个回调方法。这个回调方法在内核中叫ep_poll_callback,它会将发生的事件添加到rdlist双链表中。<br>
在epoll中，对于每一个事件，都会建立一个epitem结构体，如下所示：</p>
<pre><code class="language-c">struct epitem{
    struct rb_node  rbn;//红黑树节点
    struct list_head    rdllink;//双向链表节点
    struct epoll_filefd  ffd;  //事件句柄信息
    struct eventpoll *ep;    //指向其所属的eventpoll对象
    struct epoll_event event; //期待发生的事件类型
}
</code></pre>
<p>当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。</p>
<p>从上面的讲解可知：通过红黑树和双链表数据结构，并结合回调机制，造就了epoll的高效。<br>
讲解完了Epoll的机理，我们便能很容易掌握epoll的用法了。一句话描述就是：三步曲。</p>
<p>第一步：epoll_create()系统调用。此调用返回一个句柄，之后所有的使用都依靠这个句柄来标识。<br>
第二步：epoll_ctl()系统调用。通过此调用向epoll对象中添加、删除、修改感兴趣的事件，返回0标识成功，返回-1表示失败。<br>
第三部：epoll_wait()系统调用。通过此调用收集收集在epoll监控中已经发生的事件。</p>
<h3 id="19https是如何工作的">19.HTTPS是如何工作的</h3>
<h3 id="20http20有哪些升级合并请求头多路复用主动推送">20.HTTP2.0有哪些升级？合并请求头，多路复用，主动推送</h3>
<h3 id="21-rpc和http的区别使用用场景">21. rpc和http的区别，使⽤用场景?</h3>
<ol>
<li>区别: 传输协议<br>
RPC，可以基于TCP协议，也可以基于HTTP协议<br>
HTTP，基于HTTP协议</li>
<li>传输效率<br>
RPC，使⽤用⾃自定义的TCP协议，可以让请求报⽂文体积更更⼩小，或者使⽤用HTTP2协议，也可以很好的减少报⽂文的体积，提⾼传输效率<br>
HTTP，如果是基于HTTP1.1的协议，请求中会包含很多⽆无⽤用的内容，如果是基于HTTP2.0，那么简单的封装以下是可以作为⼀个RPC来使⽤用的，这时标准RPC框架更更多的是服务治理理</li>
<li>性能消耗，主要在于序列列化和反序列列化的耗时<br>
RPC，可以基于thrift实现⾼高效的⼆进制传输<br>
HTTP，⼤大部分是通过json来实现的，字节⼤大⼩小和序列列化耗时都⽐比thrift要更消耗性能</li>
<li>负载均衡<br>
RPC，基本都⾃自带了了负载均衡策略略<br>
HTTP，需要配置Nginx，HAProxy来实现</li>
<li>服务治理理(下游服务新增，重启，下线时如何不不影响上游调⽤用者)</li>
<li>RPC，能做到⾃自动通知，不不影响上游</li>
<li>HTTP，需要事先通知，修改Nginx/HAProxy配置</li>
</ol>
<p>总结:RPC主要⽤用于公司内部的服务调⽤用，性能消耗低，传输效率⾼高，服务治理理⽅方便便。HTTP主要⽤用于对外的异构环境，浏览器器接⼝口调⽤用，APP接⼝口调⽤用，第三⽅方接⼝口调⽤用等。</p>
<h2 id="三-jvm">三 JVM</h2>
<h3 id="1class二进制文件前面几位魔术是什么">1.class二进制文件，前面几位魔术是什么？</h3>
<p>每个Class文件的头4个字节称为魔数（Magic Number），它的唯一作用是确定这个文件是否为一个能被虚拟机接受的Class文件。之所以使用魔数而不是文件后缀名来进行识别主要是基于安全性的考虑，因为文件后缀名是可以随意更改的（当然魔术也可以改，只不过比起改后缀名来说更复杂）。<br>
Class 文件的魔数值固定为「0xCAFEBABE」。</p>
<h3 id="2多态是如何实现的invokevirtualinvokeinterface">2.多态是如何实现的，invokevirtual，invokeInterface</h3>
<p>C++中只有直接调用、间接调用，而JVM通过不同的invoke指令来实现不同属性的方法调用。<br>
那什么是多态呢，满足下面这几个条件就可以称为多态：<br>
1、继承了某个类、实现了某个接口<br>
2、重写父类的方法、实现接口中的方法<br>
3、父类引用指向子类对象</p>
<p>C++中的间接调用与直接调用，JVM抽象成了4个指令来完成：<br>
1、invokevirtual：invokevirtual指令用于调用声明为类的方法；这个指令用于调用public、protected修饰，且不被static、final修饰的方法。跟多态机制有关。<br>
2、invokeinterface：invokeinterface指令用于调用声明为接口的方法；跟invokevirtual差不多。区别是多态调用时，如果父类引用是对象，就用invokevirtual。如果父类引用是接口，就用这个。<br>
3、invokespecial：只用于调用私有方法，构造方法。跟多态无关<br>
4、invokestatic：调用静态方法；</p>
<p>以 invokevirtual 指令为例，在执行时，大致可以分为以下几步：<br>
1、先从操作栈中找到对象的实际类型 class；<br>
2、找到 class 中与被调用方法签名相同的方法，如果有访问权限就返回这个方法的直接引用，如果没有访问权限就报错 java.lang.IllegalAccessError ；<br>
3、如果第 2 步找不到相符的方法，就去搜索 class 的父类，按照继承关系自下而上依次执行第 2 步的操作；<br>
4、如果第 3 步找不到相符的方法，就报错 java.lang.AbstractMethodError ；<br>
可以看到，如果子类覆盖了父类的方法，则在多态调用中，动态绑定过程会首先确定实际类型是子类，从而先搜索到子类中的方法。这个过程便是方法覆盖的本质。</p>
<h3 id="3类加载器有哪些类型">3.类加载器有哪些类型？</h3>
<p>VM支持两种类型的类加载器 。分别为引导类加载器（Bootstrap ClassLoader）和自定义类加载器（User-Defined ClassLoader）。从概念上来讲，自定义类加载器一般指的是程序中由开发人员自定义的一类类加载器，但是Java虚拟机规范却没有这么定义，而是将所有派生于抽象类ClassLoader的类加载器都划分为自定义类加载器</p>
<ol>
<li>启动类加载器（引导类加载器，Bootstrap ClassLoader）</li>
</ol>
<ul>
<li>这个类加载使用C/C++语言实现的，嵌套在JVM内部。</li>
<li>它用来加载Java的核心库（JAVA_HOME/jre/lib/rt.jar、resources.jar或sun.boot.class.path路径下的内容），用于提供JVM自身需要的类。</li>
<li>并不继承自java.lang.ClassLoader，没有父加载器。</li>
<li>加载扩展类和应用程序类加载器，并作为他们的父类加载器（当他俩的爹）。</li>
<li>出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类。</li>
</ul>
<ol start="2">
<li>扩展类加载器（Extension ClassLoader）</li>
</ol>
<ul>
<li>java语言编写，由sun.misc.Launcher$ExtClassLoader实现。</li>
<li>派生于ClassLoader类。</li>
<li>父类加载器为启动类加载器。</li>
<li>从java.ext.dirs系统属性所指定的目录中加载类库，或从JDK的安装目录的jre/lib/ext子目录（扩展目录）下加载类库。如果用户创建的JAR放在此目录下，也会自动由扩展类加载器加载。</li>
</ul>
<ol start="3">
<li>应用程序类加载器（系统类加载器，AppClassLoader）</li>
</ol>
<ul>
<li>Java语言编写，由sun.misc.LaunchersAppClassLoader实现。</li>
<li>派生于ClassLoader类。</li>
<li>父类加载器为扩展类加载器。</li>
<li>它负责加载环境变量classpath或系统属性java.class.path指定路径下的类库。</li>
<li>该类加载是程序中默认的类加载器，一般来说，Java应用的类都是由它来完成加载。</li>
<li>通过classLoader.getSystemclassLoader()方法可以获取到该类加载器。</li>
</ul>
<ol start="4">
<li>用户自定义加载器</li>
</ol>
<h3 id="4类的加载过程">4.类的加载过程</h3>
<p>类加载的过程主要分为三个部分：加载、链接、初始化。<br>
而链接又可以细分为三个小部分：验证、准备、解析。<br>
<code>加载</code><br>
简单来说，加载指的是把class字节码文件从各个来源通过类加载器装载入内存中。这里有两个重点：</p>
<ol>
<li>字节码来源。一般的加载来源包括从本地路径下编译生成的.class文件，从jar包中的.class文件，从远程网络，以及动态代理实时编译。</li>
<li>类加载器。一般包括启动类加载器，扩展类加载器，应用类加载器以及用户的自定义类加载器。</li>
</ol>
<p><strong>加载的3个阶段</strong></p>
<ol>
<li>通过类的全限定名获取二进制字节流（将 .class 文件读进内存）；</li>
<li>将字节流的静态存储结构转化为运行时的数据结构；</li>
<li>在内存中生成该类的 Class 对象；HotSpot 虚拟机把这个对象放在方法区，非 Java 堆。</li>
</ol>
<p><code>验证</code><br>
主要是为了保证加载进来的字节流符合虚拟机规范，不会造成安全错误。<br>
包括对于文件格式的验证，比如常量中是否有不被支持的常量？是否符合 Class 文件格式规范，验证文件开头 4 个字节是不是 “魔数” 0xCAFEBABE？文件中是否有不规范的或者附加的其他信息？<br>
对于元数据的验证，比如该类是否继承了被final修饰的类？类中的字段，方法是否与父类冲突？是否出现了不合理的重载？<br>
对于字节码的验证，保证程序语义的合理性，比如要保证类型转换的合理性。<br>
对于符号引用的验证，比如校验符号引用中通过全限定名是否能够找到对应的类？校验符号引用中的访问性（private，public等）是否可被当前类访问？</p>
<p><code>准备</code><br>
主要是为类变量（注意，不是实例变量）分配内存，并且赋予初值。<br>
特别需要注意，初值，不是代码中具体写的初始化的值，而是 Java 虚拟机根据不同变量类型的默认初始值。<br>
比如 8 种基本类型的初值，默认为 0；引用类型的初值则为null；常量的初值即为代码中设置的值，例如final static tmp = 456， 那么该阶段 456 就是tmp的初值。</p>
<p><code>解析</code><br>
将常量池内的符号引用替换为直接引用的过程。两个重点：</p>
<ol>
<li>符号引用。即一个字符串，但是这个字符串给出了一些能够唯一性识别一个方法，一个变量，一个类的相关信息。</li>
<li>直接引用。可以理解为一个内存地址，或者一个偏移量。比如类方法，类变量的直接引用是指向方法区的指针；而实例方法，实例变量的直接引用则是从实例的头指针开始算起到这个实例变量位置的偏移量。<br>
举个例子来说，现在调用方法hello()，这个方法的地址是1234567，那么hello就是符号引用，1234567就是直接引用。在解析阶段，虚拟机会把所有的类名，方法名，字段名这些符号引用替换为具体的内存地址或偏移量，也就是直接引用。</li>
</ol>
<p><code>初始化</code><br>
这个阶段主要是对类变量初始化，是执行类构造器的过程。换句话说，只对static修饰的变量或语句进行初始化。如果初始化一个类的时候，其父类尚未初始化，则优先初始化其父类。如果同时包含多个静态变量和静态代码块，则按照自上而下的顺序依次执行。</p>
<h3 id="5双亲委派机制作用是什么为什么又要打破">5.双亲委派机制，作用是什么，为什么又要打破</h3>
<ol>
<li>如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行。</li>
<li>如果父类的加载器还存在其父类加载器，则进一步向上委托，依次递归请求最终达到顶层的启动类加载器。</li>
<li>如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派机制。</li>
</ol>
<p><mark>优点</mark></p>
<ul>
<li>避免类的重复加载</li>
<li>保护程序安全，防止核心API被随意篡改</li>
</ul>
<p>为什么要打破呢？因为类加载器受到加载范围的限制，在某些情况下父类加载器无法加载到需要的文件，这时候就需要委托子类加载器去加载class文件。自定义类加载器加载一个类需要：继承ClassLoader，重写findClass，如果不想打破双亲委派模型，那么只需要重写findClass；如果想打破双亲委派模型，那么就重写整个loadClass方法，设定自己的类加载逻辑。</p>
<h3 id="6jvm内存是如何划分的堆栈方法区直接内存">6.JVM内存是如何划分的，堆，栈，方法区，直接内存</h3>
<ol>
<li><code>程序计数器</code><br>
程序计数器（Program Counter Register），也有称作为PC寄存器。虽然JVM中的程序计数器并不像汇编语言中的程序计数器一样是物理概念上的CPU寄存器，但是JVM中的程序计数器的功能跟汇编语言中的程序计数器的功能在逻辑上是等同的，也就是说是用来指示执行哪条指令的。</li>
</ol>
<p>由于在JVM中，多线程是通过线程轮流切换来获得CPU执行时间的，因此，在任一具体时刻，一个CPU的内核只会执行一条线程中的指令，因此，为了能够使得每个线程都在线程切换后能够恢复在切换之前的程序执行位置，每个线程都需要有自己独立的程序计数器，并且不能互相**扰，否则就会影响到程序的正常执行次序。因此，可以这么说，程序计数器是每个线程所私有的。</p>
<p>在JVM规范中规定，如果线程执行的是非native方法，则程序计数器中保存的是当前需要执行的指令的地址；如果线程执行的是native方法，则程序计数器中的值是undefined。</p>
<p>由于程序计数器中存储的数据所占空间的大小不会随程序的执行而发生改变，因此，对于程序计数器是不会发生内存溢出现象(OutOfMemory)的。</p>
<ol start="2">
<li><code>Java栈</code><br>
Java栈也称作虚拟机栈（Java Vitual Machine Stack），也就是我们常常所说的栈，跟C语言的数据段中的栈类似。事实上，Java栈是Java方法执行的内存模型。为什么这么说呢？下面就来解释一下其中的原因。</li>
</ol>
<p>Java栈中存放的是一个个的栈帧，每个栈帧对应一个被调用的方法，在栈帧中包括局部变量表(Local Variables)、操作数栈(Operand Stack)、指向当前方法所属的类的运行时常量池（的引用(Reference to runtime constant pool)、方法返回地址(Return Address)和一些额外的附加信息。当线程执行一个方法时，就会随之创建一个对应的栈帧，并将建立的栈帧压栈。当方法执行完毕之后，便会将栈帧出栈。因此可知，线程当前执行的方法所对应的栈帧必定位于Java栈的顶部。讲到这里，大家就应该会明白为什么 在 使用 递归方法的时候容易导致栈内存溢出的现象了，这部分空间的分配和释放都是由系统自动实施的。</p>
<p><mark>局部变量表</mark>就是用来存储方法中的局部变量（包括在方法中声明的非静态变量以及函数形参）。对于基本数据类型的变量，则直接存储它的值，对于引用类型的变量，则存的是指向对象的引用。局部变量表的大小在编译器就可以确定其大小了，因此在程序执行期间局部变量表的大小是不会改变的。<br>
<mark>操作数栈</mark>，一个线程执行方法的过程中，实际上就是不断执行语句的过程，而归根到底就是进行计算的过程。因此可以这么说，程序中的所有计算过程都是在借助于操作数栈来完成的。主要用于保存计算过程的中间结果，同时作为计算过程中变量的临时存储空间。<br>
<mark>动态链接</mark>，指向运行时常量池的引用，因为在方法执行的过程中有可能需要用到类中的常量，所以必须要有一个引用指向运行时常量。<br>
<mark>方法返回地址</mark>，当一个方法执行完毕之后，要返回之前调用它的地方，因此在栈帧中必须保存一个方法返回地址。</p>
<p>由于每个线程正在执行的方法可能不同，因此每个线程都会有一个自己的Java栈，互不干扰。</p>
<ol start="3">
<li>
<p><code>本地方法栈</code><br>
本地方法栈与Java栈的作用和原理非常相似。区别只不过是Java栈是为执行Java方法服务的，而本地方法栈则是为执行本地方法（Native Method）服务的。在JVM规范中，并没有对本地方发展的具体实现方法以及数据结构作强制规定，虚拟机可以自由实现它。在HotSopt虚拟机中直接就把本地方法栈和Java栈合二为一。</p>
</li>
<li>
<p><code>堆</code><br>
Java中的堆是用来存储对象本身的以及数组（当然，数组引用是存放在Java栈中的）。这部分空间也是Java垃圾收集器管理的主要区域。另外，堆是被所有线程共享的，在JVM中只有一个堆。</p>
</li>
<li>
<p><code>方法区</code><br>
方法区在JVM中也是一个非常重要的区域，它与堆一样，是被线程共享的区域。在方法区中，存储了每个类的信息（包括类的名称、方法信息、字段信息）、静态变量、常量以及编译器编译后的代码等。</p>
</li>
</ol>
<p>在Class文件中除了类的字段、方法、接口等描述信息外，还有一项信息是常量池，用来存储编译期间生成的字面量和符号引用。</p>
<p>在方法区中有一个非常重要的部分就是运行时常量池，它是每一个类或接口的常量池的运行时表示形式，在类和接口被加载到JVM后，对应的运行时常量池就被创建出来。当然并非Class文件常量池中的内容才能进入运行时常量池，在运行期间也可将新的常量放入运行时常量池中，比如String的intern方法。</p>
<h3 id="7栈数据结构栈帧结构局部变量表操作数栈动态链接方法返回地址">7.栈数据结构：栈帧结构，局部变量表，操作数栈，动态链接，方法返回地址</h3>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1675822649183.png" alt="" loading="lazy"></figure>
<h3 id="8分代设计思想堆是如何划分">8.分代设计思想，堆是如何划分</h3>
<p>一般商业的虚拟机，大多数都遵循了分代收集的设计思想，分代收集理论主要有两条假说。<br>
第一个是强分代假说，强分代假说指的是 JVM 认为绝大多数对象的生存周期都是朝生夕灭的；<br>
第二个是弱分代假说，弱分代假说指的是只要熬过越多次垃圾收集过程的对象就越难以回收（看来对象也会长心眼）。<br>
就是基于这两个假说理论，JVM 将堆区划分为不同的区域，再将需要回收的对象根据其熬过垃圾回收的次数分配到不同的区域中存储。</p>
<p>JVM 根据这两条分代收集理论，把堆区划分为新生代(Young Generation)和老年代(Old Generation)这两个区域。其中，新生代又被划分为 Eden 区，以及两个大小相同的 Survivor 区（From Survivor 和 To Survivor）。在新生代中，每次垃圾收集时都发现有大批对象死去，剩下没有死去的对象会直接晋升到老年代中。<br>
上面这两个假说没有考虑对象的引用关系，而事实情况是，对象之间会存在引用关系，基于此又诞生了第三个假说，即跨代引用假说(Intergeneration Reference Hypothesis)，跨代引用相比较同代引用来说仅占少数。正常来说存在相互引用的两个对象应该是同生共死的，不过也会存在特例，如果一个新生代对象跨代引用了一个老年代的对象，那么垃圾回收的时候就不会回收这个新生代对象，更不会回收老年代对象，然后这个新生代对象熬过一次垃圾回收进入到老年代中，这时候跨代引用才会消除。</p>
<p>依据这条假说，我们就不应再为了少量的跨代引用去扫描整个老年代，也不必浪费空间专门记录每一个对象是否存在及存在哪些跨代引用，只需在新生代上建立一个全局的数据结构（该结构被称为“记忆集”，Remembered Set），这个结构把老年代划分成若干小块，标识出老年代的哪一块内存会存在跨代引用。此后当发生Minor GC时（指新生代的垃圾收集），只有包含了跨代引用的小块内存里的对象才会被加入到GC Roots进行扫描。虽然这种方法需要在对象改变引用关系（如将自己或者某个属性赋值）时维护记录数据的正确性，会增加一些运行时的开销，但比起收集时扫描整个老年代来说仍然是划算的。</p>
<p>JVM中大家是否还记得对象在Suvivor中每熬过一次MinorGC，年龄就增加1，当它的年龄增加到一定程度后就会被晋升到老年代中，这个次数默认是15岁，有想过为什么是15吗？在Mark Word中可以发现标记对象分代年龄的分配的空间是4bit，而4bit能表示的最大数就是2^4-1 = 15。</p>
<h3 id="9分类强-软-弱-虚引用">9.分类，强、软、弱、虚引用</h3>
<ol>
<li>强引用(StrongReference)<br>
强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。如下：</li>
</ol>
<pre><code class="language-java">Object strongReference = new Object();
</code></pre>
<p>如果强引用对象不使用时，需要弱化从而使GC能够回收，如显式地设置strongReference对象为null，或让其超出对象的生命周期范围，则gc认为该对象不存在引用，这时就可以回收这个对象。<br>
在一个方法的内部有一个强引用，这个引用保存在Java栈中，而真正的引用内容(Object)保存在Java堆中。 当这个方法运行完成后，就会退出方法栈，则引用对象的引用数为0，这个对象会被回收。</p>
<ol start="2">
<li>软引用(SoftReference)<br>
如果一个对象只具有软引用，则内存空间充足时，垃圾回收器就不会回收它；如果内存空间不足了，JVM首先将软引用中的对象引用置为null，然后等待垃圾回收器回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。</li>
</ol>
<pre><code class="language-java">// 软引用
String str = new String(&quot;abc&quot;);
SoftReference&lt;String&gt; softReference = new SoftReference&lt;String&gt;(str);
</code></pre>
<p>也就是说，垃圾收集线程会在虚拟机抛出OutOfMemoryError之前回收软引用对象，而且虚拟机会尽可能优先回收长时间闲置不用的软引用对象。对那些刚构建的或刚使用过的<strong>较新的软对象会被虚拟机尽可能保留</strong>，这就是引入引用队列ReferenceQueue的原因。</p>
<p>软引用可以和一个引用队列(ReferenceQueue)联合使用。如果软引用所引用对象被垃圾回收，JAVA虚拟机就会把这个软引用加入到与之关联的引用队列中。</p>
<ol start="3">
<li>弱引用(WeakReference)<br>
弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。</li>
</ol>
<pre><code class="language-java">    String str = new String(&quot;abc&quot;);
    WeakReference&lt;String&gt; weakReference = new WeakReference&lt;&gt;(str);
    str = null;
</code></pre>
<p>JVM首先将软引用中的对象引用置为null，然后通知垃圾回收器进行回收。<br>
同样，弱引用可以和一个引用队列(ReferenceQueue)联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。</p>
<ol start="4">
<li>虚引用(PhantomReference)<br>
虚引用顾名思义，就是形同虚设。与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。</li>
</ol>
<pre><code class="language-java">String str = new String(&quot;abc&quot;);
ReferenceQueue queue = new ReferenceQueue();
// 创建虚引用，要求必须与一个引用队列关联
PhantomReference pr = new PhantomReference(str, queue);
</code></pre>
<p>程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要进行垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。</p>
<blockquote>
<p>Java中4种引用的级别和强度由高到低依次为：强引用 -&gt; 软引用 -&gt; 弱引用 -&gt; 虚引用</p>
</blockquote>
<table>
<thead>
<tr>
<th>引用类型</th>
<th>被垃圾回收时间</th>
<th>用途</th>
<th>生存时间</th>
</tr>
</thead>
<tbody>
<tr>
<td>强引用</td>
<td>从来不会</td>
<td>对象的一般状态</td>
<td>JVM停止运行时终止</td>
</tr>
<tr>
<td>软引用</td>
<td>当内存不足时</td>
<td>对象缓存</td>
<td>内存不足时终止</td>
</tr>
<tr>
<td>弱引用</td>
<td>正常垃圾回收时</td>
<td>对象缓存</td>
<td>垃圾回收后终止</td>
</tr>
<tr>
<td>虚引用</td>
<td>正常垃圾回收时</td>
<td>跟踪对象的垃圾回收</td>
<td>垃圾回收后终止</td>
</tr>
</tbody>
</table>
<h3 id="10堆外内存如何回收">10.堆外内存如何回收？</h3>
<p><code>堆外内存的申请和释放</code><br>
JDK的ByteBuffer类提供了一个接口allocateDirect(int capacity)进行堆外内存的申请，底层通过unsafe.allocateMemory(size)实现。<br>
最底层是通过malloc方法申请的，但是这块内存需要进行手动释放，JVM并不会进行回收，幸好Unsafe提供了另一个接口freeMemory可以对申请的堆外内存进行释放。</p>
<p><code>堆外内存的回收机制</code><br>
JDK中使用DirectByteBuffer对象来表示堆外内存，每个DirectByteBuffer对象在初始化时，都会创建一个对用的Cleaner对象，这个Cleaner对象会在合适的时候执行unsafe.freeMemory(address)，从而回收这块堆外内存。</p>
<h3 id="11对象内存中数据接口对象头hash锁信息生代年龄kclass-实例数据-对齐填充">11.对象内存中数据接口：对象头（hash，锁信息，生代年龄，kclass）、实例数据、对齐填充</h3>
<p>在 JVM 中，Java对象保存在堆中时，由以下三部分组成：</p>
<p><code>对象头（object header）</code>：包括了关于堆对象的布局、类型、GC状态、同步状态和标识哈希码的基本信息。Java对象和vm内部对象都有一个共同的对象头格式。<br>
Mark Word：用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等等。Mark Word在32位JVM中的长度是32bit，在64位JVM中长度是64bit。虽然它们在不同位数的JVM中长度不一样，但是基本组成内容是一致的。</p>
<ol>
<li>锁标志位（lock）：区分锁状态，11时表示对象待GC回收状态, 只有最后2位锁标识(11)有效。</li>
<li>biased_lock：是否偏向锁，由于无锁和偏向锁的锁标识都是 01，没办法区分，这里引入一位的偏向锁标识位。</li>
<li>分代年龄（age）：表示对象被GC的次数，当该次数到达阈值的时候，对象就会转移到老年代。</li>
<li>对象的hashcode（hash）：运行期间调用System.identityHashCode()来计算，延迟计算，并把结果赋值到这里。当对象加锁后，计算的结果31位不够表示，在偏向锁，轻量锁，重量锁，hashcode会被转移到Monitor中。</li>
<li>偏向锁的线程ID（JavaThread）：偏向模式的时候，当某个线程持有对象的时候，对象这里就会被置为该线程的ID。 在后面的操作中，就无需再进行尝试获取锁的动作。</li>
<li>epoch：偏向锁在CAS锁操作过程中，偏向性标识，表示对象更偏向哪个锁。</li>
<li>ptr_to_lock_record：轻量级锁状态下，指向栈中锁记录的指针。当锁获取是无竞争的时，JVM使用原子操作而不是OS互斥。这种技术称为轻量级锁定。在轻量级锁定的情况下，JVM通过CAS操作在对象的标题字中设置指向锁记录的指针。</li>
<li>ptr_to_heavyweight_monitor：重量级锁状态下，指向对象监视器Monitor的指针。如果两个不同的线程同时在同一个对象上竞争，则必须将轻量级锁定升级到Monitor以管理等待的线程。在重量级锁定的情况下，JVM在对象的ptr_to_heavyweight_monitor设置指向Monitor的指针</li>
</ol>
<blockquote>
<p>32位JVM中Mark Word存储格式<br>
<img src="https://q456qq520.github.io/post-images/1675825680792.png" alt="" loading="lazy"><br>
64位JVM中Mark Word存储格式<br>
<img src="https://q456qq520.github.io/post-images/1675825727788.png" alt="" loading="lazy"></p>
</blockquote>
<p>Klass Pointer：即类型指针，是对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。</p>
<p><code>实例数据（Instance Data）</code>：主要是存放类的数据信息，父类的信息，对象字段属性信息。<br>
<code>对齐填充（Padding）</code>：为了字节对齐，填充的数据，不是必须的。默认情况下，Java虚拟机堆中对象的起始地址需要对齐至8的倍数。</p>
<p>为什么要对齐数据？字段内存对齐的其中一个原因，是让字段只出现在同一CPU的缓存行中。如果字段不是对齐的，那么就有可能出现跨缓存行的字段。也就是说，该字段的读取可能需要替换两个缓存行，而该字段的存储也会同时污染两个缓存行。这两种情况对程序的执行效率而言都是不利的。其实对其填充的最终目的是为了计算机高效寻址。</p>
<h3 id="12对象在内存中生命周期从new到灭亡">12.对象在内存中生命周期，从new到灭亡</h3>
<p>Java对象在JVM中的运行周期大致上分为七个阶段，创建阶段（Creation）、应用阶段（Using）、不可视阶段（Invisible）、不可到达阶段（Unreachable）、可收集阶段（Collected）、终结阶段（Finalized）与释放阶段（Free）</p>
<h3 id="13逃逸分析是什么栈上分配锁消除标量替换">13.逃逸分析是什么？栈上分配，锁消除，标量替换</h3>
<p><code>逃逸分析</code><br>
逃逸分析是一种确定指针动态范围的静态分析，它可以分析在程序的哪些地方可以访问到指针。逃逸分析不是直接优化代码的手段，而是为其它优化手段提供依据的分析技术。逃逸分析的基本行为就是分析对象的动态作用域：当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其它方法中，称为方法逃逸。甚至还有可能被外部线程访问到，例如赋值给类变量或可以在其他线程中访问的实例变量，称为线程逃逸。简单的说，逃逸分析指的是分析变量能不能逃出它的作用域。<br>
如果能证明一个对象不会逃逸到方法或者线程之外，也就是别的方法和线程无法通过任何途径访问到这个方法，则可能为这个变量进行一些高效优化。<br>
 <br>
逃逸分析可以细分为四种场景：<br>
第一：全局变量赋值逃逸。<br>
第二：方法返回至逃逸。<br>
第三：实例引用逃逸。<br>
第四：线程逃逸。当赋值给类变量或者赋值给其他线程里面可以访问的实例变量就会发生线程逃逸。</p>
<pre><code class="language-java">public class SomeClass {
    public void printClassName(EscapeDemo1 escapeDemo1){
        System.out.println(escapeDemo1.getClass().getName());
    }
}

public static  SomeClass someClass;
//全局变量赋值逃逸
public void globalVariablePointerEscape(){
    someClass=new SomeClass();
}

//方法返回值逃逸
public void someMethod(){
    SomeClass someClass=methodPointerEscape();
}
public SomeClass methodPointerEscape(){
    return new SomeClass();
}

    //方法返回值逃逸
public void someMethod(){
    SomeClass someClass=methodPointerEscape();
}
public SomeClass methodPointerEscape(){
    return new SomeClass();
}
</code></pre>
<p><code>标量替换</code><br>
所谓的标量指的是不能进一步分解的量。像 Java 的基础数据类型（int、long等数值类型以及 reference 类型等）以及对象的地址引用都是标量，因为它们是没有办法继续分解的。与标量对应的是聚合量，聚合量指的是可以进一步分解的量，比如字符串就是一个聚合量，因为字符串是用字节数组实现的，可以分解。又比如我们自己定义的变量也都是聚合量。<br>
那么什么是标量替换呢？根据程序访问的情况，将其使用到的成员变量恢复原始类型来访问就叫做标量替换。如果逃逸分析证明一个对象不会被外部访问，并且这个对象可以被拆散的话，那程序真正执行的时候将可能不创建这个对象，而改为直接创建它的若干个被这个方法使用到的成员变量来代替。将对象拆分后，除了可以让对象的成员变量在栈上（栈上存储的数据，很大机会会被虚拟机分配至物理机器的高速寄存器中存储）分配和读写之外，还可以为后续进一步的优化手段创建条件。<br>
那么标量替换有什么好处呢？就是可以大大减少堆内存的占用。因为一旦不需要创建对象了，那么就不再需要分配堆内存了。</p>
<p><code>栈上分配</code><br>
Java 虚拟机中，绝大多数对象都是存放在堆里面的，Java 堆中的对象对于各个线程都是共享和可见的，只要持有这个对象的引用，就可以访问堆中存储的对象数据。虚拟机的垃圾收集系统可以回收掉堆中不再使用的对象，但回收动作无论是筛选可回收对象，还是回收和整理内存都需要耗费时间。<br>
 <br>
但是，有一种特殊情况，那就是如果经过逃逸分析后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配,这样就无需在堆上分配内存，也无须进行垃圾回收了。</p>
<p>那么什么是栈上分配呢？指的是如果通过逃逸分析确认对象不会被外部访问到的话。那么就直接在栈上分配对象，那么在栈上分配对象的话，这个对象占用的空间就会在栈帧出站的时候被销毁了，所以通过栈上分配可以降低垃圾回收的压力。</p>
<p><code>同步消除</code><br>
如果逃逸分析能确定一个变量不会逃逸出线程，无法被其它线程访问，那这个变量的读写就不会有多线程竞争的问题，因而变量的同步措施也就可以消除了。</p>
<h3 id="14对象存活算法-引用计数器与可达性分析">14.对象存活算法。引用计数器与可达性分析</h3>
<p><code>引用计数算法</code><br>
引用计数器就是: 给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减一;任何时刻计数器为 0 的对象就是不可能再被使用的，可以此时进行回收。<br>
但是引用计数法有一个很大的缺陷，就是它很难解决对象之间相互循环引用的问题。</p>
<p><code>可达性分析算法</code><br>
可达性分析算法的基本思路就是通过一系列名为”GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。<br>
这个算法的基本思想是通过一系列称为“GC Roots”的对象作为起始点，从这些节点向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链（即GC Roots到对象不可达）时，则证明此对象是不可用的。</p>
<p>在Java语言中,可作为GCRoots对象包含为以下几种:</p>
<ol>
<li>虚拟机栈(栈帧中的本地变量表)中引用的对象。(可以理解为:引用栈帧中的本地变量表的所有对象)</li>
<li>方法区中静态属性引用的对象(可以理解为:引用方法区该静态属性的所有对象)</li>
<li>方法区中常量引用的对象(可以理解为:引用方法区中常量的所有对象)</li>
<li>本地方法栈中(Native方法)引用的对象(可以理解为:引用Native方法的所有对象)</li>
</ol>
<p>(1)首先第一种是虚拟机栈中的引用的对象，我们在程序中正常创建一个对象，对象会在堆上开辟一块空间，同时会将这块空间的地址作为引用保存到虚拟机栈中，如果对象生命周期结束了，那么引用就会从虚拟机栈中出栈，因此如果在虚拟机栈中有引用，就说明这个对象还是有用的，这种情况是最常见的。<br>
(2)第二种是我们在类中定义了全局的静态的对象，也就是使用了static关键字，由于虚拟机栈是线程私有的，所以这种对象的引用会保存在共有的方法区中，显然将方法区中的静态引用作为GC Roots是必须的。<br>
(3)第三种便是常量引用，就是使用了static final关键字，由于这种引用初始化之后不会修改，所以方法区常量池里的引用的对象也应该作为GC Roots。<br>
(4)最后一种是在使用JNI技术时，有时候单纯的Java代码并不能满足我们的需求，我们可能需要在Java中调用C或C++的代码，因此会使用native方法，JVM内存中专门有一块本地方法栈，用来保存这些对象的引用，所以本地方法栈中引用的对象也会被作为GC Roots。</p>
<h3 id="15为什么需要stw引用关系不发生变化gc-中断-取消偏向锁">15.为什么需要stw？引用关系不发生变化，GC、中断、取消偏向锁</h3>
<p>在发生GC时会停下所有的用户线程，从而导致Java程序出现全局停顿的无响应情况，而这种情况则被称为STW（Stop The World）世界暂停。在发生STW之后，所有的Java代码会停止运行，不过native代码是可以继续执行的，但也不能和JVM交互。一般发生STW都是由于GC引起的，但在某几种少数情况下，也会导致STW出现，如线程Dump、死锁检查、堆日志Dump等</p>
<p>GC发生时为什么都必须要STW呢？</p>
<p>一个是尽量为了避免浮动垃圾产生，就是刚刚标记完成一块区域中的对象，但转眼用户线程又在该区域中产生了新的“垃圾”。<br>
第二个则是为了确保一致性，分析工作必须在一个能确保一致性的快照中进行，不可以出现分析过程中对象引用关系还在不断变化的情况，该点不满足的话分析结果的准确性无法得到保证。</p>
<p>JVM在发生GC时，主要作用的区域有三个：新生代、年老代以及元数据空间，当然，程序运行期间，绝对多数GC都是在回收新生代。一般而言，GC可以分为四种类型，如下：</p>
<p>①新生代收集：只针对新生代的GC，当Eden区满了时触发，Survivor满了并不会触发。<br>
②年老代收集：针对年老代空间的GC，不过目前只有CMS存在单独回收年老代的行为。<br>
③混合收集：指收集范围覆盖整个新生代空间及部分年老代空间的GC，目前只有G1存在该行为。<br>
④全面收集：覆盖新生代、年老代以及元数据空间的GC，会对于所有可发生GC的内存进行收集。</p>
<p><code>偏向锁的撤销</code><br>
偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。</p>
<h3 id="16安全点是什么安全区域是什么-引用关系不发生变化">16.安全点是什么？安全区域是什么。引用关系不发生变化</h3>
<p>当GC发生时，必然会出现程序停顿，也就是需要停止所有用户线程。但问题在于：用户线程停止的时机必须合理，不然在恢复线程后，有可能会导致最终的执行结果出现不一致，因此用户线程必然需要在一个安全的位置暂停。<br>
而在JVM中，存在两个概念：<code>安全点</code>和<code>安全区域</code>，当用户线程执行到安全点或安全区域的代码处，此时发生停止是安全的，后续再次唤醒线程工作时，执行结果也不会因为线程暂停而受到任何影响。</p>
<p><code>安全点(SafePoint)</code><br>
无论是在GC中还是并发编程中，都会经常出现安全点这个概念，因为当我们需要阻塞停止一条线程时，都需要在安全点停止，简单说安全点就是指当线程运行到这类位置时，堆对象状态是确定一致的，线程停止后，JVM可以安全地进行操作，如GC、偏向锁撒销等。</p>
<p>而JVM中对于安全点的定义主要有如下几种：<br>
①循环结束的末尾段<br>
②方法调用之后<br>
③抛出异常的位置<br>
④方法返回之前</p>
<p>当JVM需要发生GC、偏向锁撤销等操作时，如何才能让所有线程到达安全点阻塞或停止？<br>
①主动式中断(JVM采用的方式)：不中断线程，而是设置一个标志，而后让每条线程执行时主动轮询这个标志，当一个线程到达安全点后，发现中断标志为true时就自己中断挂起。<br>
②抢断式中断：先中断所有线程，如果发现线程未执行到安全点则恢复线程让其运行到安全点位置。</p>
<p><code>安全区域(SafeRegion)</code><br>
当Java程序需要停下所有用户线程时，某些线程可能处于中断或者休眠状态，从而无法响应JVM的中断请求走到安全点位置挂起了，所以出现了安全区域的概念。</p>
<p>安全区域是指一条线程执行到一段代码时，该区域的代码不会改变堆中对象的引用。在这区域内JVM可以安全地进行操作。当线程进入到该区域时需要先标识自己进入了，这样GC线程则不会管这些已标识的线程，当线程要离开这个区域时需要先判断可达性分析是否完成，如果完成了则往下执行，如果没有则需要原地等待到GC线程发出安全离开信息为止。</p>
<h3 id="17gc回收算法复制标记清除标记整理">17.GC回收算法：复制，标记清除，标记整理</h3>
<p><code>标记-清除算法</code><br>
标记清除算法是现代GC算法的基础，标-清算法会将回收工作分为标记和清除两个阶段。在标记阶段会根据可达性分析算法，通过根节点标记堆中所有的可达对象，而这些对象则被称为堆中存活对象，反之，未被标记的则为垃圾对象。然后在清除阶段，会对于所有未标记的对象进行清除。</p>
<p>初始GC标志位都为0，也就是未标记状态，假设此时系统堆内存出现不足，那么最终会触发GC机制。GC开始时，在标记阶段首先会停下整个程序，然后GC线程开始遍历所有GC Roots节点，根据可达性分析算法找出所有的存活对象并标记为1，标记阶段完成后，会找出并标记所有存活对象，接下来就会执行清除阶段，清楚所有未被标记的对象,在清除操作完成之后，会将前面存活对象的GC标志位复位，也就是会将标记从1为还原成未标记的0。</p>
<blockquote>
<p>GC标记到底在哪儿？在对象头中存在一个markword字段，而GC标志位就存在其内部。同时，清除阶段并不是简单的置空内存，而是把需要清除的对象地址保存在空闲的地址列表里，下次有新对象需要加载时，判断垃圾的位置空间是否够，如果够就存放。</p>
</blockquote>
<p>标记-清除算法是最初的GC算法，因为在标记阶段需要停下所有用户线程，也就是发生STW，而标记的时候又需要遍历整个堆空间中的所有GcRoots，所以耗时比较长，对于客户端而言，可能会导致GC发生时，造成很长一段时间内无响应。同时，因为堆空间中的垃圾对象是会分散在内存的各个角落，所以一次GC之后，会造成大量的内存碎片，也就是通过标-清算法清理出来的内存是不连续的，为了解决这个问题，JVM就不得不再额外维持一个内存的空闲列表，这又是一种开销。而且在分配数组对象或大对象时，连续的内存空间资源又会变得很匮乏。</p>
<p><code>复制算法</code><br>
复制算法会将JVM中原有的堆内存分为两块，在同一时刻只会使用一块内存用于对象分配。在发生GC时，首先会将使用的那块内存区域中的存活对象复制到未使用的这块内存中。等复制完成之后，对当前使用的这块内存进行全面清除回收，清除完成之后，交换两块内存之间的角色，最后GC结束。</p>
<p>复制算法带来的好处是显而易见的，因为每次GC都是直接对半边区域进行回收，所以回收之后不需要考虑内存碎片的复杂情况，在内存分配时直接可以使用简单高效的 指针碰撞 方式分配对象。</p>
<p>但这种算法最大的问题在于对内存的浪费，因为在实际内存分配时只会使用一块内存，所以在实际分配时，内存直接缩水一半，这是比较头疼的事情。同时，存活的对象在GC发生时，还需要复制到另一块内存区域，因此对象移动的开销也需要考虑在内，所以想要使用这种算法，最起码对象的存活率要非常低才行。</p>
<blockquote>
<p>一般都采用复制算法来收集新生代空间，因为新生代中95%左右的对象都是朝生夕死的。在HotSpot中，新生代会被划分为Eden<em>1、Survivor</em>2三个区域，但比例并非1:1，因为经过一次GC后能够依旧活着的对象是十不存一的，所以需要转移的对象并不多，所以在HotSpotVM中，三个区域的比例默认为8:1:1。当每次新生代发生GC时，就将Eden区和一块Survivor区的存活对象移动到另外一块Survivor区中，最后对Eden区和原本那块Survivor区进行全面回收。所以也就是说，HotSpot中新生代的内存最多浪费10%，最大容量为80%+10%=90%。</p>
</blockquote>
<p>但凡事没有绝对，因为在运行时，谁也不能保证每次存活的对象总量都小于新生代空间的10%，所以有时候可能会出现：另外一块Survivor区10%的空间放不下新生代的存活对象这种情况，所以此时就需要<mark>空间分配担保机制</mark>介入了。</p>
<blockquote>
<p>空间分配担保机制机制是指：当Survivor空间不够用时，需要依赖于年老代进行分配担保，对Survivor空间空间中的存活对象进行动态晋升判定，把一些符合条件的对象提前转入到年老代空间中存储，以确保新生代能够空出足够的空间，确保新生代GC的正常工作。</p>
</blockquote>
<p><code>标记-整理算法</code><br>
标记-整理算法也被称为标记-压缩算法，标-整算法适用于存活率较高的场景，它是建立在标-清算法的基础上做了优化。标-整算法也会分为两个阶段，分别为标记阶段、整理阶段：</p>
<p>①标记阶段：和标-清算法一样。在标记阶段时也会基于GcRoots节点遍历整个内存中的所有对象，然后对所有存活对象做一次标记。<br>
②整理阶段：在整理阶段该算法并不会和标-清算法一样简单的清理内存，而是会将所有存活对象移动（压缩）到内存的一端，然后对于存活对象边界之外的内存进行统一回收。</p>
<blockquote>
<p>经过标-整算法之后的堆空间会变成整齐的内存，因为被标记为存活的对象都会被压缩到内存的一端。如此一来，当我们需要给新对象分配内存时，JVM只需要持有一个内存的起始地址即可，也就是保留一根指针指向已用内存和空闲内存的分割点，也就是可以直接采用指针碰撞的方式进行内存分配，这比维护一个空闲列表显然少了许多开销。</p>
</blockquote>
<p>标-整算法唯一的美中不足在于：它的整体收集效率并不高。因为标-整算法不仅仅要标记对象，同时还要移动存活对象，所以整个GC过程下来，它所需要耗费的时间资源开销必然是不小的。</p>
<p>不过一般年老代空间都是采用标-整算法，因为一方面年老代GC次数方面远没有新生代频繁，同时，晋升年老代的对象一般来说体积不会很小，所以在晋升时需要足够的内存大小分配，如果采用标-清算法会导致大对象无法进行分配，如若采用复制算法则没有新的空间为年老代提供。</p>
<p>如上三种GC算法则是JVM虚拟机的基础GC算法，综合对比来看：</p>
<p>收集速度：复制算法 &gt; 标-清算法 &gt; 标-整算法<br>
内存整齐度：复制算法 = 标-整算法 &gt; 标-清算法<br>
内存利用率：标-整算法 &gt; 标-清算法 &gt; 复制算法</p>
<h3 id="18cms-g1垃圾收集器的对比">18.CMS、G1垃圾收集器的对比</h3>
<p>G1 在压缩空间方面有优势。<br>
G1 通过将内存空间分成区域（Region）的方式避免内存碎片问题。Eden, Survivor, Old 区不再固定、在内存使用效率上来说更灵活。<br>
G1 可以通过设置预期停顿时间（Pause Time）来控制垃圾收集时间避免应用雪崩现象。<br>
G1 在回收内存后会马上同时做合并空闲内存的工作、而 CMS 默认是在 STW（stop the world）的时候做。<br>
G1 会在 Young GC 中使用、而 CMS 只能在 O 区使用。<br>
吞吐量优先：G1<br>
响应优先：CMS<br>
CMS 的缺点是对 cpu 的要求比较高。G1 是将内存化成了多块，所有对内段的大小有很大的要求。<br>
CMS 是清除，所以会存在很多的内存碎片。G1 是整理，所以碎片空间较小。</p>
<h3 id="19gc类型yonggc-oldgc-mixedgc-fullgc">19.GC类型：YongGC、OldGC、MixedGC、FullGC</h3>
<p><code>Mixed GC</code><br>
Mixed GC 是 G1 中特有的概念，其实说白了，主要就是说在 G1 中，一旦老年代占据堆内存的 45%（-XX:InitiatingHeapOccupancyPercent：设置触发标记周期的 Java 堆占用率阈值，默认值是 45%。这里的Java 堆占比指的是 non_young_capacity_bytes，包括 old + humongous），就要触发 Mixed GC，此时对年轻代和老年代都会进行回收。Mixed GC 只有 G1 中才会出现。</p>
<h3 id="20cms垃圾收集器的特点">20.CMS垃圾收集器的特点</h3>
<p>CMS收集器是一种以获取最短回收停顿时间为目标的收集器。基于“标记-清除”算法实现，它的运作过程如下：<br>
1）初始标记<br>
2）并发标记<br>
3）重新标记<br>
4）并发清除<br>
初始标记、重新标记这两个步骤仍然需要“stop the world”，初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生表动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长点，但远比并发标记的时间短。</p>
<p>CMS是一款优秀的收集器，主要优点：并发收集、低停顿。</p>
<p>缺点：</p>
<p>1）CMS收集器对CPU资源非常敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低。<br>
2）CMS收集器无法处理浮动垃圾，可能会出现“Concurrent Mode Failure（并发模式故障）”失败而导致Full GC产生。<br>
浮动垃圾：由于CMS并发清理阶段用户线程还在运行着，伴随着程序运行自然就会有新的垃圾不断产生，这部分垃圾出现的标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC中再清理。这些垃圾就是“浮动垃圾”。<br>
3）CMS是一款“标记--清除”算法实现的收集器，容易出现大量空间碎片。当空间碎片过多，将会给大对象分配带来很大的麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次Full GC。</p>
<h3 id="21cms垃圾收集器收集过称初始标记并发标记重新标记并发清理">21.CMS垃圾收集器收集过称，初始标记，并发标记，重新标记，并发清理</h3>
<p>CMS 处理过程有七个步骤：</p>
<ol>
<li>初始标记(CMS-initial-mark) ,会导致stw;</li>
<li>并发标记(CMS-concurrent-mark)，与用户线程同时运行；</li>
<li>预清理（CMS-concurrent-preclean），与用户线程同时运行；</li>
<li>可被终止的预清理（CMS-concurrent-abortable-preclean） 与用户线程同时运行；</li>
<li>重新标记(CMS-remark) ，会导致swt；</li>
<li>并发清除(CMS-concurrent-sweep)，与用户线程同时运行；</li>
<li>并发重置状态等待下次CMS的触发(CMS-concurrent-reset)，与用户线程同时运行；</li>
</ol>
<p>CMS是老年代垃圾收集器，在收集过程中可以与用户线程并发操作。它可以与Serial收集器和Parallel New收集器搭配使用。CMS牺牲了系统的吞吐量来追求收集速度，适合追求垃圾收集速度的服务器上。可以通过JVM启动参数：-XX:+UseConcMarkSweepGC来开启CMS。</p>
<p><code>初始标记</code><br>
这一步的作用是标记存活的对象，有两部分：</p>
<ol>
<li>标记老年代中所有的GC Roots对象</li>
<li>标记年轻代中活着的对象引用到的老年代的对象</li>
</ol>
<p><code>并发标记</code><br>
从“初始标记”阶段标记的对象开始找出所有存活的对象;因为是并发运行的，在运行期间会发生新生代的对象晋升到老年代、或者是直接在老年代分配对象、或者更新老年代对象的引用关系等等，对于这些对象，都是需要进行重新标记的，否则有些对象就会被遗漏，发生漏标的情况。为了提高重新标记的效率，该阶段会把上述对象所在的Card标识为Dirty，后续只需扫描这些Dirty Card的对象，避免扫描整个老年代；并发标记阶段只负责将引用发生改变的Card标记为Dirty状态，不负责处理；</p>
<blockquote>
<p>JVM会通过Card(卡片)的方式将发生改变的老年代区域标记为“脏”区，这就是所谓的卡片标记（Card Marking）</p>
</blockquote>
<p>并发标记的特点是和应用程序线程同时运行。并不是老年代的所有存活对象都会被标记，因为标记的同时应用程序会改变一些对象的引用等。 由于这个阶段是和用户线程并发的，可能会导致concurrent mode failure。</p>
<p><code>重新标记</code><br>
最终标记是此阶段GC事件中的第二次（也是最后一次）STW停顿。目标： 重新扫描堆中的对象，因为之前的预清理阶段是并发执行的，有可能GC线程跟不上应用程序的修改速度。扫描范围： 新生代对象+GC Roots+被标记为“脏”区的对象。如果预清理阶段没有做好，这一步扫描新生代的时候就会花很多时间。</p>
<p><code>并发清理</code><br>
此阶段与应用程序并发执行，不需要STW停顿。JVM在此阶段删除不再使用的对象，并回收他们占用的内存空间。因为重新标记已经把所有还在使用的对象进行了标记，因此此阶段可以与应用线程并发的执行。</p>
<h3 id="22cms垃圾收集器会产生内存碎片吗如何处理">22.CMS垃圾收集器会产生内存碎片吗？如何处理？</h3>
<p>由于CMS采用的是&quot;标记-清除&quot;算法，那么在运行到一定时间后，会产生一些内存碎片。当有新的对象要进入老年代时，可能会造成内存不够分配的情况。这个时候可以通过参数<code>-XX:CMSFullGCsBeforeCompaction</code>进行内存整理。比如配置-XX:CMSFullGCsBeforeCompaction=5，那么每执行5次Full GC就会对老年代进行内存空间整理。</p>
<h3 id="23并发标记三色标记法-浮动垃圾-漏标">23.并发标记：三色标记法。浮动垃圾、漏标</h3>
<p><code>三色标记法</code><br>
并发标记过程中允许用户线程正常执行，采用三色标记算法从初始标记的对象开始遍历整个老年代，进行存活对象标记，这个过程相对过长，但对于用户来说是几乎无感知的。</p>
<p>三色标记是CMS采用的标记对象算法，可以缩短STW时间并达到标记存活对象的效果。按照对象是否被垃圾收集器访问过这个条件，标记的颜色有下面三种：</p>
<p>白色：表示该对象还没有被访问过。在可达性分析开始阶段，除GC Root对象外，所有的对象节点都是白色的。如果在可达性分析执行完后，还有白色状态的对象，即对象不可达，那么这些就可以被认定为垃圾对象。<br>
黑色：表示该对象已经被访问过，并且该对象的引用对象也全部被访问过，该对象可达，为存活对象。<br>
灰色：表示该对象已经被访问过，但是存在引用对象还没有被访问过。比如在访问A对象时，A对象内部引用了B和C对象，当访问B对象时，发现内部没有引用其他对象，那么此时B对象已经被GC访问过了。但对于A对象来说，尽管B对象已经被访问，C对象还没有被访问，所以A的对象标记为灰色。</p>
<p><code>浮动垃圾</code><br>
在并发清除过程中，由于用户线程也在不断的运行，如果出现漏标情况，就会产生一些垃圾对象，这些垃圾对象叫做浮动垃圾。这些垃圾对象只能等待下次GC时才能被回收，在没被回收之前仍然占用内存空间。</p>
<p><code>错标</code><br>
在并发标记过程中不会触发STW，会导致对象引用关系的变更。那么就会产生一些问题。比如A对象被垃圾回收器访问后被标记成了黑色，但是用户线程的执行A对象和H对象产生了引用关系，但是A已经被标记为白色了，不会在被重新访问，那就意味着H对象被误认为垃圾对象了，当H对现象被回收后，那将会有严重的错标问题了。</p>
<p><code>漏标</code><br>
除错标问题外，还有另外一种情况。当扫描到C对象时，由于C对象还有引用对象没有被扫描，此时C对象会被标为灰色。但是由于用户线程的运行，A对象和C对象的引用关系被取消，垃圾收集器会继续由C对象向下进行可达性分析。原则上C对象将会是垃圾对象，但是实际上这些对象仍然会被标记为存活对象，这种情况称为漏标。</p>
<h3 id="24g1垃圾收集器的特点大内存友好可预计的暂停时间">24.G1垃圾收集器的特点，大内存友好，可预计的暂停时间</h3>
<p><code>特点</code></p>
<ol>
<li>并行和并发<br>
并行性: G1在回收期间,可以有多个GC线程同时工作,有效利用多核计算能力。此时用户线程STW<br>
并发性: G1拥有与应用程序交替执行的能力,部分工作可以和应用程序同时执行,因此,一般来说,不会在整个回收阶段发生完全阻塞应用程序的情况</li>
<li>分代收集<br>
从分代上看,G1依然属于分代型垃圾回收器,它会区分年轻代和老年代,年轻代依然有Eden区和Survivor区。但从堆的结构上看,它不要求整个Eden区、年轻代或者老年代都是连续的,也不再坚持固定大小和固定数量。将堆空间分为若干个<code>区域(Region)</code>,这些区域中包含了逻辑上的年轻代和老年代。和之前的各类回收器不同,它同时兼顾年轻代和老年代。</li>
<li>空间整合<br>
G1将内存划分为一个个的region。 内存的回收是以region作为基本单位的。Region之间是复制算法,但整体上实际可看作是标记一压缩(Mark一Compact)算法,两种算法都可以避免内存碎片。这种特性有利于程序长时间运行,分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。</li>
<li>可预测的停顿时间模型</li>
</ol>
<p><code>可预计暂停时间</code><br>
可以通过-XX:MaxGCPauseMillis参数指定预期的停顿时间，G1 GC的停顿预测模型是以衰减均值（Decaying Average）为理论基础来实现的，在垃圾收集过程中，G1收集器会记录每个Region的回收耗时、每个Region记忆集里的脏卡数量等各个可测量的步骤花费的成本，并分析得出平均值、标准偏差、置信度等统计信息。“衰减平均值”是指它会比普通的平均值更容易受到新数据的影响，平均值代表整体平均状态，但衰减平均值更准确地代表“最近的”平均状态。也就是说，Region的统计状态越新越能决定其回收的价值。然后通过这些信息预测现在开始回收的话，由哪些Region组成回收集才可以在不超过期望停顿时间的约束下获得最高的收益。</p>
<h3 id="25如何达到可预测的暂定时间remembered-set">25.如何达到可预测的暂定时间？Remembered Set</h3>
<p>见24。</p>
<p><code>已记忆集合</code><br>
<img src="https://q456qq520.github.io/post-images/1675848326032.png" alt="" loading="lazy"><br>
在串行和并行收集器中，GC通过整堆扫描，来确定对象是否处于可达路径中。然而G1为了避免STW式的整堆扫描，在每个分区记录了一个已记忆集合(Remembered Set)，内部类似一个反向指针，记录引用分区内对象的卡片索引。当要回收该分区时，通过扫描分区的RSet，来确定引用本分区内的对象是否存活，进而确定本分区内的对象存活情况。<br>
事实上，并非所有的引用都需要记录在RSet中，如果一个分区确定需要扫描，那么无需RSet也可以无遗漏的得到引用关系。那么引用源自本分区的对象，当然不用落入RSet中；同时，G1 GC每次都会对年轻代进行整体收集，因此引用源自年轻代的对象，也不需要在RSet中记录。最后只有老年代的分区可能会有RSet记录，这些分区称为拥有RSet分区。</p>
<p>对于年轻代的Region，它的RSet 只保存了来自老年代的引用（因为年轻代的没必要存储啊，自己都要做Minor GC了）而对于老年代的 Region 来说，它的 RSet 也只会保存老年代对它的引用（在G1垃圾收集器，老年代回收之前，都会先对年轻代进行回收，所以没必要保存年轻代的引用</p>
<h3 id="26g1垃圾收集器发生fullgc正常吗">26.G1垃圾收集器发生fullGC正常吗？</h3>
<p>G1的初衷就是要避免Fu1l GC的出现。但是如果上述方式不能正常工作，G1会停止应用程序的执行(Stop-The-World) ，使用单线程的内存回收算法进行垃圾回收，性能会非常差，应用程序停顿时间会很长。<br>
要避免Full GC的发生，一旦发生需要进行调整。什么时候会发生Full GC呢? 比如堆内存太小，当G1在复制存活对象的时候没有空的内存分段可用，则会回退到full gc， 这种情况可以通过增大内存解决。<br>
导致G1Full GC的原因可能有两个: .</p>
<ol>
<li>回收的时候没有足够的to-space来存放晋升的对象</li>
<li>并发处理过程没完成空间就耗尽了</li>
</ol>
<h3 id="27g1垃圾收集器收集过称年轻代gc老年代并发标记过程45混合回收fullgc">27.G1垃圾收集器收集过称，年轻代GC，老年代并发标记过程（45%），混合回收，fullGC</h3>
<p><code>设计理念</code></p>
<ol>
<li>区域划分
<ul>
<li>Region区域：将Java堆划分为多个大小相等的Region，每个Region都可以是新生代、老年代。G1收集器根据角色的不同采用不同的策略去处理。在每个分区内部又被分成了若干个大小为512 Byte卡片(Card)，标识堆内存最小可用粒度所有分区的卡片将会记录在全局卡片表(Global Card Table)中，分配的对象会占用物理上连续的若干个卡片，当查找对分区内对象的引用时便可通过记录卡片来查找该引用对象(见RSet)。每次对内存的回收，都是对指定分区的卡片进行处理。</li>
<li>Humongous区域（Region中的一部分）：专门用来存储大对象（超过Region容量一半的对象即为大对象），超过整个Region区域的会放在多个连续的Humongous区。 G1把Humongous当做老年代的一部分。</li>
</ul>
</li>
<li>垃圾收集<br>
G1的Collector一侧就是两个大部分，并且这两个部分可以相对独立执行。全局并发标记（global concurrent marking）和拷贝存活对象（evacuation）。</li>
</ol>
<p><code>垃圾回收过程</code><br>
<strong>年轻代GC (Young GC)</strong><br>
回收时机<br>
(1). 当Eden空间耗尽时,G1会启动一次年轻代垃圾回收过程<br>
(2). 年轻代垃圾回收只会回收Eden区和Survivor区</p>
<p>回收过程</p>
<ol>
<li>根扫描:一定要考虑remembered Set,看是否有老年代中的对象引用了新生代对象<br>
根是指static变量指向的对象,正在执行的方法调用链条上的局部变量等。根引用连同RSet记录的外部引用作为扫描存活对象的入口)</li>
<li>更新RSet:处理dirty card queue中的card,更新RSet。 此阶段完成后,RSet可以准确的反映老年代对所在的内存分段中对象的引用</li>
<li>处理RSet:识别被老年代对象指向的Eden中的对象,这些被指向的Eden中的对象被认为是存活的对象</li>
<li>复制对象:此阶段,对象树被遍历,Eden区 内存段中存活的对象会被复制到Survivor区中空的内存分段,Survivor区内存段中存活的对象如果年龄未达阈值,年龄会加1,达到阀值会被会被复制到old区中空的内存分段。如果Survivor空间不够,Eden空间的部分数据会直接晋升到老年代空间</li>
<li>处理引用:处理Soft,Weak, Phantom, Final, JNI Weak等引用。最终Eden空间的数据为空,GC停止工作,而目标内存中的对象都是连续存储的,没有碎片,所以复制过程可以达到内存整理的效果,减少碎片。</li>
</ol>
<p><strong>老年代并发标记过程 (Concurrent Marking)</strong></p>
<ol>
<li>初始标记阶段:<br>
标记从根节点直接可达的对象。这个阶段是STW的,并且会触发一次年轻代GC</li>
<li>根区域扫描(Root Region Scanning):<br>
G1 GC扫描Survivor区**直接可达的老年代区域对象,**并标记被引用的对象。这一过程必须在young GC之前完成(YoungGC时,会动Survivor区,所以这一过程必须在young GC之前完成)</li>
<li>并发标记(Concurrent Marking):<br>
在整个堆中进行并发标记(和应用程序并发执行),此过程可能被young GC中断。在并发标记阶段,若发现区域对象中的所有对象都是垃圾,那这个区域会被立即回收。同时,并发标记过程中,会计算每个区域的对象活性(区域中存活对象的比例)。</li>
<li>再次标记(Remark):<br>
由于应用程序持续进行,需要修正上一次的标记结果。是STW的。G1中采用了比CMS更快的初始快照算法:snapshot一at一the一beginning (SATB).</li>
<li>独占清理(cleanup,STW):<br>
计算各个区域的存活对象和GC回收比例,并进行排序,识别可以混合回收的区域。为下阶段做铺垫。是STW的。(这个阶段并不会实际上去做垃圾的收集)</li>
<li>并发清理阶段:识别并清理完全空闲的区域</li>
</ol>
<p><strong>混合回收(Mixed GC)</strong><br>
Mixed GC并不是FullGC,老年代的堆占有率达到参数(-XX:InitiatingHeapOccupancyPercent)设定的值则触发,回收所有的Young和部分Old(根据期望的GC停顿时间确定old区垃圾收集的优先顺序)以及大对象区,正常情况G1的垃圾收集是先做MixedGC,主要使用复制算法,需要把各个region中存活的对象拷贝到别的region里去,拷贝过程中如果发现没有足够的空region能够承载拷贝对象就会触发一次Full GC。</p>
<p>由于老年代中的内存分段默认分8次回收，G1会优先回收垃圾多的内存分段。垃圾占内存分段比例越高的，越会被先回收。并且有一个阈值会决定内存分段是否被回收，-XX:G1MixedGCLiveThresholdPercent，默认为65%，意思是垃圾占内存分段比例要达到65%才会被回收。如果垃圾占比太低，意味着存活的对象占比高，在复制的时候会花费更多的时间。</p>
<p>混合回收并不一定 要进行8次。有一个阈值**-XX :G1HeapWastePercent**,默认值为10%，意思是允许整个堆内存中有10%的空间被浪费，意味着如果发现可以回收的垃圾占堆内存的比例低于10%，则不再进行混合回收。因为GC会花费很多的时间但是回收到的内存却很少。</p>
<h3 id="28工作经验性能有问题如何分析oom怎么处理mat工具arthas工具">28.工作经验，性能有问题如何分析，OOM怎么处理？MAT工具，Arthas工具</h3>
<h2 id="四-框架">四 框架</h2>
<h3 id="1-spring-ioc体系结构设计">1. Spring - IOC体系结构设计</h3>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1675753715033.png" alt="" loading="lazy"></figure>
<h3 id="2-spring-ioc初始化流程">2. Spring IOC初始化流程</h3>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1675753914567.png" alt="" loading="lazy"></figure>
<h3 id="3-spring-ioc中bean的生命周期">3. spring ioc中bean的生命周期</h3>
<p>Spring如何实现将资源配置（以xml配置为例）通过加载，解析，生成BeanDefination并注册到IoC容器中的；容器中存放的是Bean的定义即BeanDefinition放到beanDefinitionMap中，本质上是一个ConcurrentHashMap&lt;String, Object&gt;；并且BeanDefinition接口中包含了这个类的Class信息以及是否是单例等。<br>
<img src="https://q456qq520.github.io/post-images/1675753903296.png" alt="" loading="lazy"></p>
<h3 id="4-beanfactory-和-factorybean-的区别">4. BeanFactory 和 FactoryBean 的区别？</h3>
<p>BeanFactory是接口，提供了IOC容器最基本的形式，给具体的IOC容器的实现提供了规范，它定义了getBean()、containsBean()等管理Bean的通用方法，并不是IOC容器的具体实现，但是Spring容器给出了很多种实现，Spring的容器都是它的具体实现如：</p>
<ul>
<li>DefaultListableBeanFactory</li>
<li>XmlBeanFactory</li>
<li>ApplicationContext</li>
</ul>
<pre><code class="language-java">public interface BeanFactory {

	//对FactoryBean的转义定义，因为如果使用bean的名字检索FactoryBean得到的对象是工厂生成的对象，
	//如果需要得到工厂本身，需要转义
	String FACTORY_BEAN_PREFIX = &quot;&amp;&quot;;

	//根据bean的名字，获取在IOC容器中得到bean实例
	Object getBean(String name) throws BeansException;

	//根据bean的名字和Class类型来得到bean实例，增加了类型安全验证机制。
	&lt;T&gt; T getBean(String name, @Nullable Class&lt;T&gt; requiredType) throws BeansException;

	Object getBean(String name, Object... args) throws BeansException;

	&lt;T&gt; T getBean(Class&lt;T&gt; requiredType) throws BeansException;

	&lt;T&gt; T getBean(Class&lt;T&gt; requiredType, Object... args) throws BeansException;

	//提供对bean的检索，看看是否在IOC容器有这个名字的bean
	boolean containsBean(String name);

	//根据bean名字得到bean实例，并同时判断这个bean是不是单例
	boolean isSingleton(String name) throws NoSuchBeanDefinitionException;

	boolean isPrototype(String name) throws NoSuchBeanDefinitionException;

	boolean isTypeMatch(String name, ResolvableType typeToMatch) throws NoSuchBeanDefinitionException;

	boolean isTypeMatch(String name, @Nullable Class&lt;?&gt; typeToMatch) throws NoSuchBeanDefinitionException;

	//得到bean实例的Class类型
	@Nullable
	Class&lt;?&gt; getType(String name) throws NoSuchBeanDefinitionException;

	//得到bean的别名，如果根据别名检索，那么其原名也会被检索出来
	String[] getAliases(String name);
}
</code></pre>
<p>FactoryBean也是接口，为IOC容器中Bean的实现提供了更加灵活的方式，FactoryBean在IOC容器的基础上给Bean的实现加上了一个简单工厂模式和装饰模式，我们可以在getObject()方法中灵活配置。一般情况下，Spring通过反射机制利用<bean>的class属性指定实现类实例化Bean，在某些情况下，实例化Bean过程比较复杂，如果按照传统的方式，则需要在<bean>中提供大量的配置信息。配置方式的灵活性是受限的，这时采用编码的方式可能会得到一个简单的方案。Spring为此提供了一个org.springframework.bean.factory.FactoryBean的工厂类接口，用户可以通过实现该接口定制实例化Bean的逻辑。</p>
<p>BeanFactory是个Factory，也就是IOC容器或对象工厂，FactoryBean是个Bean。在Spring中，所有的Bean都是由BeanFactory(也就是IOC容器)来进行管理的。但对FactoryBean而言，这个Bean不是简单的Bean，而是一个能生产或者修饰对象生成的工厂Bean。</p>
<pre><code class="language-java">public interface FactoryBean&lt;T&gt; {

	//从工厂中获取bean
	@Nullable
	T getObject() throws Exception;

	//获取Bean工厂创建的对象的类型
	@Nullable
	Class&lt;?&gt; getObjectType();

	//Bean工厂创建的对象是否是单例模式
	default boolean isSingleton() {
		return true;
	}
}
</code></pre>
<p>不同于普通Bean的是：它是实现了FactoryBean<T>接口的Bean，根据该Bean的ID从BeanFactory中获取的实际上是FactoryBean的getObject()返回的对象，而不是FactoryBean本身，如果要获取FactoryBean对象，请在id前面加一个&amp;符号来获取。</p>
<p>他们两个都是个工厂，但FactoryBean本质上还是一个Bean，也归BeanFactory管理。BeanFactory是Spring容器的顶层接口，FactoryBean更类似于用户自定义的工厂接口。</p>
<h3 id="5-springboot应用启动流程有哪些扩展点">5. springboot应用启动流程，有哪些扩展点</h3>
<h4 id="51-启动流程">5.1 启动流程</h4>
<ol>
<li>初始化spirng</li>
</ol>
<h3 id="6-value之类的标签是如何实现的">6. @Value之类的标签是如何实现的</h3>
<h3 id="7-spring的动态代理实现有哪些方式从源码来看是如何实现的">7. spring的动态代理实现有哪些方式？从源码来看是如何实现的？</h3>
<h3 id="8-mybatis一级缓存是如何实现的sqlsession级别">8. Mybatis一级缓存是如何实现的？SqlSession级别</h3>
<h3 id="9-mybatis声明interface加上注解即可被service注入使用是怎么实现的">9. Mybatis声明interface加上注解即可被service注入使用，是怎么实现的</h3>
<h2 id="五-中间件">五 中间件</h2>
<h3 id="1-zk的使用场景">1. zk的使用场景</h3>
<h3 id="2-zk节点类型有哪些有哪些角色-持久化临时leaderfollowobserver">2. zk节点类型有哪些，有哪些角色。持久化/临时，leader，follow，observer</h3>
<h3 id="3zk的恢复模式是如何工作的-按顺序启动三个zk节点他们是如何选出leader的">3.zk的恢复模式，是如何工作的。按顺序启动三个zk节点，他们是如何选出leader的</h3>
<h3 id="4zk的广播模式是如何工作的-一个写入请求是如何工作的">4.zk的广播模式，是如何工作的。一个写入请求是如何工作的</h3>
<h3 id="5mq的使用场景">5.mq的使用场景</h3>
<h3 id="6kafka为什么这么快-批量压缩磁盘顺序写零拷贝">6.kafka为什么这么快。批量，压缩，磁盘顺序写，零拷贝</h3>
<h3 id="7kafka会丢消息吗哪些场景下会存在">7.kafka会丢消息吗？哪些场景下会存在？</h3>
<h3 id="8kafka会重复消费消息吗哪些场景下会存在">8.kafka会重复消费消息吗？哪些场景下会存在？</h3>
<h3 id="9kafka的部署结构">9.kafka的部署结构</h3>
<h3 id="10kafka生产者发送消息模式同步-异步-发后既忘-失败重试">10.kafka生产者，发送消息模式：同步、异步、发后既忘。失败重试</h3>
<h3 id="11kafka生产者如何确定分区">11.kafka生产者，如何确定分区</h3>
<h3 id="12kafka生产者线程模型">12.kafka生产者，线程模型</h3>
<h3 id="13kafka消费者如何确定分区rebalance如何处理">13.kafka消费者，如何确定分区，rebalance如何处理？</h3>
<h3 id="14kafka消费者位移提交自动-手动-同步-异步">14.kafka消费者，位移提交，自动、手动、同步、异步</h3>
<h3 id="15kafka-broker如何保证消息存储持久化">15.kafka broker，如何保证消息存储持久化</h3>
<h3 id="16kafka-broker存储结构logindextimeindex">16.kafka broker，存储结构，log，index，timeIndex</h3>
<h3 id="17kafka-broker是如何保证不丢数据的isr副本管理高水位线">17.kafka broker，是如何保证不丢数据的，ISR副本管理，高水位线</h3>
<h3 id="18kafka-broker优先副本有什么作用是如何使用的">18.kafka broker，优先副本有什么作用？是如何使用的</h3>
<h3 id="19rocketmq为什么这么快-磁盘顺序写零拷贝">19.rocketMq为什么这么快。磁盘顺序写，零拷贝</h3>
<h3 id="20rocketmq会丢消息吗哪些场景下会存在">20.rocketMq会丢消息吗？哪些场景下会存在？</h3>
<h3 id="21rocketmq会重复消费消息吗哪些场景下会存在">21.rocketMq会重复消费消息吗？哪些场景下会存在？</h3>
<h3 id="22rocketmq的部署结构name-servce之间部通讯">22.rocketMq的部署结构，Name Servce之间部通讯</h3>
<h3 id="23rocketmq生产者发送消息模式同步-异步-单向">23.rocketMq生产者，发送消息模式：同步、异步、单向。</h3>
<h3 id="24rocketmq消费者如何确定分区rebalance如何处理">24.	rocketMq消费者，如何确定分区，rebalance如何处理？</h3>
<h3 id="25rocketmq消费者tag是如何实现的">25.	rocketMq消费者，tag是如何实现的</h3>
<h3 id="26rocketmq消费者顺序消息消费失败如何处理">26.rocketMq消费者，顺序消息消费失败如何处理？</h3>
<h3 id="27rocketmq消费者非顺序消息消费失败如何处理重试队列retryconsumergroupconsumergroup">27.rocketMq消费者，非顺序消息消费失败如何处理？重试队列，%RETRY%consumerGroup@consumerGroup</h3>
<h3 id="28rocketmq-broker延迟队列如何实现schedule_topic_xxxx">28.rocketMq broker，延迟队列如何实现，SCHEDULE_TOPIC_XXXX</h3>
<h3 id="29rocketmq-broker事务消息是如何处理">29.	rocketMq broker，事务消息是如何处理？</h3>
<h3 id="30rocketmq-broker存储结构commitlogconsumequeueindex">30.rocketMq broker，存储结构，commitLog，consumequeue，index</h3>
<h3 id="31rocketmq-broker如何保证消息存储持久化集群模式同步双写异步刷盘">31.	rocketMq broker，如何保证消息存储持久化，集群模式，同步双写（异步刷盘）</h3>
<h3 id="32kafka和rocketmq有啥区别">32.kafka和rocketmq有啥区别？</h3>
<h3 id="33rocketmq发现丢消息了怎么办">33.rocketmq发现丢消息了怎么办？</h3>
<h3 id="34redisredis的使用场景redis为什么这么快">34.[redis]Redis的使用场景，redis为什么这么快？</h3>
<h3 id="35rediskeys-是如何工作的scan是如何工作的">35.[redis]keys * 是如何工作的，scan是如何工作的</h3>
<h3 id="36redisredis是单线程的吗处理过期key流程-hash渐进式扩容-内存淘汰-unlink">36.[redis]Redis是单线程的吗？处理过期key流程、hash渐进式扩容、内存淘汰、UNLINK、</h3>
<h3 id="37redisredis46-线程模型文件事件处理器">37.[redis]Redis4/6 线程模型（文件事件处理器）</h3>
<h3 id="38redis数据结构string-list-hash-set-zset-位图-hyperlogloguv-布隆过滤器">38.[redis]数据结构：String、List、Hash、Set、ZSet、位图、HyperLogLog(uv)、布隆过滤器</h3>
<h3 id="39redis内部编码sdsintlinkedlistziplistquicklistintsetskiplistdict">39.[redis]内部编码：sds，int，linkedList，ziplist，quickList，intset，skiplist，dict</h3>
<h3 id="40redis持久化方式aof-rdb-混合">40.[redis]持久化方式：AOF、RDB、混合</h3>
<h3 id="41redis持久化方式aof-rdb-优缺点原理">41.[redis]持久化方式：AOF、RDB 优缺点，原理</h3>
<h3 id="42redis过期策略定期删除惰性删除从库的过期策略">42.[redis]过期策略：定期删除，惰性删除，从库的过期策略</h3>
<h3 id="43redis内存淘汰策略拒绝有过期时间无过期时间随机-快过期的">43.[redis]内存淘汰策略：拒绝，有过期时间/无过期时间；随机、快过期的</h3>
<h3 id="44redis部署模式-主从哨兵集群模式">44.[redis]部署模式。主从，哨兵，集群模式</h3>
<h3 id="45redis部署模式-主从的同步策略增量同步全量同步">45.[redis]部署模式。主从的同步策略，增量同步\全量同步</h3>
<h3 id="46redis部署模式-哨兵模式的优点是如何工作的">46.[redis]部署模式。哨兵模式的优点，是如何工作的？</h3>
<h3 id="47redis部署模式-集群模式的优点是如何分片的">47.[redis]部署模式。集群模式的优点，是如何分片的？</h3>
<h3 id="48redishash是如何扩容的">48.[redis]hash是如何扩容的？</h3>
<h3 id="49redis性能有问题如何分析缓存一致性问题删除大key会很慢吗">49.[redis]性能有问题如何分析，缓存一致性问题，删除大key会很慢吗？</h3>
<h2 id="六-mysql">六 mysql</h2>
<h2 id="七-算法-工具">七 算法、工具</h2>
<h2 id="八-设计">八 设计</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《从根儿上理解MySQL》读书笔记(三)]]></title>
        <id>https://q456qq520.github.io/post/lesslesscong-gen-er-shang-li-jie-mysqlgreatergreater-du-shu-bi-ji-san/</id>
        <link href="https://q456qq520.github.io/post/lesslesscong-gen-er-shang-li-jie-mysqlgreatergreater-du-shu-bi-ji-san/">
        </link>
        <updated>2023-01-13T10:14:23.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="第10章-条条大路通罗马-单表访问方法">第10章 条条大路通罗马-单表访问方法</h2>
<p>MySQL Server有一个称为查询优化器的模块，一条查询语句进行语法解析之后就会被交给查询优化器来进行优化，优化的结果就是生成一个所谓的执行计划，这个执行计划表明了应该使用哪些索引进行查询，表之间的连接顺序是什么样的，最后会按照执行计划中的步骤调用存储引擎提供的方法来真正的执行查询，并将查询结果返回给用户。不过查询优化这个主题有点儿大，在学会跑之前还得先学会走，所以本章先来看看MySQL怎么执行单表查询（就是FROM子句后边只有一个表，最简单的那种查询～）。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="第10章-条条大路通罗马-单表访问方法">第10章 条条大路通罗马-单表访问方法</h2>
<p>MySQL Server有一个称为查询优化器的模块，一条查询语句进行语法解析之后就会被交给查询优化器来进行优化，优化的结果就是生成一个所谓的执行计划，这个执行计划表明了应该使用哪些索引进行查询，表之间的连接顺序是什么样的，最后会按照执行计划中的步骤调用存储引擎提供的方法来真正的执行查询，并将查询结果返回给用户。不过查询优化这个主题有点儿大，在学会跑之前还得先学会走，所以本章先来看看MySQL怎么执行单表查询（就是FROM子句后边只有一个表，最简单的那种查询～）。</p>
<!-- more -->
<pre><code class="language-mysql">CREATE TABLE single_table (
    id INT NOT NULL AUTO_INCREMENT,
    key1 VARCHAR(100),
    key2 INT,
    key3 VARCHAR(100),
    key_part1 VARCHAR(100),
    key_part2 VARCHAR(100),
    key_part3 VARCHAR(100),
    common_field VARCHAR(100),
    PRIMARY KEY (id),
    KEY idx_key1 (key1),
    UNIQUE KEY idx_key2 (key2),
    KEY idx_key3 (key3),
    KEY idx_key_part(key_part1, key_part2, key_part3)
) Engine=InnoDB CHARSET=utf8;
</code></pre>
<p>我们为这个single_table表建立了1个聚簇索引和4个二级索引。然后我们需要为这个表插入10000行记录。</p>
<h3 id="101-访问方法access-method的概念">10.1 访问方法（access method）的概念</h3>
<p>MySQL把查询的执行方式大致分为下面两种：</p>
<ol>
<li>
<p>使用全表扫描进行查询<br>
  这种执行方式很好理解，就是把表的每一行记录都扫一遍嘛，把符合搜索条件的记录加入到结果集就完了。不管是什么查询都可以使用这种方式执行，当然，这种也是最笨的执行方式。</p>
</li>
<li>
<p>使用索引进行查询<br>
  因为直接使用全表扫描的方式执行查询要遍历好多记录，所以代价可能太大了。如果查询语句中的搜索条件可以使用到某个索引，那直接使用索引来执行查询可能会加快查询执行的时间。使用索引来执行查询的方式五花八门，又可以细分为许多种类：</p>
<ul>
<li>针对主键或唯一二级索引的等值查询</li>
<li>针对普通二级索引的等值查询</li>
<li>针对索引列的范围查询</li>
<li>直接扫描整个索引</li>
</ul>
</li>
</ol>
<p>把MySQL执行查询语句的方式称之为<code>访问方法</code>或者<code>访问类型</code>。同一个查询语句可能可以使用多种不同的访问方法来执行，虽然最后的查询结果都是一样的，但是执行的时间可能差老远了，下面细细道来各种访问方法的具体内容。</p>
<ol>
<li>const<br>
  有的时候我们可以通过主键列来定位一条记录，比方说这个查询：</li>
</ol>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE id = 1438;
</code></pre>
<p>MySQL会直接利用主键值在聚簇索引中定位对应的用户记录，就像这样：<br>
<img src="https://q456qq520.github.io/post-images/1673839553874.png" alt="" loading="lazy"></p>
<p>我们忽略掉了页的结构，直接把所有的叶子节点的记录都放在一起展示，而且记录中只展示我们关心的索引列，对于single_table表的聚簇索引来说，展示的就是id列。我们想突出的重点就是：B+树叶子节点中的记录是按照索引列排序的，对于的聚簇索引来说，它对应的B+树叶子节点中的记录就是按照id列排序的。所以这样根据主键值定位一条记录的速度贼快。类似的，我们根据唯一二级索引列来定位一条记录的速度也是贼快的，比如下面这个查询：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key2 = 3841;
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1673839657085.png" alt="" loading="lazy"></figure>
<p>可以看到这个查询的执行分两步，第一步先从idx_key2对应的B+树索引中根据key2列与常数的等值比较条件定位到一条二级索引记录，然后再根据该记录的id值到聚簇索引中获取到完整的用户记录。</p>
<p>把这种通过主键或者唯一二级索引列来定位一条记录的访问方法定义为：const，意思是常数级别的，代价是可以忽略不计的。不过这种const访问方法只能在主键列或者唯一二级索引列和一个常数进行等值比较时才有效，如果主键或者唯一二级索引是由多个列构成的话，索引中的每一个列都需要与常数进行等值比较，这个const访问方法才有效。</p>
<p>对于唯一二级索引来说，查询该列为NULL值的情况比较特殊，比如这样：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key2 IS NULL;
</code></pre>
<p>因为唯一二级索引列并不限制 NULL 值的数量，所以上述语句可能访问到多条记录，也就是说 上面这个语句不可以使用const访问方法来执行。</p>
<ol start="2">
<li>ref<br>
 有时候我们对某个普通的二级索引列与常数进行等值比较，比如这样：</li>
</ol>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key1 = 'abc';
</code></pre>
<p>对于这个查询，我们当然可以选择全表扫描来逐一对比搜索条件是否满足要求，我们也可以先使用二级索引找到对应记录的id值，然后再回表到聚簇索引中查找完整的用户记录。由于普通二级索引并不限制索引列值的唯一性，所以可能找到多条对应的记录，也就是说使用二级索引来执行查询的代价取决于等值匹配到的二级索引记录条数。如果匹配的记录较少，则回表的代价还是比较低的，所以MySQL可能选择使用索引而不是全表扫描的方式来执行查询。设计MySQL的大佬就把这种搜索条件为二级索引列与常数等值比较，采用二级索引来执行查询的访问方法称为：<code>ref</code>。我们看一下采用ref访问方法执行查询的图示：</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1673841047507.png" alt="" loading="lazy"></figure>
<p>从图示中可以看出，对于普通的二级索引来说，通过索引列进行等值比较后可能匹配到多条连续的记录，而不是像主键或者唯一二级索引那样最多只能匹配1条记录，所以这种ref访问方法比const差了那么一丢丢，但是在二级索引等值比较时匹配的记录数较少时的效率还是很高的（如果匹配的二级索引记录太多那么回表的成本就太大了），不过需要注意下面两种情况：</p>
<pre><code>-  二级索引列值为NULL的情况
</code></pre>
<p>不论是普通的二级索引，还是唯一二级索引，它们的索引列对包含NULL值的数量并不限制，所以我们采用key IS NULL这种形式的搜索条件最多只能使用ref的访问方法，而不是const的访问方法。<br>
- 对于某个包含多个索引列的二级索引来说，只要是最左边的连续索引列是与常数的等值比较就可能采用ref的访问方法，比方说下面这几个查询：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key_part1 = 'god like';

SELECT * FROM single_table WHERE key_part1 = 'god like' AND key_part2 = 'legendary';

SELECT * FROM single_table WHERE key_part1 = 'god like' AND key_part2 = 'legendary' AND key_part3 = 'penta kill';
</code></pre>
<p>但是如果最左边的连续索引列并不全部是等值比较的话，它的访问方法就不能称为ref了，比方说这样：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key_part1 = 'god like' AND key_part2 &gt; 'legendary';
</code></pre>
<ol start="3">
<li>ref_or_null<br>
有时候我们不仅想找出某个二级索引列的值等于某个常数的记录，还想把该列的值为NULL的记录也找出来，就像下面这个查询：</li>
</ol>
<pre><code class="language-mysql">SELECT * FROM single_demo WHERE key1 = 'abc' OR key1 IS NULL;
</code></pre>
<p>当使用二级索引而不是全表扫描的方式执行该查询时，这种类型的查询使用的访问方法就称为ref_or_null，这个ref_or_null访问方法的执行过程同上面基本类似。相当于先分别从idx_key1索引对应的B+树中找出key1 IS NULL和key1 = 'abc'的两个连续的记录范围，然后根据这些二级索引记录中的id值再回表查找完整的用户记录。</p>
<ol start="4">
<li>range</li>
</ol>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key2 IN (1438, 6328) OR (key2 &gt;= 38 AND key2 &lt;= 79);
</code></pre>
<p>我们当然还可以使用全表扫描的方式来执行这个查询，不过也可以使用二级索引 + 回表的方式执行，如果采用二级索引 + 回表的方式来执行的话，那么此时的搜索条件就不只是要求索引列与常数的等值匹配了，而是索引列需要匹配某个或某些范围的值，在本查询中key2列的值只要匹配下列3个范围中的任何一个就算是匹配成功了：<br>
- key2的值是1438<br>
- key2的值是6328<br>
- key2的值在38和79之间。<br>
把这种利用索引进行范围匹配的访问方法称之为：<code>range</code>。</p>
<ol start="5">
<li>index</li>
</ol>
<pre><code class="language-mysql">SELECT key_part1, key_part2, key_part3 FROM single_table WHERE key_part2 = 'abc';
</code></pre>
<p>由于key_part2并不是联合索引idx_key_part最左索引列，所以我们无法使用ref或者range访问方法来执行这个语句。但是这个查询符合下面这两个条件：</p>
<pre><code>- 它的查询列表只有3个列：key_part1, key_part2, key_part3，而索引idx_key_part又包含这三个列。
- 搜索条件中只有key_part2列。这个列也包含在索引idx_key_part中。
</code></pre>
<p>也就是说我们可以直接通过遍历idx_key_part索引的叶子节点的记录来比较key_part2 = 'abc'这个条件是否成立，把匹配成功的二级索引记录的key_part1, key_part2, key_part3列的值直接加到结果集中就行了。由于二级索引记录比聚簇索记录小的多（聚簇索引记录要存储所有用户定义的列以及所谓的隐藏列，而二级索引记录只需要存放索引列和主键），而且这个过程也不用进行回表操作，所以直接遍历二级索引比直接遍历聚簇索引的成本要小很多，MySQL就把这种采用遍历二级索引记录的执行方式称之为：<code>index</code>。</p>
<ol start="6">
<li>all<br>
最直接的查询执行方式就是我们已经提了无数遍的全表扫描，对于InnoDB表来说也就是直接扫描聚簇索引，MySQL把这种使用全表扫描执行查询的方式称之为：<code>all</code>。</li>
</ol>
<h3 id="102-注意事项">10.2 注意事项</h3>
<h4 id="1021-重温-二级索引-回表">10.2.1 重温 二级索引 + 回表</h4>
<p>一般情况下只能利用单个二级索引执行查询，比方说下面的这个查询：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key1 = 'abc' AND key2 &gt; 1000;
</code></pre>
<p>查询优化器会识别到这个查询中的两个搜索条件：<br>
- key1 = 'abc'<br>
- key2 &gt; 1000</p>
<p>优化器一般会根据single_table表的统计数据来判断到底使用哪个条件到对应的二级索引中查询扫描的行数会更少，选择那个扫描行数较少的条件到对应的二级索引中查询。然后将从该二级索引中查询到的结果经过回表得到完整的用户记录后再根据其余的WHERE条件过滤记录。</p>
<p>一般来说，等值查找比范围查找需要扫描的行数更少（也就是ref的访问方法一般比range好，但这也不总是一定的，也可能采用ref访问方法的那个索引列的值为特定值的行数特别多），所以这里假设优化器决定使用idx_key1索引进行查询，那么整个查询过程可以分为两个步骤：</p>
<pre><code>- 步骤1：使用二级索引定位记录的阶段，也就是根据条件key1 = 'abc'从idx_key1索引代表的B+树中找到对应的二级索引记录。
- 步骤2：回表阶段，也就是根据上一步骤中找到的记录的主键值进行回表操作，也就是到聚簇索引中找到对应的完整的用户记录，再根据条件key2 &gt; 1000到完整的用户记录继续过滤。将最终符合过滤条件的记录返回给用户。
</code></pre>
<p>这里需要特别提醒大家的一点是，因为二级索引的节点中的记录只包含索引列和主键，所以在步骤1中使用idx_key1索引进行查询时只会用到与key1列有关的搜索条件，其余条件，比如key2 &gt; 1000这个条件在步骤1中是用不到的，只有在步骤2完成回表操作后才能继续针对完整的用户记录中继续过滤。</p>
<h4 id="1022-明确range访问方法使用的范围区间">10.2.2 明确range访问方法使用的范围区间</h4>
<p>其实对于B+树索引来说，只要索引列和常数使用<code>=、&lt;=&gt;、IN、NOT IN、IS NULL、IS NOT NULL、&gt;、&lt;、&gt;=、&lt;=、BETWEEN、!=（不等于也可以写成&lt;&gt;）</code>或者<code>LIKE</code>操作符连接起来，就可以产生一个所谓的区间。</p>
<p>当我们想使用range访问方法来执行一个查询语句时，重点就是找出该查询可用的索引以及这些索引对应的范围区间。下面分两种情况看一下怎么从由AND或OR组成的复杂搜索条件中提取出正确的范围区间。</p>
<h5 id="所有搜索条件都可以使用某个索引的情况">所有搜索条件都可以使用某个索引的情况</h5>
<p>有时候每个搜索条件都可以使用到某个索引，比如下面这个查询语句：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key2 &gt; 100 AND key2 &gt; 200;
</code></pre>
<p>这个查询中的搜索条件都可以使用到key2，也就是说每个搜索条件都对应着一个idx_key2的范围区间。这两个小的搜索条件使用AND连接起来，也就是要取两个范围区间的交集，在我们使用range访问方法执行查询时，使用的idx_key2索引的范围区间的确定过程就如下图所示：<br>
<img src="https://q456qq520.github.io/post-images/1673857794078.png" alt="" loading="lazy"></p>
<p>key2 &gt; 100和key2 &gt; 200交集当然就是key2 &gt; 200了，也就是说上面这个查询使用idx_key2的范围区间就是(200, +∞)。</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key2 &gt; 100 OR key2 &gt; 200;
</code></pre>
<p>上面这个查询使用idx_key2的范围区间就是(100， +∞)。</p>
<h5 id="有的搜索条件无法使用索引的情况">有的搜索条件无法使用索引的情况</h5>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key2 &gt; 100 AND common_field = 'abc';
</code></pre>
<p>这个查询语句中能利用的索引只有idx_key2一个，而idx_key2这个二级索引的记录中又不包含common_field这个字段，所以在使用二级索引idx_key2定位记录的阶段用不到common_field = 'abc'这个条件，这个条件是在回表获取了完整的用户记录后才使用的，而范围区间是为了到索引中取记录中提出的概念，所以在确定范围区间的时候不需要考虑common_field = 'abc'这个条件，我们在为某个索引确定范围区间的时候只需要把用不到相关索引的搜索条件替换为TRUE就好了。</p>
<p>也就是说上面那个查询使用idx_key2的范围区间就是：(100, +∞)。</p>
<p>再来看一下使用OR的情况：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key2 &gt; 100 OR common_field = 'abc';
</code></pre>
<p>化简后：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key2 &gt; 100 OR TRUE;
SELECT * FROM single_table WHERE TRUE;
</code></pre>
<p>这也就说说明如果我们强制使用idx_key2执行查询的话，对应的范围区间就是(-∞, +∞)，也就是需要将全部二级索引的记录进行回表，这个代价肯定比直接全表扫描都大了。也就是说一个使用到索引的搜索条件和没有使用该索引的搜索条件使用OR连接起来后是无法使用该索引的。</p>
<blockquote>
<p>小贴士：之所以把用不到索引的搜索条件替换为TRUE，是因为我们不打算使用这些条件进行在该索引上进行过滤，所以不管索引的记录满不满足这些条件，我们都把它们选取出来，待到之后回表的时候再使用它们过滤。</p>
</blockquote>
<h5 id="复杂搜索条件下找出范围匹配的区间">复杂搜索条件下找出范围匹配的区间</h5>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE 
        (key1 &gt; 'xyz' AND key2 = 748 ) OR
        (key1 &lt; 'abc' AND key1 &gt; 'lmn') OR
        (key1 LIKE '%suf' AND key1 &gt; 'zzz' AND (key2 &lt; 8000 OR common_field = 'abc')) ;
</code></pre>
<ol>
<li>
<p>首先查看WHERE子句中的搜索条件都涉及到了哪些列，哪些列可能使用到索引。<br>
  这个查询的搜索条件涉及到了key1、key2、common_field这3个列，然后key1列有普通的二级索引idx_key1，key2列有唯一二级索引idx_key2。</p>
</li>
<li>
<p>对于那些可能用到的索引，分析它们的范围区间。<br>
假设我们使用idx_key1执行查询，我们需要把那些用不到该索引的搜索条件暂时移除掉，移除方法也简单，直接把它们替换为TRUE就好了。上面的查询中除了有关key2和common_field列不能使用到idx_key1索引外，key1 LIKE '%suf'也使用不到索引，所以把这些搜索条件替换为TRUE之后的样子就是这样：</p>
</li>
</ol>
<pre><code class="language-mysql">(key1 &gt; 'xyz' AND TRUE ) OR
(key1 &lt; 'abc' AND key1 &gt; 'lmn') OR
(TRUE AND key1 &gt; 'zzz' AND (TRUE OR TRUE))

(key1 &gt; 'xyz') OR
(key1 &lt; 'abc' AND key1 &gt; 'lmn') OR
(key1 &gt; 'zzz')

# 替换掉永远为TRUE或FALSE的条件,因为符合key1 &lt; 'abc' AND key1 &gt; 'lmn'永远为FALSE
(key1 &gt; 'xyz') OR (key1 &gt; 'zzz')
</code></pre>
<p>key1 &gt; 'xyz'和key1 &gt; 'zzz'之间使用OR操作符连接起来的，意味着要取并集，所以最终的结果化简的到的区间就是：key1 &gt; xyz。也就是说：上面那个有一坨搜索条件的查询语句如果使用 idx_key1 索引执行查询的话，需要把满足key1 &gt; xyz的二级索引记录都取出来，然后拿着这些记录的id再进行回表，得到完整的用户记录之后再使用其他的搜索条件进行过滤。</p>
<p>假设我们使用idx_key2执行查询同理，我们需要把那些用不到该索引的搜索条件暂时使用TRUE条件替换掉，其中有关key1和common_field的搜索条件都需要被替换掉。</p>
<h3 id="103-索引合并">10.3 索引合并</h3>
<p>MySQL在一般情况下执行一个查询时最多只会用到单个二级索引，但不是还有特殊情况么，在这些特殊情况下也可能在一个查询中使用到多个二级索引，设计MySQL的大佬把这种使用到多个索引来完成一次查询的执行方法称之为：<code>index merge</code>，具体的索引合并算法有下面三种。</p>
<h4 id="1031-intersection合并">10.3.1 Intersection合并</h4>
<p>Intersection翻译过来的意思是交集。这里是说某个查询可以使用多个二级索引，将从多个二级索引中查询到的结果取交集，比方说下面这个查询：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key1 = 'a' AND key3 = 'b';
</code></pre>
<p>假设这个查询使用Intersection合并的方式执行的话，那这个过程就是这样的：</p>
<ol>
<li>从idx_key1二级索引对应的B+树中取出key1 = 'a'的相关记录。</li>
<li>从idx_key3二级索引对应的B+树中取出key3 = 'b'的相关记录。</li>
<li>二级索引的记录都是由索引列 + 主键构成的，所以我们可以计算出这两个结果集中id值的交集。</li>
<li>按照上一步生成的id值列表进行回表操作，也就是从聚簇索引中把指定id值的完整用户记录取出来，返回给用户</li>
</ol>
<blockquote>
<p>虽然读取多个二级索引比读取一个二级索引消耗性能，但是读取二级索引的操作是顺序I/O，而回表操作是随机I/O，所以如果只读取一个二级索引时需要回表的记录数特别多，而读取多个二级索引之后取交集的记录数非常少，当节省的因为回表而造成的性能损耗比访问多个二级索引带来的性能损耗更高时，读取多个二级索引后取交集比只读取一个二级索引的成本更低。</p>
</blockquote>
<p>MySQL在某些特定的情况下才可能会使用到Intersection索引合并：<br>
- 情况一：二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只匹配部分列的情况。<br>
- 情况二：主键列可以是范围匹配</p>
<p>对于InnoDB的二级索引来说，记录先是按照索引列进行排序，如果该二级索引是一个联合索引，那么会按照联合索引中的各个列依次排序。而二级索引的用户记录是由索引列 + 主键构成的，二级索引列的值相同的记录可能会有好多条，这些索引列的值相同的记录又是按照主键的值进行排序的。所以重点来了，之所以在二级索引列都是等值匹配的情况下才可能使用Intersection索引合并，是因为<mark>只有在这种情况下根据二级索引查询出的结果集是按照主键值排序的。</mark></p>
<p>另外，不仅是多个二级索引之间可以采用Intersection索引合并，索引合并也可以有聚簇索引参加，也就是我们上面写的情况二：在搜索条件中有主键的范围匹配的情况下也可以使用Intersection索引合并索引合并。为什么主键这就可以范围匹配了？还是得回到应用场景里，比如看下面这个查询：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key1 = 'a' AND id &gt; 100;
</code></pre>
<p>假设这个查询可以采用Intersection索引合并，我们理所当然的以为这个查询会分别按照id &gt; 100这个条件从聚簇索引中获取一些记录，在通过key1 = 'a'这个条件从idx_key1二级索引中获取一些记录，然后再求交集，其实这样就把问题复杂化了，没必要从聚簇索引中获取一次记录。别忘了二级索引的记录中都带有主键值的，所以可以在从idx_key1中获取到的主键值上直接运用条件id &gt; 100过滤就行了，这样多简单。所以涉及主键的搜索条件只不过是为了从别的二级索引得到的结果集中过滤记录罢了，是不是等值匹配不重要。</p>
<p>当然，上面说的情况一和情况二只是发生Intersection索引合并的必要条件，不是充分条件。也就是说即使情况一、情况二成立，也不一定发生Intersection索引合并，这得看优化器的心情。优化器只有在单独根据搜索条件从某个二级索引中获取的记录数太多，导致回表开销太大，而通过Intersection索引合并后需要回表的记录数大大减少时才会使用Intersection索引合并。</p>
<h4 id="1032-union合并">10.3.2 Union合并</h4>
<p>我们在写查询语句时经常想把既符合某个搜索条件的记录取出来，也把符合另外的某个搜索条件的记录取出来，我们说这些不同的搜索条件之间是OR关系。有时候OR关系的不同搜索条件会使用到不同的索引，比方说这样：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key1 = 'a' OR key3 = 'b'
</code></pre>
<p>Intersection是交集的意思，这适用于使用不同索引的搜索条件之间使用AND连接起来的情况；Union是并集的意思，适用于使用不同索引的搜索条件之间使用OR连接起来的情况。与Intersection索引合并类似，MySQL在某些特定的情况下才可能会使用到Union索引合并：</p>
<ol>
<li>情况一：二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只出现匹配部分列的情况。<br>
  比方说下面这个查询可能用到idx_key1和idx_key_part这两个二级索引进行Union索引合并的操作：</li>
</ol>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key1 = 'a' OR ( key_part1 = 'a' AND key_part2 = 'b' AND key_part3 = 'c');
</code></pre>
<p>而下面这两个查询就不能进行Union索引合并：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key1 &gt; 'a' OR (key_part1 = 'a' AND key_part2 = 'b' AND key_part3 = 'c');

SELECT * FROM single_table WHERE key1 = 'a' OR key_part1 = 'a';
</code></pre>
<p>第一个查询是因为对key1进行了范围匹配，第二个查询是因为联合索引idx_key_part中的key_part2列并没有出现在搜索条件中，所以这两个查询不能进行Union索引合并。</p>
<ol start="2">
<li>
<p>情况二：主键列可以是范围匹配</p>
</li>
<li>
<p>情况三：使用Intersection索引合并的搜索条件<br>
  这种情况其实也挺好理解，就是搜索条件的某些部分使用Intersection索引合并的方式得到的主键集合和其他方式得到的主键集合取交集，比方说这个查询：</p>
</li>
</ol>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key_part1 = 'a' AND key_part2 = 'b' AND key_part3 = 'c' OR (key1 = 'a' AND key3 = 'b');
</code></pre>
<p>优化器可能采用这样的方式来执行这个查询：</p>
<ol>
<li>先按照搜索条件key1 = 'a' AND key3 = 'b'从索引idx_key1和idx_key3中使用Intersection索引合并的方式得到一个主键集合。</li>
<li>再按照搜索条件key_part1 = 'a' AND key_part2 = 'b' AND key_part3 = 'c'从联合索引idx_key_part中得到另一个主键集合。</li>
<li>采用Union索引合并的方式把上述两个主键集合取并集，然后进行回表操作，将结果返回给用户。</li>
</ol>
<p>当然，查询条件符合了这些情况也不一定就会采用Union索引合并，也得看优化器的心情。优化器只有在单独根据搜索条件从某个二级索引中获取的记录数比较少，通过Union索引合并后进行访问的代价比全表扫描更小时才会使用Union索引合并。</p>
<h4 id="1033-sort-union合并">10.3.3 Sort-Union合并</h4>
<p>Union索引合并的使用条件太苛刻，必须保证各个二级索引列在进行等值匹配的条件下才可能被用到，比方说下面这个查询就无法使用到Union索引合并：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key1 &lt; 'a' OR key3 &gt; 'z'
</code></pre>
<p>这是因为根据key1 &lt; 'a'从idx_key1索引中获取的二级索引记录的主键值不是排好序的，根据key3 &gt; 'z'从idx_key3索引中获取的二级索引记录的主键值也不是排好序的，但是key1 &lt; 'a'和key3 &gt; 'z'这两个条件又特别让我们动心，所以我们可以这样：</p>
<ol>
<li>先根据key1 &lt; 'a'条件从idx_key1二级索引总获取记录，并按照记录的主键值进行排序</li>
<li>再根据key3 &gt; 'z'条件从idx_key3二级索引总获取记录，并按照记录的主键值进行排序</li>
<li>因为上述的两个二级索引主键值都是排好序的，剩下的操作和Union索引合并方式就一样了。</li>
</ol>
<p>我们把上述这种先按照二级索引记录的主键值进行排序，之后按照Union索引合并方式执行的方式称之为<code>Sort-Union索引合并</code>，很显然，这种Sort-Union索引合并比单纯的Union索引合并多了一步对二级索引记录的主键值排序的过程。</p>
<blockquote>
<p>小贴士：为什么有Sort-Union索引合并，就没有Sort-Intersection索引合并么？是的，的确没有Sort-Intersection索引合并这么一说，Sort-Union的适用场景是单独根据搜索条件从某个二级索引中获取的记录数比较少，这样即使对这些二级索引记录按照主键值进行排序的成本也不会太高，而Intersection索引合并的适用场景是单独根据搜索条件从某个二级索引中获取的记录数太多，导致回表开销太大，合并后可以明显降低回表开销，但是如果加入Sort-Intersection后，就需要为大量的二级索引记录按照主键值进行排序，这个成本可能比回表查询都高了，所以也就没有引入Sort-Intersection这个玩意儿。</p>
</blockquote>
<h4 id="1034-索引合并注意事项">10.3.4 索引合并注意事项</h4>
<h5 id="联合索引替代intersection索引合并">联合索引替代Intersection索引合并</h5>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key1 = 'a' AND key3 = 'b';
</code></pre>
<p>这个查询之所以可能使用Intersection索引合并的方式执行，还不是因为idx_key1和idx_key3是两个单独的B+树索引，你要是把这两个列搞一个联合索引，那直接使用这个联合索引就把事情搞定了，何必用什么索引合并呢。</p>
<h2 id="第十一章-两个表的亲密接触-连接的原理">第十一章 两个表的亲密接触-连接的原理</h2>
<h3 id="111-连接简介">11.1 连接简介</h3>
<h4 id="1111-连接的本质">11.1.1 连接的本质</h4>
<pre><code class="language-mysql">mysql&gt; CREATE TABLE t1 (m1 int, n1 char(1));
Query OK, 0 rows affected (0.02 sec)

mysql&gt; CREATE TABLE t2 (m2 int, n2 char(1));
Query OK, 0 rows affected (0.02 sec)

mysql&gt; INSERT INTO t1 VALUES(1, 'a'), (2, 'b'), (3, 'c');
Query OK, 3 rows affected (0.00 sec)
Records: 3  Duplicates: 0  Warnings: 0

mysql&gt; INSERT INTO t2 VALUES(2, 'b'), (3, 'c'), (4, 'd');
Query OK, 3 rows affected (0.00 sec)
Records: 3  Duplicates: 0  Warnings: 0
</code></pre>
<p>我们成功建立了t1、t2两个表，这两个表都有两个列，一个是INT类型的，一个是CHAR(1)类型的，填充好数据的两个表长这样：</p>
<pre><code class="language-mysql">mysql&gt; SELECT * FROM t1;
+------+------+
| m1   | n1   |
+------+------+
|    1 | a    |
|    2 | b    |
|    3 | c    |
+------+------+
3 rows in set (0.00 sec)

mysql&gt; SELECT * FROM t2;
+------+------+
| m2   | n2   |
+------+------+
|    2 | b    |
|    3 | c    |
|    4 | d    |
+------+------+
3 rows in set (0.00 sec)
</code></pre>
<p>连接的本质就是把各个连接表中的记录都取出来依次匹配的组合加入结果集并返回给用户。所以我们把t1和t2两个表连接起来的过程如下图所示：<br>
<img src="https://q456qq520.github.io/post-images/1673920033388.png" alt="" loading="lazy"><br>
这个过程看起来就是把t1表的记录和t2的记录连起来组成新的更大的记录，所以这个查询过程称之为连接查询。连接查询的结果集中包含一个表中的每一条记录与另一个表中的每一条记录相互匹配的组合，像这样的结果集就可以称之为<code>笛卡尔积</code>。因为表t1中有3条记录，表t2中也有3条记录，所以这两个表连接之后的笛卡尔积就有3×3=9行记录。</p>
<h4 id="1112-连接过程简介">11.1.2 连接过程简介</h4>
<p>我们可以连接任意数量张表，但是如果没有任何限制条件的话，这些表连接起来产生的笛卡尔积可能是非常巨大的。比方说3个100行记录的表连接起来产生的笛卡尔积就有100×100×100=1000000行数据！所以在连接的时候过滤掉特定记录组合是有必要的，在连接查询中的过滤条件可以分成两种：</p>
<ol>
<li>涉及单表的条件<br>
  这种只设计单表的过滤条件我们之前都提到过一万遍了，我们之前也一直称为搜索条件，比如t1.m1 &gt; 1是只针对t1表的过滤条件，t2.n2 &lt; 'd'是只针对t2表的过滤条件。</li>
<li>涉及两表的条件<br>
  这种过滤条件我们之前没见过，比如t1.m1 = t2.m2、t1.n1 &gt; t2.n2等，这些条件中涉及到了两个表。</li>
</ol>
<p>下面我们就要看一下携带过滤条件的连接查询的大致执行过程了，比方说下面这个查询语句：</p>
<pre><code class="language-mysql">SELECT * FROM t1, t2 WHERE t1.m1 &gt; 1 AND t1.m1 = t2.m2 AND t2.n2 &lt; 'd';
</code></pre>
<p>那么这个连接查询的大致执行过程如下：</p>
<ol>
<li>首先确定第一个需要查询的表，这个表称之为<code>驱动表</code>。只需要选取代价最小的那种访问方法去执行单表查询语句就好了（就是说从const、ref、ref_or_null、range、index、all这些执行方法中选取代价最小的去执行查询）。<br>
  此处假设使用t1作为驱动表，那么就需要到t1表中找满足t1.m1  &gt; 1的记录，因为表中的数据太少，我们也没在表上建立二级索引，所以此处查询t1表的访问方法就设定为all吧，也就是采用全表扫描的方式执行单表查询。</li>
<li>针对上一步骤中从驱动表产生的结果集中的每一条记录，分别需要到t2表中查找匹配的记录，所谓匹配的记录，指的是符合过滤条件的记录。因为是根据t1表中的记录去找t2表中的记录，所以t2表也可以被称之为被驱动表。上一步骤从驱动表中得到了2条记录，所以需要查询2次t2表。此时涉及两个表的列的过滤条件t1.m1 = t2.m2就派上用场了：<br>
  - 当t1.m1 = 2时，过滤条件t1.m1 = t2.m2就相当于t2.m2 = 2，所以此时t2表相当于有了t2.m2 = 2、t2.n2 &lt; 'd'这两个过滤条件，然后到t2表中执行单表查询。<br>
  - 当t1.m1 = 3时，过滤条件t1.m1 = t2.m2就相当于t2.m2 = 3，所以此时t2表相当于有了t2.m2 = 3、t2.n2 &lt; 'd'这两个过滤条件，然后到t2表中执行单表查询。</li>
</ol>
<p>所以整个连接查询的执行过程就如下图所示：<br>
<img src="https://q456qq520.github.io/post-images/1673920484438.png" alt="" loading="lazy"></p>
<blockquote>
<p>从上面两个步骤可以看出来，我们上面介绍的这个两表连接查询共需要查询1次<code>t1</code>表，2次<code>t2</code>表。当然这是在特定的过滤条件下的结果，如果我们把<code>t1.m1 &gt; 1</code>这个条件去掉，那么从<code>t1</code>表中查出的记录就有3条，就需要查询3次<code>t2</code>表了。也就是说在两表连接查询中，驱动表只需要访问一次，被驱动表可能被访问多次。</p>
</blockquote>
<h3 id="112-内连接和外连接">11.2 内连接和外连接</h3>
<pre><code class="language-mysql">CREATE TABLE student (
    number INT NOT NULL AUTO_INCREMENT COMMENT '学号',
    name VARCHAR(5) COMMENT '姓名',
    major VARCHAR(30) COMMENT '专业',
    PRIMARY KEY (number)
) Engine=InnoDB CHARSET=utf8 COMMENT '学生信息表';

CREATE TABLE score (
    number INT COMMENT '学号',
    subject VARCHAR(30) COMMENT '科目',
    score TINYINT COMMENT '成绩',
    PRIMARY KEY (number, score)
) Engine=InnoDB CHARSET=utf8 COMMENT '学生成绩表';
</code></pre>
<p>我们新建了一个学生信息表，一个学生成绩表，然后我们向上述两个表中插入一些数据:</p>
<pre><code class="language-mysql">mysql&gt; SELECT * FROM student;
+----------+-----------+--------------------------+
| number   | name      | major                    |
+----------+-----------+--------------------------+
| 20180101 | 杜子腾    | 软件学院                 |
| 20180102 | 范统      | 计算机科学与工程         |
| 20180103 | 史珍香    | 计算机科学与工程         |
+----------+-----------+--------------------------+
3 rows in set (0.00 sec)

mysql&gt; SELECT * FROM score;
+----------+-----------------------------+-------+
| number   | subject                     | score |
+----------+-----------------------------+-------+
| 20180101 | 母猪的产后护理              |    78 |
| 20180101 | 论萨达姆的战争准备          |    88 |
| 20180102 | 论萨达姆的战争准备          |    98 |
| 20180102 | 母猪的产后护理              |   100 |
+----------+-----------------------------+-------+
4 rows in set (0.00 sec)
</code></pre>
<p>现在我们想把每个学生的考试成绩都查询出来就需要进行两表连接了（因为score中没有姓名信息，所以不能单纯只查询score表）。连接过程就是从student表中取出记录，在score表中查找number相同的成绩记录，所以过滤条件就是student.number = socre.number，整个查询语句就是这样：</p>
<pre><code class="language-mysql">mysql&gt; SELECT s1.number, s1.name, s2.subject, s2.score FROM student AS s1, score AS s2 WHERE s1.number = s2.number;
+----------+-----------+-----------------------------+-------+
| number   | name      | subject                     | score |
+----------+-----------+-----------------------------+-------+
| 20180101 | 杜子腾    | 母猪的产后护理              |    78 |
| 20180101 | 杜子腾    | 论萨达姆的战争准备          |    88 |
| 20180102 | 范统      | 论萨达姆的战争准备          |    98 |
| 20180102 | 范统      | 母猪的产后护理              |   100 |
+----------+-----------+-----------------------------+-------+
4 rows in set (0.00 sec)
</code></pre>
<p>从上述查询结果中我们可以看到，各个同学对应的各科成绩就都被查出来了，可是有个问题，史珍香同学，也就是学号为20180103的同学因为某些原因没有参加考试，所以在score表中没有对应的成绩记录。那如果老师想查看所有同学的考试成绩，即使是缺考的同学也应该展示出来，但是到目前为止我们介绍的连接查询是无法完成这样的需求的。</p>
<p>我们稍微思考一下这个需求，其本质是想：<mark>驱动表中的记录即使在被驱动表中没有匹配的记录，也仍然需要加入到结果集</mark>。为了解决这个问题，就有了<code>内连接</code>和<code>外连接</code>的概念：</p>
<ol>
<li>对于内连接的两个表，驱动表中的记录在被驱动表中找不到匹配的记录，该记录不会加入到最后的结果集，我们上面提到的连接都是所谓的内连接。</li>
<li>对于外连接的两个表，驱动表中的记录即使在被驱动表中没有匹配的记录，也仍然需要加入到结果集。在MySQL中，根据选取驱动表的不同，外连接仍然可以细分为2种：
<ol>
<li>左外连接：选取左侧的表为驱动表。</li>
<li>右外连接：选取右侧的表为驱动表。</li>
</ol>
</li>
</ol>
<p>放在不同地方的过滤条件是有不同语义的：</p>
<ol>
<li>WHERE子句中的过滤条件就是我们平时见的那种，不论是内连接还是外连接，凡是不符合WHERE子句中的过滤条件的记录都不会被加入最后的结果集。</li>
<li>ON子句中的过滤条件
<ul>
<li>对于外连接的驱动表的记录来说，如果无法在被驱动表中找到匹配ON子句中的过滤条件的记录，那么该记录仍然会被加入到结果集中，对应的被驱动表记录的各个字段使用NULL值填充。</li>
<li>需要注意的是，这个ON子句是专门为外连接驱动表中的记录在被驱动表找不到匹配记录时应不应该把该记录加入结果集这个场景下提出的，所以如果把ON子句放到内连接中，MySQL会把它和WHERE子句一样对待，也就是说：<mark>内连接中的WHERE子句和ON子句是等价的</mark>。</li>
<li>一般情况下，我们都把只涉及单表的过滤条件放到WHERE子句中，把涉及两表的过滤条件都放到ON子句中，我们也一般把放到ON子句中的过滤条件也称之为<code>连接条件</code>。</li>
</ul>
</li>
</ol>
<h4 id="1121-左外连接的语法">11.2.1 左（外）连接的语法</h4>
<pre><code class="language-mysql">SELECT * FROM t1 LEFT [OUTER] JOIN t2 ON 连接条件 [WHERE 普通过滤条件];
</code></pre>
<p>其中，中括号里的OUTER单词是可以省略的。对于LEFT JOIN类型的连接来说，我们把放在左边的表称之为外表或者驱动表，右边的表称之为内表或者被驱动表。</p>
<p>需要注意的是，对于左（外）连接和右（外）连接来说，必须使用ON子句来指出连接条件。</p>
<p>再次回到我们上面那个现实问题中来，看看怎样写查询语句才能把所有的学生的成绩信息都查询出来，即使是缺考的考生也应该被放到结果集中：</p>
<pre><code class="language-mysql">mysql&gt; SELECT s1.number, s1.name, s2.subject, s2.score FROM student AS s1 LEFT JOIN score AS s2 ON s1.number = s2.number;
+----------+-----------+-----------------------------+-------+
| number   | name      | subject                     | score |
+----------+-----------+-----------------------------+-------+
| 20180101 | 杜子腾    | 母猪的产后护理              |    78 |
| 20180101 | 杜子腾    | 论萨达姆的战争准备          |    88 |
| 20180102 | 范统      | 论萨达姆的战争准备          |    98 |
| 20180102 | 范统      | 母猪的产后护理              |   100 |
| 20180103 | 史珍香    | NULL                        |  NULL |
+----------+-----------+-----------------------------+-------+
5 rows in set (0.04 sec)
</code></pre>
<h4 id="1122-右外连接的语法">11.2.2 右（外）连接的语法</h4>
<p>右（外）连接和左（外）连接的原理是一样一样的，语法也只是把LEFT换成RIGHT而已：</p>
<pre><code class="language-mysql">SELECT * FROM t1 RIGHT [OUTER] JOIN t2 ON 连接条件 [WHERE 普通过滤条件];
</code></pre>
<h4 id="1123-内连接的语法">11.2.3 内连接的语法</h4>
<p><mark>内连接和外连接的根本区别就是在驱动表中的记录不符合ON子句中的连接条件时不会把该记录加入到最后的结果集</mark>，我们最开始介绍的那些连接查询的类型都是内连接。不过之前仅仅提到了一种最简单的内连接语法，就是直接把需要连接的多个表都放到FROM子句后边。其实针对内连接，MySQL提供了好多不同的语法，我们以t1和t2表为例看看：</p>
<pre><code class="language-mysql">SELECT * FROM t1 [INNER | CROSS] JOIN t2 [ON 连接条件] [WHERE 普通过滤条件];
</code></pre>
<p>也就是说在MySQL中，下面这几种内连接的写法都是等价的：</p>
<pre><code class="language-mysql">SELECT * FROM t1 JOIN t2;
SELECT * FROM t1 INNER JOIN t2;
SELECT * FROM t1 CROSS JOIN t2;
SELECT * FROM t1, t2;
</code></pre>
<p><mark>由于在内连接中ON子句和WHERE子句是等价的，所以内连接中不要求强制写明ON子句。</mark></p>
<p>我们前面说过，连接的本质就是把各个连接表中的记录都取出来依次匹配的组合加入结果集并返回给用户。不论哪个表作为驱动表，两表连接产生的笛卡尔积肯定是一样的。</p>
<p>而对于内连接来说，由于凡是不符合ON子句或WHERE子句中的条件的记录都会被过滤掉，其实也就相当于从两表连接的笛卡尔积中把不符合过滤条件的记录给踢出去，所以<mark>对于内连接来说，驱动表和被驱动表是可以互换的，并不会影响最后的查询结果</mark>。但是对于外连接来说，由于驱动表中的记录即使在被驱动表中找不到符合ON子句连接条件的记录，所以此时驱动表和被驱动表的关系就很重要了，也就是说<mark>左外连接和右外连接的驱动表和被驱动表不能轻易互换。</mark></p>
<h4 id="1124-小结">11.2.4 小结</h4>
<pre><code class="language-mysql">mysql&gt; SELECT * FROM t1 INNER JOIN t2 ON t1.m1 = t2.m2;
+------+------+------+------+
| m1   | n1   | m2   | n2   |
+------+------+------+------+
|    2 | b    |    2 | b    |
|    3 | c    |    3 | c    |
+------+------+------+------+
2 rows in set (0.00 sec)

mysql&gt; SELECT * FROM t1 LEFT JOIN t2 ON t1.m1 = t2.m2;
+------+------+------+------+
| m1   | n1   | m2   | n2   |
+------+------+------+------+
|    2 | b    |    2 | b    |
|    3 | c    |    3 | c    |
|    1 | a    | NULL | NULL |
+------+------+------+------+
3 rows in set (0.00 sec)

mysql&gt; SELECT * FROM t1 RIGHT JOIN t2 ON t1.m1 = t2.m2;
+------+------+------+------+
| m1   | n1   | m2   | n2   |
+------+------+------+------+
|    2 | b    |    2 | b    |
|    3 | c    |    3 | c    |
| NULL | NULL |    4 | d    |
+------+------+------+------+
3 rows in set (0.00 sec)
</code></pre>
<h3 id="113-连接的原理">11.3 连接的原理</h3>
<h4 id="1131-嵌套循环连接nested-loop-join">11.3.1 嵌套循环连接（Nested-Loop Join）</h4>
<p>我们上面已经大致介绍过t1表和t2表执行内连接查询的大致过程，我们温习一下：</p>
<ol>
<li>步骤1：选取驱动表，使用与驱动表相关的过滤条件，选取代价最低的单表访问方法来执行对驱动表的单表查询。</li>
<li>步骤2：对上一步骤中查询驱动表得到的结果集中每一条记录，都分别到被驱动表中查找匹配的记录。</li>
</ol>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1673923077168.png" alt="" loading="lazy"></figure>
<p>如果有3个表进行连接的话，那么步骤2中得到的结果集就像是新的驱动表，然后第三个表就成为了被驱动表，重复上面过程，也就是步骤2中得到的结果集中的每一条记录都需要到t3表中找一找有没有匹配的记录，用伪代码表示一下这个过程就是这样：</p>
<pre><code class="language-mysql">for each row in t1 {   #此处表示遍历满足对t1单表查询结果集中的每一条记录
    
    for each row in t2 {   #此处表示对于某条t1表的记录来说，遍历满足对t2单表查询结果集中的每一条记录
    
        for each row in t3 {   #此处表示对于某条t1和t2表的记录组合来说，对t3表进行单表查询
            if row satisfies join conditions, send to client
        }
    }
}
</code></pre>
<p>这个过程就像是一个嵌套的循环，所以这种<mark>驱动表只访问一次，但被驱动表却可能被多次访问，访问次数取决于对驱动表执行单表查询后的结果集中的记录条数</mark>的连接执行方式称之为<code>嵌套循环连接（Nested-Loop Join）</code>，这是最简单，也是最笨拙的一种连接查询算法。</p>
<h4 id="1132-使用索引加快连接速度">11.3.2 使用索引加快连接速度</h4>
<p>我们知道在嵌套循环连接的步骤2中可能需要访问多次被驱动表，如果访问被驱动表的方式都是全表扫描的话，那得要扫描好多次。但是别忘了，查询t2表其实就相当于一次单表扫描，我们可以利用索引来加快查询速度。</p>
<pre><code class="language-mysql">SELECT * FROM t1, t2 WHERE t1.m1 &gt; 1 AND t1.m1 = t2.m2 AND t2.n2 &lt; 'd';
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1673920484438.png" alt="" loading="lazy"></figure>
<p>查询驱动表t1后的结果集中有两条记录，嵌套循环连接算法需要对被驱动表查询2次：</p>
<ol>
<li>当t1.m1 = 2时，去查询一遍t2表，对t2表的查询语句相当于：</li>
</ol>
<pre><code class="language-mysql">SELECT * FROM t2 WHERE t2.m2 = 2 AND t2.n2 &lt; 'd';
</code></pre>
<ol start="2">
<li>当t1.m1 = 3时，再去查询一遍t2表，此时对t2表的查询语句相当于：</li>
</ol>
<pre><code class="language-mysql">SELECT * FROM t2 WHERE t2.m2 = 3 AND t2.n2 &lt; 'd';
</code></pre>
<p>可以看到，原来的t1.m1 = t2.m2这个涉及两个表的过滤条件在针对t2表做查询时关于t1表的条件就已经确定了，所以我们只需要单单优化对t2表的查询了，上述两个对t2表的查询语句中利用到的列是m2和n2列，我们可以：</p>
<ol>
<li>在m2列上建立索引，因为对m2列的条件是等值查找，比如t2.m2 = 2、t2.m2 = 3等，所以可能使用到ref的访问方法，假设使用ref的访问方法去执行对t2表的查询的话，需要回表之后再判断t2.n2 &lt; d这个条件是否成立。<br>
这里有一个比较特殊的情况，就是假设m2列是t2表的主键或者唯一二级索引列，那么使用t2.m2 = 常数值这样的条件从t2表中查找记录的过程的代价就是常数级别的。我们知道在单表中使用主键值或者唯一二级索引列的值进行等值查找的方式称之为const，而MySQL把在连接查询中对被驱动表使用主键值或者唯一二级索引列的值进行等值查找的查询执行方式称之为：<code>eq_ref</code>。</li>
<li>在n2列上建立索引，涉及到的条件是t2.n2 &lt; 'd'，可能用到range的访问方法，假设使用range的访问方法对t2表的查询的话，需要回表之后再判断在m2列上的条件是否成立。</li>
</ol>
<p>假设m2和n2列上都存在索引的话，那么就需要从这两个里边儿挑一个代价更低的去执行对t2表的查询。当然，建立了索引不一定使用索引，只有在二级索引 + 回表的代价比全表扫描的代价更低时才会使用索引。</p>
<p>另外，有时候连接查询的查询列表和过滤条件中可能只涉及被驱动表的部分列，而这些列都是某个索引的一部分，这种情况下即使不能使用<code>eq_ref</code>、<code>ref</code>、<code>ref_or_null</code>或者<code>range</code>这些访问方法执行对被驱动表的查询的话，也可以使用索引扫描，也就是<code>index</code>的访问方法来查询被驱动表。所以我们建议在真实工作中最好不要使用*作为查询列表，最好把真实用到的列作为查询列表。</p>
<h4 id="1133-基于块的嵌套循环连接block-nested-loop-join">11.3.3 基于块的嵌套循环连接（Block Nested-Loop Join）</h4>
<p>现实生活中的表可不像t1、t2这种只有3条记录，成千上万条记录都是少的，几百万、几千万甚至几亿条记录的表到处都是。内存里可能并不能完全存放的下表中所有的记录，所以在扫描表前面记录的时候后边的记录可能还在磁盘上，等扫描到后边记录的时候可能内存不足，所以需要把前面的记录从内存中释放掉。我们前面又说过，采用<code>嵌套循环连接</code>算法的两表连接过程中，被驱动表可是要被访问好多次的，如果这个被驱动表中的数据特别多而且不能使用索引进行访问，那就相当于要从磁盘上读好几次这个表，这个I/O代价就非常大了，所以我们得想办法：<mark>尽量减少访问被驱动表的次数</mark>。</p>
<p>当被驱动表中的数据非常多时，每次访问被驱动表，被驱动表的记录会被加载到内存中，在内存中的每一条记录只会和驱动表结果集的一条记录做匹配，之后就会被从内存中清除掉。然后再从驱动表结果集中拿出另一条记录，再一次把被驱动表的记录加载到内存中一遍，周而复始，驱动表结果集中有多少条记录，就得把被驱动表从磁盘上加载到内存中多少次。</p>
<p>所以我们可不可以在把被驱动表的记录加载到内存的时候，一次性和多条驱动表中的记录做匹配，这样就可以大大减少重复从磁盘上加载被驱动表的代价了。所以MySQL提出了一个<code>join buffer</code>的概念，join buffer就是执行连接查询前申请的一块固定大小的内存，先把若干条驱动表结果集中的记录装在这个join buffer中，然后开始扫描被驱动表，每一条被驱动表的记录一次性和join buffer中的多条驱动表记录做匹配，因为匹配的过程都是在内存中完成的，所以这样可以显著减少被驱动表的I/O代价。使用join buffer的过程如下图所示：</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1673923811333.png" alt="" loading="lazy"></figure>
<p>最好的情况是join buffer足够大，能容纳驱动表结果集中的所有记录，这样只需要访问一次被驱动表就可以完成连接操作了。设计MySQL的大佬把这种加入了join buffer的嵌套循环连接算法称之为<code>基于块的嵌套连接（Block Nested-Loop Join）算法</code>。</p>
<p>这个join buffer的大小是可以通过启动参数或者系统变量<code>join_buffer_size</code>进行配置，默认大小为262144字节（也就是256KB），最小可以设置为128字节。当然，对于优化被驱动表的查询来说，最好是为被驱动表加上效率高的索引，如果实在不能使用索引，并且自己的机器的内存也比较大可以尝试调大join_buffer_size的值来对连接查询进行优化。</p>
<p>另外需要注意的是，驱动表的记录并不是所有列都会被放到join buffer中，只有查询列表中的列和过滤条件中的列才会被放到join buffer中，所以再次提醒我们，最好不要把*作为查询列表，只需要把我们关心的列放到查询列表就好了，这样还可以在join buffer中放置更多的记录呢。</p>
<h2 id="第十二章-谁最便宜就选谁-mysql基于成本的优化">第十二章 谁最便宜就选谁-MySQL基于成本的优化</h2>
<h3 id="121-什么是成本">12.1 什么是成本</h3>
<p>MySQL中一条查询语句的执行成本是由下面这两个方面组成的：</p>
<ol>
<li>I/O成本<br>
  我们的表经常使用的MyISAM、InnoDB存储引擎都是将数据和索引都存储到磁盘上的，当我们想查询表中的记录时，需要先把数据或者索引加载到内存中然后再操作。这个从磁盘到内存这个加载的过程损耗的时间称之为I/O成本。</li>
<li>CPU成本<br>
  读取以及检测记录是否满足对应的搜索条件、对结果集进行排序等这些操作损耗的时间称之为CPU成本。</li>
</ol>
<p>对于InnoDB存储引擎来说，页是磁盘和内存之间交互的基本单位，设计MySQL的大佬规定读取一个页面花费的成本默认是1.0，读取以及检测一条记录是否符合搜索条件的成本默认是0.2。1.0、0.2这些数字称之为<code>成本常数</code>。</p>
<h3 id="122-单表查询的成本">12.2 单表查询的成本</h3>
<pre><code class="language-mysql">CREATE TABLE single_table (
    id INT NOT NULL AUTO_INCREMENT,
    key1 VARCHAR(100),
    key2 INT,
    key3 VARCHAR(100),
    key_part1 VARCHAR(100),
    key_part2 VARCHAR(100),
    key_part3 VARCHAR(100),
    common_field VARCHAR(100),
    PRIMARY KEY (id),
    KEY idx_key1 (key1),
    UNIQUE KEY idx_key2 (key2),
    KEY idx_key3 (key3),
    KEY idx_key_part(key_part1, key_part2, key_part3)
) Engine=InnoDB CHARSET=utf8;
</code></pre>
<p>假设这个表里边儿有10000条记录，除id列外其余的列都插入随机值。</p>
<h4 id="1221-基于成本的优化步骤">12.2.1 基于成本的优化步骤</h4>
<p>在一条单表查询语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案，这个成本最低的方案就是所谓的<code>执行计划</code>，之后才会调用存储引擎提供的接口真正的执行查询，这个过程总结一下就是这样：</p>
<ol>
<li>根据搜索条件，找出所有可能使用的索引</li>
<li>计算全表扫描的代价</li>
<li>计算使用不同索引执行查询的代价</li>
<li>对比各种执行方案的代价，找出成本最低的那一个</li>
</ol>
<p>下面我们就以一个实例来分析一下这些步骤，单表查询语句如下：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE 
    key1 IN ('a', 'b', 'c') AND 
    key2 &gt; 10 AND key2 &lt; 1000 AND 
    key3 &gt; key2 AND 
    key_part1 LIKE '%hello%' AND
    common_field = '123';
</code></pre>
<h5 id="根据搜索条件找出所有可能使用的索引">根据搜索条件，找出所有可能使用的索引</h5>
<p>对于B+树索引来说，只要索引列和常数使用=、&lt;=&gt;、IN、NOT IN、IS NULL、IS NOT NULL、&gt;、&lt;、&gt;=、&lt;=、BETWEEN、!=（不等于也可以写成&lt;&gt;）或者LIKE操作符连接起来，就可以产生一个所谓的范围区间（LIKE匹配字符串前缀也行），也就是说这些搜索条件都可能使用到索引，设计MySQL的大佬把一个查询中可能使用到的索引称之为<code>possible keys</code>。</p>
<p>我们分析一下上面查询中涉及到的几个搜索条件：</p>
<ul>
<li>key1 IN ('a', 'b', 'c')，这个搜索条件可以使用二级索引idx_key1。</li>
<li>key2 &gt; 10 AND key2 &lt; 1000，这个搜索条件可以使用二级索引idx_key2。</li>
<li>key3 &gt; key2，这个搜索条件的索引列由于没有和常数比较，所以并不能使用到索引。</li>
<li>key_part1 LIKE '%hello%'，key_part1通过LIKE操作符和以通配符开头的字符串做比较，不可以适用索引。</li>
<li>common_field = '123'，由于该列上压根儿没有索引，所以不会用到索引。<br>
综上所述，上面的查询语句可能用到的索引，也就是possible keys只有idx_key1和idx_key2。</li>
</ul>
<h5 id="计算全表扫描的代价">计算全表扫描的代价</h5>
<p>对于InnoDB存储引擎来说，全表扫描的意思就是把聚簇索引中的记录都依次和给定的搜索条件做一下比较，把符合搜索条件的记录加入到结果集，所以需要将聚簇索引对应的页面加载到内存中，然后再检测记录是否符合搜索条件。由于查询成本=I/O成本+CPU成本，所以计算全表扫描的代价需要两个信息：</p>
<ul>
<li>聚簇索引占用的页面数</li>
<li>该表中的记录数</li>
</ul>
<p>这两个信息从哪来呢？MySQL为每个表维护了一系列的统计信息，MySQL给我们提供了SHOW TABLE STATUS语句来查看表的统计信息，如果要看指定的某个表的统计信息，在该语句后加对应的LIKE语句就好了，比方说我们要查看single_table这个表的统计信息可以这么写：</p>
<pre><code class="language-mysql">mysql&gt; SHOW TABLE STATUS LIKE 'single_table'\G
*************************** 1. row ***************************
           Name: single_table
         Engine: InnoDB
        Version: 10
     Row_format: Dynamic
           Rows: 9693
 Avg_row_length: 163
    Data_length: 1589248
Max_data_length: 0
   Index_length: 2752512
      Data_free: 4194304
 Auto_increment: 10001
    Create_time: 2018-12-10 13:37:23
    Update_time: 2018-12-10 13:38:03
     Check_time: NULL
      Collation: utf8_general_ci
       Checksum: NULL
 Create_options:
        Comment:
1 row in set (0.01 sec)
</code></pre>
<ol>
<li>Rows<br>
本选项表示表中的记录条数。对于使用MyISAM存储引擎的表来说，该值是准确的，对于使用InnoDB存储引擎的表来说，该值是一个估计值。从查询结果我们也可以看出来，由于我们的single_table表是使用InnoDB存储引擎的，所以虽然实际上表中有10000条记录，但是SHOW TABLE STATUS显示的Rows值只有9693条记录。</li>
<li>Data_length<br>
本选项表示表占用的存储空间字节数。使用MyISAM存储引擎的表来说，该值就是数据文件的大小，对于使用InnoDB存储引擎的表来说，该值就相当于聚簇索引占用的存储空间大小，也就是说可以这样计算该值的大小：<mark>Data_length = 聚簇索引的页面数量 x 每个页面的大小</mark><br>
我们的single_table使用默认16KB的页面大小，而上面查询结果显示Data_length的值是1589248，所以我们可以反向来推导出聚簇索引的页面数量：<mark>聚簇索引的页面数量 = 1589248 ÷ 16 ÷ 1024 = 97</mark></li>
</ol>
<p>我们现在已经得到了聚簇索引占用的页面数量以及该表记录数的估计值，所以就可以计算全表扫描成本了，但是MySQL在真实计算成本时会进行一些微调，这些微调的值是直接硬编码到代码里的，，但是由于这些微调的值十分的小，并不影响我们分析，所以我们也没有必要在这些微调值上纠结了。现在可以看一下全表扫描成本的计算过程：</p>
<ol>
<li>I/O成本<br>
97 x 1.0 + 1.1 = 98.1<br>
97指的是聚簇索引占用的页面数，1.0指的是加载一个页面的成本常数，后边的1.1是一个微调值，我们不用在意。</li>
<li>CPU成本：<br>
9693 x 0.2 + 1.0 = 1939.6<br>
9693指的是统计数据中表的记录数，对于InnoDB存储引擎来说是一个估计值，0.2指的是访问一条记录所需的成本常数，后边的1.0是一个微调值，我们不用在意。</li>
<li>总成本<br>
98.1 + 1939.6 = 2037.7</li>
</ol>
<h5 id="计算使用不同索引执行查询的代价">计算使用不同索引执行查询的代价</h5>
<p>从第1步分析我们得到，上述查询可能使用到idx_key1和idx_key2这两个索引，我们需要分别分析单独使用这些索引执行查询的成本，最后还要分析是否可能使用到索引合并。这里需要提一点的是，MySQL查询优化器先分析使用唯一二级索引的成本，再分析使用普通索引的成本，所以我们也先分析idx_key2的成本，然后再看使用idx_key1的成本。</p>
<p><strong>使用idx_key2执行查询的成本分析</strong><br>
idx_key2对应的搜索条件是：key2 &gt; 10 AND key2 &lt; 1000，也就是说对应的范围区间就是：(10, 1000)。</p>
<p>对于使用二级索引 + 回表方式的查询，MySQL计算这种查询的成本依赖两个方面的数据：</p>
<ol>
<li>范围区间数量<br>
不论某个范围区间的二级索引到底占用了多少页面，查询优化器粗暴的认为读取索引的一个范围区间的I/O成本和读取一个页面是相同的。</li>
<li>需要回表的记录数<br>
优化器需要计算二级索引的某个范围区间到底包含多少条记录，对于本例来说就是要计算idx_key2在(10, 1000)这个范围区间中包含多少二级索引记录，计算过程是这样的：</li>
</ol>
<ul>
<li>步骤1：先根据key2 &gt; 10这个条件访问一下idx_key2对应的B+树索引，找到满足key2 &gt; 10这个条件的第一条记录，我们把这条记录称之为区间最左记录。我们前头说过在B+数树中定位一条记录的过程是贼快的，是常数级别的，所以这个过程的性能消耗是可以忽略不计的。</li>
<li>步骤2：然后再根据key2 &lt; 1000这个条件继续从idx_key2对应的B+树索引中找出第一条满足这个条件的记录，我们把这条记录称之为区间最右记录，这个过程的性能消耗也可以忽略不计的。</li>
<li>步骤3：如果区间最左记录和区间最右记录相隔不太远（在MySQL 5.7.21这个版本里，只要相隔不大于10个页面即可），那就可以精确统计出满足key2 &gt; 10 AND key2 &lt; 1000条件的二级索引记录条数。否则只沿着区间最左记录向右读10个页面，计算平均每个页面中包含多少记录，然后用这个平均值乘以区间最左记录和区间最右记录之间的页面数量就可以了。</li>
</ul>
<p>根据上述算法测得idx_key2在区间(10, 1000)之间大约有95条记录。读取这95条二级索引记录需要付出的CPU成本就是：95 x 0.2 + 0.01 = 19.01，其中95是需要读取的二级索引记录条数，0.2是读取一条记录成本常数，0.01是微调。</p>
<p>在通过二级索引获取到记录之后，还需要干两件事儿：</p>
<ol>
<li>根据这些记录里的主键值到聚簇索引中做回表操作</li>
<li>回表操作后得到的完整用户记录，然后再检测其他搜索条件是否成立</li>
</ol>
<p><strong>使用idx_key1执行查询的成本分析</strong></p>
<h5 id="对比各种执行方案的代价找出成本最低的那一个">对比各种执行方案的代价，找出成本最低的那一个</h5>
<h3 id="123-基于索引统计数据的成本计算">12.3 基于索引统计数据的成本计算</h3>
<h3 id="基于索引统计数据的成本计算">基于索引统计数据的成本计算</h3>
<p>有时候使用索引执行查询时会有许多单点区间，比如使用<code>IN</code>语句就很容易产生非常多的单点区间，比如下面这个查询（下面查询语句中的<code>...</code>表示还有很多参数）：</p>
<pre><code class="language-mysql">SELECT * FROM single_table WHERE key1 IN ('aa1', 'aa2', 'aa3', ... , 'zzz');
</code></pre>
<p>很显然，这个查询可能使用到的索引就是<code>idx_key1</code>，由于这个索引并不是唯一二级索引，所以并不能确定一个单点区间对应的二级索引记录的条数有多少，需要我们去计算。计算方式我们上面已经介绍过了，就是先获取索引对应的<code>B+</code>树的<code>区间最左记录</code>和<code>区间最右记录</code>，然后再计算这两条记录之间有多少记录（记录条数少的时候可以做到精确计算，多的时候只能估算）。设计<code>MySQL</code>的大佬把这种通过直接访问索引对应的<code>B+</code>树来计算某个范围区间对应的索引记录条数的方式称之为<code>index dive</code>。</p>
<p>有零星几个单点区间的话，使用<code>index dive</code>的方式去计算这些单点区间对应的记录数也不是什么问题，可是你架不住憋足了劲往<code>IN</code>语句里塞东西呀，我就见过有的同学写的<code>IN</code>语句里有20000个参数的，这就意味着<code>MySQL</code>的查询优化器为了计算这些单点区间对应的索引记录条数，要进行20000次<code>index dive</code>操作，这性能损耗可就大了，搞不好计算这些单点区间对应的索引记录条数的成本比直接全表扫描的成本都大了。设计<code>MySQL</code>的大佬们多聪明啊，他们当然考虑到了这种情况，所以提供了一个系统变量<code>eq_range_index_dive_limit</code>，我们看一下在<code>MySQL 5.7.21</code>中这个系统变量的默认值：</p>
<pre><code class="language-mysql">mysql&gt; SHOW VARIABLES LIKE '%dive%'; 
+---------------------------+-------+ | Variable_name | Value | +---------------------------+-------+ | eq_range_index_dive_limit | 200 | +---------------------------+-------+ 
1 row in set (0.08 sec)
</code></pre>
<p>也就是说如果我们的<code>IN</code>语句中的参数个数小于200个的话，将使用<code>index dive</code>的方式计算各个单点区间对应的记录条数，如果大于或等于200个的话，可就不能使用<code>index dive</code>了，要使用所谓的索引统计数据来进行估算。</p>
<p>像会为每个表维护一份统计数据一样，<code>MySQL</code>也会为表中的每一个索引维护一份统计数据，查看某个表中索引的统计数据可以使用<code>SHOW INDEX FROM 表名</code>的语法，比如我们查看一下<code>single_table</code>的各个索引的统计数据可以这么写：</p>
<pre><code class="language-mysql">SHOW INDEX FROM single_table; 
</code></pre>
<table>
<thead>
<tr>
<th style="text-align:center">属性名</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>Table</code></td>
<td>索引所属表的名称。</td>
</tr>
<tr>
<td style="text-align:center"><code>Non_unique</code></td>
<td>索引列的值是否是唯一的，聚簇索引和唯一二级索引的该列值为<code>0</code>，普通二级索引该列值为<code>1</code>。</td>
</tr>
<tr>
<td style="text-align:center"><code>Key_name</code></td>
<td>索引的名称。</td>
</tr>
<tr>
<td style="text-align:center"><code>Seq_in_index</code></td>
<td>索引列在索引中的位置，从1开始计数。比如对于联合索引<code>idx_key_part</code>，来说，<code>key_part1</code>、<code>key_part2</code>和<code>key_part3</code>对应的位置分别是1、2、3。</td>
</tr>
<tr>
<td style="text-align:center"><code>Column_name</code></td>
<td>索引列的名称。</td>
</tr>
<tr>
<td style="text-align:center"><code>Collation</code></td>
<td>索引列中的值是按照何种排序方式存放的，值为<code>A</code>时代表升序存放，为<code>NULL</code>时代表降序存放。</td>
</tr>
<tr>
<td style="text-align:center"><code>Cardinality</code></td>
<td>索引列中不重复值的数量。后边我们会重点看这个属性的。</td>
</tr>
<tr>
<td style="text-align:center"><code>Sub_part</code></td>
<td>对于存储字符串或者字节串的列来说，有时候我们只想对这些串的前<code>n</code>个字符或字节建立索引，这个属性表示的就是那个<code>n</code>值。如果对完整的列建立索引的话，该属性的值就是<code>NULL</code>。</td>
</tr>
<tr>
<td style="text-align:center"><code>Packed</code></td>
<td>索引列如何被压缩，<code>NULL</code>值表示未被压缩。这个属性我们暂时不了解，可以先忽略掉。</td>
</tr>
<tr>
<td style="text-align:center"><code>Null</code></td>
<td>该索引列是否允许存储<code>NULL</code>值。</td>
</tr>
<tr>
<td style="text-align:center"><code>Index_type</code></td>
<td>使用索引的类型，我们最常见的就是<code>BTREE</code>，其实也就是<code>B+</code>树索引。</td>
</tr>
<tr>
<td style="text-align:center"><code>Comment</code></td>
<td>索引列注释信息。</td>
</tr>
<tr>
<td style="text-align:center"><code>Index_comment</code></td>
<td>索引注释信息。</td>
</tr>
</tbody>
</table>
<h3 id="124-连接查询的成本">12.4 连接查询的成本</h3>
<h4 id="1241-准备工作">12.4.1 准备工作</h4>
<p>连接查询至少是要有两个表的，只有一个<code>single_table</code>表是不够的，所以为了故事的顺利发展，我们直接构造一个和<code>single_table</code>表一模一样的<code>single_table2</code>表。为了简便起见，我们把<code>single_table</code>表称为<code>s1</code>表，把<code>single_table2</code>表称为<code>s2</code>表。</p>
<h4 id="1242-condition-filtering介绍">12.4.2 Condition filtering介绍</h4>
<p>我们前面说过，<code>MySQL</code>中连接查询采用的是嵌套循环连接算法，驱动表会被访问一次，被驱动表可能会被访问多次，所以对于两表连接查询来说，它的查询成本由下面两个部分构成：</p>
<ul>
<li>单次查询驱动表的成本</li>
<li>多次查询被驱动表的成本（<span style="color:red">具体查询多少次取决于对驱动表查询的结果集中有多少条记录</span>）</li>
</ul>
<p>  我们把对驱动表进行查询后得到的记录条数称之为驱动表的<code>扇出</code>（英文名：<code>fanout</code>）。很显然驱动表的扇出值越小，对被驱动表的查询次数也就越少，连接查询的总成本也就越低。当查询优化器想计算整个连接查询所使用的成本时，就需要计算出驱动表的扇出值，有的时候扇出值的计算是很容易的，比如下面这两个查询：</p>
<ul>
<li>查询一：<pre><code>SELECT * FROM single_table AS s1 INNER JOIN single_table2 AS s2;
</code></pre>
假设使用<code>s1</code>表作为驱动表，很显然对驱动表的单表查询只能使用全表扫描的方式执行，驱动表的扇出值也很明确，那就是驱动表中有多少记录，扇出值就是多少。我们前面说过，统计数据中<code>s1</code>表的记录行数是<code>9693</code>，也就是说优化器就直接会把<code>9693</code>当作在<code>s1</code>表的扇出值。</li>
<li>查询二：<pre><code>SELECT * FROM single_table AS s1 INNER JOIN single_table2 AS s2 
WHERE s1.key2 &gt;10 AND s1.key2 &lt; 1000;
</code></pre>
仍然假设<code>s1</code>表是驱动表的话，很显然对驱动表的单表查询可以使用<code>idx_key2</code>索引执行查询。此时<code>idx_key2</code>的范围区间<code>(10, 1000)</code>中有多少条记录，那么扇出值就是多少。我们前面计算过，满足<code>idx_key2</code>的范围区间<code>(10, 1000)</code>的记录数是95条，也就是说本查询中优化器会把<code>95</code>当作驱动表<code>s1</code>的扇出值。</li>
</ul>
<p>这两种情况下计算驱动表扇出值时需要靠<code>猜</code>：</p>
<ul>
<li>如果使用的是全表扫描的方式执行的单表查询，那么计算驱动表扇出时需要猜满足搜索条件的记录到底有多少条。</li>
<li>如果使用的是索引执行的单表扫描，那么计算驱动表扇出的时候需要猜满足除使用到对应索引的搜索条件外的其他搜索条件的记录有多少条。</li>
</ul>
<p>设计<code>MySQL</code>的大佬把这个<code>猜</code>的过程称之为<code>condition filtering</code>。</p>
<h3 id="125-两表连接的成本分析">12.5 两表连接的成本分析</h3>
<p>连接查询的成本计算公式是这样的：连接查询总成本 = 单次访问驱动表的成本 + 驱动表扇出数 x 单次访问被驱动表的成本</p>
<p>对于左（外）连接和右（外）连接查询来说，它们的驱动表是固定的，所以想要得到最优的查询方案只需要：</p>
<ul>
<li>分别为驱动表和被驱动表选择成本最低的访问方法。<br>
可是对于内连接来说，驱动表和被驱动表的位置是可以互换的，所以需要考虑两个方面的问题：</li>
<li>不同的表作为驱动表最终的查询成本可能是不同的，也就是需要考虑最优的表连接顺序。</li>
<li>然后分别为驱动表和被驱动表选择成本最低的访问方法。</li>
</ul>
<p>最后优化器会比较最优访问成本，选取那个成本更低的连接顺序去真正的执行查询，连接查询成本占大头的其实是<code>驱动表扇出数 x 单次访问被驱动表的成本</code>，所以我们的优化重点其实是下面这两个部分：</p>
<ul>
<li>尽量减少驱动表的扇出</li>
<li>对被驱动表的访问成本尽量低</li>
</ul>
<p>这一点对于我们实际书写连接查询语句时十分有用，我们需要<span style="color:red">尽量在被驱动表的连接列上建立索引</span>，这样就可以使用<code>ref</code>访问方法来降低访问被驱动表的成本了。如果可以，被驱动表的连接列最好是该表的主键或者唯一二级索引列，这样就可以把访问被驱动表的成本降到更低了。</p>
<h3 id="126-多表连接的成本分析">12.6 多表连接的成本分析</h3>
<p>首先要考虑一下多表连接时可能产生出多少种连接顺序：</p>
<ul>
<li>
<p>对于两表连接，比如表A和表B连接<br>
  只有 AB、BA这两种连接顺序。其实相当于<code>2 × 1 = 2</code>种连接顺序。</p>
</li>
<li>
<p>对于三表连接，比如表A、表B、表C进行连接<br>
  有ABC、ACB、BAC、BCA、CAB、CBA这么6种连接顺序。其实相当于<code>3 × 2 × 1 = 6</code>种连接顺序。</p>
</li>
<li>
<p>对于四表连接的话，则会有<code>4 × 3 × 2 × 1 = 24</code>种连接顺序。</p>
</li>
<li>
<p>对于<code>n</code>表连接的话，则有 <code>n × (n-1) × (n-2) × ··· × 1</code>种连接顺序，就是n的阶乘种连接顺序，也就是<code>n!</code>。<br>
  有<code>n</code>个表进行连接，<code>MySQL</code>查询优化器要每一种连接顺序的成本都计算一遍么？那可是<code>n!</code>种连接顺序呀。其实真的是要都算一遍，不过设计<code>MySQL</code>的大佬们想了很多办法减少计算非常多种连接顺序的成本的方法：</p>
</li>
<li>
<p>提前结束某种顺序的成本评估<br>
  <code>MySQL</code>在计算各种链接顺序的成本之前，会维护一个全局的变量，这个变量表示当前最小的连接查询成本。如果在分析某个连接顺序的成本时，该成本已经超过当前最小的连接查询成本，那就压根儿不对该连接顺序继续往下分析了。比方说A、B、C三个表进行连接，已经得到连接顺序<code>ABC</code>是当前的最小连接成本，比方说<code>10.0</code>，在计算连接顺序<code>BCA</code>时，发现<code>B</code>和<code>C</code>的连接成本就已经大于<code>10.0</code>时，就不再继续往后分析<code>BCA</code>这个连接顺序的成本了。</p>
</li>
<li>
<p>系统变量<code>optimizer_search_depth</code><br>
  为了防止无穷无尽的分析各种连接顺序的成本，MySQL提出了<code>optimizer_search_depth</code>系统变量，如果连接表的个数小于该值，那么就继续穷举分析每一种连接顺序的成本，否则只对与<code>optimizer_search_depth</code>值相同数量的表进行穷举分析。很显然，该值越大，成本分析的越精确，越容易得到好的执行计划，但是消耗的时间也就越长，否则得到不是很好的执行计划，但可以省掉很多分析连接成本的时间。</p>
</li>
<li>
<p>根据某些规则压根儿就不考虑某些连接顺序<br>
  即使是有上面两条规则的限制，但是分析多个表不同连接顺序成本花费的时间还是会很长，所以设计<code>MySQL</code>的大佬干脆提出了一些所谓的<code>启发式规则</code>（就是根据以往经验指定的一些规则），凡是不满足这些规则的连接顺序压根儿就不分析，这样可以极大的减少需要分析的连接顺序的数量，但是也可能造成错失最优的执行计划。他们提供了一个系统变量<code>optimizer_prune_level</code>来控制到底是不是用这些启发式规则。</p>
</li>
</ul>
<h4 id="1261-调节成本常数">12.6.1 调节成本常数</h4>
<p>我们前面之介绍了两个<code>成本常数</code>：</p>
<ul>
<li>读取一个页面花费的成本默认是<code>1.0</code></li>
<li>检测一条记录是否符合搜索条件的成本默认是<code>0.2</code></li>
</ul>
<p>其实除了这两个成本常数，<code>MySQL</code>还支持好多呢，它们被存储到了<code>mysql</code>数据库的两个表中：<code>engine_cost | | server_cost</code></p>
<p>一条语句的执行其实是分为两层的：在<code>server</code>层进行连接管理、查询缓存、语法解析、查询优化等操作，在存储引擎层执行具体的数据存取操作。也就是说一条语句在<code>server</code>层中执行的成本是和它操作的表使用的存储引擎是没关系的，所以关于这些操作对应的<code>成本常数</code>就存储在了<code>server_cost</code>表中，而依赖于存储引擎的一些操作对应的<code>成本常数</code>就存储在了<code>engine_cost</code>表中。</p>
<h5 id="mysqlserver_cost表">mysql.server_cost表</h5>
<table>
<thead>
<tr>
<th style="text-align:center">成本常数名称</th>
<th style="text-align:center">默认值</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>disk_temptable_create_cost</code></td>
<td style="text-align:center"><code>40.0</code></td>
<td style="text-align:left">创建基于磁盘的临时表的成本，如果增大这个值的话会让优化器尽量少的创建基于磁盘的临时表。</td>
</tr>
<tr>
<td style="text-align:center"><code>disk_temptable_row_cost</code></td>
<td style="text-align:center"><code>1.0</code></td>
<td style="text-align:left">向基于磁盘的临时表写入或读取一条记录的成本，如果增大这个值的话会让优化器尽量少的创建基于磁盘的临时表。</td>
</tr>
<tr>
<td style="text-align:center"><code>key_compare_cost</code></td>
<td style="text-align:center"><code>0.1</code></td>
<td style="text-align:left">两条记录做比较操作的成本，多用在排序操作上，如果增大这个值的话会提升<code>filesort</code>的成本，让优化器可能更倾向于使用索引完成排序而不是<code>filesort</code>。</td>
</tr>
<tr>
<td style="text-align:center"><code>memory_temptable_create_cost</code></td>
<td style="text-align:center"><code>2.0</code></td>
<td style="text-align:left">创建基于内存的临时表的成本，如果增大这个值的话会让优化器尽量少的创建基于内存的临时表。</td>
</tr>
<tr>
<td style="text-align:center"><code>memory_temptable_row_cost</code></td>
<td style="text-align:center"><code>0.2</code></td>
<td style="text-align:left">向基于内存的临时表写入或读取一条记录的成本，如果增大这个值的话会让优化器尽量少的创建基于内存的临时表。</td>
</tr>
<tr>
<td style="text-align:center"><code>row_evaluate_cost</code></td>
<td style="text-align:center"><code>0.2</code></td>
<td style="text-align:left">这个就是我们之前一直使用的检测一条记录是否符合搜索条件的成本，增大这个值可能让优化器更倾向于使用索引而不是直接全表扫描。</td>
</tr>
</tbody>
</table>
<h5 id="mysqlengine_cost表">mysql.engine_cost表</h5>
<p>与<code>server_cost</code>相比，<code>engine_cost</code>多了两个列：</p>
<ul>
<li><code>engine_name</code>列：指成本常数适用的存储引擎名称。如果该值为<code>default</code>，意味着对应的成本常数适用于所有的存储引擎。</li>
<li><code>device_type</code>列：指存储引擎使用的设备类型，这主要是为了区分常规的机械硬盘和固态硬盘，不过在<code>MySQL 5.7.21</code>这个版本中并没有对机械硬盘的成本和固态硬盘的成本作区分，所以该值默认是<code>0</code>。</li>
</ul>
<h2 id="第十三章-兵马未动粮草先行-innodb统计数据是如何收集的">第十三章 兵马未动，粮草先行-InnoDB统计数据是如何收集的</h2>
<p>我们前面介绍查询成本的时候经常用到一些统计数据，比如通过SHOW TABLE STATUS可以看到关于表的统计数据，通过SHOW INDEX可以看到关于索引的统计数据，那么这些统计数据是怎么来的呢？它们是以什么方式收集的呢？</p>
<h3 id="131-两种不同的统计数据存储方式">13.1 两种不同的统计数据存储方式</h3>
<p>InnoDB提供了两种存储统计数据的方式：</p>
<ol>
<li>永久性的统计数据<br>
  这种统计数据存储在磁盘上，也就是服务器重启之后这些统计数据还在。</li>
<li>非永久性的统计数据<br>
  这种统计数据存储在内存中，当服务器关闭时这些这些统计数据就都被清除掉了，等到服务器重启之后，在某些适当的场景下才会重新收集这些统计数据。</li>
</ol>
<p>MySQL给我们提供了系统变量innodb_stats_persistent来控制到底采用哪种方式去存储统计数据。在MySQL 5.6.6之前，innodb_stats_persistent的值默认是OFF，也就是说InnoDB的统计数据默认是存储到内存的，之后的版本中innodb_stats_persistent的值默认是ON，也就是统计数据默认被存储到磁盘中。</p>
<p>不过InnoDB默认是<mark>以表为单位来收集和存储统计数据的</mark>，也就是说我们可以把某些表的统计数据（以及该表的索引统计数据）存储在磁盘上，把另一些表的统计数据存储在内存中。怎么做到的呢？我们可以在创建和修改表的时候通过指定STATS_PERSISTENT属性来指明该表的统计数据存储方式：</p>
<pre><code class="language-mysql">CREATE TABLE 表名 (...) Engine=InnoDB, STATS_PERSISTENT = (1|0);
ALTER TABLE 表名 Engine=InnoDB, STATS_PERSISTENT = (1|0);
</code></pre>
<p>当 STATS_PERSISTENT=1 时，表明我们想把该表的统计数据永久的存储到磁盘上，当 STATS_PERSISTENT=0 时，表 明我们想把该表的统计数据临时的存储到内存中。如果我们在创建表时未指定 STATS_PERSISTENT 属性，那默认 采用系统变量 innodb_stats_persistent 的值作为该属性的值。</p>
<h3 id="132-基于磁盘的永久性统计数据">13.2 基于磁盘的永久性统计数据</h3>
<p>当我们选择把某个表以及该表索引的统计数据存放到磁盘上时，实际上是把这些统计数据存储到了两个表里:</p>
<pre><code class="language-mysql">mysql&gt; SHOW TABLES FROM mysql LIKE 'innodb%';
    +---------------------------+
    | Tables_in_mysql (innodb%) |
    +---------------------------+
    | innodb_index_stats        |
    | innodb_table_stats        |
    +---------------------------+
    2 rows in set (0.01 sec)
</code></pre>
<p>可以看到，这两个表都位于 mysql 系统数据库下边，其中:</p>
<ul>
<li>innodb_table_stats 存储了关于表的统计数据，每一条记录对应着一个表的统计数据。</li>
<li>innodb_index_stats 存储了关于索引的统计数据，每一条记录对应着一个索引的一个统计项的统计数据。</li>
</ul>
<h4 id="1321-innodb_table_stats">13.2.1 innodb_table_stats</h4>
<table>
<thead>
<tr>
<th style="text-align:center">字段名</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>database_name</code></td>
<td style="text-align:left">数据库名</td>
</tr>
<tr>
<td style="text-align:center"><code>table_name</code></td>
<td style="text-align:left">表名</td>
</tr>
<tr>
<td style="text-align:center"><code>last_update</code></td>
<td style="text-align:left">本条记录最后更新时间</td>
</tr>
<tr>
<td style="text-align:center"><code>n_rows</code></td>
<td style="text-align:left">表中记录的条数</td>
</tr>
<tr>
<td style="text-align:center"><code>clustered_index_size</code></td>
<td style="text-align:left">表的聚簇索引占用的页面数量</td>
</tr>
<tr>
<td style="text-align:center"><code>sum_of_other_index_sizes</code></td>
<td style="text-align:left">表的其他索引占用的页面数量</td>
</tr>
</tbody>
</table>
<p>注意这个表的主键是 (database_name,table_name) ，也就是innodb_table_stats表的每条记录代表着一个表的统计信息。</p>
<h5 id="n_rows统计项的收集">n_rows统计项的收集</h5>
<p>InnoDB 统计一个表中有多少行记录的套路是这样的:</p>
<ul>
<li>按照一定算法(并不是纯粹随机的)选取几个叶子节点页面，计算每个页面中主键值记录数量，然后计算平<br>
均一个页面中主键值的记录数量乘以全部叶子节点的数量就算是该表的 n_rows 值。</li>
</ul>
<p>可以看出来这个<code>n_rows</code>值精确与否取决于统计时采样的页面数量，设计MySQL很贴心的为我们准备了一个名为<code>innodb_stats_persistent_sample_pages</code>的系统变量来控制<span style="color:red">使用永久性的统计数据时，计算统计数据时采样的页面数量</span>。该值设置的越大，统计出的<code>n_rows</code>值越精确，但是统计耗时也就最久；该值设置的越小，统计出的<code>n_rows</code>值越不精确，但是统计耗时特别少。所以在实际使用是需要我们去权衡利弊，该系统变量的默认值是<code>20</code>。</p>
<p>我们前面说过，不过<code>InnoDB</code>默认是<span style="color:red">以表为单位来收集和存储统计数据的</span>，我们也可以单独设置某个表的采样页面的数量，设置方式就是在创建或修改表的时候通过指定<code>STATS_SAMPLE_PAGES</code>属性来指明该表的统计数据存储方式：</p>
<pre><code class="language-mysql">    CREATE TABLE 表名 (...) Engine=InnoDB, STATS_SAMPLE_PAGES = 具体的采样页面数量;   
    ALTER TABLE 表名 Engine=InnoDB, STATS_SAMPLE_PAGES = 具体的采样页面数量;
</code></pre>
<h5 id="clustered_index_size和sum_of_other_index_sizes统计项的收集">clustered_index_size和sum_of_other_index_sizes统计项的收集</h5>
<p>这两个统计项的收集过程如下：</p>
<ol>
<li>从数据字典里找到表的各个索引对应的根页面位置。<br>
系统表<code>SYS_INDEXES</code>里存储了各个索引对应的根页面信息。</li>
<li>从根页面的<code>Page Header</code>里找到叶子节点段和非叶子节点段对应的<code>Segment Header</code>。<br>
在每个索引的根页面的<code>Page Header</code>部分都有两个字段：
<ul>
<li><code>PAGE_BTR_SEG_LEAF</code>：表示B+树叶子段的<code>Segment Header</code>信息。</li>
<li><code>PAGE_BTR_SEG_TOP</code>：表示B+树非叶子段的<code>Segment Header</code>信息。</li>
</ul>
</li>
<li>从叶子节点段和非叶子节点段的<code>Segment Header</code>中找到这两个段对应的<code>INODE Entry</code>结构。</li>
</ol>
<h4 id="1322-innodb_index_stats">13.2.2 innodb_index_stats</h4>
<table>
<thead>
<tr>
<th style="text-align:center">字段名</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>database_name</code></td>
<td style="text-align:left">数据库名</td>
</tr>
<tr>
<td style="text-align:center"><code>table_name</code></td>
<td style="text-align:left">表名</td>
</tr>
<tr>
<td style="text-align:center"><code>index_name</code></td>
<td style="text-align:left">索引名</td>
</tr>
<tr>
<td style="text-align:center"><code>last_update</code></td>
<td style="text-align:left">本条记录最后更新时间</td>
</tr>
<tr>
<td style="text-align:center"><code>stat_name</code></td>
<td style="text-align:left">统计项的名称</td>
</tr>
<tr>
<td style="text-align:center"><code>stat_value</code></td>
<td style="text-align:left">对应的统计项的值</td>
</tr>
<tr>
<td style="text-align:center"><code>sample_size</code></td>
<td style="text-align:left">为生成统计数据而采样的页面数量</td>
</tr>
<tr>
<td style="text-align:center"><code>stat_description</code></td>
<td style="text-align:left">对应的统计项的描述</td>
</tr>
</tbody>
</table>
<p>注意这个表的主键是<code>(database_name,table_name,index_name,stat_name)</code>，其中的<code>stat_name</code>是指统计项的名称，也就是说<span style="color:red">innodb_index_stats表的每条记录代表着一个索引的一个统计项</span>。</p>
<h4 id="1323-定期更新统计数据">13.2.3 定期更新统计数据</h4>
<p>随着我们不断的对表进行增删改操作，表中的数据也一直在变化，<code>innodb_table_stats</code>和<code>innodb_index_stats</code>表里的统计数据是不是也应该跟着变一变了？当然要变了，不变的话<code>MySQL</code>查询优化器计算的成本可就差老鼻子远了。<code>MySQL</code>提供了如下两种更新统计数据的方式：</p>
<ul>
<li>开启<code>innodb_stats_auto_recalc</code>。<br>
系统变量<code>innodb_stats_auto_recalc</code>决定着服务器是否自动重新计算统计数据，它的默认值是<code>ON</code>，也就是该功能默认是开启的。每个表都维护了一个变量，该变量记录着对该表进行增删改的记录条数，如果发生变动的记录数量超过了表大小的<code>10%</code>，并且自动重新计算统计数据的功能是打开的，那么服务器会重新进行一次统计数据的计算，并且更新<code>innodb_table_stats</code>和<code>innodb_index_stats</code>表。不过<span style="color:red">自动重新计算统计数据的过程是异步发生的</span>，也就是即使表中变动的记录数超过了<code>10%</code>，自动重新计算统计数据也不会立即发生，可能会延迟几秒才会进行计算。</li>
</ul>
<p>再一次强调，<code>InnoDB</code>默认是<span style="color:red">以表为单位来收集和存储统计数据的</span>，我们也可以单独为某个表设置是否自动重新计算统计数的属性，设置方式就是在创建或修改表的时候通过指定<code>STATS_AUTO_RECALC</code>属性来指明该表的统计数据存储方式：</p>
<pre><code class="language-mysql">CREATE TABLE 表名 (...) Engine=InnoDB, STATS_AUTO_RECALC = (1|0);
ALTER TABLE 表名 Engine=InnoDB, STATS_AUTO_RECALC = (1|0);
</code></pre>
<p>当<code>STATS_AUTO_RECALC=1</code>时，表明我们想让该表自动重新计算统计数据，当<code>STATS_PERSISTENT=0</code>时，表明不想让该表自动重新计算统计数据。如果我们在创建表时未指定<code>STATS_AUTO_RECALC</code>属性，那默认采用系统变量<code>innodb_stats_auto_recalc</code>的值作为该属性的值。</p>
<ul>
<li>手动调用<code>ANALYZE TABLE</code>语句来更新统计信息<br>
如果<code>innodb_stats_auto_recalc</code>系统变量的值为<code>OFF</code>的话，我们也可以手动调用<code>ANALYZE TABLE</code>语句来重新计算统计数据，比如我们可以这样更新关于<code>single_table</code>表的统计数据：</li>
</ul>
<pre><code class="language-mysql">mysql&gt; ANALYZE TABLE single_table;
</code></pre>
<p>需要注意的是，<span style="color:red">ANALYZE TABLE语句会立即重新计算统计数据，也就是这个过程是同步的</span>，在表中索引多或者采样页面特别多时这个过程可能会特别慢，请不要没事儿就运行一下<code>ANALYZE TABLE</code>语句，最好在业务不是很繁忙的时候再运行。</p>
<h4 id="1324-手动更新innodb_table_stats和innodb_index_stats表">13.2.4 手动更新<code>innodb_table_stats</code>和<code>innodb_index_stats</code>表</h4>
<p>其实<code>innodb_table_stats</code>和<code>innodb_index_stats</code>表就相当于一个普通的表一样，我们能对它们做增删改查操作。这也就意味着我们可以<span style="color:red">手动更新某个表或者索引的统计数据</span>。</p>
<p>更新完<code>innodb_table_stats</code>只是单纯的修改了一个表的数据，需要让<code>MySQL</code>查询优化器重新加载我们更改过的数据，运行下面的命令就可以了：</p>
<pre><code class="language-mysql">FLUSH TABLE single_table;
</code></pre>
<h3 id="133-基于内存的非永久性统计数据">13.3 基于内存的非永久性统计数据</h3>
<p>当我们把系统变量<code>innodb_stats_persistent</code>的值设置为<code>OFF</code>时，之后创建的表的统计数据默认就都是非永久性的了，或者我们直接在创建表或修改表时设置<code>STATS_PERSISTENT</code>属性的值为<code>0</code>，那么该表的统计数据就是非永久性的了。</p>
<p>与永久性的统计数据不同，非永久性的统计数据采样的页面数量是由<code>innodb_stats_transient_sample_pages</code>控制的，这个系统变量的默认值是<code>8</code>。</p>
<p>另外，由于非永久性的统计数据经常更新，所以导致<code>MySQL</code>查询优化器计算查询成本的时候依赖的是经常变化的统计数据，也就会<span style="color:red">生成经常变化的执行计划</span>。</p>
<h3 id="134-innodb_stats_method的使用">13.4 innodb_stats_method的使用</h3>
<p>我们知道<code>索引列不重复的值的数量</code>这个统计数据对于MySQL查询优化器十分重要，因为通过它可以计算出在索引列中平均一个值重复多少行，它的应用场景主要有两个：</p>
<ul>
<li>单表查询中单点区间太多，当<code>IN</code>里的参数数量过多时，采用<code>index dive</code>的方式直接访问<code>B+</code>树索引去统计每个单点区间对应的记录的数量就太耗费性能了，所以直接依赖统计数据中的平均一个值重复多少行来计算单点区间对应的记录数量。</li>
<li>连接查询时，如果有涉及两个表的等值匹配连接条件，该连接条件对应的被驱动表中的列又拥有索引时，则可以使用<code>ref</code>访问方法来对被驱动表进行查询。</li>
</ul>
<h3 id="135-总结">13.5 总结</h3>
<ul>
<li><code>InnoDB</code>以表为单位来收集统计数据，这些统计数据可以是基于磁盘的永久性统计数据，也可以是基于内存的非永久性统计数据。</li>
<li><code>innodb_stats_persistent</code>控制着使用永久性统计数据还是非永久性统计数据；<code>innodb_stats_persistent_sample_pages</code>控制着永久性统计数据的采样页面数量；<code>innodb_stats_transient_sample_pages</code>控制着非永久性统计数据的采样页面数量；<code>innodb_stats_auto_recalc</code>控制着是否自动重新计算统计数据。</li>
<li>我们可以针对某个具体的表，在创建和修改表时通过指定<code>STATS_PERSISTENT</code>、<code>STATS_AUTO_RECALC</code>、<code>STATS_SAMPLE_PAGES</code>的值来控制相关统计数据属性。</li>
<li><code>innodb_stats_method</code>决定着在统计某个索引列不重复值的数量时如何对待<code>NULL</code>值。</li>
</ul>
<h2 id="第十四章-不好看就要多整容-mysql基于规则的优化内含关于子查询优化二三事儿">第十四章 不好看就要多整容-MySQL基于规则的优化（内含关于子查询优化二三事儿）</h2>
<h3 id="141-条件化简">14.1 条件化简</h3>
<h4 id="1411-移除不必要的括号">14.1.1 移除不必要的括号</h4>
<p>有时候表达式里有许多无用的括号，优化器会把那些用不到的括号给干掉。</p>
<pre><code class="language-mysql">((a = 5 AND b = c) OR ((a &gt; c) AND (c &lt; 5)))
(a = 5 and b = c) OR (a &gt; c AND c &lt; 5)
</code></pre>
<h4 id="1412-常量传递constant_propagation">14.1.2 常量传递（constant_propagation）</h4>
<p>有时候某个表达式是某个列和某个常量做等值匹配，比如这样：</p>
<pre><code class="language-mysql">a = 5 AND b &gt; a
a = 5 AND b &gt; 5
</code></pre>
<p>当这个表达式和其他涉及列a的表达式使用AND连接起来时，可以将其他表达式中的a的值替换为5。</p>
<h4 id="1413-等值传递equality_propagation">14.1.3 等值传递（equality_propagation）</h4>
<p>有时候多个列之间存在等值匹配的关系，比如这样：</p>
<pre><code class="language-mysql">a = b and b = c and c = 5
a = 5 and b = 5 and c = 5
</code></pre>
<h4 id="1414-移除没用的条件trivial_condition_removal">14.1.4 移除没用的条件（trivial_condition_removal）</h4>
<p>对于一些明显永远为TRUE或者FALSE的表达式，优化器会移除掉它们，比如这个表达式：</p>
<pre><code class="language-mysql">(a &lt; 1 and b = b) OR (a = 6 OR 5 != 5)
(a &lt; 1 and TRUE) OR (a = 6 OR FALSE)
a &lt; 1 OR a = 6
</code></pre>
<h4 id="1415-表达式计算">14.1.5 表达式计算</h4>
<p>在查询开始执行之前，如果表达式中只包含常量的话，它的值会被先计算出来，比如这个：a = 5 + 1,所以就会被化简成：a = 6,但是这里需要注意的是，如果某个列并不是以单独的形式作为表达式的操作数时，比如出现在函数中，出现在某个更复杂表达式中，就像这样：ABS(a) &gt; 5 或者-a &lt; -8。</p>
<p>优化器是不会尝试对这些表达式进行化简的。我们前面说过只有搜索条件中索引列和常数使用某些运算符连接起来才可能使用到索引，所以如果可以的话，最好让索引列以单独的形式出现在表达式中。</p>
<h4 id="1416-having子句和where子句的合并">14.1.6 HAVING子句和WHERE子句的合并</h4>
<p>如果查询语句中没有出现诸如SUM、MAX等等的聚集函数以及GROUP BY子句，优化器就把HAVING子句和WHERE子句合并起来。</p>
<h4 id="1417-常量表检测">14.1.7 常量表检测</h4>
<p>下面这两种查询运行的特别快：</p>
<ol>
<li>查询的表中一条记录没有，或者只有一条记录。</li>
<li>使用主键等值匹配或者唯一二级索引列等值匹配作为搜索条件来查询某个表。</li>
</ol>
<p>这两种查询花费的时间特别少，少到可以忽略，所以也把通过这两种方式查询的表称之为常量表（英文名：constant tables）。优化器在分析一个查询语句时，先首先执行常量表查询，然后把查询中涉及到该表的条件全部替换成常数，最后再分析其余表的查询成本。</p>
<h3 id="142-外连接消除">14.2 外连接消除</h3>
<p>我们前面说过，内连接的驱动表和被驱动表的位置可以相互转换，而左（外）连接和右（外）连接的驱动表和被驱动表是固定的。这就导致内连接可能通过优化表的连接顺序来降低整体的查询成本，而外连接却无法优化表的连接顺序。</p>
<p>我们把这种在外连接查询中，指定的WHERE子句中包含被驱动表中的列不为NULL值的条件称之为空值拒绝（英文名：reject-NULL）。在被驱动表的WHERE子句符合空值拒绝的条件后，外连接和内连接可以相互转换。这种转换带来的好处就是查询优化器可以通过评估表的不同连接顺序的成本，选出成本最低的那种连接顺序来执行查询。</p>
<h3 id="143-子查询优化">14.3 子查询优化</h3>
<h4 id="1431-子查询语法">14.3.1 子查询语法</h4>
<p>在一个查询语句里的某个位置也可以有另一个查询语句，这个出现在某个查询语句的某个位置中的查询就被称为子查询。子查询可以在一个外层查询的各种位置出现，比如：</p>
<ol>
<li>SELECT子句中</li>
<li>FROM子句中</li>
<li>WHERE或ON子句中</li>
<li>ORDER BY子句中</li>
<li>GROUP BY子句中</li>
</ol>
<h5 id="按返回的结果集区分子查询">按返回的结果集区分子查询</h5>
<p>因为子查询本身也算是一个查询，所以可以按照它们返回的不同结果集类型而把这些子查询分为不同的类型：</p>
<ol>
<li>标量子查询<br>
那些只返回一个单一值的子查询称之为标量子查询</li>
<li>行子查询<br>
就是返回一条记录的子查询，不过这条记录需要包含多个列（只包含一个列就成了标量子查询了）</li>
<li>列子查询<br>
列子查询自然就是查询出一个列的数据喽，不过这个列的数据需要包含多条记录（只包含一条记录就成了标量子查询了）</li>
<li>表子查询<br>
就是子查询的结果既包含很多条记录，又包含很多个列</li>
</ol>
<h5 id="按与外层查询关系来区分子查询">按与外层查询关系来区分子查询</h5>
<ol>
<li>不相关子查询<br>
  如果子查询可以单独运行出结果，而不依赖于外层查询的值，我们就可以把这个子查询称之为不相关子查询。</li>
<li>相关子查询<br>
  如果子查询的执行需要依赖于外层查询的值，我们就可以把这个子查询称之为相关子查询。</li>
</ol>
<h5 id="子查询在布尔表达式中的使用">子查询在布尔表达式中的使用</h5>
<ol>
<li>
<p>使用=、&gt;、&lt;、&gt;=、&lt;=、&lt;&gt;、!=、&lt;=&gt;作为布尔表达式的操作符<br>
我们就把这些操作符称为comparison_operator吧，所以子查询组成的布尔表达式就长这样：<mark>操作数 comparison_operator (子查询)</mark><br>
这里的操作数可以是某个列名，或者是一个常量，或者是一个更复杂的表达式，甚至可以是另一个子查询。但是需要注意的是，这里的子查询只能是标量子查询或者行子查询，也就是子查询的结果只能返回一个单一的值或者只能是一条记录。</p>
</li>
<li>
<p>[NOT] IN/ANY/SOME/ALL子查询<br>
对于列子查询和表子查询来说，它们的结果集中包含很多条记录，这些记录相当于是一个集合，所以就不能单纯的和另外一个操作数使用comparison_operator来组成布尔表达式了，MySQL通过下面的语法来支持某个操作数和一个集合组成一个布尔表达式：</p>
<ul>
<li>IN或者NOT IN</li>
<li>ANY/SOME（ANY和SOME是同义词）</li>
<li>ALL</li>
</ul>
</li>
<li>
<p>EXISTS子查询</p>
</li>
</ol>
<h5 id="子查询语法注意事项">子查询语法注意事项</h5>
<ol>
<li>子查询必须用小括号扩起来。</li>
<li>在SELECT子句中的子查询必须是标量子查询</li>
<li>在想要得到标量子查询或者行子查询，但又不能保证子查询的结果集只有一条记录时，应该使用LIMIT 1语句来限制记录数量。</li>
<li>对于[NOT] IN/ANY/SOME/ALL子查询来说，子查询中不允许有LIMIT语句。<br>
正因为[NOT] IN/ANY/SOME/ALL子查询不支持LIMIT语句，所以子查询中的这些语句也就是多余的了：
<ul>
<li>ORDER BY子句</li>
<li>DISTINCT语句</li>
<li>没有聚集函数以及HAVING子句的GROUP BY子句。</li>
</ul>
</li>
<li>不允许在一条语句中增删改某个表的记录时同时还对该表进行子查询。</li>
</ol>
<h4 id="1432-子查询在mysql中是怎么执行的">14.3.2 子查询在MySQL中是怎么执行的</h4>
<pre><code class="language-mysql">CREATE TABLE single_table (
    id INT NOT NULL AUTO_INCREMENT,
    key1 VARCHAR(100),
    key2 INT,
    key3 VARCHAR(100),
    key_part1 VARCHAR(100),
    key_part2 VARCHAR(100),
    key_part3 VARCHAR(100),
    common_field VARCHAR(100),
    PRIMARY KEY (id),
    KEY idx_key1 (key1),
    UNIQUE KEY idx_key2 (key2),
    KEY idx_key3 (key3),
    KEY idx_key_part(key_part1, key_part2, key_part3)
) Engine=InnoDB CHARSET=utf8;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[动态线程池]]></title>
        <id>https://q456qq520.github.io/post/dong-tai-xian-cheng-chi/</id>
        <link href="https://q456qq520.github.io/post/dong-tai-xian-cheng-chi/">
        </link>
        <updated>2023-01-10T06:41:44.000Z</updated>
        <summary type="html"><![CDATA[<p>动态线程池</p>
]]></summary>
        <content type="html"><![CDATA[<p>动态线程池</p>
<!-- more -->
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《从根儿上理解MySQL》读书笔记(二)]]></title>
        <id>https://q456qq520.github.io/post/lesslesscong-gen-er-shang-li-jie-mysqlgreatergreater-du-shu-bi-ji-er/</id>
        <link href="https://q456qq520.github.io/post/lesslesscong-gen-er-shang-li-jie-mysqlgreatergreater-du-shu-bi-ji-er/">
        </link>
        <updated>2023-01-06T03:03:12.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="第六章-快速查询的秘籍-b树索引">第六章 快速查询的秘籍-B+树索引</h2>
<p>InnoDB数据页的7个组成部分，各个数据页可以组成一个双向链表，而每个数据页中的记录会按照主键值从小到大的顺序组成一个单向链表，每个数据页都会为存储在它里边儿的记录生成一个页目录，在通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录。页和记录的关系示意图如下：</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="第六章-快速查询的秘籍-b树索引">第六章 快速查询的秘籍-B+树索引</h2>
<p>InnoDB数据页的7个组成部分，各个数据页可以组成一个双向链表，而每个数据页中的记录会按照主键值从小到大的顺序组成一个单向链表，每个数据页都会为存储在它里边儿的记录生成一个页目录，在通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录。页和记录的关系示意图如下：</p>
<!-- more -->
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1672974328979.png" alt="" loading="lazy"></figure>
<h3 id="61-没有索引的查找">6.1 没有索引的查找</h3>
<p>假设现在有一个精准匹配的sql语句：</p>
<pre><code class="language-mysql">SELECT [列名列表] FROM 表名 WHERE 列名 = xxx;
</code></pre>
<h4 id="611-在一个页中的查找">6.1.1 在一个页中的查找</h4>
<p>假设目前表中的记录比较少，所有的记录都可以被存放到一个页中，在查找记录的时候可以根据搜索条件的不同分为两种情况：</p>
<ol>
<li>以主键为搜索条件
<ol>
<li>可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录。</li>
</ol>
</li>
<li>以其他列作为搜索条件
<ol>
<li>对非主键列的查找的过程来说，因为在数据页中并没有对非主键列建立所谓的页目录，所以我们无法通过二分法快速定位相应的槽。这种情况下只能从最小记录开始依次遍历单链表中的每条记录，然后对比每条记录是不是符合搜索条件。很显然，这种查找的效率是非常低的。</li>
</ol>
</li>
</ol>
<h4 id="612-在很多页中查找">6.1.2 在很多页中查找</h4>
<p>大部分情况下我们表中存放的记录都是非常多的，需要好多的数据页来存储这些记录。在很多页中查找记录的话可以分为两个步骤：</p>
<ol>
<li>定位到记录所在的页。</li>
<li>从所在的页内中查找相应的记录。</li>
</ol>
<p>在没有索引的情况下，不论是根据主键列或者其他列的值进行查找，由于我们并不能快速的定位到记录所在的页，所以只能从第一个页沿着双向链表一直往下找，在每一个页中根据我们刚刚介绍过的查找方式去查找指定的记录。因为要遍历所有的数据页，所以这种方式显然是超级耗时的。</p>
<h3 id="62-索引">6.2 索引</h3>
<p>首先创建一个表：</p>
<pre><code class="language-mysql">mysql&gt; CREATE TABLE index_demo(
    -&gt;     c1 INT,
    -&gt;     c2 INT,
    -&gt;     c3 CHAR(1),
    -&gt;     PRIMARY KEY(c1)
    -&gt; ) ROW_FORMAT = Compact;
Query OK, 0 rows affected (0.03 sec)
</code></pre>
<p>这个新建的index_demo表中有2个INT类型的列，1个CHAR(1)类型的列，而且我们规定了c1列为主键，这个表使用Compact行格式来实际存储记录的。简化后的行格式示意图如下：<br>
<img src="https://q456qq520.github.io/post-images/1673255537195.png" alt="" loading="lazy"></p>
<ol>
<li><font color=red>record_type</font>：记录头信息的一项属性，表示记录的类型，0表示普通记录、2表示最小记录、3表示最大记录、1表示目录项记录。</li>
<li><font color=red>next_record</font>：记录头信息的一项属性，表示下一条地址相对于本条记录的地址偏移量。</li>
<li><font color=red>各个列的值</font>：这里只记录在index_demo表中的三个列，分别是c1、c2和c3。</li>
<li><font color=red>其他信息</font>：除了上述3种信息以外的所有信息，包括其他隐藏列的值以及记录的额外信息。</li>
</ol>
<p>把一些记录放到页里边的示意图就是<br>
<img src="https://q456qq520.github.io/post-images/1673255803400.png" alt="" loading="lazy"></p>
<h4 id="621-一个简单的索引方案">6.2.1 一个简单的索引方案</h4>
<p>我们在根据某个搜索条件查找一些记录时为什么要遍历所有的数据页呢？因为各个页中的记录并没有规律，我们并不知道我们的搜索条件匹配哪些页中的记录，所以不得不依次遍历所有的数据页。所以如果我们想快速的定位到需要查找的记录在哪些数据页中该咋办？还记得我们为根据主键值快速定位一条记录在页中的位置而设立的页目录么？我们也可以想办法为快速定位记录所在的数据页而建立一个别的目录，建这个目录必须完成下面这些事儿：</p>
<ol>
<li>下一个数据页中用户记录的主键值必须大于上一个页中用户记录的主键值。<br>
根据上面的示意图，现在假设页10最多只能放3条记录，如果已经存放3条纪录，此时我们再插入一条，我们不得不再分配一个新页：</li>
</ol>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1673256353194.png" alt="" loading="lazy"></figure>
<p>新分配的数据页编号可能并不是连续的，也就是说我们使用的这些页在存储空间里可能并不挨着。它们只是通过维护着上一个页和下一个页的编号而建立了链表关系。另外，页10中用户记录最大的主键值是5，而页28中有一条记录的主键值是4，因为5 &gt; 4，所以这就不符合 <font color=red>下一个数据页中用户记录的主键值必须大于上一个页中用户记录的主键值</font>的要求，所以在插入主键值为4的记录的时候需要伴随着一次记录移动，也就是把主键值为5的记录移动到页28中，然后再把主键值为4的记录插入到页10中，这个过程的步骤如下：</p>
<pre><code>1. 将主键值为5的纪录移动到页28
2. 将主键值为4的纪录插入到页10
</code></pre>
<p>这个过程表明了在对页中的记录进行增删改操作的过程中，我们必须通过一些诸如记录移动的操作来始终保证这个状态一直成立：下一个数据页中用户记录的主键值必须大于上一个页中用户记录的主键值。这个过程我们也可以称为<font color=red>页分裂</font>。</p>
<ol start="2">
<li>给所有的页建立一个目录项。</li>
</ol>
<p>因为这些16KB的页在物理存储上可能并不挨着，所以如果想从这么多页中根据主键值快速定位某些记录所在的页，我们需要给它们做个目录，每个页对应一个目录项，每个目录项包括下面两个部分：</p>
<ol>
<li>页的用户记录中最小的主键值，我们用key来表示。</li>
<li>页号，我们用page_no表示。</li>
</ol>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1673257308373.png" alt="" loading="lazy"></figure>
<p>以页28为例，它对应目录项2，这个目录项中包含着该页的页号28以及该页中用户记录的最小主键值5。我们只需要把几个目录项在物理存储器上连续存储，比如把他们放到一个数组里，就可以实现根据主键值快速查找某条记录的功能了。比方说我们想找主键值为20的记录，具体查找过程分两步：</p>
<pre><code>1. 先从目录项中根据二分法快速确定出主键值为20的记录在目录项3中（因为 12 &lt; 20 &lt; 209），它对应的页是页9。
2. 再根据前面说的在页中查找记录的方式去页9中定位具体的记录。
</code></pre>
<p>针对数据页做的简易目录就搞定了。不过忘了说了，这个目录有一个别名，称为<font color=red>索引</font>。</p>
<h3 id="63-innodb中的索引方案">6.3 InnoDB中的索引方案</h3>
<p>上面之所以称为一个简易的索引方案，是因为我们为了在根据主键值进行查找时使用二分法快速定位具体的目录项而假设所有目录项都可以在物理存储器上连续存储，但是这样做有几个问题：</p>
<ol>
<li>InnoDB是使用页来作为管理存储空间的基本单位，也就是最多能保证16KB的连续存储空间，而随着表中记录数量的增多，需要非常大的连续的存储空间才能把所有的目录项都放下，这对记录数量非常多的表是不现实的。</li>
<li>我们时常会对记录进行增删，假设我们把页28中的记录都删除了，页28也就没有存在的必要了，那意味着目录项2也就没有存在的必要了，这就需要把目录项2后的目录项都向前移动一下，这种牵一发而动全身的设计不是什么好主意～</li>
</ol>
<p>所以，设计InnoDB的大佬们需要一种可以灵活管理所有目录项的方式。他们灵光乍现，忽然发现这些目录项其实长得跟我们的用户记录差不多，只不过目录项中的两个列是主键和页号而已，所以他们<font color=red>复用了之前存储用户记录的数据页来存储目录项，为了和用户记录做一下区分，我们把这些用来表示目录项的记录称为目录项记录</font>。那InnoDB怎么区分一条记录是普通的用户记录还是目录项记录呢？别忘了记录头信息里的record_type属性，它的各个取值代表的意思如下：</p>
<pre><code>0：普通的用户记录
1：目录项记录
2：最小记录
3：最大记录
</code></pre>
<p>我们把前面使用到的目录项放到数据页中的样子就是这样：<br>
<img src="https://q456qq520.github.io/post-images/1673257995600.png" alt="" loading="lazy"></p>
<p>从图中可以看出来，我们新分配了一个编号为30的页来专门存储目录项记录。这里再次强调一遍目录项记录和普通的用户记录的不同点：</p>
<pre><code>1. 目录项记录的record_type值是1，而普通用户记录的record_type值是0。
2. 目录项记录只有主键值和页的编号两个列，而普通的用户记录的列是用户自己定义的，可能包含很多列，另外还有InnoDB自己添加的隐藏列。
3. 还记得我们之前在介绍记录头信息的时候说过一个叫min_rec_mask的属性么，只有在存储目录项记录的页中的主键值最小的目录项记录的min_rec_mask值为1，其他别的记录的min_rec_mask值都是0。
</code></pre>
<p>现在以查找主键为20的记录为例，根据某个主键值去查找记录的步骤就可以大致拆分成下面两步：</p>
<pre><code>1. 先到存储目录项记录的页，也就是页30中通过二分法快速定位到对应目录项，因为12 &lt; 20 &lt; 209，所以定位到对应的记录所在的页就是页9。
2. 再到存储用户记录的页9中根据二分法快速定位到主键值为20的用户记录。
</code></pre>
<p>虽然说目录项记录中只存储主键值和对应的页号，比用户记录需要的存储空间小多了，但是不论怎么说一个页只有16KB大小，能存放的目录项记录也是有限的，那如果表中的数据太多，以至于一个数据页不足以存放所有的目录项记录，该咋办呢？</p>
<p>当然是再多整一个存储目录项记录的页。</p>
<p>在这个查询步骤我们需要定位存储目录项记录的页，但是这些页在存储空间中也可能不挨着，如果我们表中的数据非常多则会产生很多存储目录项记录的页，那我们怎么根据主键值快速定位一个存储目录项记录的页呢？其实也简单，为这些存储目录项记录的页再生成一个更高级的目录，就像是一个多级目录一样，大目录里嵌套小目录，小目录里才是实际的数据，所以现在各个页的示意图就是这样子：</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1673344581977.png" alt="" loading="lazy"></figure>
<p>如图，我们生成了一个存储更高级目录项的页33，这个页中的两条记录分别代表页30和页32，如果用户记录的主键值在[1, 320)之间，则到页30中查找更详细的目录项记录，如果主键值不小于320的话，就到页32中查找更详细的目录项记录。</p>
<p>当结构再深一点，看起来就会像一棵树，或者说是一种数据结构，它的名称是<font color=red>B+树</font>。</p>
<p>不论是存放用户记录的数据页，还是存放目录项记录的数据页，我们都把它们存放到B+树这个数据结构中了，所以我们也称这些数据页为节点。从图中可以看出来，我们的实际用户记录其实都存放在B+树的最底层的节点上，这些节点也被称为<strong>叶子节点</strong>或<strong>叶节点</strong>，其余用来存放目录项的节点称为<strong>非叶子节点</strong>或者<strong>内节点</strong>，其中B+树最上面的那个节点也称为<strong>根节点</strong>。</p>
<p>一个B+树的节点其实可以分成好多层，InnoDB规定最下面的那层，也就是存放我们用户记录的那层为第0层，之后依次往上加。</p>
<h4 id="631-聚簇索引">6.3.1 聚簇索引</h4>
<p>我们上面介绍的B+树本身就是一个目录，或者说本身就是一个索引。它有两个特点：</p>
<ol>
<li>
<p>使用记录主键值的大小进行记录和页的排序，这包括三个方面的含义：</p>
<ul>
<li>页内的记录是按照主键的大小顺序排成一个单向链表。</li>
<li>各个存放用户记录的页也是根据页中用户记录的主键大小顺序排成一个双向链表。</li>
<li>存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的主键大小顺序排成一个双向链表。</li>
</ul>
</li>
<li>
<p>B+树的叶子节点存储的是完整的用户记录<br>
所谓完整的用户记录，就是指这个记录中存储了所有列的值（包括隐藏列）。</p>
</li>
</ol>
<p>我们把具有这两种特性的B+树称为聚簇索引，所有完整的用户记录都存放在这个聚簇索引的叶子节点处。这种聚簇索引并不需要我们在MySQL语句中显式的使用INDEX语句去创建，InnoDB存储引擎会自动的为我们创建聚簇索引。在InnoDB存储引擎中，聚簇索引就是数据的存储方式（所有的用户记录都存储在了叶子节点），也就是所谓的索引即数据，数据即索引。</p>
<h4 id="632-二级索引">6.3.2 二级索引</h4>
<p>聚簇索引只能在搜索条件是主键值时才能发挥作用，因为B+树中的数据都是按照主键进行排序的。那如果我们想以别的列作为搜索条件该咋办呢？难道只能从头到尾沿着链表依次遍历记录么？</p>
<p>我们可以多建几棵B+树，不同的B+树中的数据采用不同的排序规则。比方说我们用c2列的大小作为数据页、页中记录的排序规则，再建一棵B+树，效果如下图所示：</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1673345776221.png" alt="" loading="lazy"></figure>
<p>这个B+树与上面介绍的聚簇索引有几处不同：</p>
<ol>
<li>使用记录c2列的大小进行记录和页的排序，这包括三个方面的含义：
<ol>
<li>页内的记录是按照c2列的大小顺序排成一个单向链表。</li>
<li>各个存放用户记录的页也是根据页中记录的c2列大小顺序排成一个双向链表。</li>
<li>存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的c2列大小顺序排成一个双向链表。</li>
</ol>
</li>
<li>B+树的叶子节点存储的并不是完整的用户记录，而只是c2列+主键这两个列的值。</li>
<li>目录项记录中不再是主键+页号的搭配，而变成了c2列+页号的搭配。</li>
</ol>
<p>所以如果我们现在想通过c2列的值查找某些记录的话就可以使用我们刚刚建好的这个B+树了。以查找c2列的值为4的记录为例，查找过程如下：</p>
<ol>
<li>确定目录项记录页<br>
根据根页面，也就是页44，可以快速定位到目录项记录所在的页为页42（因为2 &lt; 4 &lt; 9）。</li>
<li>通过目录项记录页确定用户记录真实所在的页。<br>
在页42中可以快速定位到实际存储用户记录的页，但是由于c2列并没有唯一性约束，所以c2列值为4的记录可能分布在多个数据页中，又因为2 &lt; 4 ≤ 4，所以确定实际存储用户记录的页在页34和页35中。</li>
<li>在真实存储用户记录的页中定位到具体的记录。<br>
到页34和页35中定位到具体的记录。</li>
<li>但是这个B+树的叶子节点中的记录只存储了c2和c1（也就是主键）两个列，所以我们必须再根据主键值去聚簇索引中再查找一遍完整的用户记录。</li>
</ol>
<p>我们根据这个以c2列大小排序的B+树只能确定我们要查找记录的主键值，所以如果我们想根据c2列的值查找到完整的用户记录的话，仍然需要到聚簇索引中再查一遍，这个过程也被称为回表。也就是根据c2列的值查询一条完整的用户记录需要使用到2棵B+树。</p>
<p>这种按照非主键列建立的B+树需要一次回表操作才可以定位到完整的用户记录，所以这种B+树也被称为二级索引（英文名secondary index），或者辅助索引。由于我们使用的是c2列的大小作为B+树的排序规则，所以我们也称这个B+树为为c2列建立的索引。</p>
<h3 id="633-联合索引">6.3.3 联合索引</h3>
<p>我们也可以同时以多个列的大小作为排序规则，也就是同时为多个列建立索引，比方说我们想让B+树按照c2和c3列的大小进行排序，这个包含两层含义：</p>
<ol>
<li>先把各个记录和页按照c2列进行排序。</li>
<li>在记录的c2列相同的情况下，采用c3列进行排序</li>
</ol>
<p>为c2和c3列建立的索引的示意图如下：<br>
<img src="https://q456qq520.github.io/post-images/1673346164259.png" alt="" loading="lazy"></p>
<ol>
<li>每条目录项记录都由c2、c3、页号这三个部分组成，各条记录先按照c2列的值进行排序，如果记录的c2列相同，则按照c3列的值进行排序。</li>
<li>B+树叶子节点处的用户记录由c2、c3和主键c1列组成。
<blockquote>
<p>千万要注意一点，以c2和c3列的大小为排序规则建立的B+树称为联合索引，本质上也是一个二级索引。它的意思与分别为c2和c3列分别建立索引的表述是不同的</p>
</blockquote>
</li>
</ol>
<h3 id="64-innodb的b树索引的注意事项">6.4 InnoDB的B+树索引的注意事项</h3>
<h4 id="641-b树形成规则">6.4.1 B+树形成规则</h4>
<ol>
<li>每当为某个表创建一个B+树索引（聚簇索引不是人为创建的，默认就有）的时候，都会为这个索引创建一个根节点页面。最开始表中没有数据的时候，每个B+树索引对应的根节点中既没有用户记录，也没有目录项记录。</li>
<li>随后向表中插入用户记录时，先把用户记录存储到这个根节点中。</li>
<li>当根节点中的可用空间用完时继续插入记录，此时会将根节点中的所有记录复制到一个新分配的页，比如页a中，然后对这个新页进行页分裂的操作，得到另一个新页，比如页b。这时新插入的记录根据键值（也就是聚簇索引中的主键值，二级索引中对应的索引列的值）的大小就会被分配到页a或者页b中，而根节点便升级为存储目录项记录的页。</li>
</ol>
<p><font color=red>一个B+树索引的根节点自诞生之日起，便不会再移动。</font>这样只要我们对某个表建立一个索引，那么它的根节点的页号便会被记录到某个地方，然后凡是InnoDB存储引擎需要用到这个索引的时候，都会从那个固定的地方取出根节点的页号，从而来访问这个索引。</p>
<h4 id="642-内节点中目录项记录的唯一性">6.4.2 内节点中目录项记录的唯一性</h4>
<p>为了让新插入记录能找到自己在那个页里，我们需要保证在B+树的同一层内节点的目录项记录除页号这个字段以外是唯一的。所以对于二级索引的内节点的目录项记录的内容实际上是由三个部分构成的：</p>
<ol>
<li>索引列的值</li>
<li>主键值</li>
<li>页号</li>
</ol>
<p>也就是我们把主键值也添加到二级索引内节点中的目录项记录了，这样就能保证B+树每一层节点中各条目录项记录除页号这个字段外是唯一的。</p>
<h4 id="643-一个页面最少存储2条记录">6.4.3 一个页面最少存储2条记录</h4>
<p>一个B+树只需要很少的层级就可以轻松存储数亿条记录，查询速度杠杠的！这是因为B+树本质上就是一个大的多层级目录，每经过一个目录时都会过滤掉许多无效的子目录，直到最后访问到存储真实数据的目录。那如果一个大的目录中只存放一个子目录是什么效果呢？那就是目录层级非常非常非常多，而且最后的那个存放真实数据的目录中只能存放一条记录。费了半天劲只能存放一条真实的用户记录？</p>
<p>InnoDB的一个数据页至少可以存放两条记录</p>
<h3 id="65-myisam中的索引方案简单介绍">6.5 MyISAM中的索引方案简单介绍</h3>
<p>我们知道InnoDB中索引即数据，也就是聚簇索引的那棵B+树的叶子节点中已经把所有完整的用户记录都包含了，而MyISAM的索引方案虽然也使用树形结构，但是却将索引和数据分开存储：</p>
<ol>
<li>
<p>将表中的记录按照记录的插入顺序单独存储在一个文件中，称之为数据文件。这个文件并不划分为若干个数据页，有多少记录就往这个文件中塞多少记录就成了。我们可以通过行号而快速访问到一条记录。MyISAM记录也需要记录头信息来存储一些额外数据。由于在插入数据的时候并没有刻意按照主键大小排序，所以我们并不能在这些数据上使用二分法进行查找。</p>
</li>
<li>
<p>使用MyISAM存储引擎的表会把索引信息另外存储到一个称为索引文件的另一个文件中。MyISAM会单独为表的主键创建一个索引，只不过在索引的叶子节点中存储的不是完整的用户记录，而是主键值 + 行号的组合。也就是先通过索引找到对应的行号，再通过行号去找对应的记录。</p>
<pre><code> 这一点和InnoDB是完全不相同的，在InnoDB存储引擎中，我们只需要根据主键值对聚簇索引进行一次查找就能找到对应的记录，而在MyISAM中却需要进行一次回表操作，意味着MyISAM中建立的索引相当于全部都是二级索引！
</code></pre>
</li>
<li>
<p>如果有需要的话，我们也可以对其它的列分别建立索引或者建立联合索引，原理和InnoDB中的索引差不多，不过在叶子节点处存储的是相应的列 + 行号。这些索引也全部都是二级索引。</p>
</li>
</ol>
<h3 id="66-mysql中创建和删除索引的语句">6.6 MySQL中创建和删除索引的语句</h3>
<p>InnoDB和MyISAM会自动为主键或者声明为UNIQUE的列去自动建立B+树索引，但是如果我们想为其他的列建立索引就需要我们显式的去指明。<br>
我们可以在创建表的时候指定需要建立索引的单个列或者建立联合索引的多个列：</p>
<pre><code class="language-mysql">CREATE TALBE 表名 (
    各种列的信息 ··· , 
    [KEY|INDEX] 索引名 (需要被索引的单个列或多个列)
)
</code></pre>
<p>建议以idx_为前缀，后边跟着需要建立索引的列名，多个列名之间用下划线_分隔开。<br>
其中的KEY和INDEX是同义词，任意选用一个就可以。我们也可以在修改表结构的时候添加索引：</p>
<pre><code class="language-mysql">ALTER TABLE 表名 ADD [INDEX|KEY] 索引名 (需要被索引的单个列或多个列);
</code></pre>
<p>也可以在修改表结构的时候删除索引：</p>
<pre><code class="language-mysql">ALTER TABLE 表名 DROP [INDEX|KEY] 索引名;
</code></pre>
<h2 id="第七章-学会怎么用-b树索引的使用">第七章 学会怎么用-B+树索引的使用</h2>
<ol>
<li>
<p>每个索引都对应一棵B+树，B+树分为好多层，最下面一层是叶子节点，其余的是内节点。所有用户记录都存储在B+树的叶子节点，所有目录项记录都存储在内节点。</p>
</li>
<li>
<p>InnoDB存储引擎会自动为主键（如果没有它会自动帮我们添加）建立聚簇索引，聚簇索引的叶子节点包含完整的用户记录。</p>
</li>
<li>
<p>我们可以为自己感兴趣的列建立二级索引，二级索引的叶子节点包含的用户记录由索引列 + 主键组成，所以如果想通过二级索引来查找完整的用户记录的话，需要通过回表操作，也就是在通过二级索引找到主键值之后再到聚簇索引中查找完整的用户记录。</p>
</li>
<li>
<p>B+树中每层节点都是按照索引列值从小到大的顺序排序而组成了双向链表，而且每个页内的记录（不论是用户记录还是目录项记录）都是按照索引列的值从小到大的顺序而形成了一个单链表。如果是联合索引的话，则页面和记录先按照联合索引前面的列排序，如果该列值相同，再按照联合索引后边的列排序。</p>
</li>
<li>
<p>通过索引查找记录是从B+树的根节点开始，一层一层向下搜索。由于每个页面都按照索引列的值建立了Page Directory（页目录），所以在这些页面中的查找非常快。</p>
</li>
</ol>
<h3 id="71-索引的代价">7.1 索引的代价</h3>
<p>虽然索引是个好东西，可不能乱建，它在空间和时间上都会拖后腿：</p>
<ul>
<li>空间上的代价
<ul>
<li>每建立一个索引都要为它建立一棵B+树，每一棵B+树的每一个节点都是一个数据页，一个页默认会占用16KB的存储空间，一棵很大的B+树由许多数据页组成，那可是很大的一片存储空间呢。</li>
</ul>
</li>
<li>时间上的代价
<ul>
<li>每次对表中的数据进行增、删、改操作时，都需要去修改各个B+树索引。而且我们讲过，B+树每层节点都是按照索引列的值从小到大的顺序排序而组成了双向链表。不论是叶子节点中的记录，还是内节点中的记录（也就是不论是用户记录还是目录项记录）都是按照索引列的值从小到大的顺序而形成了一个单向链表。而增、删、改操作可能会对节点和记录的排序造成破坏，所以存储引擎需要额外的时间进行一些记录移位，页面分裂、页面回收什么的操作来维护好节点和记录的排序。如果我们建了许多索引，每个索引对应的B+树都要进行相关的维护操作</li>
</ul>
</li>
</ul>
<p>所以说，一个表上索引建的越多，就会占用越多的存储空间，在增删改记录的时候性能就越差。</p>
<h3 id="72-b树索引适用的条件">7.2 B+树索引适用的条件</h3>
<p>我们需要先创建一个表，这个表是用来存储人的一些基本信息的：</p>
<pre><code class="language-mysql">CREATE TABLE person_info(
    id INT NOT NULL auto_increment,
    name VARCHAR(100) NOT NULL,
    birthday DATE NOT NULL,
    phone_number CHAR(11) NOT NULL,
    country varchar(100) NOT NULL,
    PRIMARY KEY (id),
    KEY idx_name_birthday_phone_number (name, birthday, phone_number)
);
</code></pre>
<ol>
<li>表中的主键是id列，它存储一个自动递增的整数。所以InnoDB存储引擎会自动为id列建立聚簇索引。</li>
<li>我们额外定义了一个二级索引idx_name_birthday_phone_number，它是由3个列组成的联合索引。所以在这个索引对应的B+树的叶子节点处存储的用户记录只保留name、birthday、phone_number这三个列的值以及主键id的值，并不会保存country列的值。</li>
</ol>
<p>idx_name_birthday_phone_number的示意图如下：<br>
<img src="https://q456qq520.github.io/post-images/1673492192065.png" alt="" loading="lazy"></p>
<p>从图中可以看出，这个idx_name_birthday_phone_number索引对应的B+树中页面和记录的排序方式就是这样的：</p>
<ol>
<li>先按照name列的值进行排序。</li>
<li>如果name列的值相同，则按照birthday列的值进行排序。</li>
<li>如果birthday列的值也相同，则按照phone_number的值进行排序。<br>
这个排序方式十分重要，因为只要页面和记录是排好序的，我们就可以通过二分法来快速定位查找。</li>
</ol>
<h4 id="721-全值匹配">7.2.1 全值匹配</h4>
<p>如果我们的搜索条件中的列和索引列一致的话，这种情况就称为全值匹配，比方说下面这个查找语句：</p>
<pre><code class="language-mysql">SELECT * FROM person_info WHERE name = 'Ashburn' AND birthday = '1990-09-27' AND phone_number = '15123983239';
</code></pre>
<ol>
<li>因为B+树的数据页和记录先是按照name列的值进行排序的，所以先可以很快定位name列的值是Ashburn的记录位置。</li>
<li>在name列相同的记录里又是按照birthday列的值进行排序的，所以在name列的值是Ashburn的记录里又可以快速定位birthday列的值是'1990-09-27'的记录。</li>
<li>如果很不幸，name和birthday列的值都是相同的，那记录是按照phone_number列的值排序的，所以联合索引中的三个列都可能被用到。</li>
</ol>
<blockquote>
<p>WHERE子句中的几个搜索条件的顺序对查询结果没有影响。MySQL有一个叫查询优化器的东东，会分析这些搜索条件并且按照可以使用的索引中列的顺序来决定先使用哪个搜索条件，后使用哪个搜索条件。</p>
</blockquote>
<h4 id="722-匹配左边的列">7.2.2 匹配左边的列</h4>
<p>其实在我们的搜索语句中也可以不用包含全部联合索引中的列，只包含左边的就行或者包含多个左边的列也行，比方说下面的查询语句：</p>
<pre><code class="language-mysql">SELECT * FROM person_info WHERE name = 'Ashburn';
SELECT * FROM person_info WHERE name = 'Ashburn' AND birthday = '1990-09-27';
</code></pre>
<p>那为什么搜索条件中必须出现左边的列才可以使用到这个B+树索引呢？比如下面的语句就用不到这个B+树索引么？</p>
<pre><code class="language-mysql">SELECT * FROM person_info WHERE birthday = '1990-09-27';
</code></pre>
<p>是的，的确用不到，因为B+树的数据页和记录先是按照name列的值排序的，在name列的值相同的情况下才使用birthday列进行排序，也就是说name列的值不同的记录中birthday的值可能是无序的。而现在你跳过name列直接根据birthday的值去查找，臣妾做不到呀～ 那如果我就想在只使用birthday的值去通过B+树索引进行查找咋办呢？这好办，你再对birthday列建一个B+树索引就行了。</p>
<p>但是需要特别注意的一点是，如果我们想使用联合索引中尽可能多的列，搜索条件中的各个列必须是联合索引中从最左边连续的列。比方说联合索引idx_name_birthday_phone_number中列的定义顺序是name、birthday、phone_number，如果我们的搜索条件中只有name和phone_number，而没有中间的birthday。</p>
<p>这样只能用到name列的索引，birthday和phone_number的索引就用不上了，因为name值相同的记录先按照birthday的值进行排序，birthday值相同的记录才按照phone_number值进行排序。</p>
<h4 id="723-匹配列前缀">7.2.3 匹配列前缀</h4>
<p>某个列建立索引的意思其实就是在对应的B+树的记录中使用该列的值进行排序，比方说person_info表上建立的联合索引idx_name_birthday_phone_number会先用name列的值进行排序，所以这个联合索引对应的B+树中的记录的name列的排列就是这样的：</p>
<pre><code class="language-mysql">Aaron
Aaron
...
Aaron
Asa
Ashburn
...
Ashburn
Baird
Barlow
...
Barlow
</code></pre>
<p>字符串排序的本质就是比较哪个字符串大一点儿，哪个字符串小一点，比较字符串大小就用到了该列的字符集和比较规则,一般的比较规则都是逐个比较字符的大小，也就是说我们比较两个字符串的大小的过程其实是这样的：</p>
<ol>
<li>先比较字符串的第一个字符，第一个字符小的那个字符串就比较小。</li>
<li>如果两个字符串的第一个字符相同，那就再比较第二个字符，第二个字符比较小的那个字符串就比较小。</li>
<li>如果两个字符串的第二个字符也相同，那就接着比较第三个字符，依此类推。</li>
</ol>
<p>所以一个排好序的字符串列其实有这样的特点：</p>
<ol>
<li>先按照字符串的第一个字符进行排序。</li>
<li>如果第一个字符相同再按照第二个字符进行排序。</li>
<li>如果第二个字符相同再按照第三个字符进行排序，依此类推。</li>
</ol>
<p>也就是说这些字符串的前n个字符，也就是前缀都是排好序的，所以对于字符串类型的索引列来说，我们只匹配它的前缀也是可以快速定位记录的，比方说我们想查询名字以'As'开头的记录，那就可以这么写查询语句：</p>
<pre><code class="language-mysql">SELECT * FROM person_info WHERE name LIKE 'As%';
</code></pre>
<p>但是需要注意的是，如果只给出后缀或者中间的某个字符串，比如这样：</p>
<pre><code class="language-mysql">SELECT * FROM person_info WHERE name LIKE '%As%';
</code></pre>
<p>MySQL就无法快速定位记录位置了，因为字符串中间有'As'的字符串并没有排好序，所以只能全表扫描了。有时候我们有一些匹配某些字符串后缀的需求，比方说某个表有一个url列，该列中存储了许多url：</p>
<pre><code class="language-mysql">+----------------+
| url            |
+----------------+
| www.baidu.com  |
| www.google.com |
| www.gov.cn     |
| ...            |
| www.wto.org    |
+----------------+
</code></pre>
<p>假设已经对该url列创建了索引，如果我们想查询以com为后缀的网址的话可以这样写查询条件：WHERE url LIKE '%com'，但是这样的话无法使用该url列的索引。为了在查询时用到这个索引而不至于全表扫描，我们可以把后缀查询改写成前缀查询，不过我们就得把表中的数据全部逆序存储一下，也就是说我们可以这样保存url列中的数据：</p>
<pre><code class="language-mysql">+----------------+
| url            |
+----------------+
| moc.udiab.www  |
| moc.elgoog.www |
| nc.vog.www     |
| ...            |
| gro.otw.www    |
+----------------+
</code></pre>
<p>这样再查找以com为后缀的网址时搜索条件便可以这么写：WHERE url LIKE 'moc%'，这样就可以用到索引了。</p>
<h4 id="724-匹配范围值">7.2.4 匹配范围值</h4>
<p>回头看我们idx_name_birthday_phone_number索引的B+树示意图，所有记录都是按照索引列的值从小到大的顺序排好序的，所以这极大的方便我们查找索引列的值在某个范围内的记录。比方说下面这个查询语句：</p>
<pre><code class="language-mysql">SELECT * FROM person_info WHERE name &gt; 'Asa' AND name &lt; 'Barlow';
</code></pre>
<p>由于B+树中的数据页和记录是先按name列排序的，所以我们上面的查询过程其实是这样的：</p>
<ol>
<li>找到name值为Asa的记录。</li>
<li>找到name值为Barlow的记录。</li>
<li>取出中间值。</li>
<li>找到这些记录的主键值，再到聚簇索引中回表查找完整的记录。</li>
</ol>
<p>不过在使用联合进行范围查找的时候需要注意，<font color=red>如果对多个列同时进行范围查找的话，只有对索引最左边的那个列进行范围查找的时候才能用到B+树索引</font>，比方说这样：</p>
<pre><code class="language-mysql">SELECT * FROM person_info WHERE name &gt; 'Asa' AND name &lt; 'Barlow' AND birthday &gt; '1980-01-01';
</code></pre>
<ol>
<li>通过条件name &gt; 'Asa' AND name &lt; 'Barlow' 来对name进行范围，查找的结果可能有多条name值不同的记录，</li>
<li>对这些name值不同的记录继续通过birthday &gt; '1980-01-01'条件继续过滤。</li>
</ol>
<p>这样子对于联合索引idx_name_birthday_phone_number来说，只能用到name列的部分，而用不到birthday列的部分，因为只有name值相同的情况下才能用birthday列的值进行排序，而这个查询中通过name进行范围查找的记录中可能并不是按照birthday列进行排序的，所以在搜索条件中继续以birthday列进行查找时是用不到这个B+树索引的。</p>
<h4 id="725-精确匹配某一列并范围匹配另外一列">7.2.5 精确匹配某一列并范围匹配另外一列</h4>
<p>对于同一个联合索引来说，虽然对多个列都进行范围查找时只能用到最左边那个索引列，但是如果左边的列是精确查找，则右边的列可以进行范围查找，比方说这样：</p>
<pre><code class="language-mysql">SELECT * FROM person_info WHERE name = 'Ashburn' AND birthday &gt; '1980-01-01' AND birthday &lt; '2000-12-31' AND phone_number &gt; '15100000000';
</code></pre>
<ol>
<li>name = 'Ashburn'，对name列进行精确查找，当然可以使用B+树索引了。</li>
<li>birthday &gt; '1980-01-01' AND birthday &lt; '2000-12-31'，由于name列是精确查找，所以通过name = 'Ashburn'条件查找后得到的结果的name值都是相同的，它们会再按照birthday的值进行排序。所以此时对birthday列进行范围查找是可以用到B+树索引的。</li>
<li>phone_number &gt; '15100000000'，通过birthday的范围查找的记录的birthday的值可能不同，所以这个条件无法再利用B+树索引了，只能遍历上一步查询得到的记录。</li>
</ol>
<h4 id="726-用于排序">7.2.6 用于排序</h4>
<p>我们在写查询语句的时候经常需要对查询出来的记录通过ORDER BY子句按照某种规则进行排序。一般情况下，我们只能把记录都加载到内存中，再用一些排序算法，比如快速排序、归并排序、等等排序等等在内存中对这些记录进行排序，有的时候可能查询的结果集太大以至于不能在内存中进行排序的话，还可能暂时借助磁盘的空间来存放中间结果，排序操作完成后再把排好序的结果集返回到客户端。</p>
<p>在MySQL中，把这种在内存中或者磁盘上进行排序的方式统称为文件排序（英文名：filesort），跟文件这个词儿一沾边儿，就显得这些排序操作非常慢了。但是如果ORDER BY子句里使用到了我们的索引列，就有可能省去在内存或文件中排序的步骤，比如下面这个简单的查询语句：</p>
<pre><code class="language-mysql">SELECT * FROM person_info ORDER BY name, birthday, phone_number LIMIT 10;
</code></pre>
<p>这个查询的结果集需要先按照name值排序，如果记录的name值相同，则需要按照birthday来排序，如果birthday的值相同，则需要按照phone_number排序。大家可以回过头去看我们建立的idx_name_birthday_phone_number索引的示意图，因为这个B+树索引本身就是按照上述规则排好序的，所以直接从索引中提取数据，然后进行回表操作取出该索引中不包含的列就好了。</p>
<h5 id="使用联合索引进行排序注意事项">使用联合索引进行排序注意事项</h5>
<p>对于联合索引有个问题需要注意，ORDER BY的子句后边的列的顺序也必须按照索引列的顺序给出，如果给出ORDER BY phone_number, birthday, name的顺序，那也是用不了B+树索引，这种颠倒顺序就不能使用索引的原因我们上面详细说过了，这就不赘述了。</p>
<p>同理，ORDER BY name、ORDER BY name, birthday这种匹配索引左边的列的形式可以使用部分的B+树索引。当联合索引左边列的值为常量，也可以使用后边的列进行排序，比如这样：</p>
<pre><code class="language-mysql">SELECT * FROM person_info WHERE name = 'A' ORDER BY birthday, phone_number LIMIT 10;
</code></pre>
<p>这个查询能使用联合索引进行排序是因为name列的值相同的记录是按照birthday, phone_number排序的。</p>
<h5 id="不可以使用索引进行排序的几种情况">不可以使用索引进行排序的几种情况</h5>
<p><strong>ASC、DESC混用</strong><br>
对于使用联合索引进行排序的场景，我们要求各个排序列的排序顺序是一致的，也就是要么各个列都是ASC规则排序，要么都是DESC规则排序。</p>
<blockquote>
<p>ORDER BY子句后的列如果不加ASC或者DESC默认是按照ASC排序规则排序的，也就是升序排序的。</p>
</blockquote>
<p>为什么会有这种奇葩规定呢？这个还得回头想想这个idx_name_birthday_phone_number联合索引中记录的结构：</p>
<ol>
<li>先按照记录的name列的值进行升序排列。</li>
<li>如果记录的name列的值相同，再按照birthday列的值进行升序排列。</li>
<li>如果记录的birthday列的值相同，再按照phone_number列的值进行升序排列。<br>
如果查询中的各个排序列的排序顺序是一致的，比方说下面这两种情况：
<ul>
<li>ORDER BY name, birthday LIMIT 10，这种情况直接从索引的最左边开始往右读10行记录就可以了。</li>
<li>ORDER BY name DESC, birthday DESC LIMIT 10，这种情况直接从索引的最右边开始往左读10行记录就可以了。<br>
但是如果我们查询的需求是先按照name列进行升序排列，再按照birthday列进行降序排列的话，比如说这样的查询语句：</li>
</ul>
<pre><code class="language-mysql">SELECT * FROM person_info ORDER BY name, birthday DESC LIMIT 10;
</code></pre>
这样如果使用索引排序的话过程就是这样的：
<ol>
<li>先从索引的最左边确定name列最小的值，然后找到name列等于该值的所有记录，然后从name列等于该值的最右边的那条记录开始往左找10条记录。</li>
<li>先从索引的最左边确定name列最小的值，然后找到name列等于该值的所有记录，然后从name列等于该值的最右边的那条记录开始往左找10条记录。</li>
</ol>
</li>
</ol>
<p>累不累？累！重点是这样不能高效使用索引，而要采取更复杂的算法去从索引中取数据，设计MySQL的大佬觉得这样还不如直接文件排序来的快，所以就规定使用联合索引的各个排序列的排序顺序必须是一致的。</p>
<p><strong>WHERE子句中出现非排序使用到的索引列</strong><br>
如果WHERE子句中出现了非排序使用到的索引列，那么排序依然是使用不到索引的，比方说这样：</p>
<pre><code class="language-mysql">SELECT * FROM person_info WHERE country = 'China' ORDER BY name LIMIT 10;
</code></pre>
<p>这个查询只能先把符合搜索条件country = 'China'的记录提取出来后再进行排序，是使用不到索引。</p>
<p><strong>排序列包含非同一个索引的列</strong><br>
有时候用来排序的多个列不是一个索引里的，这种情况也不能使用索引进行排序，比方说：</p>
<pre><code class="language-mysql">SELECT * FROM person_info ORDER BY name, country LIMIT 10;
</code></pre>
<p>name和country并不属于一个联合索引中的列，所以无法使用索引进行排序。</p>
<p><strong>排序列使用了复杂的表达式</strong><br>
要想使用索引进行排序操作，必须保证索引列是以单独列的形式出现，而不是修饰过的形式，比方说这样：</p>
<pre><code class="language-mysql">SELECT * FROM person_info ORDER BY UPPER(name) LIMIT 10;
</code></pre>
<p>使用了UPPER函数修饰过的列就不是单独的列啦，这样就无法使用索引进行排序啦。</p>
<h4 id="727-用于分组">7.2.7 用于分组</h4>
<p>有时候我们为了方便统计表中的一些信息，会把表中的记录按照某些列进行分组。比如下面这个分组查询：</p>
<pre><code class="language-mysql">SELECT name, birthday, phone_number, COUNT(*) FROM person_info GROUP BY name, birthday, phone_number
</code></pre>
<p>这个查询语句相当于做了3次分组操作：</p>
<ol>
<li>先把记录按照name值进行分组，所有name值相同的记录划分为一组。</li>
<li>将每个name值相同的分组里的记录再按照birthday的值进行分组，将birthday值相同的记录放到一个小分组里，所以看起来就像在一个大分组里又化分了好多小分组。</li>
<li>再将上一步中产生的小分组按照phone_number的值分成更小的分组，所以整体上看起来就像是先把记录分成一个大分组，然后把大分组分成若干个小分组，然后把若干个小分组再细分成更多的小小分组。</li>
</ol>
<p>然后针对那些小小分组进行统计，比如在我们这个查询语句中就是统计每个小小分组包含的记录条数。如果没有索引的话，这个分组过程全部需要在内存里实现，而如果有了索引的话，恰巧这个分组顺序又和我们的B+树中的索引列的顺序是一致的，而我们的B+树索引又是按照索引列排好序的，这不正好么，所以可以直接使用B+树索引进行分组。</p>
<p>和使用B+树索引进行排序是一个道理，分组列的顺序也需要和索引列的顺序一致，也可以只使用索引列中左边的列进行分组。</p>
<h3 id="73-回表的代价">7.3 回表的代价</h3>
<pre><code class="language-mysql">SELECT * FROM person_info WHERE name &gt; 'Asa' AND name &lt; 'Barlow';
</code></pre>
<p>在使用idx_name_birthday_phone_number索引进行查询时大致可以分为这两个步骤：</p>
<ol>
<li>从索引idx_name_birthday_phone_number对应的B+树中取出name值在Asa～Barlow之间的用户记录。</li>
<li>由于索引idx_name_birthday_phone_number对应的B+树用户记录中只包含name、birthday、phone_number、id这4个字段，而查询列表是*，意味着要查询表中所有字段，也就是还要包括country字段。这时需要把从上一步中获取到的每一条记录的id字段都到聚簇索引对应的B+树中找到完整的用户记录，也就是我们通常所说的回表，然后把完整的用户记录返回给查询用户。</li>
</ol>
<p>由于索引idx_name_birthday_phone_number对应的B+树中的记录首先会按照name列的值进行排序，所以值在Asa～Barlow之间的记录在磁盘中的存储是相连的，集中分布在一个或几个数据页中，我们可以很快的把这些连着的记录从磁盘中读出来，这种读取方式我们也可以称为<font color=red>顺序I/O</font>。根据第1步中获取到的记录的id字段的值可能并不相连，而在聚簇索引中记录是根据id（也就是主键）的顺序排列的，所以根据这些并不连续的id值到聚簇索引中访问完整的用户记录可能分布在不同的数据页中，这样读取完整的用户记录可能要访问更多的数据页，这种读取方式我们也可以称为<font color=red>随机I/O</font>。一般情况下，顺序I/O比随机I/O的性能高很多，所以步骤1的执行可能很快，而步骤2就慢一些。所以这个使用索引idx_name_birthday_phone_number的查询有这么两个特点：</p>
<ol>
<li>会使用到两个B+树索引，一个二级索引，一个聚簇索引。</li>
<li>访问二级索引使用顺序I/O，访问聚簇索引使用随机I/O。</li>
</ol>
<p>需要回表的记录越多，使用二级索引的性能就越低。</p>
<p>那什么时候采用全表扫描的方式，什么时候使用采用二级索引 + 回表的方式去执行查询呢？这个就是传说中的查询优化器做的工作，查询优化器会事先对表中的记录计算一些统计数据，然后再利用这些统计数据根据查询的条件来计算一下需要回表的记录数，需要回表的记录数越多，就越倾向于使用全表扫描，反之倾向于使用二级索引 + 回表的方式。</p>
<h4 id="732-覆盖索引">7.3.2 覆盖索引</h4>
<p>为了彻底告别回表操作带来的性能损耗，我们建议：最好在查询列表里只包含索引列，比如这样：</p>
<pre><code class="language-mysql">SELECT name, birthday, phone_number FROM person_info  
    WHERE name &gt; 'Asa' AND name &lt; 'Barlow';
</code></pre>
<p>因为我们只查询name, birthday, phone_number这三个索引列的值，所以在通过idx_name_birthday_phone_number索引得到结果后就不必到聚簇索引中再查找记录的剩余列，也就是country列的值了，这样就省去了回表操作带来的性能损耗。我们把这种只需要用到索引的查询方式称为索引覆盖。</p>
<h3 id="74-如何挑选索引">7.4 如何挑选索引</h3>
<h4 id="741-只为用于搜索-排序或分组的列创建索引">7.4.1 只为用于搜索、排序或分组的列创建索引</h4>
<p>只为出现在WHERE子句中的列、连接子句中的连接列，或者出现在ORDER BY或GROUP BY子句中的列创建索引。而出现在查询列表中的列就没必要建立索引了：</p>
<pre><code class="language-mysql">SELECT birthday, country FROM person_name WHERE name = 'Ashburn';
</code></pre>
<p>像查询列表中的birthday、country这两个列就不需要建立索引，我们只需要为出现在WHERE子句中的name列创建索引就可以了。</p>
<h4 id="742-考虑列的基数">7.4.2 考虑列的基数</h4>
<p>列的基数指的是某一列中不重复数据的个数，比方说某个列包含值2, 5, 8, 2, 5, 8, 2, 5, 8，虽然有9条记录，但该列的基数却是3。也就是说，在记录行数一定的情况下，列的基数越大，该列中的值越分散，列的基数越小，该列中的值越集中。</p>
<p>假设某个列的基数为1，也就是所有记录在该列中的值都一样，那为该列建立索引是没有用的，因为所有值都一样就无法排序，无法进行快速查找了～ 而且如果某个建立了二级索引的列的重复值特别多，那么使用这个二级索引查出的记录还可能要做回表操作，这样性能损耗就更大了。所以结论就是：最好为那些列的基数大的列建立索引，为基数太小列的建立索引效果可能不好。</p>
<h4 id="743-索引列的类型尽量小">7.4.3 索引列的类型尽量小</h4>
<p>我们在定义表结构的时候要显式的指定列的类型，以整数类型为例，有TINYINT、MEDIUMINT、INT、BIGINT这么几种，它们占用的存储空间依次递增，我们这里所说的类型大小指的就是<font color=red>该类型表示的数据范围的大小</font>。能表示的整数范围当然也是依次递增，如果我们想要对某个整数列建立索引的话，<font color=red>在表示的整数范围允许的情况下，尽量让索引列使用较小的类型</font>，比如我们能使用INT就不要使用BIGINT，能使用MEDIUMINT就不要使用INT</p>
<ul>
<li>数据类型越小，在查询时进行的比较操作越快</li>
<li>数据类型越小，索引占用的存储空间就越少，在一个数据页内就可以放下更多的记录，从而减少磁盘I/O带来的性能损耗，也就意味着可以把更多的数据页缓存在内存中，从而加快读写效率</li>
</ul>
<blockquote>
<p>这个建议对于表的主键来说更加适用，因为不仅是聚簇索引中会存储主键值，其他所有的二级索引的节点处都会存储一份记录的主键值，如果主键适用更小的数据类型，也就意味着节省更多的存储空间和更高效的I/O</p>
</blockquote>
<h4 id="744-索引字符串值的前缀">7.4.4 索引字符串值的前缀</h4>
<p>字符串越长，那存储一个字符串就需要占用越大的存储空间。在我们需要为这个字符串列建立索引时，那就意味着在对应的B+树中有这么两个问题：</p>
<ol>
<li>B+树索引中的记录需要把该列的完整字符串存储起来，而且字符串越长，在索引中占用的存储空间越大。</li>
<li>如果B+树索引中索引列存储的字符串很长，那在做字符串比较时会占用更多的时间。</li>
</ol>
<p>索引列的字符串前缀其实也是排好序的，所以索引的设计者提出了个方案 --- 只对字符串的前几个字符进行索引也就是说在二级索引的记录中只保留字符串前几个字符。这样在查找记录时虽然不能精确的定位到记录的位置，但是能定位到相应前缀所在的位置，然后根据前缀相同的记录的主键值回表查询完整的字符串值，再对比就好了。这样只在B+树中存储字符串的前几个字符的编码，既节约空间，又减少了字符串的比较时间，还大概能解决排序的问题，比方说我们在建表语句中只对name列的前10个字符进行索引可以这么写：</p>
<pre><code class="language-mysql">CREATE TABLE person_info(
    name VARCHAR(100) NOT NULL,
    birthday DATE NOT NULL,
    phone_number CHAR(11) NOT NULL,
    country varchar(100) NOT NULL,
    KEY idx_name_birthday_phone_number (name(10), birthday, phone_number)
);    
</code></pre>
<p>name(10)就表示在建立的B+树索引中只保留记录的前10个字符的编码，这种只索引字符串值的前缀的策略是我们非常鼓励的，尤其是在字符串类型能存储的字符比较多的时候。</p>
<p><strong>索引列前缀对排序的影响</strong><br>
因为二级索引中不包含完整的name列信息，所以无法对前十个字符相同，后边的字符不同的记录进行排序，也就是使用索引列前缀的方式无法支持使用索引排序。</p>
<h4 id="745-让索引列在比较表达式中单独出现">7.4.5 让索引列在比较表达式中单独出现</h4>
<p>假设表中有一个整数列my_col，我们为这个列建立了索引。下面的两个WHERE子句虽然语义是一致的，但是在效率上却有差别：</p>
<ol>
<li>WHERE my_col * 2 &lt; 4</li>
<li>WHERE my_col &lt; 4/2</li>
</ol>
<p>第1个WHERE子句中my_col列并不是以单独列的形式出现的，而是以my_col * 2这样的表达式的形式出现的，存储引擎会依次遍历所有的记录，计算这个表达式的值是不是小于4，所以这种情况下是使用不到为my_col列建立的B+树索引的。而第2个WHERE子句中my_col列并是以单独列的形式出现的，这样的情况可以直接使用B+树索引。</p>
<p>所以结论就是：<font color=red>如果索引列在比较表达式中不是以单独列的形式出现，而是以某个表达式，或者函数调用形式出现的话，是用不到索引的。</font></p>
<h4 id="746-主键插入顺序">7.4.6 主键插入顺序</h4>
<p>我们知道，对于一个使用InnoDB存储引擎的表来说，在我们没有显式的创建索引时，表中的数据实际上都是存储在聚簇索引的叶子节点的。而记录又是存储在数据页中的，数据页和记录又是按照记录主键值从小到大的顺序进行排序，所以如果我们插入的记录的主键值是依次增大的话，那我们每插满一个数据页就换到下一个数据页继续插，而如果我们插入的主键值忽大忽小的话,意味着：性能损耗！所以如果我们想尽量避免这样无谓的性能损耗，最好让插入的记录的主键值依次递增，这样就不会发生这样的性能损耗了。所以我们建议：<font color=red>让主键具有AUTO_INCREMENT，让存储引擎自己为表生成主键，而不是我们手动插入</font></p>
<h4 id="747-冗余和重复索引">7.4.7 冗余和重复索引</h4>
<p>通过idx_name_birthday_phone_number索引就可以对name列进行快速搜索，再创建一个专门针对name列的索引就算是一个冗余索引，维护这个索引只会增加维护的成本，并不会对搜索有什么好处。</p>
<p>另一种情况，我们可能会对某个列重复建立索引,既是主键、又给它定义为一个唯一索引，还给它定义了一个普通索引，可是主键本身就会生成聚簇索引，所以定义的唯一索引和普通索引是重复的，这种情况要避免</p>
<h3 id="75-总结">7.5 总结</h3>
<ol>
<li>B+树索引在空间和时间上都有代价</li>
<li>B+树索引适用于下面这些情况：
<ul>
<li>全值匹配</li>
<li>匹配左边的列</li>
<li>匹配范围值</li>
<li>精确匹配某一列并范围匹配另外一列</li>
<li>用于排序</li>
<li>用于分组</li>
</ul>
</li>
<li>在使用索引时需要注意下面这些事项：
<ul>
<li>只为用于搜索、排序或分组的列创建索引</li>
<li>为列的基数大的列创建索引</li>
<li>索引列的类型尽量小</li>
<li>可以只对字符串值的前缀建立索引</li>
<li>只有索引列在比较表达式中单独出现才可以适用索引</li>
<li>为了尽可能少的让聚簇索引发生页面分裂和记录移位的情况，建议让主键拥有AUTO_INCREMENT属性。</li>
<li>定位并删除表中的重复和冗余索引</li>
<li>尽量使用覆盖索引进行查询，避免回表带来的性能损耗。</li>
</ul>
</li>
</ol>
<h2 id="第八章-数据的家-mysql的数据目录">第八章 数据的家-MySQL的数据目录</h2>
<h3 id="81-数据库和文件系统的关系">8.1 数据库和文件系统的关系</h3>
<p>我们知道像InnoDB、MyISAM这样的存储引擎都是把表存储在磁盘上的，而操作系统用来管理磁盘的系统被称为文件系统，所以用一句话来表述就是：像 InnoDB 、 MyISAM 这样的存储引擎都是把表存储在文件系统上的。当我们想读取数据的时候，这些存储引擎会从文件系统中把数据读出来返回给我们，当我们想写入数据的时候，这些存储引擎会把这些数据又写回文件系统。</p>
<h3 id="82-mysql数据目录">8.2 MySQL数据目录</h3>
<p>MySQL服务器程序在启动时会到文件系统的某个目录下加载一些文件，之后在运行过程中产生的数据也都会存储到这个目录下的某些文件中，这个目录就称为数据目录。</p>
<h4 id="821-数据目录和安装目录的区别">8.2.1 数据目录和安装目录的区别</h4>
<p>安装目录下非常重要的bin目录，它里边存储了许多关于控制客户端程序和服务器程序的命令（许多可执行文件，比如mysql，mysqld，mysqld_safe等等等等好几十个）。而数据目录是用来存储MySQL在运行过程中产生的数据</p>
<h4 id="822-如何确定mysql中的数据目录">8.2.2 如何确定MySQL中的数据目录</h4>
<p>数据目录对应着一个系统变量datadir，我们在使用客户端与服务器建立连接之后查看这个系统变量的值就可以了：</p>
<pre><code class="language-mysql">mysql&gt; SHOW VARIABLES LIKE 'datadir';
+---------------+-----------------------+
| Variable_name | Value                 |
+---------------+-----------------------+
| datadir       | /usr/local/var/mysql/ |
+---------------+-----------------------+
1 row in set (0.00 sec)
</code></pre>
<h3 id="83-数据目录的结构">8.3 数据目录的结构</h3>
<h4 id="831-数据库在文件系统中的表示">8.3.1 数据库在文件系统中的表示</h4>
<p>每当我们使用CREATE DATABASE 数据库名语句创建一个数据库的时候，在文件系统上实际发生了什么呢？其实很简单，每个数据库都对应数据目录下的一个子目录，或者说对应一个文件夹，我们每当我们新建一个数据库时，MySQL会帮我们做这两件事：</p>
<ol>
<li>在数据目录下创建一个和数据库名同名的子目录（或者说是文件夹）。</li>
<li>在该与数据库名同名的子目录下创建一个名为db.opt的文件，这个文件中包含了该数据库的各种属性，比方说该数据库的字符集和比较规则是什么。</li>
</ol>
<h4 id="832-表在文件系统中的表示">8.3.2 表在文件系统中的表示</h4>
<p>我们的数据其实都是以记录的形式插入到表中的，每个表的信息其实可以分为两种：</p>
<ol>
<li>表结构的定义</li>
<li>表中的数据</li>
</ol>
<p>InnoDB和MyISAM这两种存储引擎都在数据目录下对应的数据库子目录下创建了一个专门用于描述表结构的文件，文件名是这样：表名.frm，这个后缀名为.frm是以二进制格式存储的。</p>
<h5 id="innodb是如何存储表数据的">InnoDB是如何存储表数据的</h5>
<p>innoDB其实是使用页为基本单位来管理存储空间的，为了更好的管理这些页，设计InnoDB的大佬们提出了一个表空间或者文件空间（英文名：table space或者file space）的概念，这个表空间是一个抽象的概念，它可以对应文件系统上一个或多个真实文件（不同表空间对应的文件数量可能不同）。每一个表空间可以被划分为很多很多很多个页，我们的表数据就存放在某个表空间下的某些页里。</p>
<p><strong>系统表空间（system tablespace）</strong><br>
这个所谓的系统表空间可以对应文件系统上一个或多个实际的文件，默认情况下，InnoDB会在数据目录下创建一个名为ibdata1、大小为12M的文件，这个文件就是对应的系统表空间在文件系统上的表示。这个文件是所谓的自扩展文件，也就是当不够用的时候它会自己增加文件大小。</p>
<p>当然，如果你想让系统表空间对应文件系统上多个实际文件，或者仅仅觉得原来的ibdata1这个文件名难听，那可以在MySQL启动时配置对应的文件路径以及它们的大小，比如我们这样修改一下配置文件：</p>
<pre><code class="language-mysql">[server]
innodb_data_file_path=data1:512M;data2:512M:autoextend
</code></pre>
<p>在一个MySQL服务器中，系统表空间只有一份。</p>
<p><strong>独立表空间(file-per-table tablespace)</strong><br>
在MySQL5.6.6以及之后的版本中，InnoDB并不会默认的把各个表的数据存储到系统表空间中，而是为每一个表建立一个独立表空间，也就是说我们创建了多少个表，就有多少个独立表空间。使用独立表空间来存储表数据的话，会在该表所属数据库对应的子目录下创建一个表示该独立表空间的文件，文件名和表名相同，只不过添加了一个.ibd的扩展名而已。</p>
<p>当然我们也可以自己指定使用系统表空间还是独立表空间来存储数据，这个功能由启动参数innodb_file_per_table控制，比如说我们想刻意将表数据都存储到系统表空间时，可以在启动MySQL服务器的时候这样配置：</p>
<pre><code class="language-mysql">[server]
innodb_file_per_table=0
</code></pre>
<p>当innodb_file_per_table的值为0时，代表使用系统表空间；当innodb_file_per_table的值为1时，代表使用独立表空间。不过innodb_file_per_table参数只对新建的表起作用，对于已经分配了表空间的表并不起作用。如果我们想把已经存在系统表空间中的表转移到独立表空间，可以使用下面的语法：</p>
<pre><code class="language-mysql">ALTER TABLE 表名 TABLESPACE [=] innodb_file_per_table;
</code></pre>
<p>或者把已经存在独立表空间的表转移到系统表空间，可以使用下面的语法：</p>
<pre><code class="language-mysql">ALTER TABLE 表名 TABLESPACE [=] innodb_system;
</code></pre>
<p><strong>其他类型的表空间</strong><br>
随着MySQL的发展，除了上述两种老牌表空间之外，现在还新提出了一些不同类型的表空间，比如通用表空间（general tablespace）、undo表空间（undo tablespace）、临时表空间（temporary tablespace）等等。</p>
<h5 id="myisam是如何存储表数据的">MyISAM是如何存储表数据的</h5>
<p>在MyISAM中的索引全部都是二级索引，该存储引擎的数据和索引是分开存放的。所以在文件系统中也是使用不同的文件来存储数据文件和索引文件。而且和InnoDB不同的是，MyISAM并没有什么所谓的表空间一说，<font color=red>表数据都存放到对应的数据库子目录下</font>。假如test表使用MyISAM存储引擎的话，那么在它所在数据库对应的xiaohaizi目录下会为test表创建这三个文件：</p>
<pre><code class="language-mysql">test.frm
test.MYD
test.MYI
</code></pre>
<p>其中test.MYD代表表的数据文件，也就是我们插入的用户记录；test.MYI代表表的索引文件，我们为该表创建的索引都会放到这个文件中</p>
<h4 id="833-视图在文件系统中的表示">8.3.3 视图在文件系统中的表示</h4>
<p>MySQL中的视图其实是虚拟的表，也就是某个查询语句的一个别名而已，所以在存储视图的时候是不需要存储真实的数据的，只需要把它的结构存储起来就行了。和表一样，描述视图结构的文件也会被存储到所属数据库对应的子目录下面，只会存储一个视图名.frm的文件。</p>
<h4 id="834-其他的文件">8.3.4 其他的文件</h4>
<p>除了我们上面说的这些用户自己存储的数据以外，数据目录下还包括为了更好运行程序的一些额外文件，主要包括这几种类型的文件：</p>
<ol>
<li>服务器进程文件。<br>
  我们知道每运行一个MySQL服务器程序，都意味着启动一个进程。MySQL服务器会把自己的进程ID写入到一个文件中。</li>
<li>服务器日志文件。<br>
  在服务器运行过程中，会产生各种各样的日志，比如常规的查询日志、错误日志、二进制日志、redo日志等等各种日志，这些日志各有各的用途。</li>
<li>默认/自动生成的SSL和RSA证书和密钥文件。<br>
  主要是为了客户端和服务器安全通信而创建的一些文件</li>
</ol>
<h3 id="84-文件系统对数据库的影响">8.4 文件系统对数据库的影响</h3>
<p>因为MySQL的数据都是存在文件系统中的，就不得不受到文件系统的一些制约，这在数据库和表的命名、表的大小和性能方面体现的比较明显，比如下面这些方面：</p>
<ol>
<li>数据库名称和表名称不得超过文件系统所允许的最大长度。</li>
<li>特殊字符的问题
<ol>
<li>为了避免因为数据库名和表名出现某些特殊字符而造成文件系统不支持的情况，MySQL会把数据库名和表名中所有除数字和拉丁字母以外的所有字符在文件名里都映射成 @+编码值的形式作为文件名。比方说我们创建的表的名称为'test?'，由于?不属于数字或者拉丁字母，所以会被映射成编码值，所以这个表对应的.frm文件的名称就变成了test@003f.frm。</li>
</ol>
</li>
<li>文件长度受文件系统最大长度限制</li>
</ol>
<h3 id="85-mysql系统数据库简介">8.5 MySQL系统数据库简介</h3>
<p>我们前面提到了MySQL的几个系统数据库，这几个数据库包含了MySQL服务器运行过程中所需的一些信息以及一些运行状态信息，我们现在稍微了解一下。</p>
<ol>
<li>
<p>mysql<br>
  这个数据库它存储了MySQL的用户账户和权限信息，一些存储过程、事件的定义信息，一些运行过程中产生的日志信息，一些帮助信息以及时区信息等。</p>
</li>
<li>
<p>information_schema<br>
  这个数据库保存着MySQL服务器维护的所有其他数据库的信息，比如有哪些表、哪些视图、哪些触发器、哪些列、哪些索引等等。这些信息并不是真实的用户数据，而是一些描述性信息，有时候也称之为元数据。</p>
</li>
<li>
<p>performance_schema<br>
  这个数据库里主要保存MySQL服务器运行过程中的一些状态信息，算是对MySQL服务器的一个性能监控。包括统计最近执行了哪些语句，在执行过程的每个阶段都花费了多长时间，内存的使用情况等等信息。</p>
</li>
<li>
<p>sys<br>
  这个数据库主要是通过视图的形式把information_schema 和performance_schema结合起来，让程序员可以更方便的了解MySQL服务器的一些性能信息。</p>
</li>
</ol>
<h2 id="第九章-存放页的大池子-innodb的表空间">第九章 存放页的大池子-InnoDB的表空间</h2>
<p>表空间是一个抽象的概念，对于系统表空间来说，对应着文件系统中一个或多个实际文件；对于每个独立表空间来说，对应着文件系统中一个名为表名.ibd的实际文件。大家可以把表空间想象成被切分为许许多多个页的池子，当我们想为某个表插入一条记录的时候，就从池子中捞出一个对应的页来把数据写进去。</p>
<h3 id="91-独立表空间结构">9.1 独立表空间结构</h3>
<h4 id="911-区extent的概念">9.1.1 区（extent）的概念</h4>
<p>表空间中的页实在是太多了，为了更好的管理这些页，InnoDB提出了区（英文名：extent）的概念。对于16KB的页来说，连续的64个页就是一个区，也就是说一个区默认占用1MB空间大小。不论是系统表空间还是独立表空间，都可以看成是由若干个区组成的，每256个区被划分成一组。画个图表示就是这样：</p>
<figure data-type="image" tabindex="6"><img src="https://q456qq520.github.io/post-images/1673578487397.png" alt="" loading="lazy"></figure>
<p>其中extent 0 ~ extent 255这256个区算是第一个组，extent 256 ~ extent 511这256个区算是第二个组，extent 512 ~ extent 767这256个区算是第三个组，依此类推可以划分更多的组。这些组的头几个页的类型都是类似的，就像这样：</p>
<figure data-type="image" tabindex="7"><img src="https://q456qq520.github.io/post-images/1673578645460.png" alt="" loading="lazy"></figure>
<ol>
<li>
<p>第一个组最开始的3个页的类型是固定的，也就是说extent 0这个区最开始的3个页的类型是固定的，分别是：</p>
<ul>
<li>FSP_HDR类型：这个类型的页是用来登记整个表空间的一些整体属性以及本组所有的区，也就是extent 0 ~ extent 255这256个区的属性，整个表空间只有一个FSP_HDR类型的页。</li>
<li>IBUF_BITMAP类型：这个类型的页是存储本组所有的区的所有页关于INSERT BUFFER的信息。</li>
<li>INODE类型：这个类型的页存储了许多称为INODE的数据结构。</li>
</ul>
</li>
<li>
<p>其余各组最开始的2个页的类型是固定的，也就是说extent 256、extent 512这些区最开始的2个页的类型是固定的，分别是：</p>
<ul>
<li>XDES类型：全称是extent descriptor，用来登记本组256个区的属性，也就是说对于在extent 256区中的该类型页存储的就是extent 256 ~ extent 511这些区的属性，对于在extent 512区中的该类型页存储的就是extent 512 ~ extent 767这些区的属性。上面介绍的FSP_HDR类型的页其实和XDES类型的页的作用类似，只不过FSP_HDR类型的页还会额外存储一些表空间的属性。</li>
<li>IBUF_BITMAP类型：上面介绍过了。</li>
</ul>
</li>
</ol>
<p>总结就是<font color=red>表空间被划分为许多连续的区，每个区默认由64个页组成，每256个区划分为一组，每个组的最开始的几个页类型是固定的</font>就好了。</p>
<h4 id="912-段segment的概念">9.1.2 段（segment）的概念</h4>
<p>不引入区的概念只使用页的概念对存储引擎的运行并没什么影响，但是我们来考虑一下下面这个场景：</p>
<p>我们每向表中插入一条记录，本质上就是向该表的聚簇索引以及所有二级索引代表的B+树的节点中插入数据。而B+树的每一层中的页都会形成一个双向链表，如果是以页为单位来分配存储空间的话，双向链表相邻的两个页之间的物理位置可能离得非常远。我们介绍B+树索引的适用场景的时候特别提到范围查询只需要定位到最左边的记录和最右边的记录，然后沿着双向链表一直扫描就可以了，而如果链表中相邻的两个页物理位置离得非常远，就是所谓的随机I/O。随机I/O是非常慢的，所以我们应该尽量让链表中相邻的页的物理位置也相邻，这样进行范围查询的时候才可以使用所谓的顺序I/O。</p>
<p>所以才引入了区（extent）的概念，一个区就是在物理位置上连续的64个页。在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区为单位分配，甚至在表中的数据十分非常特别多的时候，可以一次性分配多个连续的区。虽然可能造成一点点空间的浪费（数据不足填充满整个区），但是从性能角度看，可以消除很多的随机I/O。</p>
<p>我们提到的范围查询，其实是对B+树叶子节点中的记录进行顺序扫描，而如果不区分叶子节点和非叶子节点，统统把节点代表的页放到申请到的区中的话，进行范围扫描的效果就大打折扣了。InnoDB对B+树的叶子节点和非叶子节点进行了区别对待，也就是说叶子节点有自己独有的区，非叶子节点也有自己独有的区。存放叶子节点的区的集合就算是一个<font color=red>段（segment）</font>，存放非叶子节点的区的集合也算是一个段。也就是说一个索引会生成2个段，一个叶子节点段，一个非叶子节点段。</p>
<p>默认情况下一个使用InnoDB存储引擎的表只有一个聚簇索引，一个索引会生成2个段，而段是以区为单位申请存储空间的，一个区默认占用1M存储空间，所以默认情况下一个只存了几条记录的小表也需要2M的存储空间么？以后每次添加一个索引都要多申请2M的存储空间么？这对于存储记录比较少的表简直是天大的浪费。，设计InnoDB的大佬们提出了一个碎片（fragment）区的概念，也就是在一个碎片区中，并不是所有的页都是为了存储同一个段的数据而存在的，而是碎片区中的页可以用于不同的目的，比如有些页用于段A，有些页用于段B，有些页甚至哪个段都不属于。碎片区直属于表空间，并不属于任何一个段。所以此后为某个段分配存储空间的策略是这样的：</p>
<ol>
<li>在刚开始向表中插入数据的时候，段是从某个碎片区以单个页为单位来分配存储空间的。</li>
<li>当某个段已经占用了32个碎片区页之后，就会以完整的区为单位来分配存储空间。</li>
</ol>
<p>所以现在段不能仅定义为是某些区的集合，更精确的应该是某些零散的页以及一些完整的区的集合。除了索引的叶子节点段和非叶子节点段之外，InnoDB中还有为存储一些特殊的数据而定义的段，比如回滚段。</p>
<h4 id="913-区的分类">9.1.3 区的分类</h4>
<p>表空间的是由若干个区组成的，这些区大体上可以分为4种类型：</p>
<ol>
<li>空闲的区：现在还没有用到这个区中的任何页。</li>
<li>有剩余空间的碎片区：表示碎片区中还有可用的页。</li>
<li>没有剩余空间的碎片区：表示碎片区中的所有页都被使用，没有空闲页。</li>
<li>附属于某个段的区。每一个索引都可以分为叶子节点段和非叶子节点段，除此之外InnoDB还会另外定义一些特殊作用的段，在这些段中的数据量很大时将使用区来作为基本的分配单位。</li>
</ol>
<p>这4种类型的区也可以被称为区的4种状态（State），设计InnoDB的大佬们为这4种状态的区定义了特定的名词儿：</p>
<table>
<thead>
<tr>
<th>状态名</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>FREE</td>
<td>空闲的区</td>
</tr>
<tr>
<td>FREE_FRAG</td>
<td>有剩余空间的碎片区</td>
</tr>
<tr>
<td>FULL_FRAG</td>
<td>没有剩余空间的碎片区</td>
</tr>
<tr>
<td>FSEG</td>
<td>附属于某个段的区</td>
</tr>
</tbody>
</table>
<p>处于FREE、FREE_FRAG以及FULL_FRAG这三种状态的区都是独立的，算是直属于表空间；而处于FSEG状态的区是附属于某个段的。</p>
<p>为了方便管理这些区，设计InnoDB的大佬设计了一个称为XDES Entry的结构（全称就是Extent Descriptor Entry），每一个区都对应着一个XDES Entry结构，这个结构记录了对应的区的一些属性。我们先看图来对这个结构有个大致的了解：<br>
<img src="https://q456qq520.github.io/post-images/1673581652558.png" alt="" loading="lazy"></p>
<p>从图中我们可以看出，XDES Entry是一个40个字节的结构，大致分为4个部分，各个部分的释义如下：</p>
<ol>
<li>Segment ID（8字节）<br>
  每一个段都有一个唯一的编号，用ID表示，此处的Segment ID字段表示就是该区所在的段。当然前提是该区已经被分配给某个段了，不然的话该字段的值没什么意义。</li>
<li>List Node（12字节）<br>
  这个部分可以将若干个XDES Entry结构串联成一个链表，大家看一下这个List Node的结构：<br>
<img src="https://q456qq520.github.io/post-images/1673581849785.png" alt="" loading="lazy"><br>
  如果我们想定位表空间内的某一个位置的话，只需指定页号以及该位置在指定页号中的页内偏移量即可。所以：
<ul>
<li>Pre Node Page Number和Pre Node Offset的组合就是指向前一个XDES Entry的指针</li>
<li>Next Node Page Number和Next Node Offset的组合就是指向后一个XDES Entry的指针。</li>
</ul>
</li>
<li>State（4字节）<br>
  这个字段表明区的状态。可选的值就是我们前面说过的那4个，分别是：FREE、FREE_FRAG、FULL_FRAG和FSEG。</li>
<li>Page State Bitmap（16字节）<br>
  这个部分共占用16个字节，也就是128个比特位。我们说一个区默认有64个页，这128个比特位被划分为64个部分，每个部分2个比特位，对应区中的一个页。比如Page State Bitmap部分的第1和第2个比特位对应着区中的第1个页，第3和第4个比特位对应着区中的第2个页，依此类推，Page State Bitmap部分的第127和128个比特位对应着区中的第64个页。这两个比特位的第一个位表示对应的页是否是空闲的，第二个比特位还没有用。</li>
</ol>
<h5 id="xdes-entry链表">XDES Entry链表</h5>
<p>向表中插入数据本质上就是向表中各个索引的叶子节点段、非叶子节点段插入数据，捋一捋向某个段中插入数据的过程：</p>
<ol>
<li>
<p>当段中数据较少的时候，首先会查看表空间中是否有状态为FREE_FRAG的区，也就是找还有空闲空间的碎片区，如果找到了，那么从该区中取一些零碎的页把数据插进去；否则到表空间下申请一个状态为FREE的区，也就是空闲的区，把该区的状态变为FREE_FRAG，然后从该新申请的区中取一些零碎的页把数据插进去。之后不同的段使用零碎页的时候都会从该区中取，直到该区中没有空闲空间，然后该区的状态就变成了FULL_FRAG。<br>
现在的问题是你怎么知道表空间里的哪些区是FREE的，哪些区的状态是FREE_FRAG的，哪些区是FULL_FRAG的？我们可以通过List Node中的指针，做这么三件事：</p>
<ul>
<li>把状态为FREE的区对应的XDES Entry结构通过List Node来连接成一个链表，这个链表我们就称之为FREE链表。</li>
<li>把状态为FREE_FRAG的区对应的XDES Entry结构通过List Node来连接成一个链表，这个链表我们就称之为FREE_FRAG链表。</li>
<li>把状态为FULL_FRAG的区对应的XDES Entry结构通过List Node来连接成一个链表，这个链表我们就称之为FULL_FRAG链表。<br>
这样每当我们想找一个FREE_FRAG状态的区时，就直接把FREE_FRAG链表的头节点拿出来，从这个节点中取一些零碎的页来插入数据，当这个节点对应的区用完时，就修改一下这个节点的State字段的值，然后从FREE_FRAG链表中移到FULL_FRAG链表中。同理，如果FREE_FRAG链表中一个节点都没有，那么就直接从FREE链表中取一个节点移动到FREE_FRAG链表的状态，并修改该节点的STATE字段值为FREE_FRAG，然后从这个节点对应的区中获取零碎的页就好了。</li>
</ul>
</li>
<li>
<p>当段中数据已经占满了32个零散的页后，就直接申请完整的区来插入数据了。<br>
我们怎么知道哪些区属于哪个段的呢？我们想要每个段都有它独立的链表，所以可以根据段号（也就是Segment ID）来建立链表，因为一个段中可以有好多个区，有的区是完全空闲的，有的区还有一些页可以用，有的区已经没有空闲页可以用了，所以我们有必要继续细分，设计InnoDB的大佬们为每个段中的区对应的XDES Entry结构建立了三个链表：</p>
<ul>
<li>FREE链表：同一个段中，所有页都是空闲的区对应的XDES Entry结构会被加入到这个链表。注意和直属于表空间的FREE链表区别开了，此处的FREE链表是附属于某个段的。</li>
<li>NOT_FULL链表：同一个段中，仍有空闲空间的区对应的XDES Entry结构会被加入到这个链表。</li>
<li>FULL链表：同一个段中，已经没有空闲空间的区对应的XDES Entry结构会被加入到这个链表。</li>
</ul>
</li>
</ol>
<p>再次强调一遍，每一个索引都对应两个段，每个段都会维护上述的3个链表，比如下面这个表：</p>
<pre><code class="language-mysql">CREATE TABLE t (
  c1 INT NOT NULL AUTO_INCREMENT,
  c2 VARCHAR(100),
  c3 VARCHAR(100),
  PRIMARY KEY (c1),
  KEY idx_c2 (c2)
)ENGINE=InnoDB;
</code></pre>
<p>这个表t共有两个索引，一个聚簇索引，一个二级索引idx_c2，所以这个表共有4个段，每个段都会维护上述3个链表，总共是12个链表，加上我们上面说过的直属于表空间的3个链表，整个独立表空间共需要维护15个链表。所以段在数据量比较大时插入数据的话，会先获取NOT_FULL链表的头节点，直接把数据插入这个头节点对应的区中即可，如果该区的空间已经被用完，就把该节点移到FULL链表中。</p>
<h5 id="链表基节点">链表基节点</h5>
<p>我们怎么找到这些链表呢，或者说怎么找到某个链表的头节点或者尾节点在表空间中的位置呢？设计InnoDB的大佬当然考虑了这个问题，他们设计了一个叫List Base Node的结构，翻译成中文就是链表的基节点。这个结构中包含了链表的头节点和尾节点的指针以及这个链表中包含了多少节点的信息，我们画图看一下这个结构的示意图：<br>
<img src="https://q456qq520.github.io/post-images/1673592305834.png" alt="" loading="lazy"></p>
<ol>
<li>List Length表明该链表一共有多少节点，</li>
<li>First Node Page Number和First Node Offset表明该链表的头节点在表空间中的位置。</li>
<li>Last Node Page Number和Last Node Offset表明该链表的尾节点在表空间中的位置。</li>
</ol>
<h5 id="链表小结">链表小结</h5>
<p>综上所述，表空间是由若干个区组成的，每个区都对应一个XDES Entry的结构，直属于表空间的区对应的XDES Entry结构可以分成FREE、FREE_FRAG和FULL_FRAG这3个链表；每个段可以附属若干个区，每个段中的区对应的XDES Entry结构可以分成FREE、NOT_FULL和FULL这3个链表。每个链表都对应一个List Base Node的结构，这个结构里记录了链表的头、尾节点的位置以及该链表中包含的节点数。</p>
<h4 id="914-段的结构">9.1.4 段的结构</h4>
<p>段其实不对应表空间中某一个连续的物理区域，而是一个逻辑上的概念，由若干个零散的页以及一些完整的区组成。像每个区都有对应的XDES Entry来记录这个区中的属性一样，设计InnoDB的大佬为每个段都定义了一个INODE Entry结构来记录一下段中的属性。大家看一下示意图：<br>
<img src="https://q456qq520.github.io/post-images/1673592682398.png" alt="" loading="lazy"></p>
<ol>
<li>Segment ID<br>
  就是指这个INODE Entry结构对应的段的编号（ID）。</li>
<li>NOT_FULL_N_USED<br>
  这个字段指的是在NOT_FULL链表中已经使用了多少个页。下次从NOT_FULL链表分配空闲页时可以直接根据这个字段的值定位到。而不用从链表中的第一个页开始遍历着寻找空闲页。</li>
<li>3个List Base Node<br>
  分别为段的FREE链表、NOT_FULL链表、FULL链表定义了List Base Node，这样我们想查找某个段的某个链表的头节点和尾节点的时候，就可以直接到这个部分找到对应链表的List Base Node。</li>
<li>Magic Number：<br>
  这个值是用来标记这个INODE Entry是否已经被初始化了（初始化的意思就是把各个字段的值都填进去了）。如果这个数字是值的97937874，表明该INODE Entry已经初始化，否则没有被初始化。</li>
<li>Fragment Array Entry<br>
  我们前面强调过无数次：段是一些零散页和一些完整的区的集合，每个Fragment Array Entry结构都对应着一个零散的页，这个结构一共4个字节，表示一个零散页的页号。</li>
</ol>
<h3 id="92-各类型页详细情况">9.2 各类型页详细情况</h3>
<h4 id="921-fsp_hdr类型">9.2.1 FSP_HDR类型</h4>
<p>首先看第一个组的第一个页，当然也是表空间的第一个页，页号为0。这个页的类型是FSP_HDR，它存储了表空间的一些整体属性以及第一个组内256个区的对应的XDES Entry结构，直接看这个类型的页的示意图：<br>
<img src="https://q456qq520.github.io/post-images/1673594172487.png" alt="" loading="lazy"></p>
<p>一个完整的FSP_HDR类型的页大致由5个部分组成，各个部分的具体释义如下表：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>中文名</th>
<th>占用空间大小</th>
<th>简单描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>File Header</td>
<td>文件头部</td>
<td>38字节</td>
<td>页的一些通用信息</td>
</tr>
<tr>
<td>File Space Header</td>
<td>表空间头部</td>
<td>112字节</td>
<td>表空间的一些整体属性信息</td>
</tr>
<tr>
<td>XDES Entry</td>
<td>区描述信息</td>
<td>10240字节</td>
<td>存储本组256个区对应的属性信息</td>
</tr>
<tr>
<td>Empty Space</td>
<td>尚未使用空间</td>
<td>5986字节</td>
<td>用于页结构的填充，没什么实际意义</td>
</tr>
<tr>
<td>File Trailer</td>
<td>文件尾部</td>
<td>8字节</td>
<td>校验页是否完整</td>
</tr>
</tbody>
</table>
<p><strong>File Space Header部分</strong><br>
<img src="https://q456qq520.github.io/post-images/1673594304137.png" alt="" loading="lazy"></p>
<table>
<thead>
<tr>
<th>名称</th>
<th>占用空间大小</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Space ID</td>
<td>4字节</td>
<td>表空间的ID</td>
</tr>
<tr>
<td>Not Used</td>
<td>4字节</td>
<td>这4个字节未被使用，可以忽略</td>
</tr>
<tr>
<td>Size</td>
<td>4字节</td>
<td>当前表空间占有的页数</td>
</tr>
<tr>
<td>FREE Limit</td>
<td>4字节</td>
<td>尚未被初始化的最小页号，大于或等于这个页号的区对应的XDES Entry结构都没有被加入FREE链表</td>
</tr>
<tr>
<td>Space Flags</td>
<td>4字节</td>
<td>表空间的一些占用存储空间比较小的属性</td>
</tr>
<tr>
<td>FRAG_N_USED</td>
<td>4字节</td>
<td>FREE_FRAG链表中已使用的页数量</td>
</tr>
<tr>
<td>List Base Node for FREE List</td>
<td>16字节</td>
<td>FREE链表的基节点</td>
</tr>
<tr>
<td>List Base Node for FREE_FRAG List</td>
<td>16字节</td>
<td>FREE_FREG链表的基节点</td>
</tr>
<tr>
<td>List Base Node for FULL_FRAG List</td>
<td>16字节</td>
<td>FULL_FREG链表的基节点</td>
</tr>
<tr>
<td>Next Unused Segment ID</td>
<td>8字节</td>
<td>当前表空间中下一个未使用的 Segment ID</td>
</tr>
<tr>
<td>List Base Node for SEG_INODES_FULL List</td>
<td>16字节</td>
<td>SEG_INODES_FULL链表的基节点</td>
</tr>
<tr>
<td>List Base Node for SEG_INODES_FREE List</td>
<td>16字节</td>
<td>SEG_INODES_FREE链表的基节点</td>
</tr>
</tbody>
</table>
<ol>
<li>List Base Node for FREE List、List Base Node for FREE_FRAG List、List Base Node for FULL_FRAG List<br>
分别是直属于表空间的FREE链表的基节点、FREE_FRAG链表的基节点、FULL_FRAG链表的基节点，这三个链表的基节点在表空间的位置是固定的，就是在表空间的第一个页（也就是FSP_HDR类型的页）的File Space Header部分。</li>
<li>FRAG_N_USED<br>
这个字段表明在FREE_FRAG链表中已经使用的页数量，方便之后在链表中查找空闲的页。</li>
<li>FREE Limit<br>
在该字段表示的页号之前的区都被初始化了，之后的区尚未被初始化。</li>
<li>Next Unused Segment ID<br>
该字段表明当前表空间中最大的段ID的下一个ID。</li>
<li>Space Flags<br>
表空间对于一些布尔类型的属性，或者只需要寥寥几个比特位搞定的属性都放在了这个Space Flags中存储，虽然它只有4个字节，32个比特位大小，却存储了好多表空间的属性，详细情况如下表：</li>
</ol>
<table>
<thead>
<tr>
<th>标志名称</th>
<th>占用的空间（单位：bit）</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>POST_ANTELOPE</td>
<td>1</td>
<td>表示文件格式是否大于ANTELOPE</td>
</tr>
<tr>
<td>ZIP_SSIZE</td>
<td>4</td>
<td>表示压缩页的大小</td>
</tr>
<tr>
<td>ATOMIC_BLOBS</td>
<td>1</td>
<td>表示是否自动把值非常长的字段放到BLOB页里</td>
</tr>
<tr>
<td>PAGE_SSIZE</td>
<td>4</td>
<td>页大小</td>
</tr>
<tr>
<td>DATA_DIR</td>
<td>1</td>
<td>表示表空间是否是从默认的数据目录中获取的</td>
</tr>
<tr>
<td>SHARED</td>
<td>1</td>
<td>是否为共享表空间</td>
</tr>
<tr>
<td>TEMPORARY</td>
<td>1</td>
<td>是否为临时表空间</td>
</tr>
<tr>
<td>ENCRYPTION</td>
<td>1</td>
<td>表空间是否加密</td>
</tr>
<tr>
<td>UNUSED</td>
<td>18</td>
<td>没有使用到的比特位</td>
</tr>
</tbody>
</table>
<ol start="6">
<li>
<p>List Base Node for SEG_INODES_FULL List和List Base Node for SEG_INODES_FREE List<br>
每个段对应的INODE Entry结构会集中存放到一个类型位INODE的页中，如果表空间中的段特别多，则会有多个INODE Entry结构，可能一个页放不下，这些INODE类型的页会组成两种列表：</p>
<ul>
<li>SEG_INODES_FULL链表，该链表中的INODE类型的页都已经被INODE Entry结构填充满了，没空闲空间存放额外的INODE Entry了。</li>
<li>SEG_INODES_FREE链表，该链表中的INODE类型的页都已经仍有空闲空间来存放INODE Entry结构。</li>
</ul>
</li>
</ol>
<p><strong>XDES Entry部分</strong><br>
XDES Entry就是在表空间的第一个页中保存的。我们知道一个XDES Entry结构的大小是40字节，但是一个页的大小有限，只能存放有限个XDES Entry结构，所以我们才把256个区划分成一组，在每组的第一个页中存放256个XDES Entry结构。</p>
<h4 id="922-xdes类型">9.2.2 XDES类型</h4>
<p>每一个XDES Entry结构对应表空间的一个区，虽然一个XDES Entry结构只占用40字节，但你抵不住表空间的区的数量也多啊。在区的数量非常多时，一个单独的页可能就不够存放足够多的XDES Entry结构，所以我们把表空间的区分为了若干个组，每组开头的一个页记录着本组内所有的区对应的XDES Entry结构。由于第一个组的第一个页有些特殊，因为它也是整个表空间的第一个页，所以除了记录本组中的所有区对应的XDES Entry结构以外，还记录着表空间的一些整体属性，这个页的类型就是我们刚刚说完的FSP_HDR类型，整个表空间里只有一个这个类型的页。除去第一个分组以外，之后的每个分组的第一个页只需要记录本组内所有的区对应的XDES Entry结构即可，不需要再记录表空间的属性了。</p>
<p>与FSP_HDR类型的页对比，除了少了File Space Header部分之外，也就是除了少了记录表空间整体属性的部分之外，其余的部分是一样一样的。</p>
<h4 id="923-ibuf_bitmap类型">9.2.3 IBUF_BITMAP类型</h4>
<p>对比前面介绍表空间的图，每个分组的第二个页的类型都是IBUF_BITMAP，这种类型的页里边记录了一些有关Change Buffer的东西。</p>
<h4 id="924-inode类型">9.2.4 INODE类型</h4>
<p>再次对比前面介绍表空间的图，第一个分组的第三个页的类型是INODE。我们前面说过InnoDB为每个索引定义了两个段，而且为某些特殊功能定义了些特殊的段。为了方便管理，他们又为每个段设计了一个INODE Entry结构，这个结构中记录了关于这个段的相关属性。这个INODE类型的页就是为了存储INODE Entry结构而存在的。<br>
<img src="https://q456qq520.github.io/post-images/1673596556357.png" alt="" loading="lazy"></p>
<table>
<thead>
<tr>
<th>名称</th>
<th>中文名</th>
<th>占用空间大小</th>
<th>简单描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>File Header</td>
<td>文件头部</td>
<td>38字节</td>
<td>页的一些通用信息</td>
</tr>
<tr>
<td>List Node for INODE Page List</td>
<td>通用链表节点</td>
<td>12字节</td>
<td>存储上一个INODE页和下一个INODE页的指针</td>
</tr>
<tr>
<td>INODE Entry</td>
<td>段描述信息</td>
<td>16128字节</td>
<td></td>
</tr>
<tr>
<td>Empty Space</td>
<td>尚未使用空间</td>
<td>6字节</td>
<td>用于页结构的填充，没什么实际意义</td>
</tr>
<tr>
<td>File Trailer</td>
<td>文件尾部</td>
<td>8字节</td>
<td>校验页是否完整</td>
</tr>
</tbody>
</table>
<p>除了File Header、Empty Space、File Trailer这几个老朋友外，我们重点关注List Node for INODE Page List和INODE Entry这两个部分。</p>
<p>首先看INODE Entry部分，我们前面已经详细介绍过这个结构的组成了，主要包括对应的段内零散页的地址以及附属于该段的FREE、NOT_FULL和FULL链表的基节点。每个INODE Entry结构占用192字节，一个页里可以存储85个这样的结构。</p>
<p>重点看一下List Node for INODE Page List，因为一个表空间中可能存在超过85个段，所以可能一个INODE类型的页不足以存储所有的段对应的INODE Entry结构，所以就需要额外的INODE类型的页来存储这些结构。还是为了方便管理这些INODE类型的页，设计InnoDB的大佬们将这些INODE类型的页串联成两个不同的链表：</p>
<ol>
<li>SEG_INODES_FULL链表：该链表中的INODE类型的页中已经没有空闲空间来存储额外的INODE Entry结构了。</li>
<li>SEG_INODES_FREE链表：该链表中的INODE类型的页中还有空闲空间来存储额外的INODE Entry结构了。</li>
</ol>
<p>想必大家已经认出这两个链表了，我们前面提到过这两个链表的基节点就存储在File Space Header里边，也就是说这两个链表的基节点的位置是固定的，所以我们可以很轻松的访问到这两个链表。以后每当我们新创建一个段（创建索引时就会创建段）时，都会创建一个INODE Entry结构与之对应，存储INODE Entry的大致过程就是这样的：</p>
<ol>
<li>先看看SEG_INODES_FREE链表是否为空，如果不为空，直接从该链表中获取一个节点，也就相当于获取到一个仍有空闲空间的INODE类型的页，然后把该INODE Entry结构放到该页中。当该页中无剩余空间时，就把该页放到SEG_INODES_FULL链表中。</li>
<li>如果SEG_INODES_FREE链表为空，则需要从表空间的FREE_FRAG链表中申请一个页，修改该页的类型为INODE，把该页放到SEG_INODES_FREE链表中，与此同时把该INODE Entry结构放入该页。</li>
</ol>
<h3 id="93-segment-header-结构的运用">9.3 Segment Header 结构的运用</h3>
<p>我们知道一个索引会产生两个段，分别是叶子节点段和非叶子节点段，而每个段都会对应一个INODE Entry结构，那我们怎么知道某个段对应哪个INODE Entry结构呢？所以得找个地方记下来这个对应关系。</p>
<p>在数据页，也就是INDEX类型的页时有一个Page Header部分，其中的PAGE_BTR_SEG_LEAF和PAGE_BTR_SEG_TOP都占用10个字节，它们其实对应一个叫Segment Header的结构，该结构图示如下：<br>
<img src="https://q456qq520.github.io/post-images/1673597803595.png" alt="" loading="lazy"></p>
<p>各个部分的具体释义如下：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>占用字节数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Space ID of the INODE Entry</td>
<td>4</td>
<td>INODE Entry结构所在的表空间ID</td>
</tr>
<tr>
<td>Page Number of the INODE Entry</td>
<td>4</td>
<td>INODE Entry结构所在的页页号</td>
</tr>
<tr>
<td>Byte Offset of the INODE Ent</td>
<td>2</td>
<td>INODE Entry结构在该页中的偏移量</td>
</tr>
</tbody>
</table>
<p>这样子就很清晰了，PAGE_BTR_SEG_LEAF记录着叶子节点段对应的INODE Entry结构的地址是哪个表空间的哪个页的哪个偏移量，PAGE_BTR_SEG_TOP记录着非叶子节点段对应的INODE Entry结构的地址是哪个表空间的哪个页的哪个偏移量。这样子索引和其对应的段的关系就建立起来了。不过需要注意的一点是，因为一个索引只对应两个段，所以只需要在索引的根页中记录这两个结构即可。</p>
<h3 id="94-系统表空间">9.4 系统表空间</h3>
<p>系统表空间的结构和独立表空间基本类似，只不过由于整个MySQL进程只有一个系统表空间，在系统表空间中会额外记录一些有关整个系统信息的页，所以会比独立表空间多出一些记录这些信息的页。因为这个系统表空间最牛逼，相当于是表空间之首，所以它的表空间 ID（Space ID）是0。</p>
<h4 id="941-系统表空间的整体结构">9.4.1 系统表空间的整体结构</h4>
<p>系统表空间与独立表空间的一个非常明显的不同之处就是在表空间开头有许多记录整个系统属性的页，如图：<br>
<img src="https://q456qq520.github.io/post-images/1673599849681.png" alt="" loading="lazy"></p>
<p>可以看到，系统表空间和独立表空间的前三个页（页号分别为0、1、2，类型分别是FSP_HDR、IBUF_BITMAP、INODE）的类型是一致的，只是页号为3～7的页是系统表空间特有的，我们来看一下这些多出来的页都是干什么使的：</p>
<table>
<thead>
<tr>
<th>页号</th>
<th>页类型</th>
<th>英文描述</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>3</td>
<td>SYS</td>
<td>Insert Buffer Header</td>
<td>存储Insert Buffer的头部信息</td>
</tr>
<tr>
<td>4</td>
<td>INDEX</td>
<td>Insert Buffer Root</td>
<td>存储Insert Buffer的根页</td>
</tr>
<tr>
<td>5</td>
<td>TRX_SYS</td>
<td>Transction System</td>
<td>事务系统的相关信息</td>
</tr>
<tr>
<td>6</td>
<td>SYS	First</td>
<td>Rollback Segment</td>
<td>第一个回滚段的页</td>
</tr>
<tr>
<td>7</td>
<td>SYS</td>
<td>Data Dictionary Header</td>
<td>数据字典头部信息</td>
</tr>
</tbody>
</table>
<p>除了这几个记录系统属性的页之外，系统表空间的extent 1和extent 2这两个区，也就是页号从64~191这128个页被称为Doublewrite buffer，也就是双写缓冲区。</p>
<h5 id="innodb数据字典">InnoDB数据字典</h5>
<p>我们平时使用INSERT语句向表中插入的那些记录称之为用户数据，MySQL只是作为一个软件来为我们来保管这些数据，提供方便的增删改查接口而已。但是每当我们向一个表中插入一条记录的时候，MySQL先要校验一下插入语句对应的表存不存在，插入的列和表中的列是否符合，如果语法没有问题的话，还需要知道该表的聚簇索引和所有二级索引对应的根页是哪个表空间的哪个页，然后把记录插入对应索引的B+树中。所以说，MySQL除了保存着我们插入的用户数据之外，还需要保存许多额外的信息，这些数据也称为元数据。</p>
<p>InnoDB存储引擎特意定义了一些列的内部系统表（internal system table）来记录这些这些元数据：</p>
<table>
<thead>
<tr>
<th>表名</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>SYS_TABLES</td>
<td>整个InnoDB存储引擎中所有的表的信息</td>
</tr>
<tr>
<td>SYS_COLUMNS</td>
<td>整个InnoDB存储引擎中所有的列的信息</td>
</tr>
<tr>
<td>SYS_INDEXES</td>
<td>整个InnoDB存储引擎中所有的索引的信息</td>
</tr>
<tr>
<td>SYS_FIELDS</td>
<td>整个InnoDB存储引擎中所有的索引对应的列的信息</td>
</tr>
<tr>
<td>SYS_FOREIGN</td>
<td>整个InnoDB存储引擎中所有的外键的信息</td>
</tr>
<tr>
<td>SYS_FOREIGN_COLS</td>
<td>整个InnoDB存储引擎中所有的外键对应列的信息</td>
</tr>
<tr>
<td>SYS_TABLESPACES</td>
<td>整个InnoDB存储引擎中所有的表空间信息</td>
</tr>
<tr>
<td>SYS_DATAFILES</td>
<td>整个InnoDB存储引擎中所有的表空间对应文件系统的文件路径信息</td>
</tr>
<tr>
<td>SYS_VIRTUAL</td>
<td>整个InnoDB存储引擎中所有的虚拟生成列的信息</td>
</tr>
</tbody>
</table>
<p>这些系统表也被称为<mark>数据字典</mark>，它们都是以B+树的形式保存在系统表空间的某些页中，其中SYS_TABLES、SYS_COLUMNS、SYS_INDEXES、SYS_FIELDS这四个表尤其重要，称之为基本系统表（basic system tables），我们先看看这4个表的结构：</p>
<p><mark>SYS_TABLES表</mark></p>
<table>
<thead>
<tr>
<th>列名</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>NAME</td>
<td>表的名称</td>
</tr>
<tr>
<td>ID</td>
<td>InnoDB存储引擎中每个表都有一个唯一的ID</td>
</tr>
<tr>
<td>N_COLS</td>
<td>该表拥有列的个数</td>
</tr>
<tr>
<td>TYPE</td>
<td>表的类型，记录了一些文件格式、行格式、压缩等信息</td>
</tr>
<tr>
<td>MIX_ID</td>
<td>已过时，忽略</td>
</tr>
<tr>
<td>MIX_LEN</td>
<td>表的一些额外的属性</td>
</tr>
<tr>
<td>CLUSTER_ID</td>
<td>未使用，忽略</td>
</tr>
<tr>
<td>SPACE</td>
<td>该表所属表空间的ID</td>
</tr>
</tbody>
</table>
<p>这个SYS_TABLES表有两个索引：<br>
- 以NAME列为主键的聚簇索引<br>
- 以ID列建立的二级索引</p>
<p><mark>SYS_COLUMNS表</mark></p>
<table>
<thead>
<tr>
<th>列名</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>TABLE_ID</td>
<td>该列所属表对应的ID</td>
</tr>
<tr>
<td>POS</td>
<td>该列在表中是第几列</td>
</tr>
<tr>
<td>NAME</td>
<td>该列的名称</td>
</tr>
<tr>
<td>MTYPE</td>
<td>main data type，主数据类型，就是那堆INT、CHAR、VARCHAR、FLOAT、DOUBLE之类的东东</td>
</tr>
<tr>
<td>PRTYPE</td>
<td>precise type，精确数据类型，就是修饰主数据类型的那堆东东，比如是否允许NULL值，是否允许负数什么的</td>
</tr>
<tr>
<td>LEN</td>
<td>该列最多占用存储空间的字节数</td>
</tr>
<tr>
<td>PREC</td>
<td>该列的精度，不过这列貌似都没有使用，默认值都是0</td>
</tr>
</tbody>
</table>
<p>这个SYS_COLUMNS表只有一个聚集索引：<br>
- 以(TABLE_ID, POS)列为主键的聚簇索引</p>
<p><mark>SYS_INDEXES表</mark></p>
<table>
<thead>
<tr>
<th>列名</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>TABLE_ID</td>
<td>该索引所属表对应的ID</td>
</tr>
<tr>
<td>ID</td>
<td>Inn</td>
</tr>
</tbody>
</table>
<p>NAME	该索引的名称<br>
N_FIELDS|	该索引包含列的个数<br>
TYPE	|该索引的类型，比如聚簇索引、唯一索引、更改缓冲区的索引、全文索引、普通的二级索引等等各种类型<br>
SPACE|	该索引根页所在的表空间ID<br>
PAGE_NO|	该索引根页所在的页号<br>
MERGE_THRESHOLD|	如果页中的记录被删除到某个比例，就把该页和相邻页合并，这个值就是这个比例</p>
<p>这个SYS_INEXES表只有一个聚集索引：<br>
- 以(TABLE_ID, ID)列为主键的聚簇索引</p>
<p><mark>SYS_FIELDS表</mark></p>
<table>
<thead>
<tr>
<th>列名</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>INDEX_ID</td>
<td>该索引列所属的索引的ID</td>
</tr>
<tr>
<td>POS</td>
<td>该索引列在某个索引中是第几列</td>
</tr>
<tr>
<td>COL_NAME</td>
<td>该索引列的名称</td>
</tr>
</tbody>
</table>
<p>这个SYS_INEXES表只有一个聚集索引：<br>
- 以(INDEX_ID, POS)列为主键的聚簇索引</p>
<p><mark>Data Dictionary Header页</mark><br>
只要有了上述4个基本系统表，也就意味着可以获取其他系统表以及用户定义的表的所有元数据。比方说我们想看看SYS_TABLESPACES这个系统表里存储了哪些表空间以及表空间对应的属性，那就可以：</p>
<ol>
<li>到SYS_TABLES表中根据表名定位到具体的记录，就可以获取到SYS_TABLESPACES表的TABLE_ID</li>
<li>使用这个TABLE_ID到SYS_COLUMNS表中就可以获取到属于该表的所有列的信息。</li>
<li>使用这个TABLE_ID还可以到SYS_INDEXES表中获取所有的索引的信息，索引的信息中包括对应的INDEX_ID，还记录着该索引对应的B+数根页是哪个表空间的哪个页。</li>
<li>使用INDEX_ID就可以到SYS_FIELDS表中获取所有索引列的信息。</li>
</ol>
<p>InnoDB拿出一个固定的页来记录这4个表的聚簇索引和二级索引对应的B+树位置，这个页就是页号为7的页，类型为SYS，记录了Data Dictionary Header，也就是数据字典的头部信息。除了这4个表的5个索引的根页信息外，这个页号为7的页还记录了整个InnoDB存储引擎的一些全局属性，说话太啰嗦，直接看这个页的示意图：<br>
<img src="https://q456qq520.github.io/post-images/1673603125926.png" alt="" loading="lazy"></p>
<p>可以看到这个页由下面几个部分组成：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>中文名</th>
<th>占用空间大小</th>
<th>简单描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>File Header</td>
<td>文件头部</td>
<td>38字节</td>
<td>页的一些通用信息</td>
</tr>
<tr>
<td>Data Dictionary Header</td>
<td>数据字典头部信息</td>
<td>56字节</td>
<td>记录一些基本系统表的根页位置以及InnoDB存储引擎的一些全局信息</td>
</tr>
<tr>
<td>Segment Header</td>
<td>段头部信息</td>
<td>10字节</td>
<td>记录本页所在段对应的INODE Entry位置信息</td>
</tr>
<tr>
<td>Empty Space</td>
<td>尚未使用空间</td>
<td>16272字节</td>
<td>用于页结构的填充，没什么实际意义</td>
</tr>
<tr>
<td>File Trailer</td>
<td>文件尾部</td>
<td>8字节</td>
<td>校验页是否完整</td>
</tr>
</tbody>
</table>
<p>可以看到这个页里竟然有Segment Header部分，意味着InnoDB把这些有关数据字典的信息当成一个段来分配存储空间，我们就姑且称之为数据字典段吧。由于目前我们需要记录的数据字典信息非常少（可以看到Data Dictionary Header部分仅占用了56字节），所以该段只有一个碎片页，也就是页号为7的这个页。</p>
<p>接下来我们需要细细介绍一下Data Dictionary Header部分的各个字段：</p>
<ol>
<li>Max Row ID：我们说过如果我们不显式的为表定义主键，而且表中也没有UNIQUE索引，那么InnoDB存储引擎会默认为我们生成一个名为row_id的列作为主键。因为它是主键，所以每条记录的row_id列的值不能重复。原则上只要一个表中的row_id列不重复就可以了，也就是说表a和表b拥有一样的row_id列也没什么关系，不过InnoDB只提供了这个Max Row ID字段，不论哪个拥有row_id列的表插入一条记录时，该记录的row_id列的值就是Max Row ID对应的值，然后再把Max Row ID对应的值加1，也就是说这个Max Row ID是全局共享的。</li>
<li>Max Table ID：InnoDB存储引擎中的所有的表都对应一个唯一的ID，每次新建一个表时，就会把本字段的值作为该表的ID，然后自增本字段的值。</li>
<li>Max Index ID：InnoDB存储引擎中的所有的索引都对应一个唯一的ID，每次新建一个索引时，就会把本字段的值作为该索引的ID，然后自增本字段的值。</li>
<li>Max Space ID：InnoDB存储引擎中的所有的表空间都对应一个唯一的ID，每次新建一个表空间时，就会把本字段的值作为该表空间的ID，然后自增本字段的值。</li>
<li>Mix ID Low(Unused)：这个字段没什么用，跳过。</li>
<li>Root of SYS_TABLES clust index：本字段代表SYS_TABLES表聚簇索引的根页的页号。</li>
<li>Root of SYS_TABLE_IDS sec index：本字段代表SYS_TABLES表为ID列建立的二级索引的根页的页号。</li>
<li>Root of SYS_COLUMNS clust index：本字段代表SYS_COLUMNS表聚簇索引的根页的页号。</li>
<li>Root of SYS_INDEXES clust index本字段代表SYS_INDEXES表聚簇索引的根页的页号。</li>
<li>Root of SYS_FIELDS clust index：本字段代表SYS_FIELDS表聚簇索引的根页的页号。</li>
<li>Unused：这4个字节没用，跳过。</li>
</ol>
<p>==information_schema系统数据库<br>
需要注意一点的是，用户是不能直接访问InnoDB的这些内部系统表的，除非你直接去解析系统表空间对应文件系统上的文件。不过设计InnoDB的大佬考虑到查看这些表的内容可能有助于大家分析问题，所以在系统数据库information_schema中提供了一些以innodb_sys开头的表：</p>
<pre><code class="language-mysql">mysql&gt; USE information_schema;
Database changed

mysql&gt; SHOW TABLES LIKE 'innodb_sys%';
+--------------------------------------------+
| Tables_in_information_schema (innodb_sys%) |
+--------------------------------------------+
| INNODB_SYS_DATAFILES                       |
| INNODB_SYS_VIRTUAL                         |
| INNODB_SYS_INDEXES                         |
| INNODB_SYS_TABLES                          |
| INNODB_SYS_FIELDS                          |
| INNODB_SYS_TABLESPACES                     |
| INNODB_SYS_FOREIGN_COLS                    |
| INNODB_SYS_COLUMNS                         |
| INNODB_SYS_FOREIGN                         |
| INNODB_SYS_TABLESTATS                      |
+--------------------------------------------+
10 rows in set (0.00 sec)
</code></pre>
<p>在information_schema数据库中的这些以INNODB_SYS开头的表并不是真正的内部系统表（内部系统表就是我们上面介绍的以SYS开头的那些表），而是在存储引擎启动时读取这些以SYS开头的系统表，然后填充到这些以INNODB_SYS开头的表中。以INNODB_SYS开头的表和以SYS开头的表中的字段并不完全一样。</p>
<h3 id="94-总结图">9.4 总结图</h3>
<figure data-type="image" tabindex="8"><img src="https://q456qq520.github.io/post-images/1673604826737.png" alt="" loading="lazy"></figure>
<p>链接:<a href="/post/lesslesscong-gen-er-shang-li-jie-mysqlgreatergreater-du-shu-bi-ji-san">《从根儿上理解MySQL》读书笔记(三)</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《从根儿上理解MySQL》读书笔记(一)]]></title>
        <id>https://q456qq520.github.io/post/lesslesscong-gen-er-shang-li-jie-mysqlgreatergreater-du-shu-bi-ji-yi/</id>
        <link href="https://q456qq520.github.io/post/lesslesscong-gen-er-shang-li-jie-mysqlgreatergreater-du-shu-bi-ji-yi/">
        </link>
        <updated>2022-12-29T02:08:03.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="第一章-初识mysql">第一章 初识Mysql</h2>
<h3 id="11-服务器处理客户端请求">1.1 服务器处理客户端请求</h3>
]]></summary>
        <content type="html"><![CDATA[<h2 id="第一章-初识mysql">第一章 初识Mysql</h2>
<h3 id="11-服务器处理客户端请求">1.1 服务器处理客户端请求</h3>
<!-- more -->
<p>客户端进程向服务器进程发送一段文本（MySQL语句），服务器进程处理后再向客户端进程发送一段文本（处理结果）。那服务器进程对客户端进程发送的请求做了什么处理，才能产生最后的处理结果呢？客户端可以向服务器发送增删改查各类请求，我们这里以比较复杂的查询请求为例来画个图展示一下大致的过程：</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1672280638065.png" alt="" loading="lazy"></figure>
<p>服务器程序处理来自客户端的查询请求大致需要经过三个部分，分别是<strong>连接管理</strong>、<strong>解析与优化</strong>、<strong>存储引擎</strong>。</p>
<h4 id="111-连接管理">1.1.1 连接管理</h4>
<p>客户端进程可以采用TCP/IP、命名管道或共享内存、Unix域套接字这几种方式之一来与服务器进程建立连接，每当有一个客户端进程连接到服务器进程时，服务器进程都会创建一个线程来专门处理与这个客户端的交互，当该客户端退出时会与服务器断开连接，服务器并不会立即把与该客户端交互的线程销毁掉，而是把它缓存起来，在另一个新的客户端再进行连接时，把这个缓存的线程分配给该新客户端。这样就起到了不频繁创建和销毁线程的效果，从而节省开销。</p>
<p>在客户端程序发起连接的时候，需要携带主机信息、用户名、密码，服务器程序会对客户端程序提供的这些信息进行认证，如果认证失败，服务器程序会拒绝连接。另外，如果客户端程序和服务器程序不运行在一台计算机上，我们还可以采用使用了SSL（安全套接字）的网络连接进行通信，来保证数据传输的安全性。</p>
<p>当连接建立后，与该客户端关联的服务器线程会一直等待客户端发送过来的请求，MySQL服务器接收到的请求只是一个文本消息，该文本消息还要经过各种处理。</p>
<h4 id="112-解析与优化">1.1.2 解析与优化</h4>
<p><strong>查询缓存</strong><br>
MySQL服务器程序处理查询请求的过程，首先会把刚刚处理过的查询请求和结果缓存起来，如果下一次有一模一样的请求过来，直接从缓存中查找结果就好了，就不用再去底层的表中查找了。这个查询缓存可以在不同客户端之间共享，也就是说如果客户端A刚刚查询了一个语句，而客户端B之后发送了同样的查询请求，那么客户端B的这次查询就可以直接使用查询缓存中的数据。</p>
<p>当然，如果两个查询请求在任何字符上的不同（例如：空格、注释、大小写），都会导致缓存不会命中。另外，如果查询请求中包含某些<font color=red>系统函数、用户自定义变量和函数、一些系统表，如 mysql 、information_schema、 performance_schema 数据库中的表</font>，那这个请求就不会被缓存。</p>
<p>不过既然是缓存，那就有它缓存失效的时候。<font color=red>MySQL的缓存系统会监测涉及到的每张表，只要该表的结构或者数据被修改，如对该表使用了INSERT、 UPDATE、DELETE、TRUNCATE TABLE、ALTER TABLE、DROP TABLE或 DROP DATABASE语句，那使用该表的所有高速缓存查询都将变为无效并从高速缓存中删除！</font></p>
<p><strong>语法解析</strong><br>
如果查询缓存没有命中，接下来就需要进入正式的查询阶段了。因为客户端程序发送过来的请求只是一段文本而已，所以MySQL服务器程序首先要对这段文本做分析，判断请求的语法是否正确，然后从文本中将要查询的表、各种查询条件都提取出来放到MySQL服务器内部使用的一些数据结构上来。</p>
<p><strong>查询优化</strong><br>
语法解析之后，服务器程序获得到了需要的信息，比如要查询的列是哪些，表是哪个，搜索条件是什么等等，但光有这些是不够的，因为我们写的MySQL语句执行起来效率可能并不是很高，MySQL的优化程序会对我们的语句做一些优化，如外连接转换为内连接、表达式简化、子查询转为连接等等的一堆东西。优化的结果就是生成一个执行计划，这个执行计划表明了应该使用哪些索引进行查询，表之间的连接顺序是什么样的。我们可以使用<font color=red><strong>EXPLAIN语句</strong></font>来查看某个语句的执行计划。</p>
<h4 id="113-存储引擎">1.1.3 存储引擎</h4>
<pre><code> 截止到服务器程序完成了查询优化为止，还没有真正的去访问真实的数据表，MySQL服务器把数据的存储和提取操作都封装到了一个叫存储引擎的模块里。我们知道表是由一行一行的记录组成的，但这只是一个逻辑上的概念，物理上如何表示记录，怎么从表中读取数据，怎么把数据写入具体的物理存储器上，这都是存储引擎负责的事情。为了实现不同的功能，MySQL提供了各式各样的存储引擎，不同存储引擎管理的表具体的存储结构可能不同，采用的存取算法也可能不同。

 为了管理方便，人们把连接管理、查询缓存、语法解析、查询优化这些并不涉及真实数据存储的功能划分为MySQL server的功能，把真实存取数据的功能划分为存储引擎的功能。各种不同的存储引擎向上面的MySQL server层提供统一的调用接口（也就是存储引擎API），包含了几十个底层函数，像&quot;读取索引第一条内容&quot;、&quot;读取索引下一条内容&quot;、&quot;插入记录&quot;等等。

 所以在MySQL server完成了查询优化后，只需按照生成的执行计划调用底层存储引擎提供的API，获取到数据后返回给客户端就好了。
</code></pre>
<h5 id="常用存储引擎">常用存储引擎</h5>
<p>ARCHIVE	用于数据存档（行被插入后不能再修改）<br>
BLACKHOLE	丢弃写操作，读操作会返回空内容<br>
CSV	在存储数据时，以逗号分隔各个数据项<br>
FEDERATED	用来访问远程表<br>
InnoDB	具备外键支持功能的事务存储引擎<br>
MEMORY	置于内存的表<br>
MERGE	用来管理多个MyISAM表构成的表集合<br>
MyISAM	主要的非事务处理存储引擎<br>
NDB	MySQL集群专用存储引擎</p>
<p>我们可以用下面这个命令来查看当前服务器程序支持的存储引擎：</p>
<blockquote>
<p>SHOW ENGINES;</p>
</blockquote>
<h5 id="设置表的存储引擎">设置表的存储引擎</h5>
<p><em>存储引擎是负责对表中的数据进行提取和写入的，我们可以为不同的表设置不同的存储引擎，也就是说不同的表可以有不同的物理存储结构，不同的提取和写入方式。</em></p>
<p>我们之前创建表的语句都没有指定表的存储引擎，那就会使用默认的存储引擎InnoDB，如果我们想显式的指定一下表的存储引擎，那可以这么写：</p>
<pre><code class="language-mysql">CREATE TABLE 表名(
    建表语句;
) ENGINE = 存储引擎名称;
</code></pre>
<p>如果表已经建好了，我们也可以使用下面这个语句来修改表的存储引擎：</p>
<pre><code class="language-mysql">ALTER TABLE 表名 ENGINE = 存储引擎名称;
</code></pre>
<h2 id="第二章-mysql的调控按钮-启动选项和系统变量">第二章 MySQL的调控按钮-启动选项和系统变量</h2>
<h2 id="第三章-乱码的前世今生-字符集和比较规则">第三章 乱码的前世今生-字符集和比较规则</h2>
<h3 id="31-字符集简介">3.1 字符集简介</h3>
<p>我们知道在计算机中只能存储二进制数据，那该怎么存储字符串呢？当然是建立字符与二进制数据的映射关系了。其中最重要的就是界定清楚字符范围和字符编解码。</p>
<h3 id="32-mysql中支持的字符集和排序规则">3.2 MySQL中支持的字符集和排序规则</h3>
<h4 id="321-mysql中的utf8和utf8mb4">3.2.1 MySQL中的utf8和utf8mb4</h4>
<p>utf8字符集表示一个字符需要使用1～4个字节，但是我们常用的一些字符使用1～3个字节就可以表示了。而在MySQL中字符集表示一个字符所用最大字节长度在某些方面会影响系统的存储和性能，所以设计MySQL的大佬偷偷的定义了两个概念：</p>
<ul>
<li>
<p>utf8mb3：阉割过的utf8字符集，只使用1～3个字节表示字符。</p>
</li>
<li>
<p>utf8mb4：正宗的utf8字符集，使用1～4个字节表示字符。</p>
</li>
</ul>
<p>MySQL支持好多好多种字符集，查看当前MySQL中支持的字符集可以用下面这个语句：</p>
<blockquote>
<p>SHOW (CHARACTER SET|CHARSET) [LIKE 匹配的模式];</p>
</blockquote>
<p>查看MySQL中支持的比较规则的命令如下:</p>
<blockquote>
<p>SHOW COLLATION [LIKE 匹配的模式];</p>
</blockquote>
<p>每种字符集对应若干种比较规则，每种字符集都有一种默认的比较规则，SHOW COLLATION的返回结果中的Default列的值为YES的就是该字符集的默认比较规则，比方说utf8字符集默认的比较规则就是utf8_general_ci。</p>
<h2 id="第四章-从一条记录说起-innodb记录结构">第四章 从一条记录说起-InnoDB记录结构</h2>
<h3 id="41-innodb页简介">4.1 InnoDB页简介</h3>
<p>InnoDB是一个将表中的数据存储到磁盘上的存储引擎，所以即使关机后重启我们的数据还是存在的。而真正处理数据的过程是发生在内存中的，所以需要把磁盘中的数据加载到内存中，如果是处理写入或修改请求的话，还需要把内存中的内容刷新到磁盘上。而我们知道读写磁盘的速度非常慢，和内存读写差了几个数量级，所以当我们想从表中获取某些记录时，InnoDB存储引擎需要一条一条的把记录从磁盘上读出来么？不，那样会慢死，InnoDB采取的方式是：<font color=red >将数据划分为若干个页，以页作为磁盘和内存之间交互的基本单位，InnoDB中页的大小一般为 16 KB。</font>也就是在一般情况下，一次最少从磁盘中读取16KB的内容到内存中，一次最少把内存中的16KB内容刷新到磁盘中。</p>
<h3 id="42-innodb行格式">4.2 InnoDB行格式</h3>
<p>我们平时是以记录为单位来向表中插入数据的，这些记录在磁盘上的存放方式也被称为行格式或者记录格式。设计InnoDB存储引擎的大佬们到现在为止设计了4种不同类型的行格式，分别是<font color=red >Compact、Redundant、Dynamic和Compressed行格式</font>，随着时间的推移，他们可能会设计出更多的行格式，但是不管怎么变，在原理上大体都是相同的。</p>
<p>我们可以在创建或修改表的语句中指定行格式：</p>
<pre><code class="language-mysql">CREATE TABLE 表名 (列的信息) ROW_FORMAT=行格式名称
    
ALTER TABLE 表名 ROW_FORMAT=行格式名称
</code></pre>
<h4 id="421-compact行格式">4.2.1 COMPACT行格式</h4>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1672297832355.png" alt="" loading="lazy"></figure>
<p>一条完整的记录其实可以被分为记录的额外信息和记录的真实数据两大部分</p>
<p><strong>记录的额外信息</strong><br>
这部分信息是服务器为了描述这条记录而不得不额外添加的一些信息，这些额外信息分为3类，分别是变长字段长度列表、NULL值列表和记录头信息。</p>
<p><em>变长字段长度列表</em><br>
我们知道MySQL支持一些变长的数据类型，比如VARCHAR(M)、VARBINARY(M)、各种TEXT类型，各种BLOB类型，我们也可以把拥有这些数据类型的列称为变长字段，变长字段中存储多少字节的数据是不固定的，所以我们在存储真实数据的时候需要顺便把这些数据占用的字节数也存起来，这样才不至于把MySQL服务器搞懵，所以这些变长字段占用的存储空间分为两部分：</p>
<ol>
<li>真正的数据内容</li>
<li>占用的字节数</li>
</ol>
<p>在Compact行格式中，把所有变长字段的真实数据占用的字节长度都存放在记录的开头部位，从而形成一个变长字段长度列表，各变长字段数据占用的字节数<font color=red >按照列的顺序逆序存放</font>，我们再次强调一遍，是逆序存放！</p>
<p>如果该可变字段允许存储的最大字节数（M×W）超过255字节并且真实存储的字节数（L）超过127字节，则使用2个字节，否则使用1个字节。</p>
<p>另外需要注意的一点是，变长字段长度列表中只存储值为 非NULL 的列内容占用的长度，值为 NULL 的列的长度是不储存的 。</p>
<p><em>NULL值列表</em><br>
我们知道表中的某些列可能存储NULL值，如果把这些NULL值都放到记录的真实数据中存储会很占地方，所以Compact行格式把这些值为NULL的列统一管理起来，存储到NULL值列表中，它的处理过程是这样的：</p>
<ol>
<li>首先统计表中允许存储NULL的列有哪些。</li>
<li>如果表中没有允许存储 NULL 的列，则 NULL值列表也不存在了，否则将每个允许存储NULL的列对应一个二进制位，二进制位按照列的顺序<font color=red >逆序</font>排列，二进制位表示的意义如下：<br>
二进制位的值为1时，代表该列的值为NULL。<br>
二进制位的值为0时，代表该列的值不为NULL。</li>
<li>MySQL规定NULL值列表必须用整数个字节的位表示，如果使用的二进制位个数不是整数个字节，则在字节的高位补0。如果一个表中有9个允许为NULL，那这个记录的NULL值列表部分就需要2个字节来表示了。</li>
</ol>
<p><em>记录头信息</em><br>
除了变长字段长度列表、NULL值列表之外，还有一个用于描述记录的记录头信息，它是由固定的5个字节组成。5个字节也就是40个二进制位，不同的位代表不同的意思，如图：</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1672302498380.png" alt="" loading="lazy"></figure>
<table>
<thead>
<tr>
<th>名称</th>
<th>大小（单位：bit）</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>预留位1</td>
<td>1</td>
<td>没有使用</td>
</tr>
<tr>
<td>预留位2</td>
<td>1</td>
<td>没有使用</td>
</tr>
<tr>
<td>delete_mask</td>
<td>1</td>
<td>标记该记录是否被删除</td>
</tr>
<tr>
<td>min_rec_mask</td>
<td>1</td>
<td>B+树的每层非叶子节点中的最小记录都会添加该标记</td>
</tr>
<tr>
<td>n_owned</td>
<td>4</td>
<td>表示当前记录拥有的记录数</td>
</tr>
<tr>
<td>heap_no</td>
<td>13</td>
<td>表示当前记录在记录堆的位置信息</td>
</tr>
<tr>
<td>record_type</td>
<td>3</td>
<td>表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录</td>
</tr>
<tr>
<td>next_record</td>
<td>16</td>
<td>表示下一条记录的相对位置</td>
</tr>
</tbody>
</table>
<p><strong>记录的真实数据</strong><br>
记录的真实数据我们自己定义的列的数据以外，MySQL会为每个记录默认的添加一些列（也称为隐藏列），具体的列如下：</p>
<table>
<thead>
<tr>
<th>列名</th>
<th>是否必须</th>
<th>占用空间</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>row_id</td>
<td>否</td>
<td>6字节</td>
<td>行ID，唯一标识一条记录</td>
</tr>
<tr>
<td>transaction_id</td>
<td>是</td>
<td>6字节</td>
<td>事务ID</td>
</tr>
<tr>
<td>roll_pointer</td>
<td>是</td>
<td>7字节</td>
<td>回滚指针</td>
</tr>
</tbody>
</table>
<p>InnoDB表对主键的生成策略：优先使用用户自定义主键作为主键，如果用户没有定义主键，则选取一个Unique键作为主键，如果表中连Unique键都没有定义的话，则InnoDB会为表默认添加一个名为row_id的隐藏列作为主键。所以我们从上表中可以看出：InnoDB存储引擎会为每条记录都添加 transaction_id 和 roll_pointer 这两个列，但是 row_id 是可选的（在没有自定义主键以及Unique键的情况下才会添加该列）。</p>
<h5 id="charm列的存储格式">CHAR(M)列的存储格式</h5>
<p>对于 CHAR(M) 类型的列来说，当列采用的是定长字符集时，该列占用的字节数不会被加到变长字段长度列表，而如果采用变长字符集时，该列占用的字节数也会被加到变长字段长度列表。</p>
<p>另外有一点还需要注意，变长字符集的CHAR(M)类型的列要求至少占用M个字节，而VARCHAR(M)却没有这个要求。比方说对于使用utf8字符集的CHAR(10)的列来说，该列存储的数据字节长度的范围是10～30个字节。即使我们向该列中存储一个空字符串也会占用10个字节，这是怕将来更新该列的值的字节长度大于原有值的字节长度而小于10个字节时，可以在该记录处直接更新，而不是在存储空间中重新分配一个新的记录空间，导致原有的记录空间成为所谓的碎片。</p>
<h4 id="422-redundant行格式">4.2.2 Redundant行格式</h4>
<p>Redundant行格式是MySQL5.0之前用的一种行格式，也就是说它已经非常老了。<br>
<img src="https://q456qq520.github.io/post-images/1672304003648.png" alt="" loading="lazy"></p>
<h4 id="行溢出数据">行溢出数据</h4>
<h5 id="varcharm最多能存储的数据">VARCHAR(M)最多能存储的数据</h5>
<p>我们知道对于VARCHAR(M)类型的列最多可以占用65535个字节。其中的M代表该类型最多存储的字符数量，如果我们使用ascii字符集的话，一个字符就代表一个字节，这个65535个字节除了列本身的数据之外，还包括一些其他的数据（storage overhead），比如说我们为了存储一个VARCHAR(M)类型的列，其实需要占用3部分存储空间：</p>
<ol>
<li>真实数据</li>
<li>真实数据占用字节的长度</li>
<li>NULL值标识，如果该列有NOT NULL属性则可以没有这部分存储空间</li>
</ol>
<p>如果该VARCHAR类型的列没有NOT NULL属性，那最多只能存储65532个字节的数据，因为真实数据的长度可能占用2个字节，NULL值标识需要占用1个字节。<br>
如果VARCHAR类型的列有NOT NULL属性，那最多只能存储65533个字节的数据，因为真实数据的长度可能占用2个字节，不需要NULL值标识。</p>
<p>如果VARCHAR(M)类型的列使用的不是ascii字符集，那会怎么样呢？来看一下：</p>
<p>如果VARCHAR(M)类型的列使用的不是ascii字符集，那M的最大取值取决于该字符集表示一个字符最多需要的字节数。在列的值允许为NULL的情况下，gbk字符集表示一个字符最多需要2个字节，那在该字符集下，M的最大取值就是32766（也就是：65532/2），也就是说最多能存储32766个字符；utf8字符集表示一个字符最多需要3个字节，那在该字符集下，M的最大取值就是21844，就是说最多能存储21844（也就是：65532/3）个字符。</p>
<h5 id="记录中的数据太多产生的溢出">记录中的数据太多产生的溢出</h5>
<p>前面说过，MySQL中磁盘和内存交互的基本单位是页，也就是说MySQL是以页为基本单位来管理存储空间的，我们的记录都会被分配到某个页中存储。而一个页的大小一般是16KB，也就是16384字节，而一个VARCHAR(M)类型的列就最多可以存储65532个字节，这样就可能造成一个页存放不了一条记录的尴尬情况，被称为行溢出。</p>
<p>在Compact和Reduntant行格式中，对于占用存储空间非常大的列，在记录的真实数据处只会存储该列的一部分数据，把剩余的数据分散存储在几个其他的页中，然后记录的真实数据处用20个字节存储指向这些页的地址（当然这20个字节中还包括这些分散在其他页面中的数据的占用的字节数），从而可以找到剩余数据所在的页。</p>
<p>不只是VARCHAR(M)类型的列，其他的TEXT、<strong>BLOB</strong> 类型的列在存储数据非常多的时候也会发生行溢出。</p>
<h5 id="行溢出的临界点">行溢出的临界点</h5>
<p>MySQL中规定一个页中至少存放两行记录，如果一个列中存储的数据不大于8098个字节，那就不会发生行溢出，否则就会发生行溢出。不过这个8098个字节的结论只是针对只有一个列的表来说的，如果表中有多个列，那上面的式子和结论都需要改一改了，所以重点就是：你不用关注这个临界点是什么，只要知道如果我们向一个行中存储了很大的数据时，可能发生行溢出的现象。</p>
<h4 id="423-dynamic和compressed行格式">4.2.3 Dynamic和Compressed行格式</h4>
<p>Dynamic和Compressed行格式，我现在使用的MySQL版本是5.7，它的默认行格式就是Dynamic，这俩行格式和Compact行格式挺像，只不过在处理行溢出数据时有点儿分歧，它们不会在记录的真实数据处存储字段真实数据的前768个字节，而是把所有的字节都存储到其他页面中，只在记录的真实数据处存储其他页面的地址。</p>
<p>Compressed行格式和Dynamic不同的一点是，Compressed行格式会采用压缩算法对页面进行压缩，以节省空间。</p>
<h3 id="43-总结">4.3 总结</h3>
<ol>
<li>页是MySQL中磁盘和内存交互的基本单位，也是MySQL是管理存储空间的基本单位。</li>
<li>指定和修改行格式的语法如下：
<ol>
<li>CREATE TABLE 表名 (列的信息) ROW_FORMAT=行格式名称</li>
<li>ALTER TABLE 表名 ROW_FORMAT=行格式名称</li>
</ol>
</li>
<li>InnoDB目前定义了4种行格式
<ol>
<li>COMPACT行格式、Redundant行格式、Dynamic和Compressed行格式</li>
</ol>
</li>
<li>一个页一般是16KB，当记录中的数据太多，当前页放不下的时候，会把多余的数据存储到其他页中，这种现象称为行溢出。</li>
</ol>
<h2 id="第五章-盛放记录的大盒子-innodb数据页结构">第五章 盛放记录的大盒子-InnoDB数据页结构</h2>
<h3 id="51-不同类型的页简介">5.1 不同类型的页简介</h3>
<p>页的概念，它是InnoDB管理存储空间的基本单位，一个页的大小一般是16KB。InnoDB为了不同的目的而设计了许多种不同类型的页，比如存放表空间头部信息的页，存放Insert Buffer信息的页，存放INODE信息的页，存放undo日志信息的页等等。</p>
<p>我们聚焦的是那些存放我们表中记录的那种类型的页，官方称这种存放记录的页为索引（INDEX）页，而这些表中的记录就是我们日常口中所称的数据，所以目前还是叫这种存放记录的页为数据页吧。</p>
<h3 id="52-数据页结构的快速浏览">5.2 数据页结构的快速浏览</h3>
<p>数据页代表的这块16KB大小的存储空间可以被划分为多个部分，不同部分有不同的功能，各个部分如图所示：<br>
<img src="https://q456qq520.github.io/post-images/1672392812009.png" alt="" loading="lazy"></p>
<p>从图中可以看出，一个InnoDB数据页的存储空间大致被划分成了7个部分，有的部分占用的字节数是确定的，有的部分占用的字节数是不确定的。下面我们用表格的方式来大致描述一下这7个部分都存储一些什么内容：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>中文名</th>
<th>占用空间大小</th>
<th>简单描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>File Header</td>
<td>文件头部</td>
<td>38字节</td>
<td>页的一些通用信息</td>
</tr>
<tr>
<td>Page Header</td>
<td>页面头部</td>
<td>56字节</td>
<td>数据页专有的一些信息</td>
</tr>
<tr>
<td>Infimum + Supremum</td>
<td>最小记录和最大记录</td>
<td>26字节</td>
<td>两个虚拟的行记录</td>
</tr>
<tr>
<td>User Records</td>
<td>用户记录</td>
<td>不确定</td>
<td>实际存储的行记录内容</td>
</tr>
<tr>
<td>Free Space</td>
<td>空闲空间</td>
<td>不确定</td>
<td>页中尚未使用的空间</td>
</tr>
<tr>
<td>Page Directory</td>
<td>页面目录</td>
<td>不确定</td>
<td>页中的某些记录的相对位置</td>
</tr>
<tr>
<td>File Trailer</td>
<td>文件尾部</td>
<td>8字节</td>
<td>校验页是否完整</td>
</tr>
</tbody>
</table>
<h3 id="53-记录在页中的存储">5.3 记录在页中的存储</h3>
<p>在页的7个组成部分中，我们自己存储的记录会按照我们指定的行格式存储到User Records部分。但是在一开始生成页的时候，其实并没有User Records这个部分，每当我们插入一条记录，都会从Free Space部分，也就是尚未使用的存储空间中申请一个记录大小的空间划分到User Records部分，当Free Space部分的空间全部被User Records部分替代掉之后，也就意味着这个页使用完了，如果还有新的记录插入的话，就需要去申请新的页了。</p>
<h3 id="54-记录头信息的秘密">5.4 记录头信息的秘密</h3>
<p>首先创建一个表：</p>
<pre><code class="language-mysql">mysql&gt; CREATE TABLE page_demo(
    -&gt;     c1 INT,
    -&gt;     c2 INT,
    -&gt;     c3 VARCHAR(10000),
    -&gt;     PRIMARY KEY (c1)
    -&gt; ) CHARSET=ascii ROW_FORMAT=Compact;
Query OK, 0 rows affected (0.03 sec)
</code></pre>
<p>这个新创建的page_demo表有3个列，其中c1和c2列是用来存储整数的，c3列是用来存储字符串的。需要注意的是，我们把 c1 列指定为主键，所以在具体的行格式中InnoDB就没必要为我们去创建那个所谓的 row_id 隐藏列了。而且我们为这个表指定了ascii字符集以及Compact的行格式。所以这个表中记录的行格式示意图就是这样的：</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1672884076221.png" alt="" loading="lazy"></figure>
<p>从图中可以看到，我们特意把记录头信息的5个字节的数据给标出来了，说明它很重要，我们再次先把这些记录头信息中各个属性的大体意思浏览一下（我们目前使用Compact行格式进行演示）：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>大小（单位：bit）</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>预留位1</td>
<td>1</td>
<td>没有使用</td>
</tr>
<tr>
<td>预留位2</td>
<td>1</td>
<td>没有使用</td>
</tr>
<tr>
<td>delete_mask</td>
<td>1</td>
<td>标记该记录是否被删除</td>
</tr>
<tr>
<td>min_rec_mask</td>
<td>1</td>
<td>B+树的每层非叶子节点中的最小记录都会添加该标记</td>
</tr>
<tr>
<td>n_owned</td>
<td>4</td>
<td>表示当前记录拥有的记录数</td>
</tr>
<tr>
<td>heap_no</td>
<td>13</td>
<td>表示当前记录在记录堆的位置信息</td>
</tr>
<tr>
<td>record_type</td>
<td>3</td>
<td>表示当前记录的类型，0表示普通记录，1表示B+树非叶节点记录，2表示最小记录，3表示最大记录</td>
</tr>
<tr>
<td>next_record</td>
<td>16</td>
<td>表示下一条记录的相对位置</td>
</tr>
</tbody>
</table>
<p>下面我们试着向page_demo表中插入几条记录：</p>
<pre><code class="language-mysql">mysql&gt; INSERT INTO page_demo VALUES(1, 100, 'aaaa'), (2, 200, 'bbbb'), (3, 300, 'cccc'), (4, 400, 'dddd');
Query OK, 4 rows affected (0.00 sec)
Records: 4  Duplicates: 0  Warnings: 0
</code></pre>
<p>把记录中头信息和实际的列数据都用十进制表示出来了（其实是一堆二进制位），所以这些记录的示意图就是：<br>
<img src="https://q456qq520.github.io/post-images/1672884402896.png" alt="" loading="lazy"></p>
<p>看这个图的时候需要注意一下，各条记录在User Records中存储的时候并没有空隙，这里只是为了大家观看方便才把每条记录单独画在一行中。我们对照着这个图来看看记录头信息中的各个属性是什么意思：</p>
<ul>
<li>
<p><font color=red>delete_mask</font><br>
这个属性标记着当前记录是否被删除，占用1个二进制位，值为0的时候代表记录并没有被删除，为1的时候代表记录被删除掉了。</p>
<p>被删除的记录还在页中么？这些被删除的记录之所以不立即从磁盘上移除，是因为移除它们之后把其他的记录在磁盘上重新排列需要性能消耗，所以只是打一个删除标记而已，所有被删除掉的记录都会组成一个所谓的垃圾链表，在这个链表中的记录占用的空间称之为所谓的可重用空间，之后如果有新记录插入到表中的话，可能把这些被删除的记录占用的存储空间覆盖掉。</p>
<blockquote>
<p>⚠️将这个delete_mask位设置为1和将被删除的记录加入到垃圾链表中其实是两个阶段</p>
</blockquote>
</li>
<li>
<p><font color=red>min_rec_mask</font><br>
B+树的每层非叶子节点中的最小记录都会添加该标记，插入的四条记录的min_rec_mask值都是0，意味着它们都不是B+树的非叶子节点中的最小记录。</p>
</li>
<li>
<p><font color=red>n_owned</font></p>
</li>
<li>
<p><font color=red>heap_no</font><br>
这个属性表示当前记录在本页中的位置，从图中可以看出来，我们插入的4条记录在本页中的位置分别是：2、3、4、5。是不是少了点什么？是的，怎么不见heap_no值为0和1的记录呢？</p>
<p>这其实是设计InnoDB的大佬们玩的一个小把戏，他们自动给每个页里边儿加了两个记录，由于这两个记录并不是我们自己插入的，所以有时候也称为伪记录或者虚拟记录。这两个伪记录一个代表最小记录，一个代表最大记录，等一下~，记录可以比大小么？</p>
<p>是的，记录也可以比大小，对于一条<strong>完整的记录</strong>来说，比较记录的大小就是比较主键的大小。比方说我们插入的4行记录的主键值分别是：1、2、3、4，这也就意味着这4条记录的大小从小到大依次递增。</p>
<p>但是不管我们向页中插入了多少自己的记录，设计InnoDB的大佬们都规定他们定义的两条伪记录分别为最小记录与最大记录。这两条记录的构造十分简单，都是由5字节大小的记录头信息和8字节大小的一个固定的部分组成的，如图所示</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1672885704690.png" alt="" loading="lazy"></figure>
<p>由于这两条记录不是我们自己定义的记录，所以它们并不存放在页的User Records部分，他们被单独放在一个称为Infimum + Supremum的部分。</p>
<p>最小记录和最大记录的heap_no值分别是0和1，也就是说它们的位置最靠前。</p>
</li>
<li>
<p><font color=red>record_type</font><br>
这个属性表示当前记录的类型，一共有4种类型的记录，0表示普通记录，1表示B+树非叶节点记录，2表示最小记录，3表示最大记录。从图中我们也可以看出来，我们自己插入的记录就是普通记录，它们的record_type值都是0，而最小记录和最大记录的record_type值分别为2和3。</p>
</li>
<li>
<p><font color=red>next_record</font><br>
它表示<strong>从当前记录的真实数据到下一条记录的真实数据的地址偏移量</strong>。比方说第一条记录的next_record值为32，意味着从第一条记录的真实数据的地址处向后找32个字节便是下一条记录的真实数据。</p>
<p>但是需要注意注意再注意的一点是，下一条记录指得并不是按照我们插入顺序的下一条记录，而是按照主键值由小到大的顺序的下一条记录。而且规定 Infimum记录（也就是最小记录） 的下一条记录就是本页中主键值最小的用户记录，而本页中主键值最大的用户记录的下一条记录就是 Supremum记录（也就是最大记录）</p>
<p>我们的记录按照主键从小到大的顺序形成了一个单链表。最大记录的next_record的值为0，这也就是说最大记录是没有下一条记录了，它是这个单链表中的最后一个节点。如果从中删除掉一条记录，这个链表也是会跟着变化。</p>
<blockquote>
<p>⚠️小贴士：为什么要指向记录头信息和真实数据之间的位置呢？为什么不干脆指向整条记录的开头位置，也就是记录的额外信息开头的位置呢？因为这个位置刚刚好，向左读取就是记录头信息，向右读取就是真实数据。我们前面还说过变长字段长度列表、NULL值列表中的信息都是逆序存放，这样可以使记录中位置靠前的字段和它们对应的字段长度信息在内存中的距离更近，可能会提高高速缓存的命中率。</p>
</blockquote>
</li>
</ul>
<h3 id="55-page-directory页目录">5.5 Page Directory（页目录）</h3>
<p>我们平常想从一本书中查找某个内容的时候，一般会先看目录，找到需要查找的内容对应的书的页码，然后到对应的页码查看内容。InnoDB也制作了一个类似的目录，他们的制作过程是这样的：</p>
<ol>
<li>将所有正常的记录（包括最大和最小记录，不包括标记为已删除的记录）划分为几个组。</li>
<li>每个组的最后一条记录（也就是组内最大的那条记录）的头信息中的n_owned属性表示该记录拥有多少条记录，也就是该组内共有几条记录。</li>
<li>将每个组的最后一条记录的地址偏移量单独提取出来按顺序存储到靠近页的尾部的地方，这个地方就是所谓的Page Directory，也就是页目录（此时应该返回头看看页面各个部分的图）。页面目录中的这些地址偏移量被称为槽（英文名：Slot），所以这个页面目录就是由槽组成的。</li>
</ol>
<p>比方说现在的page_demo表中正常的记录共有6条，InnoDB会把它们分成两组，第一组中只有一个最小记录，第二组中是剩余的5条记录，看下面的示意图：</p>
<figure data-type="image" tabindex="6"><img src="https://q456qq520.github.io/post-images/1672887389345.png" alt="" loading="lazy"></figure>
<p>现在页目录部分中有两个槽，也就意味着我们的记录被分成了两个组，槽1中的值是112，代表最大记录的地址偏移量（就是从页面的0字节开始数，数112个字节）；槽0中的值是99，代表最小记录的地址偏移量。</p>
<p>注意最小和最大记录的头信息中的n_owned属性</p>
<pre><code>- 最小记录的n_owned值为1，这就代表着以最小记录结尾的这个分组中只有1条记录，也就是最小记录本身。
- 最大记录的n_owned值为5，这就代表着以最大记录结尾的这个分组中只有5条记录，包括最大记录本身还有我们自己插入的4条记录。
</code></pre>
<p>为什么最小记录的n_owned值为1，而最大记录的n_owned值为5呢？</p>
<p>是的，设计InnoDB的大佬们对每个分组中的记录条数是有规定的：<font color=red>对于最小记录所在的分组只能有 1 条记录，最大记录所在的分组拥有的记录条数只能在 1~8 条之间，剩下的分组中记录的条数范围只能在是 4~8 条之间</font>。所以分组是按照下面的步骤进行的：</p>
<ol>
<li>初始情况下一个数据页里只有最小记录和最大记录两条记录，它们分属于两个分组。</li>
<li>之后每插入一条记录，都会从页目录中找到主键值比本记录的主键值大并且差值最小的槽，然后把该槽对应的记录的n_owned值加1，表示本组内又添加了一条记录，直到该组中的记录数等于8个。</li>
<li>在一个组中的记录数等于8个后再插入一条记录时，会将组中的记录拆分成两个组，一个组中4条记录，另一个5条记录。这个过程会在页目录中新增一个槽来记录这个新增分组中最大的那条记录的偏移量。</li>
</ol>
<p>在一个数据页中查找指定主键值的记录的过程分为两步：</p>
<ol>
<li>通过二分法确定该记录所在的槽，并找到该槽中主键值最小的那条记录。</li>
<li>通过记录的next_record属性遍历该槽所在的组中的各个记录。</li>
</ol>
<h3 id="56-page-header页面头部">5.6 Page Header（页面头部）</h3>
<p>Page Header是页结构的第二部分，这个部分占用固定的56个字节，专门存储各种状态信息，具体各个字节都是干嘛的看下表：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>占用空间大小</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>PAGE_N_DIR_SLOTS</td>
<td>2字节</td>
<td></td>
</tr>
<tr>
<td>PAGE_HEAP_TOP</td>
<td>2字节</td>
<td>还未使用的空间最小地址，也就是说从该地址之后就是Free Space</td>
</tr>
<tr>
<td>PAGE_N_HEAP</td>
<td>2字节</td>
<td>本页中的记录的数量（包括最小和最大记录以及标记为删除的记录）</td>
</tr>
<tr>
<td>PAGE_FREE</td>
<td>2字节</td>
<td>第一个已经标记为删除的记录地址（各个已删除的记录通过next_record也会组成一个单链表，这个单链表中的记录可以被重新利用）</td>
</tr>
<tr>
<td>PAGE_GARBAGE</td>
<td>2字节</td>
<td>已删除记录占用的字节数</td>
</tr>
<tr>
<td>PAGE_LAST_INSERT</td>
<td>2字节</td>
<td>最后插入记录的位置</td>
</tr>
<tr>
<td>PAGE_DIRECTION</td>
<td>2字节</td>
<td>记录插入的方向</td>
</tr>
<tr>
<td>PAGE_N_DIRECTION</td>
<td>2字节</td>
<td>一个方向连续插入的记录数量</td>
</tr>
<tr>
<td>PAGE_N_RECS</td>
<td>2字节</td>
<td>该页中记录的数量（不包括最小和最大记录以及被标记为删除的记录）</td>
</tr>
<tr>
<td>PAGE_MAX_TRX_ID</td>
<td>8字节</td>
<td>修改当前页的最大事务ID，该值仅在二级索引中定义</td>
</tr>
<tr>
<td>PAGE_LEVEL</td>
<td>2字节</td>
<td>当前页在B+树中所处的层级</td>
</tr>
<tr>
<td>PAGE_INDEX_ID</td>
<td>8字节</td>
<td>索引ID，表示当前页属于哪个索引</td>
</tr>
<tr>
<td>PAGE_BTR_SEG_LEAF</td>
<td>10字节</td>
<td>B+树叶子段的头部信息，仅在B+树的Root页定义</td>
</tr>
<tr>
<td>PAGE_BTR_SEG_TOP</td>
<td>10字节</td>
<td>B+树非叶子段的头部信息，仅在B+树的Root页定义</td>
</tr>
</tbody>
</table>
<ul>
<li><font color=red>PAGE_DIRECTION</font><br>
假如新插入的一条记录的主键值比上一条记录的主键值大，我们说这条记录的插入方向是右边，反之则是左边。用来表示最后一条记录插入方向的状态就是PAGE_DIRECTION。</li>
<li><font color=red>PAGE_N_DIRECTION</font><br>
假设连续几次插入新记录的方向都是一致的，InnoDB会把沿着同一个方向插入记录的条数记下来，这个条数就用PAGE_N_DIRECTION这个状态表示。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。</li>
</ul>
<h3 id="57-file-header文件头部">5.7 File Header（文件头部）</h3>
<p>File Header针对各种类型的页都通用，也就是说不同类型的页都会以File Header作为第一个组成部分，它描述了一些针对各种页都通用的一些信息，比方说这个页的编号是多少，它的上一个页、下一个页是谁啦等等～ 这个部分占用固定的38个字节，是由下面这些内容组成的：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>占用空间大小</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>FIL_PAGE_SPACE_OR_CHKSUM</td>
<td>4字节</td>
<td>页的校验和（checksum值）</td>
</tr>
<tr>
<td>FIL_PAGE_OFFSET</td>
<td>4字节</td>
<td>页号</td>
</tr>
<tr>
<td>FIL_PAGE_PREV</td>
<td>4字节</td>
<td>上一个页的页号</td>
</tr>
<tr>
<td>FIL_PAGE_NEXT</td>
<td>4字节</td>
<td>下一个页的页号</td>
</tr>
<tr>
<td>FIL_PAGE_LSN</td>
<td>8字节</td>
<td>页面被最后修改时对应的日志序列位置（英文名是：Log Sequence Number）</td>
</tr>
<tr>
<td>FIL_PAGE_TYPE</td>
<td>2字节</td>
<td>该页的类型</td>
</tr>
<tr>
<td>FIL_PAGE_FILE_FLUSH_LSN</td>
<td>8字节</td>
<td>仅在系统表空间的一个页中定义，代表文件至少被刷新到了对应的LSN值</td>
</tr>
<tr>
<td>FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID</td>
<td>4字节</td>
<td>页属于哪个表空间</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p><font color=red>FIL_PAGE_SPACE_OR_CHKSUM</font><br>
这个代表当前页面的校验和（checksum）。什么是个校验和？就是对于一个很长很长的字节串来说，我们会通过某种算法来计算一个比较短的值来代表这个很长的字节串，这个比较短的值就称为校验和。这样在比较两个很长的字节串之前先比较这两个长字节串的校验和，如果校验和都不一样两个长字节串肯定是不同的，所以省去了直接比较两个比较长的字节串的时间损耗。</p>
</li>
<li>
<p><font color=red>FIL_PAGE_OFFSET</font><br>
每一个页都有一个单独的页号，就跟你的身份证号码一样，InnoDB通过页号来可以唯一定位一个页。</p>
</li>
<li>
<p><font color=red>FIL_PAGE_TYPE</font><br>
这个代表当前页的类型，InnoDB为了不同的目的而把页分为不同的类型</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>类型名称</th>
<th>十六进制</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>FIL_PAGE_TYPE_ALLOCATED</td>
<td>0x0000</td>
<td>最新分配，还没使用</td>
</tr>
<tr>
<td>FIL_PAGE_UNDO_LOG</td>
<td>0x0002</td>
<td>Undo日志页</td>
</tr>
<tr>
<td>FIL_PAGE_INODE</td>
<td>0x0003</td>
<td>段信息节点</td>
</tr>
<tr>
<td>FIL_PAGE_IBUF_FREE_LIST</td>
<td>0x0004</td>
<td>Insert Buffer空闲列表</td>
</tr>
<tr>
<td>FIL_PAGE_IBUF_BITMAP</td>
<td>0x0005</td>
<td>Insert Buffer位图</td>
</tr>
<tr>
<td>FIL_PAGE_TYPE_SYS</td>
<td>0x0006</td>
<td>系统页</td>
</tr>
<tr>
<td>FIL_PAGE_TYPE_TRX_SYS</td>
<td>0x0007</td>
<td>事务系统数据</td>
</tr>
<tr>
<td>FIL_PAGE_TYPE_FSP_HDR</td>
<td>0x0008</td>
<td>表空间头部信息</td>
</tr>
<tr>
<td>FIL_PAGE_TYPE_XDES</td>
<td>0x0009</td>
<td>扩展描述页</td>
</tr>
<tr>
<td>FIL_PAGE_TYPE_BLOB</td>
<td>0x000A</td>
<td>BLOB页</td>
</tr>
<tr>
<td>FIL_PAGE_INDEX</td>
<td>0x45BF</td>
<td>索引页，也就是我们所说的数据页</td>
</tr>
</tbody>
</table>
<ul>
<li><font color=red>FIL_PAGE_PREV和FIL_PAGE_NEXT</font><br>
InnoDB都是以页为单位存放数据的，有时候我们存放某种类型的数据占用的空间非常大（比方说一张表中可以有成千上万条记录），InnoDB可能不可以一次性为这么多数据分配一个非常大的存储空间，如果分散到多个不连续的页中存储的话需要把这些页关联起来，FIL_PAGE_PREV和FIL_PAGE_NEXT就分别代表本页的上一个和下一个页的页号。这样通过建立一个双向链表把许许多多的页就都串联起来了，而无需这些页在物理上真正连着。需要注意的是，并不是所有类型的页都有上一个和下一个页的属性。</li>
</ul>
<h3 id="57-file-trailer">5.7 File Trailer</h3>
<p>InnoDB存储引擎会把数据存储到磁盘上，但是磁盘速度太慢，需要以页为单位把数据加载到内存中处理，如果该页中的数据在内存中被修改了，那么在修改后的某个时间需要把数据同步到磁盘中。为了检测一个页是否完整（也就是在同步的时候有没有发生只同步一半的尴尬情况），InnoDB在每个页的尾部都加了一个File Trailer部分，这个部分由8个字节组成，可以分成2个小部分：</p>
<ul>
<li>前4个字节代表页的校验和<br>
这个部分是和File Header中的校验和相对应的。每当一个页面在内存中修改了，在同步之前就要把它的校验和算出来，因为File Header在页面的前面，所以校验和会被首先同步到磁盘，当完全写完时，校验和也会被写到页的尾部，如果完全同步成功，则页的首部和尾部的校验和应该是一致的。如果写了一半儿断电了，那么在File Header中的校验和就代表着已经修改过的页，而在File Trialer中的校验和代表着原先的页，二者不同则意味着同步中间出了错。</li>
<li>后4个字节代表页面被最后修改时对应的日志序列位置（LSN）</li>
</ul>
<h3 id="58-总结">5.8 总结</h3>
<ol>
<li>InnoDB为了不同的目的而设计了不同类型的页，我们把用于存放记录的页叫做数据页。</li>
<li>一个数据页可以被大致划分为7个部分，分别是<br>
File Header，表示页的一些通用信息，占固定的38字节。<br>
Page Header，表示数据页专有的一些信息，占固定的56个字节。<br>
Infimum + Supremum，两个虚拟的伪记录，分别表示页中的最小和最大记录，占固定的26个字节。<br>
User Records：真实存储我们插入的记录的部分，大小不固定。<br>
Free Space：页中尚未使用的部分，大小不确定。<br>
Page Directory：页中的某些记录相对位置，也就是各个槽在页面中的地址偏移量，大小不固定，插入的记录越多，这个部分占用的空间越多。<br>
File Trailer：用于检验页是否完整的部分，占用固定的8个字节。</li>
<li>每个记录的头信息中都有一个next_record属性，从而使页中的所有记录串联成一个单链表。</li>
<li>InnoDB会为把页中的记录划分为若干个组，每个组的最后一个记录的地址偏移量作为一个槽，存放在Page Directory中，所以在一个页中根据主键查找记录是非常快的，分为两步：
<ul>
<li>通过二分法确定该记录所在的槽。</li>
<li>通过记录的next_record属性遍历该槽所在的组中的各个记录。</li>
</ul>
</li>
<li>每个数据页的File Header部分都有上一个和下一个页的编号，所以所有的数据页会组成一个双链表。</li>
<li>为保证从内存中同步到磁盘的页的完整性，在页的首部和尾部都会存储页中数据的校验和和页面最后修改时对应的LSN值，如果首部和尾部的校验和和LSN值校验不成功的话，就说明同步过程出现了问题。</li>
</ol>
<p>链接:<a href="/post/lesslesscong-gen-er-shang-li-jie-mysqlgreatergreater-du-shu-bi-ji-er">《从根儿上理解MySQL》读书笔记(二)</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Netty权威指南(三)]]></title>
        <id>https://q456qq520.github.io/post/netty-quan-wei-zhi-nan-san/</id>
        <link href="https://q456qq520.github.io/post/netty-quan-wei-zhi-nan-san/">
        </link>
        <updated>2022-10-27T08:00:59.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="11-服务端创建">11 服务端创建</h2>
<h3 id="111-netty服务端创建源码分析">11.1 Netty服务端创建源码分析</h3>
]]></summary>
        <content type="html"><![CDATA[<h2 id="11-服务端创建">11 服务端创建</h2>
<h3 id="111-netty服务端创建源码分析">11.1 Netty服务端创建源码分析</h3>
<!-- more -->
<h4 id="1111-netty服务端创建时序图">11.1.1 Netty服务端创建时序图</h4>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1666860196968.png" alt="Netty服务端创建时序图" loading="lazy"></figure>
<ol>
<li>创建ServerBootstrap实例。ServerBootstrap是Netty服务端的启动辅助类，它提供了一系列的方法用于设置服务端启动相关参数。</li>
<li>设置并绑定Reactor线程池，Netty的Reactor线程池是EventLoopGroup它实际就是EventLoop的数组。EventLoop的职责就是处理所有注册到本线程多路复用器Selector上的Channel，Selector的轮询操作由绑定EventLoop线程run方法驱动，在一个循环体内循环执行。EventLoop的职责不仅仅是处理网络I/O事件，用户自定义的Task的定时任务Tak也统一由EventLoop负责处理，实现线程模型统一。</li>
<li>设置并绑定服务端Channel。作为NIO服务端需要创建ServerSocketChannel，Netty对原生的NIo类库进行了封装，对应实现是NioServerSocketChannel。</li>
</ol>
<pre><code class="language-java">public ServerBootstrap channel(Class&lt;? extends ServerChannel&gt; channelClass) {
    if (channelClass == null) {
        throw new NullPointerException(&quot;channelClass&quot;);
    } else {
        return this.channelFactory(new ServerBootstrap.ServerBootstrapChannelFactory(channelClass));
    }
}
</code></pre>
<ol start="4">
<li>链路建立的时候创建并初始化ChannelPipeline.ChannelPipeline并不是NIO服务端必须的，它本质就是一个负责处理网络事件的职责链，负责管理和执行ChannelHandler。网络事件以事件流的形式ChannelPipeline中流转，由ChannelPipeline根据ChannelHandler的执行策略调度ChannelHandler的执行。网络事件一般有：链路注册、链路激活、链路断开、接收请求、请求消息接收并处理完成、发送应答消息、链路异常、自定义事件。</li>
<li>初始化ChannelPipeline完成之后，添加并设置ChannelHandler。ChannelHandler是Netty提供给用户定制和扩展的关键接口。利用ChannelHandler用户可以完成大多数的功能定制。比如
<ol>
<li>系统编解码框架-BtyeToMessageCodec</li>
<li>通用基于长度的半包解码器-LengthFieldBasedFrameDecoder</li>
<li>码流日志打印-LoggingHandler</li>
<li>SSL安全认证-SslHandler</li>
<li>链路空闲检测-IdleStateHandler</li>
<li>流量整形-ChannelTrafficShapingHandler</li>
<li>Base64编解码-Base64Decoder和Base64Encoder</li>
</ol>
</li>
</ol>
<blockquote>
<p>创建和添加ChannelHandler代码示例</p>
</blockquote>
<pre><code class="language-java">.childHandler(new ChannelInitializer&lt;SocketChannel&gt;() {
    @Override
    public void initChannel(SocketChannel ch)
            throws IOException {
        ch.pipeline().addLast(
                new NettyMessageDecoder(1024 * 1024, 4, 4));
        ch.pipeline().addLast(new NettyMessageEncoder());
        ch.pipeline().addLast(&quot;readTimeoutHandler&quot;,
                new ReadTimeoutHandler(50));
        ch.pipeline().addLast(new LoginAuthRespHandler());
        ch.pipeline().addLast(&quot;HeartBeatHandler&quot;,
                new HeartBeatRespHandler());
    }
});
</code></pre>
<ol start="6">
<li>绑定并启动监听端口。在绑定监听端口之前系统会做一系列的初始化和检测工作，完成之后，会启动监听端口，并将ServerSocketChannel注册到Selector上监听客户端连接。</li>
</ol>
<pre><code class="language-java">private ChannelFuture doBind(final SocketAddress localAddress) {
    final ChannelFuture regFuture = this.initAndRegister();
    final Channel channel = regFuture.channel();
    if (regFuture.cause() != null) {
        return regFuture;
    } else {
        final Object promise;
        if (regFuture.isDone()) {
            promise = channel.newPromise();
            doBind0(regFuture, channel, localAddress, (ChannelPromise)promise);
        } else {
            promise = new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE);
            regFuture.addListener(new ChannelFutureListener() {
                public void operationComplete(ChannelFuture future) throws Exception {
                    AbstractBootstrap.doBind0(regFuture, channel, localAddress, (ChannelPromise)promise);
                }
            });
        }

        return (ChannelFuture)promise;
    }
}
</code></pre>
<ol start="7">
<li>Selector轮询。由Reactor线程NioeventLoop负责调度和执行Selector轮询操作，选择准备就绪到Channel集合。</li>
<li>当轮询到准备就绪的Channel之后，就由Reactor线程NioEventLoop执行ChannelPipeline的相应方法，最终调度并执行ChannelHandler。</li>
<li>执行Netty系统ChannelHandler和用户添加定制的ChannelHandler。ChannelPipeline根据网络事件类型，调度并执行ChannelHandler。</li>
</ol>
<pre><code class="language-java">public ChannelHandlerContext fireChannelRead(Object msg) {
    DefaultChannelHandlerContext next = this.findContextInbound(64);
    next.invoker.invokeChannelRead(next, msg);
    return this;
}
</code></pre>
<h4 id="1112-netty服务端创建源码分析">11.1.2 Netty服务端创建源码分析</h4>
<p>首先通过构造函数创建ServerBootstrap实例，随后，通常会创建两个EventLoopGroup。</p>
<pre><code class="language-java">EventLoopGroup bossGroup = new NioEventLoopGroup();
EventLoopGroup workerGroup = new NioEventLoopGroup();
</code></pre>
<p>NioEventLoopGroup实际就是Reactor线程池，负责调度和执行客户端的接入、网络读写事件的处理、用户自定义任务和定时任务的执行。通过ServerBootstrao的group方法将两个EventLoopGroup实例传入。</p>
<pre><code class="language-java">public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) {
    super.group(parentGroup);
    if (childGroup == null) {
        throw new NullPointerException(&quot;childGroup&quot;);
    } else if (this.childGroup != null) {
        throw new IllegalStateException(&quot;childGroup set already&quot;);
    } else {
        this.childGroup = childGroup;
        return this;
    }
}
</code></pre>
<p>其中父NioEventLoopGroup被传入了父</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Netty权威指南(二)]]></title>
        <id>https://q456qq520.github.io/post/netty-quan-wei-zhi-nan-er/</id>
        <link href="https://q456qq520.github.io/post/netty-quan-wei-zhi-nan-er/">
        </link>
        <updated>2022-10-19T03:18:46.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="6-编解码技术">6 编解码技术</h2>
<p>在Netty的NIO网络开发中，当进行远程跨进程服务调用时，需要把被传输当java对象编码为字节数组或者ByteBuffer对象，而当远程服务读取到BtyeBuffer对象或者字节数组时，需要将其解码为发送时的java对象。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="6-编解码技术">6 编解码技术</h2>
<p>在Netty的NIO网络开发中，当进行远程跨进程服务调用时，需要把被传输当java对象编码为字节数组或者ByteBuffer对象，而当远程服务读取到BtyeBuffer对象或者字节数组时，需要将其解码为发送时的java对象。</p>
<!-- more -->
<h3 id="61-java序列化的缺点">6.1 Java序列化的缺点</h3>
<ol>
<li>无法跨语言</li>
<li>序列化后的码流太大</li>
<li>序列化性能太低</li>
</ol>
<h3 id="62-主流编解码框架">6.2 主流编解码框架</h3>
<ol>
<li>Protobuf</li>
<li>Thrift</li>
</ol>
<h2 id="7-messagepack编解码">7 MessagePack编解码</h2>
<h3 id="71-messagepack优点">7.1 MessagePack优点</h3>
<ol>
<li>编解码高效</li>
<li>序列化后码流小</li>
<li>跨语言</li>
</ol>
<h3 id="72-messagepack-编解码器开发">7.2 MessagePack 编解码器开发</h3>
<h4 id="721-messagepack编码器开发">7.2.1 MessagePack编码器开发</h4>
<blockquote>
<p>MessagePack 编码器</p>
</blockquote>
<pre><code class="language-java">/**
 * MessagePack 编码器
 * @author likecat
 * @version 1.0
 * @date 2022/10/19 11:47
 */
public class MsgpackEncoder extends MessageToByteEncoder&lt;Object&gt; {
    @Override
    protected void encode(ChannelHandlerContext channelHandlerContext, Object o, ByteBuf byteBuf) throws Exception {

        MessagePack msgpack = new MessagePack();
        byte[] raw = msgpack.write(o);
        byteBuf.writeBytes(raw);
    }
}
</code></pre>
<h4 id="722-messagepack解码器开发">7.2.2 MessagePack解码器开发</h4>
<blockquote>
<p>MessagePack 解码器</p>
</blockquote>
<pre><code class="language-java">/**
 * MessagePack 解码器
 * @author likecat
 * @version 1.0
 * @date 2022/10/19 11:52
 */
public class MsgpackDecoder extends MessageToMessageDecoder&lt;ByteBuf&gt; {
    @Override
    protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf byteBuf, List&lt;Object&gt; list) throws Exception {

        //首先从数据包bytebuf中获取需要解码的字节数组，然后用MessagePack的read方法将其反序列化为object对象
        final byte[] array;
        final int length = byteBuf.readableBytes();
        array = new byte[length];

        byteBuf.getBytes(byteBuf.readerIndex(), array, 0, length);
        MessagePack messagePack = new MessagePack();

        list.add(messagePack.read(array));
    }
}
</code></pre>
<h4 id="723-运行">7.2.3 运行</h4>
<blockquote>
<p>服务端 -》EchoMsgServer</p>
</blockquote>
<pre><code class="language-java">public class EchoMsgServer {
    public void bind(int port) throws Exception {
        // 配置服务端的NIO线程组
        // 服务端接受客户端的连接
        NioEventLoopGroup bossGroup = new NioEventLoopGroup();
        // 进行SocketChannel的网络读写
        NioEventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap b = new ServerBootstrap();
            b.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class)
                    .option(ChannelOption.SO_BACKLOG, 100)
                    .handler(new LoggingHandler(LogLevel.INFO))
                    .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() {

                        @Override
                        protected void initChannel(SocketChannel ch) throws Exception {
                            ch.pipeline().addLast(&quot;frameDecoder&quot;,new LengthFieldBasedFrameDecoder(65535, 0, 2,0,2));
                            // 添加msgpack的编码和解码器
                            ch.pipeline().addLast(&quot;msgpack decoder&quot;,new MsgpackDecoder());
                            ch.pipeline().addLast(&quot;frameEncoder&quot;,new LengthFieldPrepender(2));
                            ch.pipeline().addLast(&quot;msgpack encoder&quot;,new MsgpackEncoder());
                            // 添加自定义的处理器
                            ch.pipeline().addLast(new EchoMsgServerHandler());

                        }
                    });

            // 绑定端口，同步等待成功
            ChannelFuture f = b.bind(port).sync();
            // 等待服务端监听端口关闭
            f.channel().closeFuture().sync();
        }catch(Exception e){
            e.printStackTrace();
        } finally {
            // 优雅退出，释放线程池资源
            bossGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        int port = 8080;
        if(args!=null &amp;&amp; args.length &gt; 0){
            try{
                port = Integer.valueOf(args[0]);
            }catch(NumberFormatException e){
                // 采用默认值
            }
        }
        new EchoMsgServer().bind(port);
    }
}
</code></pre>
<blockquote>
<p>服务端 -》EchoMsgServerHandler</p>
</blockquote>
<pre><code class="language-java">public class EchoMsgServerHandler extends ChannelInboundHandlerAdapter {

    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws UnsupportedEncodingException {
        System.out.println(&quot;server receive the msgpack message :&quot;+msg);
        ctx.writeAndFlush(msg);
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) {
        // Close the connection when an exception is raised.
        cause.printStackTrace();
        ctx.close();
    }
}
</code></pre>
<blockquote>
<p>客户端 -》EchoMsgClient</p>
</blockquote>
<pre><code class="language-java">public class EchoMsgClient {

    private final String host;
    private final int port;
    private final int sendNumber;

    public EchoMsgClient(String host, int port, int sendNumber) {
        this.host = host;
        this.port = port;
        this.sendNumber = sendNumber;
    }

    public void run() throws Exception {

        //配置nio线程组
        EventLoopGroup group = new NioEventLoopGroup();

        try{
            Bootstrap b = new Bootstrap();
            b.group(group).channel(NioSocketChannel.class)
                    .option(ChannelOption.TCP_NODELAY, true)
                    .option(ChannelOption.CONNECT_TIMEOUT_MILLIS,3000)
                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel socketChannel) throws Exception {
                            //为了处理半包消息，添加如下两个 Netty 内置的编解码器
                            //LengthFieldPrepender：前置长度域编码器——放在MsgpackEncoder编码器前面
                            //LengthFieldBasedFrameDecoder：长度域解码器——放在MsgpackDecoder解码器前面
                            socketChannel.pipeline().addLast(&quot;frameDecoder&quot;,new LengthFieldBasedFrameDecoder(65535, 0, 2,0,2));
                            // 添加msgpack的编码和解码器
                            socketChannel.pipeline().addLast(&quot;msgpack decoder&quot;,new MsgpackDecoder());
                            socketChannel.pipeline().addLast(&quot;frameEncoder&quot;,new LengthFieldPrepender(2));
                            socketChannel.pipeline().addLast(&quot;msgpack encoder&quot;,new MsgpackEncoder());
                            socketChannel.pipeline().addLast(new EchoMsgClientHandler(sendNumber));//接收消息
                        }
                    });

            //发起异步连接操作
            ChannelFuture f = b.connect(host, port).sync();
            //等待客户端链路关闭
            f.channel().closeFuture().sync();
            //优雅退出，释放NIO线程组
        }finally {
            group.shutdownGracefully();
        }


    }

    public static void main(String[] args) throws Exception {
        int port = 8080;

        if(args != null &amp;&amp; args.length &gt; 0){
            try {
                port = Integer.valueOf(args[0]);
            } catch (NumberFormatException e) {
                e.printStackTrace();
            }
        }
        new EchoMsgClient(&quot;127.0.0.1&quot;,port,10).run();
    }
}
</code></pre>
<blockquote>
<p>客户端 -》EchoMsgClientHandler</p>
</blockquote>
<pre><code class="language-java">public class EchoMsgClientHandler extends ChannelInboundHandlerAdapter {
    private final int sendNumber;

    public EchoMsgClientHandler(int sendNumber) {
        this.sendNumber = sendNumber;
    }

    @Override
    public void channelActive(ChannelHandlerContext ctx){
        UserInfo[] infos = UserInfo();
        for (UserInfo in:infos ) {
            ctx.writeAndFlush(in);
        }
        ctx.writeAndFlush(&quot;我是普通的字符串消息&quot; + Thread.currentThread().getName());
    }

    private UserInfo [] UserInfo(){
        UserInfo[] userInfos = new UserInfo[sendNumber];
        UserInfo userInfo = null;
        for (int i = 0; i &lt; sendNumber; i++) {
            userInfo = new UserInfo();
            userInfo.setAge(i);
            userInfo.setUserName(&quot;ABCDEFG ----&gt;&quot; + i);
            userInfos[i] = userInfo;
        }
        return userInfos;
    }
    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg){
        System.out.println(&quot;Client receive the msgpack message: [&quot; + msg + &quot;]&quot;);
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause){
        ctx.close();
    }

    @Override
    public void channelReadComplete(ChannelHandlerContext ctx){
        ctx.flush();
    }
}
</code></pre>
<h2 id="8-http多协议开发和应用">8 HTTP多协议开发和应用</h2>
<h3 id="81-netty-http服务端入门开发">8.1 Netty HTTP服务端入门开发</h3>
<p>基于NIO TCP协议栈开发的HTTP协议栈也是异步非阻塞的。</p>
<blockquote>
<p>文件服务器启动类</p>
</blockquote>
<pre><code class="language-java">public class HttpFileServer {

    private static final String DEFAULT_URL = &quot;/src/main/java/com/likecat/netty/&quot;;

    public void run(final int port, final String url) throws Exception {
        EventLoopGroup bossGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap b = new ServerBootstrap();
            b.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class)
                    .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel ch) throws Exception {
                            // 添加请求消息解码器
                            ch.pipeline().addLast(&quot;http-decoder&quot;, new HttpRequestDecoder());
                            //HttpObjectAggregator的作用 将多个消息转换为单一的FullHttpRequest或者FullHttpResponse
                            ch.pipeline().addLast(&quot;http-aggregator&quot;, new HttpObjectAggregator(65536));
                            // 添加响应解码器
                            ch.pipeline().addLast(&quot;http-encoder&quot;, new HttpResponseEncoder());
                            // 支持异步发送大的码流(大的文件传输),但不占用过多的内存，防止java内存溢出
                            ch.pipeline().addLast(&quot;http-chunked&quot;, new ChunkedWriteHandler());
                            // 添加自定义handler 处理文件服务器业务逻辑
                            ch.pipeline().addLast(&quot;fileServerHandler&quot;, new HttpFileServerHandler(url));
                        }
                    });
            ChannelFuture future = b.bind(&quot;127.0.0.1&quot;, port).sync();
            System.out.println(&quot;HTTP文件目录服务器启动，网址是 : &quot; + &quot;http://127.0.0.1:&quot; + port + url);
            future.channel().closeFuture().sync();
        } finally {
            bossGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        int port = 8080;
        if (args.length &gt; 0) {
            try {
                port = Integer.parseInt(args[0]);
            } catch (NumberFormatException e) {
                e.printStackTrace();
            }
        }
        String url = DEFAULT_URL;
        if (args.length &gt; 1)
            url = args[1];
        new HttpFileServer().run(port, url);
    }
}
</code></pre>
<blockquote>
<p>文件服务器处理类</p>
</blockquote>
<pre><code class="language-java">public class HttpFileServerHandler extends SimpleChannelInboundHandler&lt;FullHttpRequest&gt; {

    private final String url;

    public HttpFileServerHandler(String url) {
        this.url = url;
    }

    @Override
    public void messageReceived(ChannelHandlerContext ctx, FullHttpRequest request) throws Exception {
        // 解码失败 400
        if (!request.getDecoderResult().isSuccess()) {
            sendError(ctx, BAD_REQUEST);
            return;
        }
        // 只支持get方法
        if (request.getMethod() != GET) {
            sendError(ctx, METHOD_NOT_ALLOWED);
            return;
        }
        //
        final String uri = request.getUri();
        // 处理Uri地址
        final String path = sanitizeUri(uri);

        if (path == null) {
            sendError(ctx, FORBIDDEN);
            return;
        }
        File file = new File(path);
        // 如果文件不存在，或不可访问
        if (file.isHidden() || !file.exists()) {
            sendError(ctx, NOT_FOUND);
            return;
        }
        // 如果请求是文件夹
        if (file.isDirectory()) {
            // 请求以 '/'结尾，列出该文件夹下的所有内容
            if (uri.endsWith(&quot;/&quot;)) {
                sendListing(ctx, file);
            } else {
                // 否则自动补全'/' 然后再重定向访问
                sendRedirect(ctx, uri + '/');
            }
            return;
        }

        if (!file.isFile()) {
            sendError(ctx, FORBIDDEN);
            return;
        }
        RandomAccessFile randomAccessFile = null;
        try {
            randomAccessFile = new RandomAccessFile(file, &quot;r&quot;);// 以只读的方式打开文件
        } catch (FileNotFoundException fnfe) {
            sendError(ctx, NOT_FOUND);
            return;
        }
        long fileLength = randomAccessFile.length();
        // 创建一个默认的Http响应
        HttpResponse response = new DefaultHttpResponse(HTTP_1_1, OK);
        // 设置响应文件大小
        setContentLength(response, fileLength);
        // 设置 content Type
        setContentTypeHeader(response, file);
        // 设置 keep alive
        if (isKeepAlive(request)) {
            response.headers().set(CONNECTION, HttpHeaders.Values.KEEP_ALIVE);
        }
        ctx.write(response);
        ChannelFuture sendFileFuture;
        //通过Netty的ChunkedFile对象直接将文件写入发送到缓冲区中
        sendFileFuture = ctx.write(new ChunkedFile(randomAccessFile, 0, fileLength, 8192), ctx.newProgressivePromise());
        sendFileFuture.addListener(new ChannelProgressiveFutureListener() {
            @Override
            public void operationProgressed(ChannelProgressiveFuture future, long progress, long total) {
                if (total &lt; 0) { // total unknown
                    System.err.println(&quot;Transfer progress: &quot; + progress);
                } else {
                    System.err.println(&quot;Transfer progress: &quot; + progress + &quot; / &quot; + total);
                }
            }

            @Override
            public void operationComplete(ChannelProgressiveFuture future) throws Exception {
                System.out.println(&quot;Transfer complete.&quot;);
            }
        });
        ChannelFuture lastContentFuture = ctx.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT);
        //如果不支持keep-Alive，服务器端主动关闭请求
        if (!isKeepAlive(request)) {
            lastContentFuture.addListener(ChannelFutureListener.CLOSE);
        }
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        cause.printStackTrace();
        if (ctx.channel().isActive()) {
            sendError(ctx, INTERNAL_SERVER_ERROR);
        }
    }

    private static final Pattern INSECURE_URI = Pattern.compile(&quot;.*[&lt;&gt;&amp;\&quot;].*&quot;);

    /**
     * 格式化uri并且获取路径
     * @param uri
     * @return
     */
    private String sanitizeUri(String uri) {
        try {
            uri = URLDecoder.decode(uri, &quot;UTF-8&quot;);
        } catch (UnsupportedEncodingException e) {
            try {
                uri = URLDecoder.decode(uri, &quot;ISO-8859-1&quot;);
            } catch (UnsupportedEncodingException e1) {
                throw new Error();
            }
        }
        if (!uri.startsWith(url)) {
            return null;
        }
        if (!uri.startsWith(&quot;/&quot;)) {
            return null;
        }
        uri = uri.replace('/', File.separatorChar);
        if (uri.contains(File.separator + '.') || uri.contains('.' + File.separator) || uri.startsWith(&quot;.&quot;)
                || uri.endsWith(&quot;.&quot;) || INSECURE_URI.matcher(uri).matches()) {
            return null;
        }
        return System.getProperty(&quot;user.dir&quot;) + File.separator + uri;
    }

    private static final Pattern ALLOWED_FILE_NAME = Pattern.compile(&quot;[A-Za-z0-9][-_A-Za-z0-9\\.]*&quot;);

    private static void sendListing(ChannelHandlerContext ctx, File dir) {
        FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, OK);
        response.headers().set(CONTENT_TYPE, &quot;text/html; charset=UTF-8&quot;);
        StringBuilder buf = new StringBuilder();
        String dirPath = dir.getPath();
        buf.append(&quot;&lt;!DOCTYPE html&gt;\r\n&quot;);
        buf.append(&quot;&lt;html&gt;&lt;head&gt;&lt;title&gt;&quot;);
        buf.append(dirPath);
        buf.append(&quot; 目录：&quot;);
        buf.append(&quot;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;\r\n&quot;);
        buf.append(&quot;&lt;h3&gt;&quot;);
        buf.append(dirPath).append(&quot; 目录：&quot;);
        buf.append(&quot;&lt;/h3&gt;\r\n&quot;);
        buf.append(&quot;&lt;ul&gt;&quot;);
        buf.append(&quot;&lt;li&gt;链接：&lt;a href=\&quot;../\&quot;&gt;..&lt;/a&gt;&lt;/li&gt;\r\n&quot;);
        for (File f : dir.listFiles()) {
            if (f.isHidden() || !f.canRead()) {
                continue;
            }
            String name = f.getName();
            if (!ALLOWED_FILE_NAME.matcher(name).matches()) {
                continue;
            }
            buf.append(&quot;&lt;li&gt;链接：&lt;a href=\&quot;&quot;);
            buf.append(name);
            buf.append(&quot;\&quot;&gt;&quot;);
            buf.append(name);
            buf.append(&quot;&lt;/a&gt;&lt;/li&gt;\r\n&quot;);
        }
        buf.append(&quot;&lt;/ul&gt;&lt;/body&gt;&lt;/html&gt;\r\n&quot;);
        ByteBuf buffer = Unpooled.copiedBuffer(buf, CharsetUtil.UTF_8);
        response.content().writeBytes(buffer);
        buffer.release();
        ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
    }

    private static void sendRedirect(ChannelHandlerContext ctx, String newUri) {
        FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, FOUND);
        response.headers().set(LOCATION, newUri);
        ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
    }

    private static void sendError(ChannelHandlerContext ctx, HttpResponseStatus status) {
        FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, status,
                Unpooled.copiedBuffer(&quot;Failure: &quot; + status.toString() + &quot;\r\n&quot;, CharsetUtil.UTF_8));
        response.headers().set(CONTENT_TYPE, &quot;text/plain; charset=UTF-8&quot;);
        ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
    }

    private static void setContentTypeHeader(HttpResponse response, File file) {
        MimetypesFileTypeMap mimeTypesMap = new MimetypesFileTypeMap();
        response.headers().set(CONTENT_TYPE, mimeTypesMap.getContentType(file.getPath()));
    }
}
</code></pre>
<h3 id="82-netty-http-xml-协议栈开发">8.2 Netty HTTP + XML 协议栈开发</h3>
<p>自行百度 or 谷歌</p>
<h2 id="9-websocket协议开发">9 WebSocket协议开发</h2>
<h3 id="91-http协议的弊端">9.1 HTTP协议的弊端</h3>
<ol>
<li>HTTP协议为半双工协议，这就意味着在同一时刻，数据不能同时传输，只能有一个方向的数据传送。</li>
<li>HTTP消息冗长而繁琐。</li>
<li>安全性低。</li>
</ol>
<h3 id="92-websocket入门">9.2 WebSocket入门</h3>
<p>WebSocket是一种全双工通信协议，浏览器于服务器只需要做一个握手动作 ，就能形成一条快速通道，双方就能互相传送数据。WebSocket基于TCP双向全双工进行消息传递。在同一时刻既可以发送消息，也能接收消息。</p>
<p>WebSocket的特点：</p>
<ul>
<li>单一的TCP连接，采用全双工模式通信。</li>
<li>对代理、防火墙和路由器透明</li>
<li>无头部信息、Cookie和身份验证</li>
<li>无安全开销</li>
<li>服务器可以主动传递消息给客户端，无需客户端轮询</li>
<li>通过“ping/pong”帧保持链路激活</li>
</ul>
<h4 id="921-websocket连接建立">9.2.1 WebSocket连接建立</h4>
<p>建立WebSocket连接时，需要通过客户端或者浏览器发出握手请求，和互动首先要向服务器发出一个HTTP请求，这个请求和通常的HTTP请求不同，包含了一些附加头信息，其中附加头信息“Upgrade:WebSocket”表明这是一个申请协议升级的HTTP请求。服务端解析附加头信息，然后生成应答信息返回客户端，双方的连接就建立了，这个连接会持续存在知道客户端或者服务器的某一方主动关闭连接。</p>
<h4 id="922-websocket生命周期">9.2.2 WebSocket生命周期</h4>
<p>握手成功之后，服务端和客户端就可以通过“messages”的方式进行通信了，一个消息由一个或者多个帧组成，WebSocket的消息并不一定对应一个特定网络层的帧，它可以被分割成多个帧或者被合并。</p>
<p>帧都有自己对应的类型，属于同一个消息的多个帧具有相同类型的数据。数据类型可以是文本数据、二进制数据和控制帧。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1666231566945.png" alt="" loading="lazy"></figure>
<h4 id="923-websocket连接关闭">9.2.3 WebSocket连接关闭</h4>
<p>为关闭WebSocket连接，客户端和服务端需要通过一个安全的方法关闭底层TCP连接已经TLS会话，丢弃任何可能已经接收的字节，必要时可以通过任何可用的手段关闭连接。</p>
<p>底层的TCP连接在正常情况下应该首先由服务器关闭。再一次情况下客户端可以发起TCP Close。因此当服务器被指示关闭WebSocket连接时，它应该立即发起一个TCP Close操作，客户端应该等待服务器的TCP Close。</p>
<p>WebSocket的握手关闭消息带有一个状态码和一个可选的关闭原因，它必须按照协议要求发送一个Close控制帧，当对端接收到关闭控制帧指令时，需要主动关闭WebSocket连接。</p>
<h3 id="93-netty-websocket协议开发">9.3 Netty WebSocket协议开发</h3>
<h4 id="931-websocket服务端">9.3.1 WebSocket服务端</h4>
<p>WebSocket服务端接收到请求消息之后，先对消息的类型进行盘判断，如果不是WebSocket握手请求消息，则返回400状态码给客户端。服务端对握手请求消息进行处理，构造握手响应返回，双方的socket连接正式建立。连接建立成功后，到被关闭之前，双方都可以主动向对方发送消息。</p>
<blockquote>
<p>WebSocketServer</p>
</blockquote>
<pre><code>public class WebSocketServer {

    public void run(int port)throws Exception{
        EventLoopGroup bossGroup=new NioEventLoopGroup();
        EventLoopGroup workerGroup=new NioEventLoopGroup();
        try
        {
            ServerBootstrap b=new ServerBootstrap();
            b.group(bossGroup, workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .childHandler(new ChannelInitializer&lt;SocketChannel&gt;()
                    {

                        @Override
                        protected void initChannel(SocketChannel ch)
                                throws Exception
                        {
                            ChannelPipeline pipeline=ch.pipeline();
                            //将请求和应答消息编码或解码为HTTP消息
                            pipeline.addLast(&quot;http-codec&quot;,new HttpServerCodec());
                            //将HTTP消息的多个部分组合成一条完整的HTTP消息
                            pipeline.addLast(&quot;aggregator&quot;,new HttpObjectAggregator(65536));
                            //向客户端发送HTML5文件，主要用于支持浏览器和服务端进行WebSocket通信
                            pipeline.addLast(&quot;http-chunked&quot;,new ChunkedWriteHandler());
                            pipeline.addLast(&quot;handler&quot;,new WebSocketServerHandler());
                        }

                    });
            Channel f=b.bind(port).sync().channel();
            System.out.println(&quot;Web socket server started at port &quot;+port+&quot;.&quot;);
            System.out.println(&quot;Open your browser and navigate to http://localhost:&quot;+port+&quot;/&quot;);
            f.closeFuture().sync();
        }
        catch (Exception e)
        {
            e.printStackTrace();
        }
        finally{
            bossGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args)throws Exception
    {
        int port =8080;
        try
        {
            if (args!=null&amp;&amp;args.length&gt;0)
            {
                port=Integer.valueOf(args[0]);
            }
        }
        catch (Exception e)
        {
            e.printStackTrace();
        }

        new WebSocketServer().run(port);
    }
}
</code></pre>
<blockquote>
<p>WebSocketServerHandler</p>
</blockquote>
<pre><code>public class WebSocketServerHandler extends SimpleChannelInboundHandler&lt;Object&gt;
{
    private static final Logger logger=Logger.getLogger(WebSocketServerHandler.class.getName());
    private WebSocketServerHandshaker handshaker;

    @Override
    protected void messageReceived(ChannelHandlerContext ctx, Object msg)
            throws Exception
    {
        //判断请求是HTTP请求还是WebSocket请求
        if (msg instanceof FullHttpRequest)
        {
            //处理WebSocket握手请求
            handleHttpRequest(ctx, (FullHttpRequest)msg);
        }else if (msg instanceof WebSocketFrame) {
            //处理WebSocket请求
            handleWebSocketFrame(ctx, (WebSocketFrame)msg);
        }
    }

    @Override
    public void channelReadComplete(ChannelHandlerContext ctx)throws Exception{
        ctx.flush();
    }

    private void handleHttpRequest(ChannelHandlerContext ctx,FullHttpRequest req)throws Exception{
        //先判断解码是否成功，然后判断是不是请求建立WebSocket连接
        //如果HTTP解码失败，返回HTTP异常
        if(!req.getDecoderResult().isSuccess()
                ||(!&quot;websocket&quot;.equals(req.headers().get(&quot;Upgrade&quot;)))){
            sendHttpResponse(ctx,req,new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.BAD_REQUEST));
        }
        //构造握手工厂创建握手处理类 WebSocketServerHandshaker，来构造握手响应返回给客户端
        WebSocketServerHandshakerFactory wsFactory=new WebSocketServerHandshakerFactory(&quot;ws://localhost:8080/websocket&quot;, null, false);
        handshaker=wsFactory.newHandshaker(req);
        if(handshaker==null){
            WebSocketServerHandshakerFactory.sendUnsupportedWebSocketVersionResponse(ctx.channel());
        }else {
            handshaker.handshake(ctx.channel(), req);
        }
    }

    //如果接收到的消息是已经解码的WebSocketFrame消息
    public void handleWebSocketFrame(ChannelHandlerContext ctx,WebSocketFrame frame)throws Exception{
        //先对控制帧进行判断
        //判断是否是关闭链路的指令
        if (frame instanceof CloseWebSocketFrame)
        {
            handshaker.close(ctx.channel(), (CloseWebSocketFrame)frame.retain());
            return;
        }
        //判断是否是维持链路的Ping消息
        if (frame instanceof PingWebSocketFrame)
        {
            ctx.channel().write(new PongWebSocketFrame(frame.content().retain()));
            return;
        }
        //本例程仅支持文本消息，不支持二进制消息
        if (!(frame instanceof TextWebSocketFrame))
        {
            throw new UnsupportedOperationException(String.format(&quot;%s frame type not supported&quot;, frame.getClass().getName()));
        }
        //返回应答消息
        String request=((TextWebSocketFrame)frame).text();
        if(logger.isLoggable(java.util.logging.Level.FINE)){
            logger.fine(String.format(&quot;%s received %s&quot;, ctx.channel(),request));
        }
        ctx.channel().write(new TextWebSocketFrame(request+&quot; , 欢迎使用Netty WebSocket服务，现在时刻：&quot;+new Date().toString()));
    }

    private void sendHttpResponse(ChannelHandlerContext ctx,FullHttpRequest req,FullHttpResponse resp){
        if(resp.getStatus().code()!=200){
            ByteBuf buf=Unpooled.copiedBuffer(resp.getStatus().toString(),CharsetUtil.UTF_8);
            resp.content().writeBytes(buf);
            buf.release();
            setContentLength(resp,resp.content().readableBytes());
        }
        ChannelFuture f=ctx.channel().writeAndFlush(resp);
        if(!isKeepAlive(resp)||resp.getStatus().code()!=200){
            f.addListener(ChannelFutureListener.CLOSE);
        }
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause)throws Exception{
        cause.printStackTrace();
        ctx.close();
    }
}
</code></pre>
<blockquote>
<p>客户端</p>
</blockquote>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Netty WebSocket时间服务器&lt;/title&gt;
    &lt;meta name=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;
  &lt;/head&gt;
  &lt;br&gt;
  &lt;body&gt;
    &lt;br&gt;
    &lt;script type=&quot;text/javascript&quot;&gt;
    	var socket;
    	if(!window.WebSocket){
    		window.WebSocket=window.MozWebSocket;
    	}
    	if(window.WebSocket){
    		socket=new WebSocket(&quot;ws://localhost:8080/webSocket&quot;);
    		socket.onmessage=function(event){
    			var ta=document.getElementById('responseText');
    			ta.value=&quot;&quot;;
    			ta.value=event.data;
    		};
    		socket.onopen=function(event){
    			var ta=document.getElementById('responseText');
    			ta.value='打开WebSocket服务器正常，浏览器支持WebSocket！';
    		};
    		socket.onclose=function(event){
    			var ta=document.getElementById('responseText');
    			ta.value='';
    			ta.value=&quot;WebSocket 关闭！&quot;;
    		};
    	}else{
    		alert(&quot;抱歉，您的浏览器不支持WebSocket协议！&quot;);
    	}
    	function send(message){
    		if(!window.WebSocket){
    			return;
    		}
    		if(socket!=null){
    			socket.send(message);
    		}else{
    			alert(&quot;WebSocket连接没有建立成功，请刷新页面！&quot;);
    		}
    		/* if(socket.readyState==WebSocket.open){
    			socket.send(message);
    		}else{
    			alert(&quot;WebSocket连接没有建立成功！&quot;);
    		} */
    	}
    &lt;/script&gt;
    &lt;form onsubmit=&quot;return false;&quot;&gt;
		&lt;input type=&quot;text&quot; name=&quot;message&quot; value=&quot;Netty最佳实践&quot;/&gt;
		&lt;br&gt;&lt;br&gt;
			&lt;input type=&quot;button&quot; value=&quot;发送WebSocket请求消息&quot; onclick=&quot;send(this.form.message.value)&quot;/&gt;
			&lt;hr color=&quot;blue&quot;/&gt;
			&lt;h3&gt;服务端返回的应答消息&lt;/h3&gt;
			&lt;textarea id=&quot;responseText&quot; style=&quot;width:500px;height:300px;&quot;&gt;&lt;/textarea&gt;
	&lt;/form&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h2 id="10-私有协议栈开发">10 私有协议栈开发</h2>
<p>广义上，通信协议可以分为公有协议和私有协议。由于私有协议的灵活性，它往往使用起来更加便利。绝大多数私有协议传输层有基于TCP/IP，所以利用Netty的NIO TCP协议栈可以非常方便的进行私有协议的定制和开发。</p>
<h3 id="101-私有协议介绍">10.1 私有协议介绍</h3>
<p>私有协议具有封闭性、垄断性、排他性等特点。私有协议并没有标准的定义，只要是能够用于跨进程、跨主机数据交换的非标准协议，都可以称为私有协议。</p>
<h3 id="102-netty协议栈功能设计">10.2 Netty协议栈功能设计</h3>
<p>Netty协议栈用于内部各模块之间的通信，它基于TCP/IP协议栈，是一个类HTTP协议的应用层协议栈。</p>
<h4 id="1021-网络拓扑图">10.2.1 网络拓扑图</h4>
<p>在分布式环境下，每个Netty节点之间建立长连接，使用Netty协议进行通信。Netty节点并没有服务端和客户端的区分，谁首先发起连接，谁就作为客户端，另一方自然就成为服务端。一个Netty节点既可以作为客户端连接另外的Netty节点，也可以作为Netty服务端被其他Netty节点连接。</p>
<h4 id="1022-协议栈功能描述">10.2.2 协议栈功能描述</h4>
<ol>
<li>基于Netty的NIO通信框架，提供高性能的异步通信能力</li>
<li>提供消息的编解码框架，可以实现POJO的序列化和反序列化</li>
<li>提供基于IP地址的白名单接入认证机制</li>
<li>链路的有效性校验机制</li>
<li>链路的断连重联机制</li>
</ol>
<h4 id="1023-通信模型">10.2.3 通信模型</h4>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1666748292421.png" alt="" loading="lazy"></figure>
<ol>
<li>Netty协议栈客户端发送握手请求消息，携带节点ID等有效身份认证信息</li>
<li>Netty协议栈服务端对握手消息进行合法性校验，包括节点ID有效性校验、节点重复登陆校验、IP地址合法性校验，校验通过后，返回登陆成功的握手应答消息</li>
<li>链路建立成功之后客户端发送业务消息</li>
<li>服务端发送心跳消息</li>
<li>客户端发送心跳消息</li>
<li>服务端发送业务消息</li>
<li>服务端退出时，服务端关闭连接，客户端感知对方关闭连接，被动关闭客户端连接</li>
</ol>
<p>⚠️双方之间的心跳采用PING-PONG机制，当链路处于空闲状态时，客户端主动发送ping消息给服务端，服务端接收到ping消息后发送应答消息pong给客户端，如果客户端连续发送n条ping消息都没有收到服务端返回都pong消息，说明链路已经挂死或者对方处于异常状态，客户端主动关闭连接，间隔周期T后发起重连操作，直到重连成功。</p>
<h4 id="1024-消息定义">10.2.4 消息定义</h4>
<p>Netty协议栈消息定义包含两部分：消息头，消息体。</p>
<blockquote>
<p>消息定义</p>
</blockquote>
<table>
<thead>
<tr>
<th>名称</th>
<th style="text-align:center">类型</th>
<th style="text-align:center">长度</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>header</td>
<td style="text-align:center">Header</td>
<td style="text-align:center">变长</td>
<td style="text-align:center">消息头定义</td>
</tr>
<tr>
<td>body</td>
<td style="text-align:center">Object</td>
<td style="text-align:center">变长</td>
<td style="text-align:center">请求消息</td>
</tr>
</tbody>
</table>
<blockquote>
<p>消息头定义</p>
</blockquote>
<table>
<thead>
<tr>
<th>名称</th>
<th style="text-align:center">类型</th>
<th style="text-align:center">长度</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>crcCode</td>
<td style="text-align:center">int</td>
<td style="text-align:center">32</td>
<td style="text-align:center">0xABEF（2个字节） + 主版本号（1~255 1个字节） + 次版本号(1~255 1个字节)</td>
</tr>
<tr>
<td>length</td>
<td style="text-align:center">int</td>
<td style="text-align:center">32</td>
<td style="text-align:center">消息长度</td>
</tr>
<tr>
<td>sessionID</td>
<td style="text-align:center">long</td>
<td style="text-align:center">64</td>
<td style="text-align:center">集群节点内全局唯一</td>
</tr>
<tr>
<td>type</td>
<td style="text-align:center">byte</td>
<td style="text-align:center">8</td>
<td style="text-align:center">类型枚举</td>
</tr>
<tr>
<td>priority</td>
<td style="text-align:center">byte</td>
<td style="text-align:center">8</td>
<td style="text-align:center">消息优先级</td>
</tr>
<tr>
<td>attachment</td>
<td style="text-align:center">Map&lt;String,Object&gt;</td>
<td style="text-align:center">变长</td>
<td style="text-align:center">可选字段</td>
</tr>
</tbody>
</table>
<p>⚠️其中type分别为<br>
0:业务请求消息<br>
1:业务响应消息<br>
2:业务ONE WAY消息<br>
3:握手请求消息<br>
4:握手应答消息<br>
5:心跳请求消息<br>
6:心跳应答消息</p>
<h3 id="103-netty协议栈开发">10.3 Netty协议栈开发</h3>
<h4 id="1031-数据接口定义">10.3.1 数据接口定义</h4>
<p>首先对Netty协议栈使用到的数据结构进行定义。</p>
<blockquote>
<p>NettyMessage</p>
</blockquote>
<pre><code class="language-java">/**
 * 消息
 * @author likecat
 * @version 1.0
 * @date 2022/10/26 10:27
 */
public final class NettyMessage {

    private Header header;

    private Object body;

    public Header getHeader() {
        return header;
    }

    public void setHeader(Header header) {
        this.header = header;
    }

    public Object getBody() {
        return body;
    }

    public void setBody(Object body) {
        this.body = body;
    }

    @Override
    public String toString() {
        return &quot;NettyMessage{&quot; +
                &quot;header=&quot; + header +
                '}';
    }
}
</code></pre>
<blockquote>
<p>消息头Header</p>
</blockquote>
<pre><code class="language-java">/**
 * 消息头
 * @author likecat
 * @version 1.0
 * @date 2022/10/26 11:35
 */
public class Header {
    private int crcCode = 0xabef0101;

    private int length;

    private long sessionID;

    private byte type;

    private byte priority;

    private Map&lt;String, Object&gt; attachment = new HashMap&lt;&gt;();

    public int getCrcCode() {
        return crcCode;
    }

    public void setCrcCode(int crcCode) {
        this.crcCode = crcCode;
    }

    public int getLength() {
        return length;
    }

    public void setLength(int length) {
        this.length = length;
    }

    public long getSessionID() {
        return sessionID;
    }

    public void setSessionID(long sessionID) {
        this.sessionID = sessionID;
    }

    public byte getType() {
        return type;
    }

    public void setType(byte type) {
        this.type = type;
    }

    public byte getPriority() {
        return priority;
    }

    public void setPriority(byte priority) {
        this.priority = priority;
    }

    public Map&lt;String, Object&gt; getAttachment() {
        return attachment;
    }

    public void setAttachment(Map&lt;String, Object&gt; attachment) {
        this.attachment = attachment;
    }

    @Override
    public String toString() {
        return &quot;Header{&quot; +
                &quot;crcCode=&quot; + crcCode +
                &quot;, length=&quot; + length +
                &quot;, sessionID=&quot; + sessionID +
                &quot;, type=&quot; + type +
                &quot;, priority=&quot; + priority +
                &quot;, attachment=&quot; + attachment +
                '}';
    }
}
</code></pre>
<p>由于心跳消息、握手请求和握手应答消息都可以统一由NettyMessage承载，所以不需要单独做数据定义。</p>
<h4 id="1032-消息编解码">10.3.2 消息编解码</h4>
<p>分别定义NettyMessageDecoder和NettyMessage用于NettyMessage消息的编解码。</p>
<blockquote>
<p>消息编码类</p>
</blockquote>
<pre><code class="language-java">/**
 * 消息编码
 * @author likecat
 * @version 1.0
 * @date 2022/10/26 11:38
 */
public class NettyMessageEncoder extends MessageToByteEncoder&lt;NettyMessage&gt; {
    MarshallingEncoder marshallingEncoder;

    public NettyMessageEncoder() throws IOException {
        this.marshallingEncoder = new MarshallingEncoder();
    }

    @Override
    protected void encode(ChannelHandlerContext channelHandlerContext, NettyMessage msg, List&lt;Object&gt; out) throws Exception {
        if(msg == null || msg.getHeader() == null){
            throw new Exception(&quot;The encode message is null&quot;);
        }
        ByteBuf sendBuf = Unpooled.buffer();
        sendBuf.writeInt(msg.getHeader().getCrcCode());
        sendBuf.writeInt(msg.getHeader().getLength());
        sendBuf.writeLong(msg.getHeader().getSessionID());
        sendBuf.writeByte(msg.getHeader().getType());
        sendBuf.writeByte(msg.getHeader().getPriority());
        sendBuf.writeInt(msg.getHeader().getAttachment().size());

        String key = null;
        byte[] keyArray = null;
        Object value = null;
        for (Map.Entry&lt;String,Object&gt; param:msg.getHeader().getAttachment().entrySet()) {
            key = param.getKey();
            keyArray = key.getBytes(StandardCharsets.UTF_8);
            sendBuf.writeBytes(keyArray);

            value = param.getValue();
            marshallingEncoder.encode(value, sendBuf);
        }

        key = null;
        keyArray = null;
        value = null;

        if(msg.getBody() != null){
            marshallingEncoder.encode(msg.getBody(), sendBuf);
        }else {
            sendBuf.writeInt(0);
            sendBuf.setInt(4, sendBuf.readableBytes());
        }
    }
}
</code></pre>
<blockquote>
<p>消息编码工具类</p>
</blockquote>
<pre><code class="language-java">/**
 * 消息编码工具类
 * @author likecat
 * @version 1.0
 * @date 2022/10/26 15:09
 */
public class MarshallingEncoder {

    private static final byte[] LENGTH_PLACEHOLDER = new byte[4];
    Marshaller marshaller;

    public MarshallingEncoder() throws IOException {
        marshaller = MarshallingCodeCFactory.buildMarshalling();
    }

    protected void encode(Object msg, ByteBuf out) throws Exception {
        try {
            // 写入编码信息
            int lengthPos = out.writerIndex();
            out.writeBytes(LENGTH_PLACEHOLDER);
            ChannelBufferByteOutput output = new ChannelBufferByteOutput(out);
            marshaller.start(output);
            marshaller.writeObject(msg);
            marshaller.finish();
            out.setInt(lengthPos, out.writerIndex() - lengthPos - 4);
        } finally {
            marshaller.close();
        }
    }
}
</code></pre>
<blockquote>
<p>消息解码类</p>
</blockquote>
<pre><code class="language-java">/**
 * 消息解码
 * @author likecat
 * @version 1.0
 * @date 2022/10/26 15:30
 */
public class NettyMessageDecoder extends LengthFieldBasedFrameDecoder {

    MarshallingDecoder marshallingDecoder;

    public NettyMessageDecoder(int maxFrameLength, int lengthFieldOffset,
                          int lengthFieldLength) throws IOException {
        super(maxFrameLength, lengthFieldOffset, lengthFieldLength);
        marshallingDecoder = new MarshallingDecoder();
    }

    @Override
    protected Object decode(ChannelHandlerContext ctx, ByteBuf in)
            throws Exception {
        ByteBuf frame = (ByteBuf) super.decode(ctx, in);
        if (frame == null) {
            return null;
        }

        NettyMessage message = new NettyMessage();
        Header header = new Header();
        header.setCrcCode(frame.readInt());
        header.setLength(frame.readInt());
        header.setSessionID(frame.readLong());
        header.setType(frame.readByte());
        header.setPriority(frame.readByte());

        int size = frame.readInt();
        if (size &gt; 0) {
            Map&lt;String, Object&gt; attch = new HashMap&lt;String, Object&gt;(size);
            int keySize = 0;
            byte[] keyArray = null;
            String key = null;
            for (int i = 0; i &lt; size; i++) {
                keySize = frame.readInt();
                keyArray = new byte[keySize];
                frame.readBytes(keyArray);
                key = new String(keyArray, &quot;UTF-8&quot;);
                attch.put(key, marshallingDecoder.decode(frame));
            }
            keyArray = null;
            key = null;
            header.setAttachment(attch);
        }
        if (frame.readableBytes() &gt; 4) {
            message.setBody(marshallingDecoder.decode(frame));
        }
        message.setHeader(header);
        return message;
    }
}
</code></pre>
<p>这里用到了Netty的LengthFieldBasedFrameDecoder解码器,它支持自动的TCP粘包和半包处理，只需要给出标识消息长度的字段偏移量和消息长度自身所占的字节数，Netty就能自动实现对半包的处理。</p>
<blockquote>
<p>消息解码工具类</p>
</blockquote>
<pre><code class="language-java">/**
 * 消息解码工具类
 * @author likecat
 * @version 1.0
 * @date 2022/10/26 15:27
 */
public class MarshallingDecoder {

    private final Unmarshaller unmarshaller;

    public MarshallingDecoder() throws IOException {
        unmarshaller = MarshallingCodeCFactory.buildUnMarshalling();
    }

    protected Object decode(ByteBuf in) throws Exception {
        int objectSize = in.readInt();
        ByteBuf buf = in.slice(in.readerIndex(), objectSize);
        ByteInput input = new ChannelBufferByteInput(buf);
        try {
            unmarshaller.start(input);
            Object obj = unmarshaller.readObject();
            unmarshaller.finish();
            in.readerIndex(in.readerIndex() + objectSize);
            return obj;
        } finally {
            unmarshaller.close();
        }
    }
}
</code></pre>
<blockquote>
<p>消息编解码工厂类</p>
</blockquote>
<pre><code class="language-java">/**
 * @author likecat
 * @version 1.0
 * @date 2022/10/26 11:47
 */
public final class MarshallingCodeCFactory {
    /** 创建Jboss Marshaller */
    protected static Marshaller buildMarshalling() throws IOException {
        final MarshallerFactory marshallerFactory = Marshalling
                .getProvidedMarshallerFactory(&quot;serial&quot;);
        final MarshallingConfiguration configuration = new MarshallingConfiguration();
        configuration.setVersion(5);
        Marshaller marshaller = marshallerFactory.createMarshaller(configuration);
        return marshaller;
    }

    /** 创建Jboss Unmarshaller */
    protected static Unmarshaller buildUnMarshalling() throws IOException {
        final MarshallerFactory marshallerFactory = Marshalling
                .getProvidedMarshallerFactory(&quot;serial&quot;);
        final MarshallingConfiguration configuration = new MarshallingConfiguration();
        configuration.setVersion(5);
        final Unmarshaller unmarshaller = marshallerFactory
                .createUnmarshaller(configuration);
        return unmarshaller;
    }
}
</code></pre>
<blockquote>
<p>字节输入实现类</p>
</blockquote>
<pre><code class="language-java">/* channel 字节输入实现类 */
class ChannelBufferByteInput implements ByteInput {

    private final ByteBuf buffer;

    public ChannelBufferByteInput(ByteBuf buffer) {
        this.buffer = buffer;
    }

    @Override
    public void close() throws IOException {
        // nothing to do
    }

    @Override
    public int available() throws IOException {
        return buffer.readableBytes();
    }

    @Override
    public int read() throws IOException {
        if (buffer.isReadable()) {
            return buffer.readByte() &amp; 0xff;
        }
        return -1;
    }

    @Override
    public int read(byte[] array) throws IOException {
        return read(array, 0, array.length);
    }

    @Override
    public int read(byte[] dst, int dstIndex, int length) throws IOException {
        int available = available();
        if (available == 0) {
            return -1;
        }

        length = Math.min(available, length);
        buffer.readBytes(dst, dstIndex, length);
        return length;
    }

    @Override
    public long skip(long bytes) throws IOException {
        int readable = buffer.readableBytes();
        if (readable &lt; bytes) {
            bytes = readable;
        }
        buffer.readerIndex((int) (buffer.readerIndex() + bytes));
        return bytes;
    }

}
</code></pre>
<blockquote>
<p>字节输出实现类</p>
</blockquote>
<pre><code class="language-java">/* channel 字节输出实现类 */
class ChannelBufferByteOutput implements ByteOutput {

    private final ByteBuf buffer;

    public ChannelBufferByteOutput(ByteBuf buffer) {
        this.buffer = buffer;
    }

    @Override
    public void close() throws IOException {
        // Nothing to do
    }

    @Override
    public void flush() throws IOException {
        // nothing to do
    }

    @Override
    public void write(int b) throws IOException {
        buffer.writeByte(b);
    }

    @Override
    public void write(byte[] bytes) throws IOException {
        buffer.writeBytes(bytes);
    }

    @Override
    public void write(byte[] bytes, int srcIndex, int length) throws IOException {
        buffer.writeBytes(bytes, srcIndex, length);
    }

    /**
     * Return the {@link ByteBuf} which contains the written content
     *
     */
    ByteBuf getBuffer() {
        return buffer;
    }
}
</code></pre>
<h4 id="1033-握手和安全认证">10.3.3 握手和安全认证</h4>
<p>握手的发起是在客户端和服务器TCP链路建立成功通过激活时，握手消息的接入和安全认证在服务器端处理。</p>
<p>首先需要一个握手认证的客户端ChannelHandler，用于在通道激活时发起握手请求。</p>
<blockquote>
<p>客户端握手认证</p>
</blockquote>
<pre><code class="language-java">/**
 * 客户端握手认证
 * @author likecat
 * @version 1.0
 * @date 2022/10/26 16:21
 */
public class LoginAuthReqHandler extends ChannelHandlerAdapter {

    private static final Logger LOG = Logger.getLogger(LoginAuthReqHandler.class.getName());

    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        ctx.writeAndFlush(buildLoginReq());
    }

    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg)
            throws Exception {
        NettyMessage message = (NettyMessage) msg;

        // 如果是握手应答消息，需要判断是否认证成功
        if (message.getHeader() != null
                &amp;&amp; message.getHeader().getType() == MessageType.LOGIN_RESP
                .getCode()) {
            byte loginResult = (byte) message.getBody();
            if (loginResult != (byte) 0) {
                // 握手失败，关闭连接
                ctx.close();
            } else {
                LOG.info(&quot;Login is ok : &quot; + message);
                ctx.fireChannelRead(msg);
            }
        } else
            ctx.fireChannelRead(msg);
    }
    //构造登录请求
    private NettyMessage buildLoginReq() {
        NettyMessage message = new NettyMessage();
        Header header = new Header();
        header.setType(MessageType.LOGIN_REQ.getCode());
        message.setHeader(header);
        return message;
    }
    //异常跑错
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause)
            throws Exception {
        ctx.fireExceptionCaught(cause);
    }
}
</code></pre>
<p>客户端跟服务端TCP三次握手成功之后，由客户端构造握手请求消息发送给服务端。</p>
<blockquote>
<p>服务端握手认证</p>
</blockquote>
<pre><code class="language-java">/**
 * 服务端握手认证
 * @author likecat
 * @version 1.0
 * @date 2022/10/26 16:07
 */
public class LoginAuthRespHandler extends ChannelHandlerAdapter {

    private static final Logger LOG = Logger.getLogger(LoginAuthRespHandler.class.getName());
    //缓存框架，用于维护是否登录
    private Map&lt;String, Boolean&gt; nodeCheck = new ConcurrentHashMap&lt;String, Boolean&gt;();
    private String[] whitekList = { &quot;127.0.0.1&quot;};

    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg)
            throws Exception {
        NettyMessage message = (NettyMessage) msg;

        // 如果是握手请求消息，处理，其它消息透传
        if (message.getHeader() != null
                &amp;&amp; message.getHeader().getType() == MessageType.LOGIN_REQ
                .getCode()) {
            String nodeIndex = ctx.channel().remoteAddress().toString();
            NettyMessage loginResp = null;
            // 重复登陆，拒绝
            if (nodeCheck.containsKey(nodeIndex)) {
                loginResp = buildResponse((byte) -1);
            } else {
                InetSocketAddress address = (InetSocketAddress) ctx.channel()
                        .remoteAddress();
                String ip = address.getAddress().getHostAddress();
                boolean isOK = false;
                for (String WIP : whitekList) {
                    if (WIP.equals(ip)) {
                        isOK = true;
                        break;
                    }
                }
                loginResp = isOK ? buildResponse((byte) 0)
                        : buildResponse((byte) -1);
                if (isOK)
                    nodeCheck.put(nodeIndex, true);
            }
            LOG.info(&quot;The login response is : &quot; + loginResp
                    + &quot; body [&quot; + loginResp.getBody() + &quot;]&quot;);
            ctx.writeAndFlush(loginResp);
        } else {
            ctx.fireChannelRead(msg);
        }
    }

    private NettyMessage buildResponse(byte result) {
        NettyMessage message = new NettyMessage();
        Header header = new Header();
        header.setType(MessageType.LOGIN_RESP.getCode());
        message.setHeader(header);
        message.setBody(result);
        return message;
    }

    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause)
            throws Exception {
        cause.printStackTrace();
        nodeCheck.remove(ctx.channel().remoteAddress().toString());// 删除缓存
        ctx.close();
        ctx.fireExceptionCaught(cause);
    }
}
</code></pre>
<p>首先根据客户端的源地址进行重复登陆判断，如果已经登陆成功，则拒绝重复登录，以防止客户端重复登录导致的句柄泄漏。随后进行白名单校验，校验通过后握手成功，最后通过buildResponse构造握手应答消息。</p>
<h4 id="1034-心跳检测机制">10.3.4 心跳检测机制</h4>
<p>握手成功之后，由客户端主动发送心跳消息，服务端接收到心跳消息之后，返回心跳应答消息。由于心跳消息的目的是为了检测链路的可用性，因此不需要携带消息体。</p>
<blockquote>
<p>客户端发送心跳请求消息</p>
</blockquote>
<pre><code class="language-java">/**
 * 客户端发送心跳请求消息
 * @author likecat
 * @version 1.0
 * @date 2022/10/26 16:35
 */
public class HeartBeatReqHandler extends ChannelHandlerAdapter {

    private static final Logger LOG = Logger.getLogger(HeartBeatReqHandler.class.getName());

    private volatile ScheduledFuture&lt;?&gt; heartBeat;

    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg)
            throws Exception {
        NettyMessage message = (NettyMessage) msg;
        // 握手成功，主动发送心跳消息
        if (message.getHeader() != null
                &amp;&amp; message.getHeader().getType() == MessageType.LOGIN_RESP
                .getCode()) {
            heartBeat = ctx.executor().scheduleAtFixedRate(
                    new HeartBeatReqHandler.HeartBeatTask(ctx), 0, 5000,
                    TimeUnit.MILLISECONDS);
        } else if (message.getHeader() != null
                &amp;&amp; message.getHeader().getType() == MessageType.HEARTBEAT_RESP
                .getCode()) {
            LOG.info(&quot;Client receive server heart beat message : ---&gt; &quot;
                    + message);
        } else
            ctx.fireChannelRead(msg);
    }

    private class HeartBeatTask implements Runnable {
        private final ChannelHandlerContext ctx;

        public HeartBeatTask(final ChannelHandlerContext ctx) {
            this.ctx = ctx;
        }

        @Override
        public void run() {
            NettyMessage heatBeat = buildHeatBeat();
            LOG.info(&quot;Client send heart beat message to server : ---&gt; &quot;
                    + heatBeat);
            ctx.writeAndFlush(heatBeat);
        }

        private NettyMessage buildHeatBeat() {
            NettyMessage message = new NettyMessage();
            Header header = new Header();
            header.setType(MessageType.HEARTBEAT_REQ.getCode());
            message.setHeader(header);
            return message;
        }
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause)
            throws Exception {
        cause.printStackTrace();
        if (heartBeat != null) {
            heartBeat.cancel(true);
            heartBeat = null;
        }
        ctx.fireExceptionCaught(cause);
    }
}
</code></pre>
<p>当握手成功之后，握手请求Handler会继续将握手成功消息向下透传，HeartBeatReqHandler接收到之后对消息进行判断，如果是握手成功消息，则启动无限循环定时器用于定期发送心跳。由于NioEventLoop是一个Schedule，因此它支持定时器的执行。默认5000ms发送一次心跳。</p>
<blockquote>
<p>服务器心跳应答</p>
</blockquote>
<pre><code class="language-java">/**
 * 心跳消息服务端
 * @author likecat
 * @version 1.0
 * @date 2022/10/26 18:06
 */
public class HeartBeatRespHandler extends ChannelHandlerAdapter {

    private static final Logger LOG = Logger.getLogger(HeartBeatRespHandler.class.getName());
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg)
            throws Exception {
        NettyMessage message = (NettyMessage) msg;
        // 返回心跳应答消息
        if (message.getHeader() != null
                &amp;&amp; message.getHeader().getType() == MessageType.HEARTBEAT_REQ
                .getCode()) {
            LOG.info(&quot;Receive client heart beat message : ---&gt; &quot;
                    + message);
            NettyMessage heartBeat = buildHeatBeat();
            LOG.info(&quot;Send heart beat response message to client : ---&gt; &quot;
                    + heartBeat);
            ctx.writeAndFlush(heartBeat);
        } else
            ctx.fireChannelRead(msg);
    }
    //心跳构造器
    private NettyMessage buildHeatBeat() {
        NettyMessage message = new NettyMessage();
        Header header = new Header();
        header.setType(MessageType.HEARTBEAT_RESP.getCode());
        message.setHeader(header);
        return message;
    }
}
</code></pre>
<p>服务端接收到心跳请求消息之后，构造心跳应答消息返回，并打印接收和发送的心跳消息。</p>
<p>心跳超时的实现非常简单，直接利用Netty的ReadTimeoutHandler机制，当一定周期内没有读取到对方任何消息时，需要主动关闭链路。如果是客户端，重启发起连接，如果是服务端，释放资源，清除客户端登陆缓存信息，等待客户端重连。</p>
<h4 id="1035-断连重连">10.3.5 断连重连</h4>
<p>当客户端感知断连事件之后，释放资源，重新发起连接。</p>
<p>具体实现为首先监听网络断连事件，如果Channel关闭，则执行后续的重连任务，然后重启发起连接，客户端挂在closeFuture上监听链路关闭信号，一旦关闭，则创建重连定时器，5s之后重新发起连接，直到重连成功。</p>
<p>服务端感知到断连事件之后，需要清空缓存的登陆认证注册信息，以保存后续客户端能够正常连接。</p>
<blockquote>
<p>客户端</p>
</blockquote>
<pre><code class="language-java">/**
 * 客户端
 * @author likecat
 * @version 1.0
 * @date 2022/10/27 10:47
 */
public class NettyClient {

    private static final Logger LOG = Logger.getLogger(NettyClient.class.getName());
    private ScheduledExecutorService executor = Executors
            .newScheduledThreadPool(1);
    EventLoopGroup group = new NioEventLoopGroup();

    public void connect(int port, String host) throws Exception {
        // 配置客户端NIO线程组
        try {
            Bootstrap b = new Bootstrap();
            b.group(group).channel(NioSocketChannel.class)
                    .option(ChannelOption.TCP_NODELAY, true)
                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        public void initChannel(SocketChannel ch)
                                throws Exception {
                            ch.pipeline().addLast(
                                    new NettyMessageDecoder(1024 * 1024, 4, 4));
                            ch.pipeline().addLast(&quot;MessageEncoder&quot;,
                                    new NettyMessageEncoder());
                            ch.pipeline().addLast(&quot;readTimeoutHandler&quot;,
                                    new ReadTimeoutHandler(50));
                            ch.pipeline().addLast(&quot;LoginAuthHandler&quot;,
                                    new LoginAuthReqHandler());
                            ch.pipeline().addLast(&quot;HeartBeatHandler&quot;,
                                    new HeartBeatReqHandler());
                        }
                    });
            // 发起异步连接操作
            ChannelFuture future = b.connect(
                    new InetSocketAddress(host, port),
                    new InetSocketAddress(NettyConstant.LOCALIP,
                            NettyConstant.LOCAL_PORT)).sync();
            // 当对应的channel关闭的时候，就会返回对应的channel。
            future.channel().closeFuture().sync();
        } finally {
            // 所有资源释放完成之后，清空资源，再次发起重连操作
            executor.execute(new Runnable() {
                @Override
                public void run() {
                    try {
                        TimeUnit.SECONDS.sleep(1);
                        try {
                            connect(NettyConstant.PORT, NettyConstant.REMOTEIP);// 发起重连操作
                        } catch (Exception e) {
                            e.printStackTrace();
                        }
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            });
        }
    }

    public static void main(String[] args) throws Exception {
        new NettyClient().connect(NettyConstant.PORT, NettyConstant.REMOTEIP);
    }
}
</code></pre>
<blockquote>
<p>服务端</p>
</blockquote>
<pre><code class="language-java">/**
 * 服务端
 * @author likecat
 * @version 1.0
 * @date 2022/10/27 11:26
 */
public class NettyServer {
    private static final Logger LOG = Logger.getLogger(NettyServer.class.getName());

    public void bind() throws Exception {
        // 配置服务端的NIO线程组
        EventLoopGroup bossGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        ServerBootstrap b = new ServerBootstrap();
        b.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class)
                .option(ChannelOption.SO_BACKLOG, 100)
                .handler(new LoggingHandler(LogLevel.INFO))
                .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() {
                    @Override
                    public void initChannel(SocketChannel ch)
                            throws IOException {
                        ch.pipeline().addLast(
                                new NettyMessageDecoder(1024 * 1024, 4, 4));
                        ch.pipeline().addLast(new NettyMessageEncoder());
                        ch.pipeline().addLast(&quot;readTimeoutHandler&quot;,
                                new ReadTimeoutHandler(50));
                        ch.pipeline().addLast(new LoginAuthRespHandler());
                        ch.pipeline().addLast(&quot;HeartBeatHandler&quot;,
                                new HeartBeatRespHandler());
                    }
                });

        // 绑定端口，同步等待成功
        b.bind(NettyConstant.REMOTEIP, NettyConstant.PORT).sync();
        LOG.info(&quot;server start ok : &quot;
                + (NettyConstant.REMOTEIP + &quot; : &quot; + NettyConstant.PORT));
    }

    public static void main(String[] args) throws Exception {
        new NettyServer().bind();
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Netty权威指南(一)]]></title>
        <id>https://q456qq520.github.io/post/netty-quan-wei-zhi-nan-yi/</id>
        <link href="https://q456qq520.github.io/post/netty-quan-wei-zhi-nan-yi/">
        </link>
        <updated>2022-10-13T02:01:23.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="1-java的io演进之路">1. Java的IO演进之路</h2>
]]></summary>
        <content type="html"><![CDATA[<h2 id="1-java的io演进之路">1. Java的IO演进之路</h2>
<!-- more -->
<h3 id="11-io">1.1 I/O</h3>
<h4 id="111-linux网络io模型">1.1.1 LINUX网络I/O模型</h4>
<p>Linux的内核将所有外部设备都看作一个文件来操作，对一个文件对读写操作会调用内核提供好的系统命令，返回一个file descriotor（fd，文件描述符）。而对一个socket的读写也会有相应的描述符，称为socketfd，描述符就是一个数字，它指向内核中的一个结构体（文件路径，数据去等一些属性）。</p>
<p>UNIX中，I/O模型种类有如下：</p>
<ol>
<li>阻塞I/O模型：为最常用的io模型，缺省情况下所有文件操作都是阻塞的。<br>
以套接字接口为例：在进程空间中调用Recvfrom,其系统调用直到数据包到达且被复制到应用进程的缓冲区中或者发生错误时才返回，在此期间一直会等待，进程在从调用recvfrom开始到它返回到整段时间内都是被阻塞到，因此被称为阻塞I/O模型。</li>
</ol>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1665627501192.png" alt="" loading="lazy"></figure>
<ol start="2">
<li>非阻塞I/O模型：recvfrom从应用层到内核到时候，如果该缓冲区没有数据到话，就直接返回一个EWOULDBLOCK错误，一般都是对非阻塞I/O模型进行轮询检查这个状态，看内核是不是有数据到来。</li>
</ol>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1665627510514.png" alt="" loading="lazy"></figure>
<ol start="3">
<li>I/O复用模型：Linux提供select/poll，进程通过将一个或多个fd传递给select或poll系统调用，阻塞在select操作上，这是select/poll可以帮我们侦测多个fd是否处于就绪状态。select/poll上顺序扫描fd是否就绪，而且支持等fd数量有限，因此它的使用受到了一些制约。Linux还提供了一个epoll系统调用，epoll使用基于事件驱动方式代替顺序扫描，性能更高。当有fd就绪时，立即回调函数rollbock。</li>
</ol>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1665628231352.png" alt="" loading="lazy"></figure>
<ol start="4">
<li>信号驱动I/O模型：首先开启套接口信号驱动I/O功能，并通过系统调用sigaction执行一个信号处理函数。当数据准备就绪时，就为该进程生产一个SIGIO信号，通过信号回调通知应用程序调用recvfrom来读取数据，并通知主循环函数处理数据。</li>
</ol>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1665628476732.png" alt="" loading="lazy"></figure>
<ol start="5">
<li>异步I/O：告知内核启动某个操作，并让内核在整个操作完成后（包括将数据从内核复制到用户直接到缓冲区）通知我们。<br>
这种模型与信号驱动模型到主要区别是：信号驱动I/O由内核通知我们何时开始下一个I/O操作；异步I/O模型由内核通知我们I/O操作何时已经完成。</li>
</ol>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1665628659332.png" alt="" loading="lazy"></figure>
<h4 id="112-io多路复用技术">1.1.2 I/O多路复用技术</h4>
<p>在I/O编程过程中，当需要处理多个客户端接入请求时，可以利用多线程或者I/O多路复用技术处理。</p>
<p>I/O多路复用通过把多个I/O的阻塞复用到同一个select到阻塞上，从而可以在单线程的情况下可以同时处理多个客户端请求。I/O多路复用最大的优势就是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降低系统的维护工作量，节省了系统资源，I/O多路复用主要应用场景为：</p>
<pre><code>- 服务器需要同时处理多个处于监听状态或者多个连接状态的套接字。
- 服务器需要同时处理多种网络协议的套接字。
</code></pre>
<p>目前支持I/O多路复用的系统调用有<strong>select、pselect、poll、epoll</strong>。</p>
<p>其中epoll为select的替代，相较于select，epoll做了很多改进，如下：</p>
<ol>
<li>支持一个进程打开的socket描述符不受限制（仅受限与操作系统的最大文件句柄数）。</li>
<li>I/O效率不会随着FD树木的增加而线性下降。</li>
<li>使用mmap加速内核与用户空间的消息传递。</li>
<li>epoll的api更加简单</li>
</ol>
<h2 id="2-nio">2. NIO</h2>
<h3 id="21-传统的bio编程">2.1 传统的BIO编程</h3>
<p>网络编程的基本模型是Client/Server模型，也就行两个进程之间进行相互通信，其中服务端提供位置信息（ip&amp;port），客户端通过连接操作向服务端监听的地址发起连接请求，通过3次握手建立连接，双方就可以通过网络套接字（socket）进行通信。</p>
<h4 id="211-bio通信模型">2.1.1 BIO通信模型</h4>
<p>BIO通信的服务端通常由一个独立的Acceptor线程负责监听客户端的连接，它接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成后通过输出流返回应答给客户端，线程销毁。</p>
<p>该模型最大的问题是缺乏弹性伸缩能力，当客户端并发访问量增加后，服务端的线程个数和客户端并发访问数呈现1:1的正比关系，导致系统的性能急剧下降。</p>
<h3 id="22-伪异步io编程">2.2 伪异步I/O编程</h3>
<p>为了解决同步阻塞I/O中一个链路一个线程的问题，通过一个线程池或者任务队列来处理多个客户端的请求接入，形成客户端数M：线程池最大线程数N的比例关系，其中M可以远远大于N。通过线程池可以灵活的调配线程资源，设置线程的最大值，防止线程耗尽。</p>
<h4 id="221-伪异步io模型图">2.2.1 伪异步I/O模型图</h4>
<p>当有新的客户端接入时，将客户端的socket封装称一个Task投递到后端到线程池中进行处理。因为线程池到资源占用是可控的，无论多少个客户端并发访问们都不会导致资源的耗尽和宕机。</p>
<p>但是在同步I/O中，对当对Socket对输入流进行读取操作的时候，它会一直阻塞下去，直到发生如下三种事情：</p>
<ul>
<li>1.有数据可读</li>
<li>2.可用数据已经读取完毕</li>
<li>3.发生异常</li>
</ul>
<p>这意味着当对方发送请求或者应答消息比较缓慢，或者网络传输较慢时，读取输入流一方当通信线程将被长时间阻塞，而且在此期间，其他接入消息只能在消息队列中排队。</p>
<h4 id="222-同步io的问题">2.2.2 同步I/O的问题</h4>
<ol>
<li>服务器处理缓慢，返回应答消息耗时也相应变慢。</li>
<li>采用伪异步I/O的线程正在读取故障服务节点的响应，由于读取输入流是阻塞的，那该线程也同步阻塞。</li>
<li>加入所有的可用线程都被故障服务器阻塞，那后续所有的I/O消息都将在队列中排队。</li>
<li>由于线程池采用阻塞队列实现，当队列积满以后，后续入队列的操作将被阻塞。</li>
<li>由于只有一个Accptor线程接收客户端请求，它被阻塞在线程池的同步阻塞队列之后，新的客户端请求消息将被拒绝，客户端会发生大量的连接超时。</li>
<li>由于几乎所有的连接都超时，调用者会认为系统已经崩溃，无法接受新的消息。</li>
</ol>
<p>这几乎是一个链式的级联故障，那该怎么解决呢？</p>
<p>答案是NIO。</p>
<h3 id="23-nionon-block-io编程">2.3 NIO（Non-block I/O）编程</h3>
<h4 id="231-nio类库简介">2.3.1 NIO类库简介</h4>
<p>首先介绍一下NIO的一些概念与功能：</p>
<p><strong>1. 缓冲区Buffer</strong></p>
<p>Buffer是一个对象，它包含一些要写入或者要读出的数据。在面向流的I/O中，可以将数据直接写入或者将数据直接读到Stream对象中。</p>
<p>在NIO库中，所有数据都是用缓冲区处理的。在读取数据时是直接渠道缓冲区中的；在写入数据时也是写入到缓冲区中。</p>
<p>缓冲区实质上似一个数组，通常是一个字节数组-ByteBuffer，也可以使用其他种类的数组。但是一个缓冲区不及您是一个数组，缓冲区提供了对数据对结构化访问以及维护读写位置（limit）等信息。</p>
<p>最常用对缓冲区是BtyeBuffer，下面是Java提供对根据数据类型区分的缓冲区：</p>
<ul>
<li>ByteBuffer：字节缓冲区</li>
<li>CharBuffer：字符缓冲区</li>
<li>ShortBuffer：短整型缓冲区</li>
<li>IntBuffer：整形缓冲区</li>
<li>LongBuffer：长整形缓冲区</li>
<li>FloatBuffer：浮点型缓冲区</li>
<li>DoubleBuffer：双精度浮点型缓冲区</li>
</ul>
<p>每一个Buffer类都是Buffer接口的一个子实例，除ByteBuffer外每一个Buffer类都有完全一样的操作，只是所处理的数据类型不一样。因为大多数标准I/O操作都使用BtyeBuffer，所以它具有一般缓冲区的操作之外还提供了一些特有的操作，以方便网络读写。</p>
<p><strong>2. 通道 Channel</strong></p>
<p>Channel是一个通道，网络数据通过Channel读取和写入。通道与流的不同之处在于通道是双向的，流只是在一个方向上移动，而通过可以用于读、写或者二者同时进行。</p>
<p>因为Channel是全双工的，所以它可以比流更好地映射底层操作系统的API。</p>
<p><strong>3. 多路复用器 Selector</strong></p>
<p>多路复用器提供选择已经就绪的任务的能力，简单来说就是Selector会不断地轮询注册在其上的Channel，如果某个Channel上面发生读或者写事件，这个Channel就处于就绪状态，会被Selector轮询出来，然后通过SelectionKey可以获取就绪Channel的集合，进行后续的I/O操作。</p>
<p>一个多路复用器Selector可以同时轮询多个Channel，而且因为Jdk使用的是epoll（）代替select，并没有最大连接句柄的限制。</p>
<h4 id="232-nio服务端">2.3.2 NIO服务端</h4>
<figure data-type="image" tabindex="6"><img src="https://q456qq520.github.io/post-images/1665650232697.png" alt="NIO服务端时序图" loading="lazy"></figure>
<p>Step 1：打开ServerSocketChannel，用于监听客户端的连接，它是所有客户端连接的父管道。<br>
Step 2：绑定监听端口，设置连接为非阻塞模式。<br>
Step 3：创建Reactor线程，创建多路复用器并启动线程。<br>
Step 4：将ServerSocketChannel注册到Reactor线程的多路复用器Selector上，检查ACCEPT事件。<br>
Step 5：多路复用器在线程run方法的无限循环体内轮询准备就绪的key<br>
Step 6：多路复用器监听到有新到客户端接入，处理新到接入请求，完成TCP三次握手，建立物理链路。<br>
Step 7：设置客户端链路为非阻塞模式<br>
Step 8：将新接入到库护短注册到Reactor线程到多路复用器上，监听读操作，读取客户端发送到网络消息。<br>
Step 9：异步读取客户端请求消息到缓冲区。<br>
Step 10：对ByteBuffer进行编解码，如果有半包消息指针reset，继续读取后续对豹纹，将解码成功对消息封装成task，投递到业务线程池中进行业务逻辑。<br>
Step 11：将POJO对象encode成ByteBuffer，调用SocketChannel到异步write接口，将消息异步发送给客户端。</p>
<p>⚠️注意：如果发送区Tcp缓冲区满，会导致写半包，此时需要注册监听写操作位，循环写直到整包消息写入缓冲区。</p>
<h4 id="233-nio客户端">2.3.3 NIO客户端</h4>
<figure data-type="image" tabindex="7"><img src="https://q456qq520.github.io/post-images/1665655179085.png" alt="NIO客户端" loading="lazy"></figure>
<p>Step 1：打开ServerSocketChannel，绑定客户端本地地址。<br>
Step 2：设置SocketChannel为非阻塞模式，同时设置客户端连接的Tcp参数。<br>
Step 3：异步连接服务端。<br>
Step 4：判断是否连接成功，如果成功则直接注册读状态到多路复用器中。<br>
Step 5：向Reactor线程的多路复用器注册OP_CONNECT状态位，监听服务端的TCP ACk应答。<br>
Step 6：创建Reactor线程，创建多路复用器并启动线程。<br>
Step 7：多路复用器在线程run方法的无限循环体内轮询准备就绪的key。<br>
Step 8：接收connect事件进行处理。<br>
Step 9：判断连接结果，如果成功注册读时间到多路复用器。<br>
Step 10：注册读事件到多路复用器。<br>
Step 11：异步读客户端请求到缓冲区。<br>
Step 10：对ByteBuffer进行编解码，如果有半包消息指针reset，继续读取后续对豹纹，将解码成功对消息封装成task，投递到业务线程池中进行业务逻辑。<br>
Step 11：将POJO对象encode成ByteBuffer，调用SocketChannel到异步write接口，将消息异步发送给客户端。</p>
<p>总结：<br>
1）客户端发起的连接操作是异步的，可以通过多路复用器注册OP_CONNECT等带后续结果，不需要像之前一样被同步阻塞。<br>
2）SocketChannel的读写操作都是异步的，如果没有可读写的数据它不会同步等待，直接返回。这样I/O通信线程就可以处理其他的链路无需同步等待。<br>
3）线程模型的优化：没有连接句柄数</p>
<h3 id="24-aio新异步非阻塞io编程">2.4 AIO（新异步非阻塞IO）编程</h3>
<p>AIO为UNIX网络编程中的事件驱动I/O，它不需要多路复用器对注册对通道进行轮询操作即可实现异步读写，从而简化NIO对编程模型。</p>
<h3 id="25-4种io的对比">2.5 4种I/O的对比</h3>
<h4 id="251-不同io模型对比">2.5.1 不同I/O模型对比</h4>
<table>
<thead>
<tr>
<th>-</th>
<th style="text-align:center">同步阻塞I/O（BIO）</th>
<th style="text-align:right">伪异步I/O</th>
<th style="text-align:right">非阻塞I/O（NIO）</th>
<th style="text-align:right">异步I/O（AIO）</th>
</tr>
</thead>
<tbody>
<tr>
<td>客户端个数：I/O线程</td>
<td style="text-align:center">1:1</td>
<td style="text-align:right">M：N</td>
<td style="text-align:right">M：1</td>
<td style="text-align:right">M：0（不需要启动额外的I/O线程，被动回调）</td>
</tr>
<tr>
<td>I/O类型</td>
<td style="text-align:center">阻塞I/O</td>
<td style="text-align:right">阻塞I/O</td>
<td style="text-align:right">非阻塞I/O</td>
<td style="text-align:right">非阻塞I/O</td>
</tr>
<tr>
<td>I/O类型（同步）</td>
<td style="text-align:center">同步I/O</td>
<td style="text-align:right">同步I/O</td>
<td style="text-align:right">同步I/O（I/O多路复用）</td>
<td style="text-align:right">异步I/O</td>
</tr>
<tr>
<td>可靠性</td>
<td style="text-align:center">非常差</td>
<td style="text-align:right">差</td>
<td style="text-align:right">高</td>
<td style="text-align:right">高</td>
</tr>
<tr>
<td>吞吐量</td>
<td style="text-align:center">低</td>
<td style="text-align:right">中</td>
<td style="text-align:right">高</td>
<td style="text-align:right">高</td>
</tr>
</tbody>
</table>
<h2 id="3-netty入门">3 Netty入门</h2>
<h3 id="31-netty服务端开发">3.1 Netty服务端开发</h3>
<p>🏠例子：</p>
<blockquote>
<p>服务端</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.book;

import io.netty.bootstrap.ServerBootstrap;
import io.netty.channel.*;
import io.netty.channel.nio.NioEventLoopGroup;
import io.netty.channel.socket.SocketChannel;
import io.netty.channel.socket.nio.NioServerSocketChannel;

/**
 * 服务端
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 10:21
 */
public class TimeServer {

    public void bind(int port){
        //配置服务端nio线程组,处理网络事件
        EventLoopGroup boosGroup = new NioEventLoopGroup();//用于服务端接受客户端连接
        EventLoopGroup workerGroup = new NioEventLoopGroup();//用于进行SocketChannel网络读写

        try {
            ServerBootstrap b = new ServerBootstrap();
            b.group(boosGroup, workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .option(ChannelOption.SO_BACKLOG, 1024)
                    .childHandler(new ChildChannelHandler());

            //绑定端口，同步等待成功
            ChannelFuture f = b.bind(port).sync();
            //等待服务端监听端口关闭
            f.channel().closeFuture().sync();
            //退出
        } catch (InterruptedException e) {
            e.printStackTrace();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    private class ChildChannelHandler extends ChannelInitializer&lt;SocketChannel&gt; {

        @Override
        protected void initChannel(SocketChannel socketChannel) throws Exception {
            socketChannel.pipeline().addLast(new TimeServerHandler());
        }
    }

    public static void main(String[] args) {
        int port = 8080;

        if(args != null &amp;&amp; args.length &gt; 0){
            try {
                port = Integer.valueOf(args[0]);
            } catch (NumberFormatException e) {
                e.printStackTrace();
            }
        }

        new TimeServer().bind(port);
    }
}
</code></pre>
<blockquote>
<p>服务端具体操作类</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.book;

import io.netty.buffer.ByteBuf;
import io.netty.buffer.Unpooled;
import io.netty.channel.ChannelHandlerAdapter;
import io.netty.channel.ChannelHandlerContext;
import io.netty.channel.ChannelInboundHandlerAdapter;

import java.io.UnsupportedEncodingException;
import java.util.Date;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 10:41
 */
public class TimeServerHandler extends ChannelInboundHandlerAdapter {

    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception {
        ByteBuf byteBuf = (ByteBuf) msg;

        byte[] req = new byte[byteBuf.readableBytes()];
        byteBuf.readBytes(req);

        String body = new String(req, &quot;UTF-8&quot;);
        System.out.println(&quot;The time server receive order :&quot; + body);

        String currentTime = &quot;QUERY TIME ORDER&quot;.equalsIgnoreCase(body) ? new Date(System.currentTimeMillis()).toString() : &quot;BAD ORDER&quot;;
        ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes());

        //为了效率，write并不直接将消息写入到SocketChannel中，调用write方法只是把待发送的消息
        //放到发送缓冲数组中，再调用flush发送
        ctx.write(resp);
        System.out.println(&quot;写入完成&quot;);
    }

    @Override
    public void channelReadComplete(ChannelHandlerContext ctx){
        //将消息发送队列中的消息写到SocketChannel中发送给对方
        ctx.flush();
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause){
        ctx.close();
    }
}
</code></pre>
<h3 id="32-netty客户端开发">3.2 Netty客户端开发</h3>
<blockquote>
<p>客户端</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.book;

import io.netty.bootstrap.Bootstrap;
import io.netty.channel.ChannelFuture;
import io.netty.channel.ChannelInitializer;
import io.netty.channel.ChannelOption;
import io.netty.channel.EventLoopGroup;
import io.netty.channel.nio.NioEventLoopGroup;
import io.netty.channel.socket.SocketChannel;
import io.netty.channel.socket.nio.NioSocketChannel;

/**
 * 客户端
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 11:06
 */
public class TimeClient {

    public void connect(int port ,String host) throws Exception {

        //配置nio线程组
        EventLoopGroup group = new NioEventLoopGroup();

        try{
            Bootstrap b = new Bootstrap();
            b.group(group).channel(NioSocketChannel.class)
                    .option(ChannelOption.TCP_NODELAY, true)
                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel socketChannel) throws Exception {
                            socketChannel.pipeline().addLast(new TimeClientHandler());
                        }
                    });

            //发起异步连接操作
            ChannelFuture f = b.connect(host, port).sync();
            //等待客户端链路关闭
            f.channel().closeFuture().sync();
            //优雅退出，释放NIO线程组
        }finally {
            group.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        int port = 8080;

        if(args != null &amp;&amp; args.length &gt; 0){
            try {
                port = Integer.valueOf(args[0]);
            } catch (NumberFormatException e) {
                e.printStackTrace();
            }
        }

        new TimeClient().connect(port,&quot;127.0.0.1&quot;);
    }
}
</code></pre>
<blockquote>
<p>客户端具体操作类</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.book;

import io.netty.buffer.ByteBuf;
import io.netty.buffer.Unpooled;
import io.netty.channel.ChannelHandlerContext;
import io.netty.channel.ChannelInboundHandlerAdapter;


/**
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 11:09
 */
public class TimeClientHandler extends ChannelInboundHandlerAdapter {

    private final ByteBuf firstMessage;

    public TimeClientHandler() {
        byte[] req = &quot;QUERY TIME ORDER&quot;.getBytes();
        firstMessage = Unpooled.buffer(req.length);
        firstMessage.writeBytes(req);
    }

    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        ctx.writeAndFlush(firstMessage);
    }

    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception{
        ByteBuf byteBuf = (ByteBuf) msg;

        byte[] req = new byte[byteBuf.readableBytes()];
        byteBuf.readBytes(req);

        String body = new String(req, &quot;UTF-8&quot;);
        System.out.println(&quot;Now is :&quot; + body);

    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause){
        System.out.println(&quot;释放资源&quot;);
        ctx.close();
    }
}
</code></pre>
<p>当客户端和服务端建立TCP链路成功后，Netty端NIO线程会调用channelActive方法，发送查询时间端指令给服务端，调用writeAndFlush方法将请求消息发送给服务端。</p>
<p>当服务端返回应答消息时，channelRead方法被调用。</p>
<h3 id="33-运行">3.3 运行</h3>
<blockquote>
<p>执行结果 -&gt; 服务端</p>
</blockquote>
<pre><code class="language-java">The time server receive order :QUERY TIME ORDER
写入完成
</code></pre>
<blockquote>
<p>执行结果 -&gt; 客户端</p>
</blockquote>
<pre><code class="language-java">Now is :Mon Oct 17 11:25:40 CST 2022
</code></pre>
<h2 id="4-tcp粘包拆包问题">4 TCP粘包/拆包问题</h2>
<h3 id="41-tcp粘包拆包">4.1 TCP粘包/拆包</h3>
<p>TCP是个“流‘协议，所谓流，就是没有界限的一串数据。一个完整的包可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送。</p>
<h4 id="411-tcp粘包拆包问题说明">4.1.1 TCP粘包/拆包问题说明</h4>
<figure data-type="image" tabindex="8"><img src="https://q456qq520.github.io/post-images/1665978556282.png" alt="TCP粘包/拆包" loading="lazy"></figure>
<p>TCP粘包/拆包具体分析如上图，假设客户端分别发送了2个数据包D1和D2给服务端，由于服务端一次读取到到字节数是不确定的，故可能存在以下4种情况。</p>
<ol>
<li>服务端分2此读取到了2个独立的数据包，分别是D1和D2，没有粘包，拆包。</li>
<li>服务点一次接收到了2个数据包，D1和D2粘合在一起，被称为TCP粘包。</li>
<li>服务点分2次读取到了2个数据包，一次读取到了完整的D1和D2包的一部分内容，第二次读取到了D2包到剩余内容，被称为TCP拆包。</li>
<li>服务端分2次读取道理2个数据包，第一次读取到了D1包的部分内容D1-1，第二次读取到了D1包的剩余内容D1-2和D2包的整包。</li>
</ol>
<p>如果此时服务端TCP接受滑窗非常小，而数据包D1和D2比较大，很有可能会发生第五种可能，即服务端分多次次才能将D1和D2包接收完全，期间发送多次拆包。</p>
<h4 id="412-tcp粘包拆包发生的原因">4.1.2 TCP粘包/拆包发生的原因</h4>
<ol>
<li>应用程序write写入的字节大小大于套接口发送缓冲区大小</li>
<li>进行MSS大小的TCP分段</li>
<li>以太网帧的payload大于MTU进行IP分片</li>
</ol>
<h4 id="413-粘包问题的解决策略">4.1.3 粘包问题的解决策略</h4>
<p>TCP无法理解上层业务逻辑，只能通过上层应用协议栈设计来解决，如下：</p>
<ol>
<li>消息定长</li>
<li>在包尾增加回车换行符进行分割</li>
<li>将消息分为消息头和消息体，消息头中包含表示消息总长度的字段</li>
<li>更富在的应用层协议</li>
</ol>
<p>接下来看Netty如果解决TCP粘包/拆包问题</p>
<h3 id="42-未考虑tcp粘包案例">4.2 未考虑TCP粘包案例</h3>
<h4 id="421-timeserver改造">4.2.1 TimeServer改造</h4>
<p>我们用上面的例子复刻一下粘包场景。</p>
<blockquote>
<p>TimeServerHandler改造</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.book;

import io.netty.buffer.ByteBuf;
import io.netty.buffer.Unpooled;
import io.netty.channel.ChannelHandlerContext;
import io.netty.channel.ChannelInboundHandlerAdapter;

import java.util.Date;

/**
 * 粘包
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 10:41
 */
public class TimeServerApHandler extends ChannelInboundHandlerAdapter {

    private int counter;

    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception {
        ByteBuf byteBuf = (ByteBuf) msg;

        byte[] req = new byte[byteBuf.readableBytes()];
        byteBuf.readBytes(req);

        String body = new String(req, &quot;UTF-8&quot;).substring(0,req.length - System.getProperty(&quot;line.separator&quot;).length());
        //每读到一条消息后就记一次数，然后发送消息给客户端
        //按照设计，服务端接收到的消息总数应该于客户端发送的消息总数相同
        System.out.println(&quot;The time server receive order :&quot; + body + &quot;; the counter is : &quot; + ++counter);

        String currentTime = &quot;QUERY TIME ORDER&quot;.equalsIgnoreCase(body) ? new Date(System.currentTimeMillis()).toString() : &quot;BAD ORDER&quot;;

        currentTime = currentTime + System.getProperty(&quot;line.separator&quot;);
        ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes());

        //为了效率，write并不直接将消息写入到SocketChannel中，调用write方法只是把待发送的消息
        //放到发送缓冲数组中，再调用flush发送
        ctx.write(resp);
        System.out.println(&quot;写入完成&quot;);
    }

    @Override
    public void channelReadComplete(ChannelHandlerContext ctx){
        //将消息发送队列中的消息写到SocketChannel中发送给对方
        ctx.flush();
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause){
        ctx.close();
    }
}
</code></pre>
<h4 id="422-timeclienthandler改造">4.2.2 TimeClientHandler改造</h4>
<blockquote>
<p>TimeClientHandler改造</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.book;

import io.netty.buffer.ByteBuf;
import io.netty.buffer.Unpooled;
import io.netty.channel.ChannelHandlerContext;
import io.netty.channel.ChannelInboundHandlerAdapter;


/**
 * 客户端粘包
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 11:09
 */
public class TimeClientApHandler extends ChannelInboundHandlerAdapter {

//    private final ByteBuf firstMessage;
    private int counter;
    private byte[] req;

    public TimeClientApHandler() {
       req = ( &quot;QUERY TIME ORDER&quot; + System.getProperty(&quot;line.separator&quot;) ).getBytes();
//        firstMessage = Unpooled.buffer(req.length);
//        firstMessage.writeBytes(req);
    }

    @Override
    public void channelActive(ChannelHandlerContext ctx){
        ByteBuf message = null;
        for (int i = 0; i &lt; 100; i++) {
            message = Unpooled.buffer(req.length);
            message.writeBytes(req);
            ctx.writeAndFlush(message);
        }
    }

    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception{
        ByteBuf byteBuf = (ByteBuf) msg;

        byte[] req = new byte[byteBuf.readableBytes()];
        byteBuf.readBytes(req);

        String body = new String(req, &quot;UTF-8&quot;);
        System.out.println(&quot;Now is :&quot; + body + &quot;; the counter is :&quot; + ++counter);

    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause){
        System.out.println(&quot;释放资源&quot;);
        ctx.close();
    }
}
</code></pre>
<h4 id="423-运行">4.2.3 运行</h4>
<blockquote>
<p>执行结果</p>
</blockquote>
<pre><code class="language-java">QUERY TIME ORDER; the counter is : 18

Now is :BAD ORDER
; the counter is :1
</code></pre>
<p>服务端运行结果表明他没有接收到100条消息，说明发生了TCP粘包。</p>
<p>客户端应该接收到100条当前时间到消息，但实际上只接收到了1条，说明服务端返回应答消息也发生了粘包。</p>
<p>当TCP粘包时，我们到程序就不能正常工作。</p>
<h3 id="43-利用linebasedframedecoder解决tcp粘包问题">4.3 利用LineBasedFrameDecoder解决TCP粘包问题</h3>
<h4 id="431-支持tcp粘包的timeserver">4.3.1 支持TCP粘包的TimeServer</h4>
<p>Netty默认提供了多种编解码器用于处理半包问题。</p>
<blockquote>
<p>TimeServer</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.book;

import io.netty.bootstrap.ServerBootstrap;
import io.netty.channel.ChannelFuture;
import io.netty.channel.ChannelInitializer;
import io.netty.channel.ChannelOption;
import io.netty.channel.EventLoopGroup;
import io.netty.channel.nio.NioEventLoopGroup;
import io.netty.channel.socket.SocketChannel;
import io.netty.channel.socket.nio.NioServerSocketChannel;
import io.netty.handler.codec.LineBasedFrameDecoder;
import io.netty.handler.codec.string.StringDecoder;

/**
 * 服务端（支持粘包）
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 10:21
 */
public class TimeApServer {

    public void bind(int port){
        //配置服务端nio线程组,处理网络事件
        EventLoopGroup boosGroup = new NioEventLoopGroup();//用于服务端接受客户端连接
        EventLoopGroup workerGroup = new NioEventLoopGroup();//用于进行SocketChannel网络读写

        try {
            ServerBootstrap b = new ServerBootstrap();
            b.group(boosGroup, workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .option(ChannelOption.SO_BACKLOG, 1024)
                    .childHandler(new ChildChannelHandler());

            //绑定端口，同步等待成功
            ChannelFuture f = b.bind(port).sync();
            //等待服务端监听端口关闭
            f.channel().closeFuture().sync();
            //退出
        } catch (InterruptedException e) {
            e.printStackTrace();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    private class ChildChannelHandler extends ChannelInitializer&lt;SocketChannel&gt; {

        @Override
        protected void initChannel(SocketChannel socketChannel) throws Exception {
            socketChannel.pipeline().addLast(new LineBasedFrameDecoder(1024));
            socketChannel.pipeline().addLast(new StringDecoder());
            socketChannel.pipeline().addLast(new TimeServerApHandler());
        }
    }

    public static void main(String[] args) {
        int port = 8080;

        if(args != null &amp;&amp; args.length &gt; 0){
            try {
                port = Integer.valueOf(args[0]);
            } catch (NumberFormatException e) {
                e.printStackTrace();
            }
        }

        new TimeApServer().bind(port);
    }
}

</code></pre>
<blockquote>
<p>TimeServerApHandler</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.book;

import io.netty.buffer.ByteBuf;
import io.netty.buffer.Unpooled;
import io.netty.channel.ChannelHandlerContext;
import io.netty.channel.ChannelInboundHandlerAdapter;

import java.util.Date;

/**
 * 粘包
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 10:41
 */
public class TimeServerApHandler extends ChannelInboundHandlerAdapter {

    private int counter;

    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception {
        String body = (String) msg;
        //每读到一条消息后就记一次数，然后发送消息给客户端
        //按照设计，服务端接收到的消息总数应该于客户端发送的消息总数相同
        System.out.println(&quot;The time server receive order :&quot; + body + &quot;; the counter is : &quot; + ++counter);

        String currentTime = &quot;QUERY TIME ORDER&quot;.equalsIgnoreCase(body) ? new Date(System.currentTimeMillis()).toString() : &quot;BAD ORDER&quot;;

        currentTime = currentTime + System.getProperty(&quot;line.separator&quot;);
        ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes());

        //为了效率，write并不直接将消息写入到SocketChannel中，调用write方法只是把待发送的消息
        //放到发送缓冲数组中，再调用flush发送
        ctx.write(resp);
        System.out.println(&quot;写入完成&quot;);
    }

    @Override
    public void channelReadComplete(ChannelHandlerContext ctx){
        //将消息发送队列中的消息写到SocketChannel中发送给对方
        ctx.flush();
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause){
        ctx.close();
    }
}

</code></pre>
<h4 id="432-支持tcp粘包的tcpclient">4.3.2 支持TCP粘包的TcpClient</h4>
<blockquote>
<p>TimeApClient</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.book;

import io.netty.bootstrap.Bootstrap;
import io.netty.channel.ChannelFuture;
import io.netty.channel.ChannelInitializer;
import io.netty.channel.ChannelOption;
import io.netty.channel.EventLoopGroup;
import io.netty.channel.nio.NioEventLoopGroup;
import io.netty.channel.socket.SocketChannel;
import io.netty.channel.socket.nio.NioSocketChannel;
import io.netty.handler.codec.LineBasedFrameDecoder;
import io.netty.handler.codec.string.StringDecoder;

/**
 * 粘包客户端
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 11:06
 */
public class TimeApClient {

    public void connect(int port ,String host) throws Exception {

        //配置nio线程组
        EventLoopGroup group = new NioEventLoopGroup();

        try{
            Bootstrap b = new Bootstrap();
            b.group(group).channel(NioSocketChannel.class)
                    .option(ChannelOption.TCP_NODELAY, true)
                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel socketChannel) throws Exception {
                            socketChannel.pipeline().addLast(new LineBasedFrameDecoder(1024));
                            socketChannel.pipeline().addLast(new StringDecoder());
                            socketChannel.pipeline().addLast(new TimeClientApHandler());
                        }
                    });

            //发起异步连接操作
            ChannelFuture f = b.connect(host, port).sync();
            //等待客户端链路关闭
            f.channel().closeFuture().sync();
            //优雅退出，释放NIO线程组
        }finally {
            group.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        int port = 8080;

        if(args != null &amp;&amp; args.length &gt; 0){
            try {
                port = Integer.valueOf(args[0]);
            } catch (NumberFormatException e) {
                e.printStackTrace();
            }
        }

        new TimeApClient().connect(port,&quot;127.0.0.1&quot;);
    }
}

</code></pre>
<blockquote>
<p>TimeClientApHandler</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.book;

import io.netty.buffer.ByteBuf;
import io.netty.buffer.Unpooled;
import io.netty.channel.ChannelHandlerContext;
import io.netty.channel.ChannelInboundHandlerAdapter;


/**
 * 客户端粘包
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 11:09
 */
public class TimeClientApHandler extends ChannelInboundHandlerAdapter {

//    private final ByteBuf firstMessage;
    private int counter;
    private byte[] req;

    public TimeClientApHandler() {
       req = ( &quot;QUERY TIME ORDER&quot; + System.getProperty(&quot;line.separator&quot;) ).getBytes();
//        firstMessage = Unpooled.buffer(req.length);
//        firstMessage.writeBytes(req);
    }

    @Override
    public void channelActive(ChannelHandlerContext ctx){
        ByteBuf message = null;
        for (int i = 0; i &lt; 100; i++) {
            message = Unpooled.buffer(req.length);
            message.writeBytes(req);
            ctx.writeAndFlush(message);
        }
    }

    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception{
        String body = (String) msg;
        System.out.println(&quot;Now is :&quot; + body + &quot;; the counter is :&quot; + ++counter);

    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause){
        System.out.println(&quot;释放资源&quot;);
        ctx.close();
    }
}

</code></pre>
<h4 id="433-运行">4.3.3 运行</h4>
<blockquote>
<p>服务端</p>
</blockquote>
<pre><code class="language-java">The time server receive order :QUERY TIME ORDER; the counter is : 100
写入完成
</code></pre>
<blockquote>
<p>客户端</p>
</blockquote>
<pre><code class="language-java">Now is :Mon Oct 17 15:41:57 CST 2022; the counter is :98
Now is :Mon Oct 17 15:41:57 CST 2022; the counter is :99
Now is :Mon Oct 17 15:41:57 CST 2022; the counter is :100
</code></pre>
<h4 id="434-linebasedframedecoder-和-stringdecoder原理分析">4.3.4 LineBasedFrameDecoder 和 StringDecoder原理分析</h4>
<p>LineBasedFrameDecoder的工作原理是它一次遍历ByteBuf的可读字节，判断看是否有\n或者\r\n，如果有就以次位置为结束位置，从可读索引到结束位置区间的字节就组成了一行。</p>
<p>它是以换行符为结束标志的解码器，支持携带结束符或者不携带结束符2种解码方式，同时支持配置但行最大长度。如果连续读取到最大长度后仍然没有出现换行符，就会抛出异常。</p>
<p>StringDecoder的功能非常简单，就是将接收到到对象转换成字符串，然后继续调用后续到Handler。</p>
<h2 id="5-分隔符和定长解码器到应用">5 分隔符和定长解码器到应用</h2>
<p>TCP以流的方式进行数据传输，上层的应用协议为了对消息进行区分，一般采用如下方式：</p>
<ol>
<li>消息长度固定，累计读取到长度总和为定长LEN的报文后，就认为读取到了一个完整到消息，然后将计数器置位，重新开始读取下一个数据报。</li>
<li>将回车换行符作为消息结束符</li>
<li>将特殊到分隔符作为消息到结束标志</li>
<li>通过在消息头中定义长度字段来表示消息到总长度</li>
</ol>
<p>Netty对上面4种做了统一抽象，提供了4种解码器来解决对应对问题。上述使用LineBasedFrameDecoder 就是其中之一，还有<strong>DelimiterBasedFrameDecoder</strong>用于自动完成以分隔符做结束标志对解码，<strong>FixedLengthFrameDecoder</strong>用于自动完成对定长消息对解码。</p>
<h3 id="51-delimiterbasedframedecoder应用开发">5.1 DelimiterBasedFrameDecoder应用开发</h3>
<p>🏠例子：本例将以$_作为分隔符</p>
<h4 id="511-delimiterbasedframedecoder服务端开发">5.1.1 DelimiterBasedFrameDecoder服务端开发</h4>
<blockquote>
<p>EchoServer</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.echo;

import io.netty.bootstrap.ServerBootstrap;
import io.netty.buffer.ByteBuf;
import io.netty.buffer.Unpooled;
import io.netty.channel.*;
import io.netty.channel.nio.NioEventLoopGroup;
import io.netty.channel.socket.SocketChannel;
import io.netty.channel.socket.nio.NioServerSocketChannel;
import io.netty.handler.codec.DelimiterBasedFrameDecoder;
import io.netty.handler.codec.string.StringDecoder;

/**
 * ECHO服务端
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 10:21
 */
public class EchoServer {

    public void bind(int port){
        //配置服务端nio线程组,处理网络事件
        EventLoopGroup boosGroup = new NioEventLoopGroup();//用于服务端接受客户端连接
        EventLoopGroup workerGroup = new NioEventLoopGroup();//用于进行SocketChannel网络读写

        try {
            ServerBootstrap b = new ServerBootstrap();
            b.group(boosGroup, workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .option(ChannelOption.SO_BACKLOG, 1024)
                    .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel channel) throws Exception {
                            ByteBuf delimiter = Unpooled.copiedBuffer(&quot;$_&quot;.getBytes());
                            //单体消息最大长度1024，当达到该长度后仍然没有查找到分隔符就抛出异常
                            channel.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, delimiter));
                            channel.pipeline().addLast(new StringDecoder());//将ByteBuf解码成字符串对象
                            channel.pipeline().addLast(new EchoServerHandler());//接收消息
                        }
                    });

            //绑定端口，同步等待成功
            ChannelFuture f = b.bind(port).sync();
            //等待服务端监听端口关闭
            f.channel().closeFuture().sync();
            //退出
        } catch (InterruptedException e) {
            e.printStackTrace();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) {
        int port = 8080;

        if(args != null &amp;&amp; args.length &gt; 0){
            try {
                port = Integer.valueOf(args[0]);
            } catch (NumberFormatException e) {
                e.printStackTrace();
            }
        }

        new EchoServer().bind(port);
    }
}

</code></pre>
<blockquote>
<p>EchoServerHandler</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.echo;

import io.netty.buffer.ByteBuf;
import io.netty.buffer.Unpooled;
import io.netty.channel.ChannelHandlerContext;
import io.netty.channel.ChannelInboundHandlerAdapter;

import java.util.Date;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 10:41
 */
public class EchoServerHandler extends ChannelInboundHandlerAdapter {
    private int counter = 0;

    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception {
        String body = (String) msg;
        System.out.println(&quot;This is&quot; + ++counter + &quot;The time server receive client :&quot; + body);

        body += &quot;$_&quot;;
        ByteBuf echo = Unpooled.copiedBuffer(body.getBytes());
        ctx.write(echo);
    }

    @Override
    public void channelReadComplete(ChannelHandlerContext ctx){
        ctx.flush();
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause){
        ctx.close();
    }
}

</code></pre>
<h4 id="512-delimiterbasedframedecoder客户端开发">5.1.2 DelimiterBasedFrameDecoder客户端开发</h4>
<blockquote>
<p>EchoClient</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.echo;

import io.netty.bootstrap.Bootstrap;
import io.netty.buffer.ByteBuf;
import io.netty.buffer.Unpooled;
import io.netty.channel.ChannelFuture;
import io.netty.channel.ChannelInitializer;
import io.netty.channel.ChannelOption;
import io.netty.channel.EventLoopGroup;
import io.netty.channel.nio.NioEventLoopGroup;
import io.netty.channel.socket.SocketChannel;
import io.netty.channel.socket.nio.NioSocketChannel;
import io.netty.handler.codec.DelimiterBasedFrameDecoder;
import io.netty.handler.codec.string.StringDecoder;

/**
 * ECHO客户端
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 11:06
 */
public class EchoClient {

    public void connect(int port ,String host) throws Exception {

        //配置nio线程组
        EventLoopGroup group = new NioEventLoopGroup();

        try{
            Bootstrap b = new Bootstrap();
            b.group(group).channel(NioSocketChannel.class)
                    .option(ChannelOption.TCP_NODELAY, true)
                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel socketChannel) throws Exception {
                            ByteBuf delimiter = Unpooled.copiedBuffer(&quot;$_&quot;.getBytes());
                            //单体消息最大长度1024，当达到该长度后仍然没有查找到分隔符就抛出异常
                            socketChannel.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, delimiter));
                            socketChannel.pipeline().addLast(new StringDecoder());//将ByteBuf解码成字符串对象
                            socketChannel.pipeline().addLast(new EchoClientHandler());//接收消息
                        }
                    });

            //发起异步连接操作
            ChannelFuture f = b.connect(host, port).sync();
            //等待客户端链路关闭
            f.channel().closeFuture().sync();
            //优雅退出，释放NIO线程组
        }finally {
            group.shutdownGracefully();
        }
    }

    public static void main(String[] args) throws Exception {
        int port = 8080;

        if(args != null &amp;&amp; args.length &gt; 0){
            try {
                port = Integer.valueOf(args[0]);
            } catch (NumberFormatException e) {
                e.printStackTrace();
            }
        }

        new EchoClient().connect(port,&quot;127.0.0.1&quot;);
    }
}
</code></pre>
<blockquote>
<p>EchoClientHandler</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.echo;

import io.netty.buffer.Unpooled;
import io.netty.channel.ChannelHandlerContext;
import io.netty.channel.ChannelInboundHandlerAdapter;


/**
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 11:09
 */
public class EchoClientHandler extends ChannelInboundHandlerAdapter {

    private int counter;
    static final String ECHO_REQ = &quot;Hi LIKECAT,Welcome to my home.$_&quot;;

    public EchoClientHandler() {
    }

    @Override
    public void channelActive(ChannelHandlerContext ctx){
        for (int i = 0; i &lt; 10; i++) {
            ctx.writeAndFlush(Unpooled.copiedBuffer(ECHO_REQ.getBytes()));
        }
    }

    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg){
        System.out.println(&quot;This is&quot; + ++counter + &quot;The times  receive server : [&quot; + msg + &quot;]&quot;);

    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause){
        ctx.close();
    }

    @Override
    public void channelReadComplete(ChannelHandlerContext ctx){
        ctx.flush();
    }
}
</code></pre>
<h4 id="513-delimiterbasedframedecoder运行">5.1.3 DelimiterBasedFrameDecoder运行</h4>
<blockquote>
<p>执行结果</p>
</blockquote>
<pre><code class="language-java">This is1The time server receive client :Hi LIKECAT,Welcome to my home.
This is2The time server receive client :Hi LIKECAT,Welcome to my home.
This is3The time server receive client :Hi LIKECAT,Welcome to my home.
This is4The time server receive client :Hi LIKECAT,Welcome to my home.
This is5The time server receive client :Hi LIKECAT,Welcome to my home.
This is6The time server receive client :Hi LIKECAT,Welcome to my home.
This is7The time server receive client :Hi LIKECAT,Welcome to my home.
This is8The time server receive client :Hi LIKECAT,Welcome to my home.
This is9The time server receive client :Hi LIKECAT,Welcome to my home.
This is10The time server receive client :Hi LIKECAT,Welcome to my home.

</code></pre>
<p>如果没有使用DelimiterBasedFrameDecoder则会出现下面的情况，因为服务端一次读取了客户端发送的所有消息，导致TCP粘包拆包问题的出现。</p>
<blockquote>
<p>执行结果</p>
</blockquote>
<pre><code class="language-java">This is1The time server receive client :Hi LIKECAT,Welcome to my home.$_Hi LIKECAT,Welcome to my home.$_Hi LIKECAT,Welcome to my home.$_Hi LIKECAT,Welcome to my home.$_Hi LIKECAT,Welcome to my home.$_Hi LIKECAT,Welcome to my home.$_Hi LIKECAT,Welcome to my home.$_Hi LIKECAT,Welcome to my home.$_Hi LIKECAT,Welcome to my home.$_Hi LIKECAT,Welcome to my home.$_
</code></pre>
<h3 id="52-fixedlengthframedecoder应用开发">5.2 FixedLengthFrameDecoder应用开发</h3>
<p>FixedLengthFrameDecoder是固定长度解码器。无论一次接收到多少数据包，它都会按照构造函数中设置都固定长度进行解码，如果是半包消息，则会缓存半包消息并等待下个包到达后进行拼包，知道读取一个完整的包。</p>
<h4 id="521-fixedlengthframedecoder服务端开发">5.2.1 FixedLengthFrameDecoder服务端开发</h4>
<p>在服务端中新增FixedLengthFrameDecoder，长度设置为20。</p>
<blockquote>
<p>FixedServer</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.fixed;

import io.netty.bootstrap.ServerBootstrap;
import io.netty.channel.ChannelFuture;
import io.netty.channel.ChannelInitializer;
import io.netty.channel.ChannelOption;
import io.netty.channel.EventLoopGroup;
import io.netty.channel.nio.NioEventLoopGroup;
import io.netty.channel.socket.SocketChannel;
import io.netty.channel.socket.nio.NioServerSocketChannel;
import io.netty.handler.codec.FixedLengthFrameDecoder;
import io.netty.handler.codec.string.StringDecoder;

/**
 * 定长解码服务端
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 10:21
 */
public class FixedServer {

    public void bind(int port){
        //配置服务端nio线程组,处理网络事件
        EventLoopGroup boosGroup = new NioEventLoopGroup();//用于服务端接受客户端连接
        EventLoopGroup workerGroup = new NioEventLoopGroup();//用于进行SocketChannel网络读写

        try {
            ServerBootstrap b = new ServerBootstrap();
            b.group(boosGroup, workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .option(ChannelOption.SO_BACKLOG, 100)
                    .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel channel) throws Exception {
                            channel.pipeline().addLast(new FixedLengthFrameDecoder(20));
                            channel.pipeline().addLast(new StringDecoder());//将ByteBuf解码成字符串对象
                            channel.pipeline().addLast(new FixedServerHandler());//接收消息
                        }
                    });

            //绑定端口，同步等待成功
            ChannelFuture f = b.bind(port).sync();
            //等待服务端监听端口关闭
            f.channel().closeFuture().sync();
            //退出
        } catch (InterruptedException e) {
            e.printStackTrace();
        }finally {
            boosGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }

    public static void main(String[] args) {
        int port = 8080;

        if(args != null &amp;&amp; args.length &gt; 0){
            try {
                port = Integer.valueOf(args[0]);
            } catch (NumberFormatException e) {
                e.printStackTrace();
            }
        }

        new FixedServer().bind(port);
    }
}
</code></pre>
<blockquote>
<p>FixedServerHandler</p>
</blockquote>
<pre><code class="language-java">package com.likecat.netty.fixed;

import io.netty.channel.ChannelHandlerContext;
import io.netty.channel.ChannelInboundHandlerAdapter;

/**
 * @author likecat
 * @version 1.0
 * @date 2022/10/17 10:41
 */
public class FixedServerHandler extends ChannelInboundHandlerAdapter {

    @Override
    public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception {
//        String body = (String) msg;
        System.out.println(&quot;The receive client :&quot; + msg);
    }

    @Override
    public void channelReadComplete(ChannelHandlerContext ctx){
        ctx.flush();
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause){
        ctx.close();
    }
}
</code></pre>
<h4 id="522-fixedlengthframedecoder运行">5.2.2 FixedLengthFrameDecoder运行</h4>
<p>这次我们通过命令的形式运行，执行下面命令，即可于服务端通信：</p>
<pre><code class="language-mysql">telnet localhost 8080
</code></pre>
]]></content>
    </entry>
</feed>